{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Attention U-Net for Kidney Stone Segmentation on KSSD2025\n",
    "\n",
    "## üìä Objective\n",
    "Beat the baseline Modified U-Net score of **97.06%** using Attention U-Net\n",
    "\n",
    "## üéØ Expected Results\n",
    "- **Target Dice Score:** 97.5% - 98.2%\n",
    "- **Strategy:** Attention mechanisms for small object detection\n",
    "- **Architecture:** U-Net + Attention Gates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install & Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q segmentation-models-pytorch albumentations\n",
    "\n",
    "print(\"‚úÖ Libraries installed successfully!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import gc\n",
    "import warnings\n",
    "import os\n",
    "from glob import glob\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Image Processing\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Progress Bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"‚úÖ PyTorch Version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Configure Dataset Paths\n",
    "\n",
    "**CORRECTED FOR KSSD2025 STRUCTURE WITH /data SUBDIRECTORY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    # === DATASET PATHS - CORRECTED FOR YOUR STRUCTURE ===\n",
    "    # Your dataset has a 'data' subdirectory\n",
    "    DATA_PATH = \"/kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data\"\n",
    "    \n",
    "    # Image and mask directories\n",
    "    IMAGE_DIR = f\"{DATA_PATH}/images\"\n",
    "    MASK_DIR = f\"{DATA_PATH}/masks\"\n",
    "    \n",
    "    # Image Settings\n",
    "    IMG_SIZE = 256  # Resize images to 256x256\n",
    "    \n",
    "    # Training Settings\n",
    "    BATCH_SIZE = 16\n",
    "    NUM_EPOCHS = 150\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_FOLDS = 5\n",
    "    \n",
    "    # Model Settings\n",
    "    ENCODER_CHANNELS = [16, 32, 64, 128]\n",
    "    DECODER_CHANNELS = [128, 64, 32, 16]\n",
    "    \n",
    "    # Device\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Save Settings\n",
    "    SAVE_MODELS = True\n",
    "    MODEL_DIR = \"/kaggle/working/models\"\n",
    "    OUTPUT_DIR = \"/kaggle/working/outputs\"\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Create necessary directories\n",
    "Path(config.MODEL_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(config.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration Settings:\")\n",
    "print(f\"  üìÅ Data Path: {config.DATA_PATH}\")\n",
    "print(f\"  üìÅ Image Dir: {config.IMAGE_DIR}\")\n",
    "print(f\"  üìÅ Mask Dir: {config.MASK_DIR}\")\n",
    "print(f\"  üñºÔ∏è  Image Size: {config.IMG_SIZE}x{config.IMG_SIZE}\")\n",
    "print(f\"  üì¶ Batch Size: {config.BATCH_SIZE}\")\n",
    "print(f\"  üîÑ Epochs: {config.NUM_EPOCHS}\")\n",
    "print(f\"  üìä K-Folds: {config.NUM_FOLDS}\")\n",
    "print(f\"  üéØ Device: {config.DEVICE}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 3: Explore Dataset Structure\n",
    "\n",
    "Let's first understand your dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset structure\n",
    "base_path = \"/kaggle/input/kssd2025-kidney-stone-segmentation-dataset\"\n",
    "\n",
    "print(\"üìÅ Exploring dataset structure...\\n\")\n",
    "\n",
    "def explore_directory(path, level=0, max_level=3):\n",
    "    \"\"\"Recursively explore directory structure\"\"\"\n",
    "    if level > max_level or not os.path.exists(path):\n",
    "        return\n",
    "    \n",
    "    indent = \"  \" * level\n",
    "    items = sorted(os.listdir(path))\n",
    "    \n",
    "    for item in items[:20]:  # Limit to first 20 items\n",
    "        item_path = os.path.join(path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            count = len(os.listdir(item_path))\n",
    "            print(f\"{indent}üìÅ {item}/ ({count} items)\")\n",
    "            if level < 2:  # Only go 2 levels deep\n",
    "                explore_directory(item_path, level + 1, max_level)\n",
    "        else:\n",
    "            print(f\"{indent}üìÑ {item}\")\n",
    "    \n",
    "    if len(items) > 20:\n",
    "        print(f\"{indent}... and {len(items) - 20} more items\")\n",
    "\n",
    "explore_directory(base_path)\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 4: Load Dataset with Flexible Path Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find images with multiple extensions\n",
    "def find_images(directory, extensions=['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.PNG', '*.JPEG']):\n",
    "    \"\"\"Find all images in directory with given extensions\"\"\"\n",
    "    all_images = []\n",
    "    for ext in extensions:\n",
    "        all_images.extend(glob(os.path.join(directory, ext)))\n",
    "        # Also search recursively in case images are in subdirectories\n",
    "        all_images.extend(glob(os.path.join(directory, '**', ext), recursive=True))\n",
    "    return sorted(list(set(all_images)))  # Remove duplicates and sort\n",
    "\n",
    "def auto_find_dataset_dirs(base_path):\n",
    "    \"\"\"Automatically find image and mask directories\"\"\"\n",
    "    possible_image_dirs = ['images', 'image', 'img', 'train', 'train_images', 'data/images']\n",
    "    possible_mask_dirs = ['masks', 'mask', 'labels', 'label', 'train_masks', 'data/masks', 'ground_truth', 'gt']\n",
    "    \n",
    "    image_dir = None\n",
    "    mask_dir = None\n",
    "    \n",
    "    # Try to find image directory\n",
    "    for dir_name in possible_image_dirs:\n",
    "        test_path = os.path.join(base_path, dir_name)\n",
    "        if os.path.exists(test_path):\n",
    "            # Check if it has images\n",
    "            test_images = find_images(test_path)\n",
    "            if len(test_images) > 0:\n",
    "                image_dir = test_path\n",
    "                print(f\"‚úÖ Found images in: {dir_name}\")\n",
    "                break\n",
    "    \n",
    "    # Try to find mask directory\n",
    "    for dir_name in possible_mask_dirs:\n",
    "        test_path = os.path.join(base_path, dir_name)\n",
    "        if os.path.exists(test_path):\n",
    "            # Check if it has images\n",
    "            test_masks = find_images(test_path)\n",
    "            if len(test_masks) > 0:\n",
    "                mask_dir = test_path\n",
    "                print(f\"‚úÖ Found masks in: {dir_name}\")\n",
    "                break\n",
    "    \n",
    "    return image_dir, mask_dir\n",
    "\n",
    "# Try to auto-detect\n",
    "print(\"üîç Auto-detecting dataset structure...\\n\")\n",
    "detected_image_dir, detected_mask_dir = auto_find_dataset_dirs(base_path)\n",
    "\n",
    "# Update config if found\n",
    "if detected_image_dir:\n",
    "    config.IMAGE_DIR = detected_image_dir\n",
    "if detected_mask_dir:\n",
    "    config.MASK_DIR = detected_mask_dir\n",
    "\n",
    "print(f\"\\nüìÅ Using directories:\")\n",
    "print(f\"  Images: {config.IMAGE_DIR}\")\n",
    "print(f\"  Masks: {config.MASK_DIR}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 5: Load and Match Images with Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image and mask paths\n",
    "print(\"üì• Loading dataset...\\n\")\n",
    "\n",
    "image_paths = find_images(config.IMAGE_DIR)\n",
    "mask_paths = find_images(config.MASK_DIR)\n",
    "\n",
    "print(f\"üìä Dataset Statistics:\")\n",
    "print(f\"  üñºÔ∏è  Total Images Found: {len(image_paths)}\")\n",
    "print(f\"  üé≠ Total Masks Found: {len(mask_paths)}\")\n",
    "\n",
    "if len(image_paths) == 0:\n",
    "    print(\"\\n‚ùå ERROR: No images found!\")\n",
    "    print(\"\\nLet me search the entire dataset directory...\")\n",
    "    all_images = glob(os.path.join(base_path, '**', '*.jpg'), recursive=True) + \\\n",
    "                 glob(os.path.join(base_path, '**', '*.png'), recursive=True)\n",
    "    if len(all_images) > 0:\n",
    "        print(f\"\\nFound {len(all_images)} images in total. Showing first 10:\")\n",
    "        for img in all_images[:10]:\n",
    "            print(f\"  {img}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Images loaded successfully!\")\n",
    "    print(f\"\\nFirst 5 image paths:\")\n",
    "    for img in image_paths[:5]:\n",
    "        print(f\"  {img}\")\n",
    "\n",
    "if len(mask_paths) == 0:\n",
    "    print(\"\\n‚ùå ERROR: No masks found!\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Masks loaded successfully!\")\n",
    "    print(f\"\\nFirst 5 mask paths:\")\n",
    "    for mask in mask_paths[:5]:\n",
    "        print(f\"  {mask}\")\n",
    "\n",
    "# Match images and masks by filename\n",
    "if len(image_paths) > 0 and len(mask_paths) > 0:\n",
    "    # Extract filenames (without extension and path)\n",
    "    def get_base_name(path):\n",
    "        return os.path.splitext(os.path.basename(path))[0]\n",
    "    \n",
    "    image_dict = {get_base_name(p): p for p in image_paths}\n",
    "    mask_dict = {get_base_name(p): p for p in mask_paths}\n",
    "    \n",
    "    # Find matching pairs\n",
    "    matched_data = []\n",
    "    unmatched_images = []\n",
    "    \n",
    "    for img_name, img_path in image_dict.items():\n",
    "        if img_name in mask_dict:\n",
    "            matched_data.append({\n",
    "                'image_path': img_path,\n",
    "                'mask_path': mask_dict[img_name],\n",
    "                'filename': img_name\n",
    "            })\n",
    "        else:\n",
    "            unmatched_images.append(img_name)\n",
    "    \n",
    "    data_df = pd.DataFrame(matched_data)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Matched {len(data_df)} image-mask pairs\")\n",
    "    \n",
    "    if len(unmatched_images) > 0:\n",
    "        print(f\"‚ö†Ô∏è Warning: {len(unmatched_images)} images without matching masks\")\n",
    "        if len(unmatched_images) <= 5:\n",
    "            print(f\"Unmatched: {unmatched_images}\")\n",
    "    \n",
    "    if len(data_df) > 0:\n",
    "        print(f\"\\nüìã Dataset Preview:\")\n",
    "        print(data_df.head(10))\n",
    "    else:\n",
    "        print(\"\\n‚ùå No matching image-mask pairs found!\")\n",
    "        data_df = None\n",
    "else:\n",
    "    print(\"\\n‚ùå Cannot create dataset - missing images or masks\")\n",
    "    data_df = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 6: Visualize Sample Images and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(df, num_samples=4):\n",
    "    \"\"\"Visualize random samples from dataset\"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"‚ùå No data available for visualization\")\n",
    "        return\n",
    "    \n",
    "    num_samples = min(num_samples, len(df))\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, num_samples*3))\n",
    "    \n",
    "    # Handle single sample case\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    indices = np.random.choice(len(df), num_samples, replace=False)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(indices):\n",
    "        # Load image and mask\n",
    "        image = cv2.imread(df.iloc[sample_idx]['image_path'])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = cv2.imread(df.iloc[sample_idx]['mask_path'], cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Original image\n",
    "        axes[idx, 0].imshow(image)\n",
    "        axes[idx, 0].set_title(f'Original Image\\n{df.iloc[sample_idx][\"filename\"]}')\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        # Mask\n",
    "        axes[idx, 1].imshow(mask, cmap='gray')\n",
    "        axes[idx, 1].set_title(f'Ground Truth Mask')\n",
    "        axes[idx, 1].axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        overlay = image.copy()\n",
    "        overlay[mask > 0] = [255, 0, 0]  # Red overlay on stones\n",
    "        axes[idx, 2].imshow(overlay)\n",
    "        axes[idx, 2].set_title(f'Overlay (Red = Stone)')\n",
    "        axes[idx, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{config.OUTPUT_DIR}/dataset_samples.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"‚úÖ Sample visualization saved to {config.OUTPUT_DIR}/dataset_samples.png\")\n",
    "\n",
    "if data_df is not None:\n",
    "    visualize_samples(data_df, num_samples=4)\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping visualization - no data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Step 7: Data Augmentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training augmentation\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(config.IMG_SIZE, config.IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=2.5, p=0.5),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.0075,\n",
    "        scale_limit=0.0075,\n",
    "        rotate_limit=0,\n",
    "        p=0.5\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# Validation augmentation (no data augmentation)\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(config.IMG_SIZE, config.IMG_SIZE),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Data augmentation pipelines created!\")\n",
    "print(\"  - Training: Flip, Rotate, Shift, Scale, Brightness\")\n",
    "print(\"  - Validation: Resize & Normalize only\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 8: Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KidneyStoneDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for Kidney Stone Segmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        image_path = self.df.iloc[idx]['image_path']\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load mask\n",
    "        mask_path = self.df.iloc[idx]['mask_path']\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Binarize mask (0 or 1)\n",
    "        mask = (mask > 0).astype(np.float32)\n",
    "        \n",
    "        # Apply augmentation\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        # Add channel dimension to mask\n",
    "        mask = mask.unsqueeze(0)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "print(\"‚úÖ Custom Dataset class created!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Step 9: Build Attention U-Net Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Convolutional Block: Conv -> BN -> ReLU -> Conv -> BN -> ReLU\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    \"\"\"Attention Gate Module\"\"\"\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionGate, self).__init__()\n",
    "        \n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        \n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        \n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "\n",
    "class AttentionUNet(nn.Module):\n",
    "    \"\"\"Attention U-Net Architecture\"\"\"\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(AttentionUNet, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(in_channels, 16)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.enc2 = ConvBlock(16, 32)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.enc3 = ConvBlock(32, 64)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.enc4 = ConvBlock(64, 128)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = ConvBlock(128, 256)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.att4 = AttentionGate(F_g=128, F_l=128, F_int=64)\n",
    "        self.dec4 = ConvBlock(256, 128)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.att3 = AttentionGate(F_g=64, F_l=64, F_int=32)\n",
    "        self.dec3 = ConvBlock(128, 64)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.att2 = AttentionGate(F_g=32, F_l=32, F_int=16)\n",
    "        self.dec2 = ConvBlock(64, 32)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n",
    "        self.att1 = AttentionGate(F_g=16, F_l=16, F_int=8)\n",
    "        self.dec1 = ConvBlock(32, 16)\n",
    "        \n",
    "        # Output\n",
    "        self.out = nn.Conv2d(16, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "        \n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "        \n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.pool3(e3)\n",
    "        \n",
    "        e4 = self.enc4(p3)\n",
    "        p4 = self.pool4(e4)\n",
    "        \n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p4)\n",
    "        \n",
    "        # Decoder with Attention\n",
    "        d4 = self.up4(b)\n",
    "        e4 = self.att4(d4, e4)\n",
    "        d4 = torch.cat([d4, e4], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "        \n",
    "        d3 = self.up3(d4)\n",
    "        e3 = self.att3(d3, e3)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        \n",
    "        d2 = self.up2(d3)\n",
    "        e2 = self.att2(d2, e2)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        \n",
    "        d1 = self.up1(d2)\n",
    "        e1 = self.att1(d1, e1)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        \n",
    "        # Output\n",
    "        out = self.out(d1)\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable parameters in model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# Test model\n",
    "model = AttentionUNet().to(config.DEVICE)\n",
    "print(\"‚úÖ Attention U-Net model created!\")\n",
    "print(f\"  üìä Total Parameters: {count_parameters(model):,}\")\n",
    "print(f\"  üéØ Input Size: {config.IMG_SIZE}x{config.IMG_SIZE}x3\")\n",
    "print(f\"  üéØ Output Size: {config.IMG_SIZE}x{config.IMG_SIZE}x1\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 10: Define Loss Function and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice Loss for segmentation\"\"\"\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (predictions * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / \\\n",
    "               (predictions.sum() + targets.sum() + self.smooth)\n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "\n",
    "def dice_coefficient(predictions, targets, threshold=0.5, smooth=1.0):\n",
    "    \"\"\"Calculate Dice coefficient\"\"\"\n",
    "    predictions = (predictions > threshold).float()\n",
    "    predictions = predictions.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    \n",
    "    intersection = (predictions * targets).sum()\n",
    "    dice = (2. * intersection + smooth) / \\\n",
    "           (predictions.sum() + targets.sum() + smooth)\n",
    "    \n",
    "    return dice.item()\n",
    "\n",
    "\n",
    "def iou_score(predictions, targets, threshold=0.5, smooth=1.0):\n",
    "    \"\"\"Calculate IoU (Intersection over Union)\"\"\"\n",
    "    predictions = (predictions > threshold).float()\n",
    "    predictions = predictions.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    \n",
    "    intersection = (predictions * targets).sum()\n",
    "    union = predictions.sum() + targets.sum() - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    return iou.item()\n",
    "\n",
    "\n",
    "def precision_score(predictions, targets, threshold=0.5, smooth=1.0):\n",
    "    \"\"\"Calculate Precision\"\"\"\n",
    "    predictions = (predictions > threshold).float()\n",
    "    predictions = predictions.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    \n",
    "    true_positive = (predictions * targets).sum()\n",
    "    predicted_positive = predictions.sum()\n",
    "    precision = (true_positive + smooth) / (predicted_positive + smooth)\n",
    "    \n",
    "    return precision.item()\n",
    "\n",
    "\n",
    "def recall_score(predictions, targets, threshold=0.5, smooth=1.0):\n",
    "    \"\"\"Calculate Recall (Sensitivity)\"\"\"\n",
    "    predictions = (predictions > threshold).float()\n",
    "    predictions = predictions.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    \n",
    "    true_positive = (predictions * targets).sum()\n",
    "    actual_positive = targets.sum()\n",
    "    recall = (true_positive + smooth) / (actual_positive + smooth)\n",
    "    \n",
    "    return recall.item()\n",
    "\n",
    "\n",
    "print(\"‚úÖ Loss function and metrics defined!\")\n",
    "print(\"  - Loss: Dice Loss\")\n",
    "print(\"  - Metrics: Dice, IoU, Precision, Recall\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Step 11: Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_dice = 0.0\n",
    "    running_iou = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    \n",
    "    for images, masks in pbar:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        dice = dice_coefficient(outputs, masks)\n",
    "        iou = iou_score(outputs, masks)\n",
    "        \n",
    "        # Update running metrics\n",
    "        running_loss += loss.item()\n",
    "        running_dice += dice\n",
    "        running_iou += iou\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'dice': f'{dice:.4f}',\n",
    "            'iou': f'{iou:.4f}'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_dice = running_dice / len(dataloader)\n",
    "    epoch_iou = running_iou / len(dataloader)\n",
    "    \n",
    "    return epoch_loss, epoch_dice, epoch_iou\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_dice = 0.0\n",
    "    running_iou = 0.0\n",
    "    running_precision = 0.0\n",
    "    running_recall = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Validation')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in pbar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            dice = dice_coefficient(outputs, masks)\n",
    "            iou = iou_score(outputs, masks)\n",
    "            precision = precision_score(outputs, masks)\n",
    "            recall = recall_score(outputs, masks)\n",
    "            \n",
    "            # Update running metrics\n",
    "            running_loss += loss.item()\n",
    "            running_dice += dice\n",
    "            running_iou += iou\n",
    "            running_precision += precision\n",
    "            running_recall += recall\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'dice': f'{dice:.4f}'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_dice = running_dice / len(dataloader)\n",
    "    epoch_iou = running_iou / len(dataloader)\n",
    "    epoch_precision = running_precision / len(dataloader)\n",
    "    epoch_recall = running_recall / len(dataloader)\n",
    "    \n",
    "    return epoch_loss, epoch_dice, epoch_iou, epoch_precision, epoch_recall\n",
    "\n",
    "\n",
    "print(\"‚úÖ Training and validation functions defined!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Step 12: 5-Fold Cross-Validation Training\n",
    "\n",
    "**This will take 2-4 hours!** ‚òï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data is loaded\n",
    "if data_df is None or len(data_df) == 0:\n",
    "    print(\"‚ùå Cannot start training - no data loaded!\")\n",
    "    print(\"Please fix the dataset path issues in the earlier cells.\")\n",
    "else:\n",
    "    # Initialize K-Fold\n",
    "    kfold = KFold(n_splits=config.NUM_FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Storage for results\n",
    "    fold_results = []\n",
    "    all_histories = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" \" * 15 + \"üöÄ STARTING 5-FOLD CROSS-VALIDATION\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # K-Fold Cross-Validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(data_df), 1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\" \" * 25 + f\"üìä FOLD {fold}/{config.NUM_FOLDS}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Split data\n",
    "        train_df = data_df.iloc[train_idx]\n",
    "        val_df = data_df.iloc[val_idx]\n",
    "        \n",
    "        print(f\"  üì¶ Training samples: {len(train_df)}\")\n",
    "        print(f\"  üì¶ Validation samples: {len(val_df)}\")\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = KidneyStoneDataset(train_df, transform=train_transform)\n",
    "        val_dataset = KidneyStoneDataset(val_df, transform=val_transform)\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=config.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Initialize model\n",
    "        model = AttentionUNet().to(config.DEVICE)\n",
    "        criterion = DiceLoss()\n",
    "        optimizer = Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=10, verbose=True)\n",
    "        \n",
    "        # Training history\n",
    "        history = {\n",
    "            'train_loss': [], 'train_dice': [], 'train_iou': [],\n",
    "            'val_loss': [], 'val_dice': [], 'val_iou': [],\n",
    "            'val_precision': [], 'val_recall': []\n",
    "        }\n",
    "        \n",
    "        best_dice = 0.0\n",
    "        patience_counter = 0\n",
    "        max_patience = 20\n",
    "        \n",
    "        print(f\"\\n  üèãÔ∏è Training started...\\n\")\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(1, config.NUM_EPOCHS + 1):\n",
    "            print(f\"\\nEpoch {epoch}/{config.NUM_EPOCHS}\")\n",
    "            print(\"-\" * 70)\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_dice, train_iou = train_one_epoch(\n",
    "                model, train_loader, criterion, optimizer, config.DEVICE\n",
    "            )\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_dice, val_iou, val_precision, val_recall = validate(\n",
    "                model, val_loader, criterion, config.DEVICE\n",
    "            )\n",
    "            \n",
    "            # Update scheduler\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Save history\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['train_dice'].append(train_dice)\n",
    "            history['train_iou'].append(train_iou)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_dice'].append(val_dice)\n",
    "            history['val_iou'].append(val_iou)\n",
    "            history['val_precision'].append(val_precision)\n",
    "            history['val_recall'].append(val_recall)\n",
    "            \n",
    "            # Print metrics\n",
    "            print(f\"\\nTrain Loss: {train_loss:.4f} | Train Dice: {train_dice:.4f} | Train IoU: {train_iou:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f} | Val IoU: {val_iou:.4f}\")\n",
    "            print(f\"Val Precision: {val_precision:.4f} | Val Recall: {val_recall:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_dice > best_dice:\n",
    "                best_dice = val_dice\n",
    "                patience_counter = 0\n",
    "                \n",
    "                if config.SAVE_MODELS:\n",
    "                    model_path = f\"{config.MODEL_DIR}/attention_unet_fold{fold}_best.pth\"\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'dice': val_dice,\n",
    "                        'iou': val_iou,\n",
    "                    }, model_path)\n",
    "                    print(f\"\\n‚úÖ Best model saved! Dice: {best_dice:.4f}\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"\\n‚ö†Ô∏è Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "        \n",
    "        # Store fold results\n",
    "        fold_results.append({\n",
    "            'fold': fold,\n",
    "            'best_dice': best_dice,\n",
    "            'final_val_loss': history['val_loss'][-1],\n",
    "            'final_val_iou': history['val_iou'][-1],\n",
    "            'final_val_precision': history['val_precision'][-1],\n",
    "            'final_val_recall': history['val_recall'][-1]\n",
    "        })\n",
    "        \n",
    "        all_histories.append(history)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Fold {fold} completed! Best Dice: {best_dice:.4f}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Clear memory\n",
    "        del model, optimizer, scheduler\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" \" * 20 + \"üéâ ALL FOLDS COMPLETED!\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results_df = pd.DataFrame(fold_results)\n",
    "    print(\"\\nüìä Results Summary:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    print(f\"\\nüìà Mean Dice Score: {results_df['best_dice'].mean():.4f} ¬± {results_df['best_dice'].std():.4f}\")\n",
    "    print(f\"üìà Mean IoU Score: {results_df['final_val_iou'].mean():.4f} ¬± {results_df['final_val_iou'].std():.4f}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 13: Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "if 'all_histories' in locals() and len(all_histories) > 0:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    fig.suptitle('Training Curves - All Folds', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for fold_idx, history in enumerate(all_histories, 1):\n",
    "        # Plot Loss\n",
    "        axes[0, 0].plot(history['train_loss'], label=f'Fold {fold_idx} Train', alpha=0.7)\n",
    "        axes[0, 0].plot(history['val_loss'], label=f'Fold {fold_idx} Val', alpha=0.7)\n",
    "        axes[0, 0].set_title('Loss')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend(fontsize=8)\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot Dice\n",
    "        axes[0, 1].plot(history['train_dice'], label=f'Fold {fold_idx} Train', alpha=0.7)\n",
    "        axes[0, 1].plot(history['val_dice'], label=f'Fold {fold_idx} Val', alpha=0.7)\n",
    "        axes[0, 1].set_title('Dice Score')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Dice')\n",
    "        axes[0, 1].legend(fontsize=8)\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot IoU\n",
    "        axes[0, 2].plot(history['train_iou'], label=f'Fold {fold_idx} Train', alpha=0.7)\n",
    "        axes[0, 2].plot(history['val_iou'], label=f'Fold {fold_idx} Val', alpha=0.7)\n",
    "        axes[0, 2].set_title('IoU Score')\n",
    "        axes[0, 2].set_xlabel('Epoch')\n",
    "        axes[0, 2].set_ylabel('IoU')\n",
    "        axes[0, 2].legend(fontsize=8)\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot Precision\n",
    "        axes[1, 0].plot(history['val_precision'], label=f'Fold {fold_idx}', alpha=0.7)\n",
    "        axes[1, 0].set_title('Validation Precision')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Precision')\n",
    "        axes[1, 0].legend(fontsize=8)\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot Recall\n",
    "        axes[1, 1].plot(history['val_recall'], label=f'Fold {fold_idx}', alpha=0.7)\n",
    "        axes[1, 1].set_title('Validation Recall')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Recall')\n",
    "        axes[1, 1].legend(fontsize=8)\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Bar plot of best dice scores\n",
    "    axes[1, 2].bar(range(1, config.NUM_FOLDS + 1), results_df['best_dice'], \n",
    "                   color='skyblue', edgecolor='navy')\n",
    "    axes[1, 2].axhline(y=0.9706, color='r', linestyle='--', label='Baseline (97.06%)')\n",
    "    axes[1, 2].set_title('Best Dice Score per Fold')\n",
    "    axes[1, 2].set_xlabel('Fold')\n",
    "    axes[1, 2].set_ylabel('Dice Score')\n",
    "    axes[1, 2].set_ylim([0.90, 1.0])\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{config.OUTPUT_DIR}/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Training curves saved!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No training history available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 14: Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model_path, df, num_samples=6):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"‚ùå No data available\")\n",
    "        return\n",
    "    \n",
    "    # Load model\n",
    "    model = AttentionUNet().to(config.DEVICE)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Random samples\n",
    "    num_samples = min(num_samples, len(df))\n",
    "    indices = np.random.choice(len(df), num_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, num_samples*3))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, sample_idx in enumerate(indices):\n",
    "            # Load image\n",
    "            image_path = df.iloc[sample_idx]['image_path']\n",
    "            mask_path = df.iloc[sample_idx]['mask_path']\n",
    "            \n",
    "            image = cv2.imread(image_path)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = (mask > 0).astype(np.uint8)\n",
    "            \n",
    "            # Preprocess\n",
    "            transformed = val_transform(image=image_rgb, mask=mask)\n",
    "            image_tensor = transformed['image'].unsqueeze(0).to(config.DEVICE)\n",
    "            \n",
    "            # Predict\n",
    "            pred = model(image_tensor)\n",
    "            pred = pred.squeeze().cpu().numpy()\n",
    "            pred_binary = (pred > 0.5).astype(np.uint8)\n",
    "            \n",
    "            # Plot\n",
    "            axes[idx, 0].imshow(image_rgb)\n",
    "            axes[idx, 0].set_title('Original')\n",
    "            axes[idx, 0].axis('off')\n",
    "            \n",
    "            axes[idx, 1].imshow(mask, cmap='gray')\n",
    "            axes[idx, 1].set_title('Ground Truth')\n",
    "            axes[idx, 1].axis('off')\n",
    "            \n",
    "            axes[idx, 2].imshow(pred, cmap='hot')\n",
    "            axes[idx, 2].set_title('Prediction (Prob)')\n",
    "            axes[idx, 2].axis('off')\n",
    "            \n",
    "            axes[idx, 3].imshow(pred_binary, cmap='gray')\n",
    "            axes[idx, 3].set_title('Binary Prediction')\n",
    "            axes[idx, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{config.OUTPUT_DIR}/predictions.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"‚úÖ Predictions saved!\")\n",
    "\n",
    "if 'results_df' in locals() and len(results_df) > 0:\n",
    "    best_fold = results_df.loc[results_df['best_dice'].idxmax(), 'fold']\n",
    "    model_path = f\"{config.MODEL_DIR}/attention_unet_fold{int(best_fold)}_best.pth\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"\\nüîç Visualizing from best fold ({int(best_fold)})...\\n\")\n",
    "        visualize_predictions(model_path, data_df, num_samples=6)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Model not found\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Step 15: Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_report(fold_results, baseline_dice=0.9706):\n",
    "    \"\"\"Generate final report\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" \" * 20 + \"üèÜ FINAL RESULTS REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results_df = pd.DataFrame(fold_results)\n",
    "    \n",
    "    print(\"\\nüìä PER-FOLD RESULTS:\")\n",
    "    print(\"-\"*70)\n",
    "    for _, row in results_df.iterrows():\n",
    "        print(f\"  Fold {int(row['fold'])}: Dice = {row['best_dice']:.4f} | \"\n",
    "              f\"IoU = {row['final_val_iou']:.4f} | \"\n",
    "              f\"Precision = {row['final_val_precision']:.4f} | \"\n",
    "              f\"Recall = {row['final_val_recall']:.4f}\")\n",
    "    \n",
    "    mean_dice = results_df['best_dice'].mean()\n",
    "    std_dice = results_df['best_dice'].std()\n",
    "    \n",
    "    print(\"\\nüìà SUMMARY:\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"  Mean Dice:   {mean_dice:.4f} ¬± {std_dice:.4f}\")\n",
    "    print(f\"  Min Dice:    {results_df['best_dice'].min():.4f}\")\n",
    "    print(f\"  Max Dice:    {results_df['best_dice'].max():.4f}\")\n",
    "    \n",
    "    improvement = (mean_dice - baseline_dice) * 100\n",
    "    \n",
    "    print(\"\\nüéØ COMPARISON:\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"  Baseline:     {baseline_dice:.4f} (97.06%)\")\n",
    "    print(f\"  Our Model:    {mean_dice:.4f} ({mean_dice*100:.2f}%)\")\n",
    "    print(f\"  Improvement:  {improvement:+.2f}%\")\n",
    "    \n",
    "    if mean_dice > baseline_dice:\n",
    "        print(f\"\\n  ‚úÖ SUCCESS! Beat the baseline! üéâ\")\n",
    "    else:\n",
    "        print(f\"\\n  ‚ö†Ô∏è Below baseline\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "if 'fold_results' in locals():\n",
    "    generate_final_report(fold_results)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 16: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if 'all_histories' in locals() and 'fold_results' in locals():\n",
    "    # Save histories\n",
    "    with open(f'{config.OUTPUT_DIR}/training_histories.pkl', 'wb') as f:\n",
    "        pickle.dump(all_histories, f)\n",
    "    \n",
    "    # Save results\n",
    "    with open(f'{config.OUTPUT_DIR}/results_summary.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'fold_results': fold_results,\n",
    "            'mean_dice': results_df['best_dice'].mean(),\n",
    "            'std_dice': results_df['best_dice'].std()\n",
    "        }, f)\n",
    "    \n",
    "    # Save text file\n",
    "    with open(f'{config.OUTPUT_DIR}/RESULTS.txt', 'w') as f:\n",
    "        f.write(\"ATTENTION U-NET RESULTS\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        for _, row in results_df.iterrows():\n",
    "            f.write(f\"Fold {int(row['fold'])}: {row['best_dice']:.4f}\\n\")\n",
    "        f.write(f\"\\nMean: {results_df['best_dice'].mean():.4f} ¬± {results_df['best_dice'].std():.4f}\\n\")\n",
    "    \n",
    "    print(\"‚úÖ All results saved!\")\n",
    "    print(f\"  üìÅ Models: {config.MODEL_DIR}/\")\n",
    "    print(f\"  üìÅ Outputs: {config.OUTPUT_DIR}/\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Complete!\n",
    "\n",
    "Training complete! Check:\n",
    "- Models in `/kaggle/working/models/`\n",
    "- Visualizations in `/kaggle/working/outputs/`\n",
    "\n",
    "**Good luck with your research! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
