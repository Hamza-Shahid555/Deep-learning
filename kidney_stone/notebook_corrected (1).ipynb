{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11407583,
          "sourceType": "datasetVersion",
          "datasetId": 7145805
        }
      ],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "\"\"\"\n# \ud83c\udfaf Attention U-Net for Kidney Stone Segmentation on KSSD2025\n\n## \ud83d\udcca Objective\nBeat the baseline Modified U-Net score of **97.06%** using Attention U-Net\n\n## \ud83c\udfaf Expected Results\n- **Target Dice Score:** 97.5% - 98.2%\n- **Strategy:** Attention mechanisms for small object detection\n- **Architecture:** U-Net + Attention Gates\n\n## \ud83d\udccb Implementation Plan\n1. \u2705 Setup & Import Libraries\n2. \u2705 Load KSSD2025 Dataset\n3. \u2705 Data Preprocessing & Augmentation\n4. \u2705 Build Attention U-Net Architecture\n5. \u2705 Training with 5-Fold Cross-Validation\n6. \u2705 Evaluation & Visualization\n7. \u2705 Results Comparison",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## \ud83d\udce6 Step 1: Install & Import Required Libraries\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import sys\n!{sys.executable} -m pip install -q segmentation-models-pytorch albumentations\n\nprint(\"\u2705 Libraries installed successfully!\")\nprint(\"=\"*50)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-06T16:59:43.400784Z",
          "iopub.execute_input": "2026-02-06T16:59:43.401341Z",
          "iopub.status.idle": "2026-02-06T16:59:47.929693Z",
          "shell.execute_reply.started": "2026-02-06T16:59:43.401313Z",
          "shell.execute_reply": "2026-02-06T16:59:47.928853Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h\u2705 Libraries installed successfully!\n==================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "# Core Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport cv2\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Deep Learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n# Sklearn\nfrom sklearn.model_selection import KFold\n\n# Image Processing\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# Progress Bar\nfrom tqdm.auto import tqdm\n\n# Set random seeds for reproducibility\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\nprint(\"\u2705 All libraries imported successfully!\")\nprint(f\"\u2705 PyTorch Version: {torch.__version__}\")\nprint(f\"\u2705 CUDA Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"\u2705 CUDA Device: {torch.cuda.get_device_name(0)}\")\nprint(\"=\"*50)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-06T17:01:03.107252Z",
          "iopub.execute_input": "2026-02-06T17:01:03.107893Z",
          "iopub.status.idle": "2026-02-06T17:01:09.855921Z",
          "shell.execute_reply.started": "2026-02-06T17:01:03.107856Z",
          "shell.execute_reply": "2026-02-06T17:01:09.855252Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u2705 All libraries imported successfully!\n\u2705 PyTorch Version: 2.8.0+cu126\n\u2705 CUDA Available: True\n\u2705 CUDA Device: Tesla T4\n==================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "## \ud83d\udcc2 Step 2: Configure Dataset Paths\n\n**IMPORTANT:** ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Configuration\nclass Config:\n    # === DATASET PATHS - CORRECTED FOR YOUR STRUCTURE ===\n    # Your dataset has a 'data' subdirectory\n    DATA_PATH = \"/kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data\"\n    \n    # Image and mask directories\n    IMAGE_DIR = f\"{DATA_PATH}/image\"\n    MASK_DIR = f\"{DATA_PATH}/label\"\n    \n    # Image Settings\n    IMG_SIZE = 256  # Resize images to 256x256\n    \n    # Training Settings\n    BATCH_SIZE = 16\n    NUM_EPOCHS = 150\n    LEARNING_RATE = 0.001\n    NUM_FOLDS = 5\n    \n    # Model Settings\n    ENCODER_CHANNELS = [16, 32, 64, 128]\n    DECODER_CHANNELS = [128, 64, 32, 16]\n    \n    # Device\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Save Settings\n    SAVE_MODELS = True\n    MODEL_DIR = \"/kaggle/working/models\"\n    OUTPUT_DIR = \"/kaggle/working/outputs\"\n\nconfig = Config()\n\n# Create necessary directories\nPath(config.MODEL_DIR).mkdir(parents=True, exist_ok=True)\nPath(config.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n\nprint(\"\u2699\ufe0f Configuration Settings:\")\nprint(f\"  \ud83d\udcc1 Data Path: {config.DATA_PATH}\")\nprint(f\"  \ud83d\udcc1 Image Dir: {config.IMAGE_DIR}\")\nprint(f\"  \ud83d\udcc1 Mask Dir: {config.MASK_DIR}\")\nprint(f\"  \ud83d\uddbc\ufe0f  Image Size: {config.IMG_SIZE}x{config.IMG_SIZE}\")\nprint(f\"  \ud83d\udce6 Batch Size: {config.BATCH_SIZE}\")\nprint(f\"  \ud83d\udd04 Epochs: {config.NUM_EPOCHS}\")\nprint(f\"  \ud83d\udcca K-Folds: {config.NUM_FOLDS}\")\nprint(f\"  \ud83c\udfaf Device: {config.DEVICE}\")\nprint(\"=\"*50)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-06T17:43:20.407550Z",
          "iopub.execute_input": "2026-02-06T17:43:20.408360Z",
          "iopub.status.idle": "2026-02-06T17:43:20.415539Z",
          "shell.execute_reply.started": "2026-02-06T17:43:20.408328Z",
          "shell.execute_reply": "2026-02-06T17:43:20.414942Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u2699\ufe0f Configuration Settings:\n  \ud83d\udcc1 Data Path: /kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data\n  \ud83d\udcc1 Image Dir: /kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data/images\n  \ud83d\udcc1 Mask Dir: /kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data/masks\n  \ud83d\uddbc\ufe0f  Image Size: 256x256\n  \ud83d\udce6 Batch Size: 16\n  \ud83d\udd04 Epochs: 150\n  \ud83d\udcca K-Folds: 5\n  \ud83c\udfaf Device: cuda\n==================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": "## \ud83d\udd0d Step 3: Load and Explore Dataset",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Explore the dataset structure\nbase_path = \"/kaggle/input/kssd2025-kidney-stone-segmentation-dataset\"\n\nprint(\"\ud83d\udcc1 Exploring dataset structure...\\n\")\n\ndef explore_directory(path, level=0, max_level=3):\n    \"\"\"Recursively explore directory structure\"\"\"\n    if level > max_level or not os.path.exists(path):\n        return\n    \n    indent = \"  \" * level\n    items = sorted(os.listdir(path))\n    \n    for item in items[:20]:  # Limit to first 20 items\n        item_path = os.path.join(path, item)\n        if os.path.isdir(item_path):\n            count = len(os.listdir(item_path))\n            print(f\"{indent}\ud83d\udcc1 {item}/ ({count} items)\")\n            if level < 2:  # Only go 2 levels deep\n                explore_directory(item_path, level + 1, max_level)\n        else:\n            print(f\"{indent}\ud83d\udcc4 {item}\")\n    \n    if len(items) > 20:\n        print(f\"{indent}... and {len(items) - 20} more items\")\n\nexplore_directory(base_path)\nprint(\"\\n\" + \"=\"*50)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-06T17:43:51.538249Z",
          "iopub.execute_input": "2026-02-06T17:43:51.538557Z",
          "iopub.status.idle": "2026-02-06T17:43:51.664908Z",
          "shell.execute_reply.started": "2026-02-06T17:43:51.538529Z",
          "shell.execute_reply": "2026-02-06T17:43:51.664365Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\ud83d\udcc1 Exploring dataset structure...\n\n\ud83d\udcc1 data/ (2 items)\n  \ud83d\udcc1 image/ (838 items)\n    \ud83d\udcc4 1.tif\n    \ud83d\udcc4 10.tif\n    \ud83d\udcc4 1000.tif\n    \ud83d\udcc4 1001.tif\n    \ud83d\udcc4 1002.tif\n    \ud83d\udcc4 1003.tif\n    \ud83d\udcc4 1012.tif\n    \ud83d\udcc4 1013.tif\n    \ud83d\udcc4 1014.tif\n    \ud83d\udcc4 1015.tif\n    \ud83d\udcc4 1020.tif\n    \ud83d\udcc4 1021.tif\n    \ud83d\udcc4 1022.tif\n    \ud83d\udcc4 1023.tif\n    \ud83d\udcc4 1024.tif\n    \ud83d\udcc4 1025.tif\n    \ud83d\udcc4 1026.tif\n    \ud83d\udcc4 1027.tif\n    \ud83d\udcc4 1028.tif\n    \ud83d\udcc4 1029.tif\n    ... and 818 more items\n  \ud83d\udcc1 label/ (838 items)\n    \ud83d\udcc4 1.tif\n    \ud83d\udcc4 10.tif\n    \ud83d\udcc4 1000.tif\n    \ud83d\udcc4 1001.tif\n    \ud83d\udcc4 1002.tif\n    \ud83d\udcc4 1003.tif\n    \ud83d\udcc4 1012.tif\n    \ud83d\udcc4 1013.tif\n    \ud83d\udcc4 1014.tif\n    \ud83d\udcc4 1015.tif\n    \ud83d\udcc4 1020.tif\n    \ud83d\udcc4 1021.tif\n    \ud83d\udcc4 1022.tif\n    \ud83d\udcc4 1023.tif\n    \ud83d\udcc4 1024.tif\n    \ud83d\udcc4 1025.tif\n    \ud83d\udcc4 1026.tif\n    \ud83d\udcc4 1027.tif\n    \ud83d\udcc4 1028.tif\n    \ud83d\udcc4 1029.tif\n    ... and 818 more items\n\n==================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": "## \ud83d\udcca Step 4: Load Dataset with Flexible Path Detection",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Function to find images with multiple extensions\ndef find_images(directory, extensions=['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.PNG', '*.JPEG', '*.tif', '*.TIF', '*.tiff', '*.TIFF']):\n    \"\"\"Find all images in directory with given extensions\"\"\"\n    all_images = []\n    for ext in extensions:\n        all_images.extend(glob(os.path.join(directory, ext)))\n        # Also search recursively in case images are in subdirectories\n        all_images.extend(glob(os.path.join(directory, '**', ext), recursive=True))\n    return sorted(list(set(all_images)))  # Remove duplicates and sort\n\ndef auto_find_dataset_dirs(base_path):\n    \"\"\"Automatically find image and mask directories\"\"\"\n    possible_image_dirs = ['images', 'image', 'img', 'train', 'train_images', 'data/images']\n    possible_mask_dirs = ['masks', 'mask', 'labels', 'label', 'train_masks', 'data/masks', 'ground_truth', 'gt']\n    \n    image_dir = None\n    mask_dir = None\n    \n    # Try to find image directory\n    for dir_name in possible_image_dirs:\n        test_path = os.path.join(base_path, dir_name)\n        if os.path.exists(test_path):\n            # Check if it has images\n            test_images = find_images(test_path)\n            if len(test_images) > 0:\n                image_dir = test_path\n                print(f\"\u2705 Found images in: {dir_name}\")\n                break\n    \n    # Try to find mask directory\n    for dir_name in possible_mask_dirs:\n        test_path = os.path.join(base_path, dir_name)\n        if os.path.exists(test_path):\n            # Check if it has images\n            test_masks = find_images(test_path)\n            if len(test_masks) > 0:\n                mask_dir = test_path\n                print(f\"\u2705 Found masks in: {dir_name}\")\n                break\n    \n    return image_dir, mask_dir\n\n# Try to auto-detect\nprint(\"\ud83d\udd0d Auto-detecting dataset structure...\\n\")\ndetected_image_dir, detected_mask_dir = auto_find_dataset_dirs(base_path)\n\n# Update config if found\nif detected_image_dir:\n    config.IMAGE_DIR = detected_image_dir\nif detected_mask_dir:\n    config.MASK_DIR = detected_mask_dir\n\nprint(f\"\\n\ud83d\udcc1 Using directories:\")\nprint(f\"  Images: {config.IMAGE_DIR}\")\nprint(f\"  Masks: {config.MASK_DIR}\")\nprint(\"=\"*50)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-06T17:44:22.639844Z",
          "iopub.execute_input": "2026-02-06T17:44:22.640404Z",
          "iopub.status.idle": "2026-02-06T17:44:22.654015Z",
          "shell.execute_reply.started": "2026-02-06T17:44:22.640373Z",
          "shell.execute_reply": "2026-02-06T17:44:22.653383Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\ud83d\udd0d Auto-detecting dataset structure...\n\n\n\ud83d\udcc1 Using directories:\n  Images: /kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data/images\n  Masks: /kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data/masks\n==================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": "## \ud83d\udce5 Step 5: Load and Match Images with Masks",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import os\nfrom glob import glob\nimport pandas as pd\n\n# ===============================\n# CONFIG\n# ===============================\nclass config:\n    IMAGE_DIR = \"/kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data/image\"\n    MASK_DIR  = \"/kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data/label\"\n\n# base path only for fallback search\nbase_path = \"/kaggle/input/kssd2025-kidney-stone-segmentation-dataset\"\n\n# ===============================\n# Helper\n# ===============================\ndef find_images(folder):\n    return (\n        glob(os.path.join(folder, \"*.png\")) +\n        glob(os.path.join(folder, \"*.jpg\")) +\n        glob(os.path.join(folder, \"*.jpeg\"))\n    )\n\n# Get image and mask paths\nprint(\"\ud83d\udce5 Loading dataset...\\n\")\n\nimage_paths = find_images(config.IMAGE_DIR)\nmask_paths = find_images(config.MASK_DIR)\n\nprint(f\"\ud83d\udcca Dataset Statistics:\")\nprint(f\"  \ud83d\uddbc\ufe0f  Total Images Found: {len(image_paths)}\")\nprint(f\"  \ud83c\udfad Total Masks Found: {len(mask_paths)}\")\n\nif len(image_paths) == 0:\n    print(\"\\n\u274c ERROR: No images found!\")\n    print(\"\\nLet me search the entire dataset directory...\")\n    all_images = glob(os.path.join(base_path, '**', '*.jpg'), recursive=True) + \\\n                 glob(os.path.join(base_path, '**', '*.png'), recursive=True)\n    if len(all_images) > 0:\n        print(f\"\\nFound {len(all_images)} images in total. Showing first 10:\")\n        for img in all_images[:10]:\n            print(f\"  {img}\")\nelse:\n    print(\"\\n\u2705 Images loaded successfully!\")\n    print(f\"\\nFirst 5 image paths:\")\n    for img in image_paths[:5]:\n        print(f\"  {img}\")\n\nif len(mask_paths) == 0:\n    print(\"\\n\u274c ERROR: No masks found!\")\nelse:\n    print(\"\\n\u2705 Masks loaded successfully!\")\n    print(f\"\\nFirst 5 mask paths:\")\n    for mask in mask_paths[:5]:\n        print(f\"  {mask}\")\n\n# Match images and masks by filename\nif len(image_paths) > 0 and len(mask_paths) > 0:\n    # Extract filenames (without extension and path)\n    def get_base_name(path):\n        return os.path.splitext(os.path.basename(path))[0]\n    \n    image_dict = {get_base_name(p): p for p in image_paths}\n    mask_dict = {get_base_name(p): p for p in mask_paths}\n    \n    # Find matching pairs\n    matched_data = []\n    unmatched_images = []\n    \n    for img_name, img_path in image_dict.items():\n        if img_name in mask_dict:\n            matched_data.append({\n                'image_path': img_path,\n                'mask_path': mask_dict[img_name],\n                'filename': img_name\n            })\n        else:\n            unmatched_images.append(img_name)\n    \n    data_df = pd.DataFrame(matched_data)\n    \n    print(f\"\\n\u2705 Matched {len(data_df)} image-mask pairs\")\n    \n    if len(unmatched_images) > 0:\n        print(f\"\u26a0\ufe0f Warning: {len(unmatched_images)} images without matching masks\")\n        if len(unmatched_images) <= 5:\n            print(f\"Unmatched: {unmatched_images}\")\n    \n    if len(data_df) > 0:\n        print(f\"\\n\ud83d\udccb Dataset Preview:\")\n        print(data_df.head(10))\n    else:\n        print(\"\\n\u274c No matching image-mask pairs found!\")\n        data_df = None\nelse:\n    print(\"\\n\u274c Cannot create dataset - missing images or masks\")\n    data_df = None\n\nprint(\"\\n\" + \"=\"*50)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-06T17:54:55.782683Z",
          "iopub.execute_input": "2026-02-06T17:54:55.782947Z",
          "iopub.status.idle": "2026-02-06T17:54:56.651075Z",
          "shell.execute_reply.started": "2026-02-06T17:54:55.782925Z",
          "shell.execute_reply": "2026-02-06T17:54:56.650511Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\ud83d\udce5 Loading dataset...\n\n\ud83d\udcca Dataset Statistics:\n  \ud83d\uddbc\ufe0f  Total Images Found: 0\n  \ud83c\udfad Total Masks Found: 0\n\n\u274c ERROR: No images found!\n\nLet me search the entire dataset directory...\n\n\u274c ERROR: No masks found!\n\n\u274c Cannot create dataset - missing images or masks\n\n==================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}