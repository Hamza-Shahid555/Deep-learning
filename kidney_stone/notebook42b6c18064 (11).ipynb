{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11407583,"sourceType":"datasetVersion","datasetId":7145805}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\"\"\"\n# ğŸ¯ Attention U-Net for Kidney Stone Segmentation on KSSD2025\n\n## ğŸ“Š Objective\nBeat the baseline Modified U-Net score of **97.06%** using Attention U-Net\n\n## ğŸ¯ Expected Results\n- **Target Dice Score:** 97.5% - 98.2%\n- **Strategy:** Attention mechanisms for small object detection\n- **Architecture:** U-Net + Attention Gates\n\n## ğŸ“‹ Implementation Plan\n1. âœ… Setup & Import Libraries\n2. âœ… Load KSSD2025 Dataset\n3. âœ… Data Preprocessing & Augmentation\n4. âœ… Build Attention U-Net Architecture\n5. âœ… Training with 5-Fold Cross-Validation\n6. âœ… Evaluation & Visualization\n7. âœ… Results Comparison","metadata":{}},{"cell_type":"markdown","source":"## ğŸ“¦ Step 1: Install & Import Required Libraries\n","metadata":{}},{"cell_type":"code","source":"import sys\n!{sys.executable} -m pip install -q segmentation-models-pytorch albumentations\n\nprint(\"âœ… Libraries installed successfully!\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T16:59:43.400784Z","iopub.execute_input":"2026-02-06T16:59:43.401341Z","iopub.status.idle":"2026-02-06T16:59:47.929693Z","shell.execute_reply.started":"2026-02-06T16:59:43.401313Z","shell.execute_reply":"2026-02-06T16:59:47.928853Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hâœ… Libraries installed successfully!\n==================================================\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Core Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport cv2\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Deep Learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n# Sklearn\nfrom sklearn.model_selection import KFold\n\n# Image Processing\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# Progress Bar\nfrom tqdm.auto import tqdm\n\n# Set random seeds for reproducibility\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\nprint(\"âœ… All libraries imported successfully!\")\nprint(f\"âœ… PyTorch Version: {torch.__version__}\")\nprint(f\"âœ… CUDA Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"âœ… CUDA Device: {torch.cuda.get_device_name(0)}\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T17:01:03.107252Z","iopub.execute_input":"2026-02-06T17:01:03.107893Z","iopub.status.idle":"2026-02-06T17:01:09.855921Z","shell.execute_reply.started":"2026-02-06T17:01:03.107856Z","shell.execute_reply":"2026-02-06T17:01:09.855252Z"}},"outputs":[{"name":"stdout","text":"âœ… All libraries imported successfully!\nâœ… PyTorch Version: 2.8.0+cu126\nâœ… CUDA Available: True\nâœ… CUDA Device: Tesla T4\n==================================================\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## ğŸ“‚ Step 2: Configure Dataset Paths\n\n**IMPORTANT:** ","metadata":{}},{"cell_type":"code","source":"# Configuration\nclass Config:\n    # === DATASET PATHS - CORRECTED FOR YOUR STRUCTURE ===\n    # Your dataset has a 'data' subdirectory\n    DATA_PATH = \"/kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data\"\n    \n    # Image and mask directories\n    IMAGE_DIR = f\"{DATA_PATH}/images\"\n    MASK_DIR = f\"{DATA_PATH}/masks\"\n    \n    # Image Settings\n    IMG_SIZE = 256  # Resize images to 256x256\n    \n    # Training Settings\n    BATCH_SIZE = 16\n    NUM_EPOCHS = 150\n    LEARNING_RATE = 0.001\n    NUM_FOLDS = 5\n    \n    # Model Settings\n    ENCODER_CHANNELS = [16, 32, 64, 128]\n    DECODER_CHANNELS = [128, 64, 32, 16]\n    \n    # Device\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Save Settings\n    SAVE_MODELS = True\n    MODEL_DIR = \"/kaggle/working/models\"\n    OUTPUT_DIR = \"/kaggle/working/outputs\"\n\nconfig = Config()\n\n# Create necessary directories\nPath(config.MODEL_DIR).mkdir(parents=True, exist_ok=True)\nPath(config.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n\nprint(\"âš™ï¸ Configuration Settings:\")\nprint(f\"  ğŸ“ Data Path: {config.DATA_PATH}\")\nprint(f\"  ğŸ“ Image Dir: {config.IMAGE_DIR}\")\nprint(f\"  ğŸ“ Mask Dir: {config.MASK_DIR}\")\nprint(f\"  ğŸ–¼ï¸  Image Size: {config.IMG_SIZE}x{config.IMG_SIZE}\")\nprint(f\"  ğŸ“¦ Batch Size: {config.BATCH_SIZE}\")\nprint(f\"  ğŸ”„ Epochs: {config.NUM_EPOCHS}\")\nprint(f\"  ğŸ“Š K-Folds: {config.NUM_FOLDS}\")\nprint(f\"  ğŸ¯ Device: {config.DEVICE}\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T17:43:20.407550Z","iopub.execute_input":"2026-02-06T17:43:20.408360Z","iopub.status.idle":"2026-02-06T17:43:20.415539Z","shell.execute_reply.started":"2026-02-06T17:43:20.408328Z","shell.execute_reply":"2026-02-06T17:43:20.414942Z"}},"outputs":[{"name":"stdout","text":"âš™ï¸ Configuration Settings:\n  ğŸ“ Data Path: /kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data\n  ğŸ“ Image Dir: /kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data/images\n  ğŸ“ Mask Dir: /kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data/masks\n  ğŸ–¼ï¸  Image Size: 256x256\n  ğŸ“¦ Batch Size: 16\n  ğŸ”„ Epochs: 150\n  ğŸ“Š K-Folds: 5\n  ğŸ¯ Device: cuda\n==================================================\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## ğŸ” Step 3: Load and Explore Dataset","metadata":{}},{"cell_type":"code","source":"# Explore the dataset structure\nbase_path = \"/kaggle/input/kssd2025-kidney-stone-segmentation-dataset\"\n\nprint(\"ğŸ“ Exploring dataset structure...\\n\")\n\ndef explore_directory(path, level=0, max_level=3):\n    \"\"\"Recursively explore directory structure\"\"\"\n    if level > max_level or not os.path.exists(path):\n        return\n    \n    indent = \"  \" * level\n    items = sorted(os.listdir(path))\n    \n    for item in items[:20]:  # Limit to first 20 items\n        item_path = os.path.join(path, item)\n        if os.path.isdir(item_path):\n            count = len(os.listdir(item_path))\n            print(f\"{indent}ğŸ“ {item}/ ({count} items)\")\n            if level < 2:  # Only go 2 levels deep\n                explore_directory(item_path, level + 1, max_level)\n        else:\n            print(f\"{indent}ğŸ“„ {item}\")\n    \n    if len(items) > 20:\n        print(f\"{indent}... and {len(items) - 20} more items\")\n\nexplore_directory(base_path)\nprint(\"\\n\" + \"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T17:43:51.538249Z","iopub.execute_input":"2026-02-06T17:43:51.538557Z","iopub.status.idle":"2026-02-06T17:43:51.664908Z","shell.execute_reply.started":"2026-02-06T17:43:51.538529Z","shell.execute_reply":"2026-02-06T17:43:51.664365Z"}},"outputs":[{"name":"stdout","text":"ğŸ“ Exploring dataset structure...\n\nğŸ“ data/ (2 items)\n  ğŸ“ image/ (838 items)\n    ğŸ“„ 1.tif\n    ğŸ“„ 10.tif\n    ğŸ“„ 1000.tif\n    ğŸ“„ 1001.tif\n    ğŸ“„ 1002.tif\n    ğŸ“„ 1003.tif\n    ğŸ“„ 1012.tif\n    ğŸ“„ 1013.tif\n    ğŸ“„ 1014.tif\n    ğŸ“„ 1015.tif\n    ğŸ“„ 1020.tif\n    ğŸ“„ 1021.tif\n    ğŸ“„ 1022.tif\n    ğŸ“„ 1023.tif\n    ğŸ“„ 1024.tif\n    ğŸ“„ 1025.tif\n    ğŸ“„ 1026.tif\n    ğŸ“„ 1027.tif\n    ğŸ“„ 1028.tif\n    ğŸ“„ 1029.tif\n    ... and 818 more items\n  ğŸ“ label/ (838 items)\n    ğŸ“„ 1.tif\n    ğŸ“„ 10.tif\n    ğŸ“„ 1000.tif\n    ğŸ“„ 1001.tif\n    ğŸ“„ 1002.tif\n    ğŸ“„ 1003.tif\n    ğŸ“„ 1012.tif\n    ğŸ“„ 1013.tif\n    ğŸ“„ 1014.tif\n    ğŸ“„ 1015.tif\n    ğŸ“„ 1020.tif\n    ğŸ“„ 1021.tif\n    ğŸ“„ 1022.tif\n    ğŸ“„ 1023.tif\n    ğŸ“„ 1024.tif\n    ğŸ“„ 1025.tif\n    ğŸ“„ 1026.tif\n    ğŸ“„ 1027.tif\n    ğŸ“„ 1028.tif\n    ğŸ“„ 1029.tif\n    ... and 818 more items\n\n==================================================\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## ğŸ“Š Step 4: Load Dataset with Flexible Path Detection","metadata":{}},{"cell_type":"code","source":"# Function to find images with multiple extensions\ndef find_images(directory, extensions=['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.PNG', '*.JPEG']):\n    \"\"\"Find all images in directory with given extensions\"\"\"\n    all_images = []\n    for ext in extensions:\n        all_images.extend(glob(os.path.join(directory, ext)))\n        # Also search recursively in case images are in subdirectories\n        all_images.extend(glob(os.path.join(directory, '**', ext), recursive=True))\n    return sorted(list(set(all_images)))  # Remove duplicates and sort\n\ndef auto_find_dataset_dirs(base_path):\n    \"\"\"Automatically find image and mask directories\"\"\"\n    possible_image_dirs = ['images', 'image', 'img', 'train', 'train_images', 'data/images']\n    possible_mask_dirs = ['masks', 'mask', 'labels', 'label', 'train_masks', 'data/masks', 'ground_truth', 'gt']\n    \n    image_dir = None\n    mask_dir = None\n    \n    # Try to find image directory\n    for dir_name in possible_image_dirs:\n        test_path = os.path.join(base_path, dir_name)\n        if os.path.exists(test_path):\n            # Check if it has images\n            test_images = find_images(test_path)\n            if len(test_images) > 0:\n                image_dir = test_path\n                print(f\"âœ… Found images in: {dir_name}\")\n                break\n    \n    # Try to find mask directory\n    for dir_name in possible_mask_dirs:\n        test_path = os.path.join(base_path, dir_name)\n        if os.path.exists(test_path):\n            # Check if it has images\n            test_masks = find_images(test_path)\n            if len(test_masks) > 0:\n                mask_dir = test_path\n                print(f\"âœ… Found masks in: {dir_name}\")\n                break\n    \n    return image_dir, mask_dir\n\n# Try to auto-detect\nprint(\"ğŸ” Auto-detecting dataset structure...\\n\")\ndetected_image_dir, detected_mask_dir = auto_find_dataset_dirs(base_path)\n\n# Update config if found\nif detected_image_dir:\n    config.IMAGE_DIR = detected_image_dir\nif detected_mask_dir:\n    config.MASK_DIR = detected_mask_dir\n\nprint(f\"\\nğŸ“ Using directories:\")\nprint(f\"  Images: {config.IMAGE_DIR}\")\nprint(f\"  Masks: {config.MASK_DIR}\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T17:44:22.639844Z","iopub.execute_input":"2026-02-06T17:44:22.640404Z","iopub.status.idle":"2026-02-06T17:44:22.654015Z","shell.execute_reply.started":"2026-02-06T17:44:22.640373Z","shell.execute_reply":"2026-02-06T17:44:22.653383Z"}},"outputs":[{"name":"stdout","text":"ğŸ” Auto-detecting dataset structure...\n\n\nğŸ“ Using directories:\n  Images: /kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data/images\n  Masks: /kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data/masks\n==================================================\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## ğŸ“¥ Step 5: Load and Match Images with Masks","metadata":{}},{"cell_type":"code","source":"import os\nfrom glob import glob\nimport pandas as pd\n\n# ===============================\n# CONFIG\n# ===============================\nclass config:\n    IMAGE_DIR = \"/kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data/image\"\n    MASK_DIR  = \"/kaggle/input/kssd2025-kidney-stone-segmentation-dataset/data/label\"\n\n# base path only for fallback search\nbase_path = \"/kaggle/input/kssd2025-kidney-stone-segmentation-dataset\"\n\n# ===============================\n# Helper\n# ===============================\ndef find_images(folder):\n    return (\n        glob(os.path.join(folder, \"*.png\")) +\n        glob(os.path.join(folder, \"*.jpg\")) +\n        glob(os.path.join(folder, \"*.jpeg\"))\n    )\n\n# Get image and mask paths\nprint(\"ğŸ“¥ Loading dataset...\\n\")\n\nimage_paths = find_images(config.IMAGE_DIR)\nmask_paths = find_images(config.MASK_DIR)\n\nprint(f\"ğŸ“Š Dataset Statistics:\")\nprint(f\"  ğŸ–¼ï¸  Total Images Found: {len(image_paths)}\")\nprint(f\"  ğŸ­ Total Masks Found: {len(mask_paths)}\")\n\nif len(image_paths) == 0:\n    print(\"\\nâŒ ERROR: No images found!\")\n    print(\"\\nLet me search the entire dataset directory...\")\n    all_images = glob(os.path.join(base_path, '**', '*.jpg'), recursive=True) + \\\n                 glob(os.path.join(base_path, '**', '*.png'), recursive=True)\n    if len(all_images) > 0:\n        print(f\"\\nFound {len(all_images)} images in total. Showing first 10:\")\n        for img in all_images[:10]:\n            print(f\"  {img}\")\nelse:\n    print(\"\\nâœ… Images loaded successfully!\")\n    print(f\"\\nFirst 5 image paths:\")\n    for img in image_paths[:5]:\n        print(f\"  {img}\")\n\nif len(mask_paths) == 0:\n    print(\"\\nâŒ ERROR: No masks found!\")\nelse:\n    print(\"\\nâœ… Masks loaded successfully!\")\n    print(f\"\\nFirst 5 mask paths:\")\n    for mask in mask_paths[:5]:\n        print(f\"  {mask}\")\n\n# Match images and masks by filename\nif len(image_paths) > 0 and len(mask_paths) > 0:\n    # Extract filenames (without extension and path)\n    def get_base_name(path):\n        return os.path.splitext(os.path.basename(path))[0]\n    \n    image_dict = {get_base_name(p): p for p in image_paths}\n    mask_dict = {get_base_name(p): p for p in mask_paths}\n    \n    # Find matching pairs\n    matched_data = []\n    unmatched_images = []\n    \n    for img_name, img_path in image_dict.items():\n        if img_name in mask_dict:\n            matched_data.append({\n                'image_path': img_path,\n                'mask_path': mask_dict[img_name],\n                'filename': img_name\n            })\n        else:\n            unmatched_images.append(img_name)\n    \n    data_df = pd.DataFrame(matched_data)\n    \n    print(f\"\\nâœ… Matched {len(data_df)} image-mask pairs\")\n    \n    if len(unmatched_images) > 0:\n        print(f\"âš ï¸ Warning: {len(unmatched_images)} images without matching masks\")\n        if len(unmatched_images) <= 5:\n            print(f\"Unmatched: {unmatched_images}\")\n    \n    if len(data_df) > 0:\n        print(f\"\\nğŸ“‹ Dataset Preview:\")\n        print(data_df.head(10))\n    else:\n        print(\"\\nâŒ No matching image-mask pairs found!\")\n        data_df = None\nelse:\n    print(\"\\nâŒ Cannot create dataset - missing images or masks\")\n    data_df = None\n\nprint(\"\\n\" + \"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T17:54:55.782683Z","iopub.execute_input":"2026-02-06T17:54:55.782947Z","iopub.status.idle":"2026-02-06T17:54:56.651075Z","shell.execute_reply.started":"2026-02-06T17:54:55.782925Z","shell.execute_reply":"2026-02-06T17:54:56.650511Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Loading dataset...\n\nğŸ“Š Dataset Statistics:\n  ğŸ–¼ï¸  Total Images Found: 0\n  ğŸ­ Total Masks Found: 0\n\nâŒ ERROR: No images found!\n\nLet me search the entire dataset directory...\n\nâŒ ERROR: No masks found!\n\nâŒ Cannot create dataset - missing images or masks\n\n==================================================\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}