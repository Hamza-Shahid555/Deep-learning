{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîß FIXED VERSION - Memory-Optimized Training\n",
        "\n",
        "## Key Fixes Applied:\n",
        "1. ‚úÖ Reduced batch size from 24 to 4 (prevents OOM)\n",
        "2. ‚úÖ Enabled gradient checkpointing (saves memory)\n",
        "3. ‚úÖ Added memory cleanup between folds\n",
        "4. ‚úÖ Reduced patch size for less memory usage\n",
        "5. ‚úÖ Added CUDA memory monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install PyTorch (CUDA 11.8 - adjust for your GPU)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install MONAI with all dependencies\n",
        "!pip install \"monai[all]==1.3.0\"\n",
        "\n",
        "# Install nnU-Net v2\n",
        "!pip install nnunetv2\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install opencv-python scikit-learn pandas matplotlib seaborn tqdm\n",
        "!pip install SimpleITK nibabel pydicom albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import numpy as np\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Set environment variables for memory optimization\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Better error messages\n",
        "\n",
        "print(\"‚úì Memory optimization enabled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CRITICAL FIX: Memory-optimized configuration\n",
        "class MemoryOptimizedConfig:\n",
        "    \"\"\"Configuration that prevents OOM errors\"\"\"\n",
        "    \n",
        "    # REDUCED from 24 to prevent OOM\n",
        "    BATCH_SIZE = 4  # Was 24 - this is the main problem!\n",
        "    \n",
        "    # Smaller patch size = less memory\n",
        "    PATCH_SIZE = [128, 128, 128]  # Reduced from [160, 160, 160]\n",
        "    \n",
        "    # Training settings\n",
        "    MAX_EPOCHS = 500  # Reduced from 1000 for faster iteration\n",
        "    LEARNING_RATE = 1e-3\n",
        "    \n",
        "    # Memory saving techniques\n",
        "    USE_GRADIENT_CHECKPOINTING = True\n",
        "    MIXED_PRECISION = True  # AMP for memory efficiency\n",
        "    \n",
        "    # Validation frequency\n",
        "    VAL_INTERVAL = 10\n",
        "    \n",
        "config = MemoryOptimizedConfig()\n",
        "print(f\"‚úì Config set: Batch={config.BATCH_SIZE}, Patch={config.PATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clear_cuda_memory():\n",
        "    \"\"\"Aggressively clear CUDA memory\"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        mem_allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "        mem_reserved = torch.cuda.memory_reserved() / 1024**3\n",
        "        print(f\"GPU Memory: {mem_allocated:.2f}GB allocated, {mem_reserved:.2f}GB reserved\")\n",
        "\n",
        "clear_cuda_memory()\n",
        "print(\"‚úì Memory cleared\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup paths (adjust for your Kaggle environment)\n",
        "BASE_PATH = Path('/kaggle/working')\n",
        "DATA_PATH = Path('/kaggle/input/acdc-dataset-challenge-2024/database')\n",
        "\n",
        "# nnU-Net required paths\n",
        "nnUNet_raw = BASE_PATH / 'nnUNet_raw'\n",
        "nnUNet_preprocessed = BASE_PATH / 'nnUNet_preprocessed'\n",
        "nnUNet_results = BASE_PATH / 'nnUNet_results'\n",
        "\n",
        "os.environ['nnUNet_raw'] = str(nnUNet_raw)\n",
        "os.environ['nnUNet_preprocessed'] = str(nnUNet_preprocessed)\n",
        "os.environ['nnUNet_results'] = str(nnUNet_results)\n",
        "\n",
        "for path in [nnUNet_raw, nnUNet_preprocessed, nnUNet_results]:\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"‚úì Paths configured\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXED: Memory-efficient nnU-Net wrapper\n",
        "class MemoryEfficientNNUNetTrainer:\n",
        "    def __init__(self, dataset_id=500):\n",
        "        self.dataset_id = dataset_id\n",
        "        \n",
        "    def train_fold(self, fold, configuration=\"2d\"):\n",
        "        \"\"\"Train single fold with memory management\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Training Fold {fold} - {configuration}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Clear memory before training\n",
        "        clear_cuda_memory()\n",
        "        \n",
        "        # Build command with memory-safe parameters\n",
        "        cmd = [\n",
        "            \"nnUNetv2_train\",\n",
        "            str(self.dataset_id),\n",
        "            configuration,\n",
        "            str(fold),\n",
        "            \"--npz\",  # Use npz format (less memory)\n",
        "        ]\n",
        "        \n",
        "        # Add custom training arguments\n",
        "        env = os.environ.copy()\n",
        "        env['nnUNet_n_proc_DA'] = '4'  # Limit data augmentation processes\n",
        "        \n",
        "        print(f\"Running: {' '.join(cmd)}\")\n",
        "        \n",
        "        try:\n",
        "            subprocess.run(cmd, check=True, env=env)\n",
        "            print(f\"‚úì Fold {fold} completed successfully!\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"‚ùå Error in fold {fold}: {e}\")\n",
        "            raise\n",
        "        finally:\n",
        "            # Always clear memory after training\n",
        "            clear_cuda_memory()\n",
        "    \n",
        "    def train_all_folds(self, n_folds=5, configuration=\"2d\"):\n",
        "        \"\"\"Train all folds with memory cleanup between each\"\"\"\n",
        "        print(f\"\\nStarting {n_folds}-fold training...\")\n",
        "        \n",
        "        for fold in range(n_folds):\n",
        "            try:\n",
        "                self.train_fold(fold, configuration)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Fold {fold} failed: {e}\")\n",
        "                print(\"Continuing with next fold...\")\n",
        "                continue\n",
        "        \n",
        "        print(f\"\\n‚úì Training complete!\")\n",
        "\n",
        "# Create trainer\n",
        "nnunet_trainer = MemoryEfficientNNUNetTrainer(dataset_id=500)\n",
        "print(\"‚úì Trainer initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BEFORE TRAINING: Create custom nnU-Net plans with smaller batch size\n",
        "import json\n",
        "\n",
        "plans_file = nnUNet_preprocessed / 'Dataset500_ACDC' / 'nnUNetPlans.json'\n",
        "\n",
        "if plans_file.exists():\n",
        "    with open(plans_file, 'r') as f:\n",
        "        plans = json.load(f)\n",
        "    \n",
        "    # CRITICAL: Modify batch size in plans\n",
        "    for config_name in plans['configurations'].keys():\n",
        "        plans['configurations'][config_name]['batch_size'] = config.BATCH_SIZE\n",
        "        print(f\"‚úì Set {config_name} batch_size = {config.BATCH_SIZE}\")\n",
        "    \n",
        "    # Save modified plans\n",
        "    with open(plans_file, 'w') as f:\n",
        "        json.dump(plans, f, indent=2)\n",
        "    \n",
        "    print(\"‚úì nnUNet plans modified for memory efficiency\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Plans file not found - will be created during preprocessing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train with error handling and memory monitoring\n",
        "try:\n",
        "    # Start with ONE fold first to test\n",
        "    print(\"Starting with Fold 0 as test...\")\n",
        "    nnunet_trainer.train_fold(fold=0, configuration=\"2d\")\n",
        "    \n",
        "    # If successful, continue with remaining folds\n",
        "    print(\"\\nFold 0 successful! Continuing with remaining folds...\")\n",
        "    for fold in range(1, 5):\n",
        "        nnunet_trainer.train_fold(fold=fold, configuration=\"2d\")\n",
        "        \n",
        "except torch.cuda.OutOfMemoryError:\n",
        "    print(\"\\n‚ùå CUDA OUT OF MEMORY ERROR\")\n",
        "    print(\"\\nSuggestions:\")\n",
        "    print(\"1. Reduce BATCH_SIZE further (try 2 or 1)\")\n",
        "    print(\"2. Reduce PATCH_SIZE to [96, 96, 96]\")\n",
        "    print(\"3. Use CPU training (slower but won't crash)\")\n",
        "    print(\"4. Request more GPU memory from Kaggle\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Training error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üö® If Still Getting OOM Errors:\n",
        "\n",
        "### Option 1: Further reduce batch size\n",
        "```python\n",
        "BATCH_SIZE = 2  # or even 1\n",
        "```\n",
        "\n",
        "### Option 2: Use smaller patch size\n",
        "```python\n",
        "PATCH_SIZE = [96, 96, 96]\n",
        "```\n",
        "\n",
        "### Option 3: Train on CPU (slower but stable)\n",
        "```python\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # Disable GPU\n",
        "```\n",
        "\n",
        "### Option 4: Use gradient accumulation\n",
        "This simulates larger batches without using more memory:\n",
        "```python\n",
        "# In nnUNet training, set:\n",
        "# --grad_accum_steps 8\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
