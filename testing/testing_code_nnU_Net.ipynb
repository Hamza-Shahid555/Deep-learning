{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zKJmz5nY9Tn5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ_5zZtZ9Tkb",
        "outputId": "818838bc-7aa0-45bc-9f69-4ab21433576c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 22 21:33:39 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   28C    P0             47W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U nnunetv2 nibabel tifffile simpleitk blosc2 kaggle matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sDfesVEd9Tfv",
        "outputId": "7618e06f-d37e-46d2-9bfb-8db2aa6610b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/211.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m204.8/211.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.4/86.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.4/256.4 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m134.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m134.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.3/159.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.0/189.0 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3 — Set up Kaggle authentication\n",
        "\n",
        "Why: Kaggle downloads require kaggle.json API key.\n",
        "\n",
        "What you must do:\n",
        "\n",
        "Kaggle → Account → Create New API Token\n",
        "\n",
        "It downloads kaggle.json\n",
        "\n",
        "Upload kaggle.json into Colab (Files panel)"
      ],
      "metadata": {
        "id": "uExZ9Eul_FWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pathlib, stat\n",
        "\n",
        "kaggle_json = \"/content/kaggle.json\"\n",
        "assert os.path.exists(kaggle_json), \"Upload kaggle.json to /content/ first (Files panel).\"\n",
        "\n",
        "pathlib.Path(\"/root/.kaggle\").mkdir(parents=True, exist_ok=True)\n",
        "!cp /content/kaggle.json /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "print(\"Kaggle configured.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDLqV3GY9TW8",
        "outputId": "290b38f0-1bed-47d9-db5c-cd5aff39cae8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download dataset from Kaggle + unzip\n",
        "\n",
        "Why: brings the data into Colab storage."
      ],
      "metadata": {
        "id": "Bv45BFJL_U6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "KAGGLE_DATASET = \"murillobouzon/kssd2025-kidney-stone-segmentation-dataset\"  # <-- CHANGE THIS\n",
        "OUT_DIR = \"/content/KSSD2025_kaggle\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "!kaggle datasets download -d {KAGGLE_DATASET} -p {OUT_DIR} --unzip\n",
        "\n",
        "print(\"Downloaded and unzipped to:\", OUT_DIR)\n",
        "!find {OUT_DIR} -maxdepth 3 -type d | head -n 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNuiEDbV_JmH",
        "outputId": "95e89c1f-8940-4887-8957-55d172cdfde8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/murillobouzon/kssd2025-kidney-stone-segmentation-dataset\n",
            "License(s): unknown\n",
            "Downloading kssd2025-kidney-stone-segmentation-dataset.zip to /content/KSSD2025_kaggle\n",
            " 93% 73.0M/78.5M [00:00<00:00, 143MB/s]\n",
            "100% 78.5M/78.5M [00:00<00:00, 146MB/s]\n",
            "Downloaded and unzipped to: /content/KSSD2025_kaggle\n",
            "/content/KSSD2025_kaggle\n",
            "/content/KSSD2025_kaggle/data\n",
            "/content/KSSD2025_kaggle/data/label\n",
            "/content/KSSD2025_kaggle/data/image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Locate images/labels folders\n",
        "\n",
        "Why: Kaggle zips sometimes have different folder names. We auto-detect."
      ],
      "metadata": {
        "id": "l0b0meHh_zuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "\n",
        "def find_folder(root, candidates):\n",
        "    for c in candidates:\n",
        "        p = os.path.join(root, c)\n",
        "        if os.path.isdir(p):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "root = OUT_DIR\n",
        "\n",
        "# Common patterns (edit if your Kaggle zip uses different names)\n",
        "image_candidates = [\n",
        "    \"dataset/image\", \"dataset/images\", \"images\", \"image\", \"data/image\", \"data/images\"\n",
        "]\n",
        "label_candidates = [\n",
        "    \"dataset/label\", \"dataset/labels\", \"labels\", \"label\", \"data/label\", \"data/labels\", \"mask\", \"masks\"\n",
        "]\n",
        "\n",
        "img_dir = find_folder(root, image_candidates)\n",
        "lbl_dir = find_folder(root, label_candidates)\n",
        "\n",
        "# If not found, try recursive search for folders containing .tif\n",
        "if img_dir is None:\n",
        "    tif_dirs = {}\n",
        "    for p in glob.glob(root + \"/**/*.tif\", recursive=True):\n",
        "        d = os.path.dirname(p)\n",
        "        tif_dirs[d] = tif_dirs.get(d, 0) + 1\n",
        "    # pick top tif folder as image guess\n",
        "    if tif_dirs:\n",
        "        img_dir = sorted(tif_dirs.items(), key=lambda x: -x[1])[0][0]\n",
        "\n",
        "print(\"img_dir:\", img_dir)\n",
        "print(\"lbl_dir:\", lbl_dir)\n",
        "\n",
        "# sanity list\n",
        "if img_dir:\n",
        "    print(\"Sample images:\", sorted(os.listdir(img_dir))[:10])\n",
        "if lbl_dir:\n",
        "    print(\"Sample labels:\", sorted(os.listdir(lbl_dir))[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R_ixMLA_dhD",
        "outputId": "f64330b3-4edf-4b13-caec-e61ec468c0bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_dir: /content/KSSD2025_kaggle/data/image\n",
            "lbl_dir: /content/KSSD2025_kaggle/data/label\n",
            "Sample images: ['1.tif', '10.tif', '1000.tif', '1001.tif', '1002.tif', '1003.tif', '1012.tif', '1013.tif', '1014.tif', '1015.tif']\n",
            "Sample labels: ['1.tif', '10.tif', '1000.tif', '1001.tif', '1002.tif', '1003.tif', '1012.tif', '1013.tif', '1014.tif', '1015.tif']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set nnU-Net directories"
      ],
      "metadata": {
        "id": "JTHWYJnb_7BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE = \"/content/nnUNet\"\n",
        "os.environ[\"nnUNet_raw\"] = f\"{BASE}/nnUNet_raw\"\n",
        "os.environ[\"nnUNet_preprocessed\"] = f\"{BASE}/nnUNet_preprocessed\"\n",
        "os.environ[\"nnUNet_results\"] = f\"{BASE}/nnUNet_results\"\n",
        "\n",
        "for p in [os.environ[\"nnUNet_raw\"], os.environ[\"nnUNet_preprocessed\"], os.environ[\"nnUNet_results\"]]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "print(\"nnUNet_raw:\", os.environ[\"nnUNet_raw\"])\n",
        "print(\"nnUNet_preprocessed:\", os.environ[\"nnUNet_preprocessed\"])\n",
        "print(\"nnUNet_results:\", os.environ[\"nnUNet_results\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe83EEGq_3pE",
        "outputId": "98fbdc49-d84f-4239-e4f1-3d79166b9076"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nnUNet_raw: /content/nnUNet/nnUNet_raw\n",
            "nnUNet_preprocessed: /content/nnUNet/nnUNet_preprocessed\n",
            "nnUNet_results: /content/nnUNet/nnUNet_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create nnU-Net dataset folders"
      ],
      "metadata": {
        "id": "mt7CxUOEABM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATASET_ID = 501\n",
        "DATASET_NAME = \"KSSD\"\n",
        "\n",
        "nn_folder = f\"{os.environ['nnUNet_raw']}/Dataset{DATASET_ID:03d}_{DATASET_NAME}\"\n",
        "imagesTr = f\"{nn_folder}/imagesTr\"\n",
        "labelsTr = f\"{nn_folder}/labelsTr\"\n",
        "\n",
        "os.makedirs(imagesTr, exist_ok=True)\n",
        "os.makedirs(labelsTr, exist_ok=True)\n",
        "\n",
        "print(\"nn_folder:\", nn_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wu2V7Nb_9Yt",
        "outputId": "0a0e2041-ab29-472b-9571-1eab13e8de24"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nn_folder: /content/nnUNet/nnUNet_raw/Dataset501_KSSD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "convert .tif → .nii.gz with label remap"
      ],
      "metadata": {
        "id": "5a37YvokAKOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import tifffile as tiff\n",
        "import nibabel as nib\n",
        "\n",
        "img_files = sorted(glob.glob(os.path.join(img_dir, \"*.tif\")))\n",
        "lbl_files = sorted(glob.glob(os.path.join(lbl_dir, \"*.tif\")))\n",
        "\n",
        "print(\"Found images:\", len(img_files))\n",
        "print(\"Found labels:\", len(lbl_files))\n",
        "assert len(img_files) == len(lbl_files), \"Mismatch counts. Check img_dir/lbl_dir.\"\n",
        "\n",
        "for i, (img_p, lbl_p) in enumerate(zip(img_files, lbl_files)):\n",
        "    img = tiff.imread(img_p).astype(np.float32)\n",
        "    lbl = tiff.imread(lbl_p).astype(np.uint8)\n",
        "\n",
        "    # IMPORTANT: binary remap based on your earlier discovery\n",
        "    lbl = (lbl >= 251).astype(np.uint8)\n",
        "\n",
        "    if img.ndim == 2:\n",
        "        img = img[..., None]\n",
        "    if lbl.ndim == 2:\n",
        "        lbl = lbl[..., None]\n",
        "\n",
        "    affine = np.eye(4)\n",
        "    case_id = f\"case_{i:04d}\"\n",
        "\n",
        "    nib.save(nib.Nifti1Image(img, affine), f\"{imagesTr}/{case_id}_0000.nii.gz\")\n",
        "    nib.save(nib.Nifti1Image(lbl, affine), f\"{labelsTr}/{case_id}.nii.gz\")\n",
        "\n",
        "print(\"Conversion finished.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxgUNUUbAFGf",
        "outputId": "6200dce4-f38e-4812-8b99-313702f5b491"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found images: 838\n",
            "Found labels: 838\n",
            "Conversion finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirm labels are clean {0,1}"
      ],
      "metadata": {
        "id": "HOk50sGAARNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, numpy as np\n",
        "import nibabel as nib\n",
        "\n",
        "sample = sorted(glob.glob(labelsTr + \"/*.nii.gz\"))[0]\n",
        "u = np.unique(nib.load(sample).get_fdata())\n",
        "print(\"Unique label values in converted label:\", u)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtvc8ScpAHqQ",
        "outputId": "22b2dd05-d024-479c-d71e-09570aca04d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique label values in converted label: [0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write dataset.json\n",
        "\n",
        "Why: nnU-Net needs class names and file ending."
      ],
      "metadata": {
        "id": "ubFL8BVHAYPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, glob\n",
        "\n",
        "dataset_json = {\n",
        "    \"channel_names\": {\"0\": \"CT\"},\n",
        "    \"labels\": {\"background\": 0, \"stone\": 1},\n",
        "    \"numTraining\": len(glob.glob(imagesTr + \"/*.nii.gz\")),\n",
        "    \"file_ending\": \".nii.gz\"\n",
        "}\n",
        "\n",
        "with open(f\"{nn_folder}/dataset.json\", \"w\") as f:\n",
        "    json.dump(dataset_json, f, indent=2)\n",
        "\n",
        "print(\"Wrote:\", f\"{nn_folder}/dataset.json\")\n",
        "print(dataset_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2u-h02iAQc7",
        "outputId": "34f8e707-1a3e-4885-b3ee-a7381b7f0e76"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: /content/nnUNet/nnUNet_raw/Dataset501_KSSD/dataset.json\n",
            "{'channel_names': {'0': 'CT'}, 'labels': {'background': 0, 'stone': 1}, 'numTraining': 838, 'file_ending': '.nii.gz'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plan + preprocess\n",
        "\n",
        "Why: nnU-Net auto-configures everything."
      ],
      "metadata": {
        "id": "EV9-PVz4Ag8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_plan_and_preprocess -d 501 --verify_dataset_integrity\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDM9iTuPAa4X",
        "outputId": "bdb01d39-9eb1-4a3e-df47-21420241f917"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fingerprint extraction...\n",
            "Dataset501_KSSD\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "\n",
            "####################\n",
            "verify_dataset_integrity Done. \n",
            "If you didn't see any error messages then your dataset is most likely OK!\n",
            "####################\n",
            "\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "100% 838/838 [00:07<00:00, 109.23it/s]\n",
            "Experiment planning...\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "2D U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 14, 'patch_size': (np.int64(512), np.int64(448)), 'median_image_size_in_voxels': array([512., 416.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
            "\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "Plans were saved to /content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/nnUNetPlans.json\n",
            "Preprocessing...\n",
            "Preprocessing dataset Dataset501_KSSD\n",
            "Configuration: 2d...\n",
            "100% 838/838 [00:34<00:00, 24.46it/s]\n",
            "Configuration: 3d_fullres...\n",
            "INFO: Configuration 3d_fullres not found in plans file nnUNetPlans.json of dataset Dataset501_KSSD. Skipping.\n",
            "Configuration: 3d_lowres...\n",
            "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset501_KSSD. Skipping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train 501 2d 0\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4y52u1iAfy3",
        "outputId": "5fcfba7e-957d-4473-9d40-e4ffc10b166a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "2025-12-23 00:02:37.455714: val_loss -0.9842\n",
            "2025-12-23 00:02:37.455827: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 00:02:37.455936: Epoch time: 22.41 s\n",
            "2025-12-23 00:02:38.898661: \n",
            "2025-12-23 00:02:38.898940: Epoch 344\n",
            "2025-12-23 00:02:38.899075: Current learning rate: 0.00684\n",
            "2025-12-23 00:03:01.339194: train_loss -0.9667\n",
            "2025-12-23 00:03:01.339449: val_loss -0.9781\n",
            "2025-12-23 00:03:01.339546: Pseudo dice [np.float32(0.984)]\n",
            "2025-12-23 00:03:01.339637: Epoch time: 22.44 s\n",
            "2025-12-23 00:03:02.768365: \n",
            "2025-12-23 00:03:02.768631: Epoch 345\n",
            "2025-12-23 00:03:02.768795: Current learning rate: 0.00683\n",
            "2025-12-23 00:03:25.214919: train_loss -0.9656\n",
            "2025-12-23 00:03:25.215166: val_loss -0.9825\n",
            "2025-12-23 00:03:25.215299: Pseudo dice [np.float32(0.987)]\n",
            "2025-12-23 00:03:25.215400: Epoch time: 22.45 s\n",
            "2025-12-23 00:03:26.587313: \n",
            "2025-12-23 00:03:26.587517: Epoch 346\n",
            "2025-12-23 00:03:26.587672: Current learning rate: 0.00682\n",
            "2025-12-23 00:03:48.975145: train_loss -0.9692\n",
            "2025-12-23 00:03:48.975554: val_loss -0.9813\n",
            "2025-12-23 00:03:48.975756: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 00:03:48.975903: Epoch time: 22.39 s\n",
            "2025-12-23 00:03:50.390834: \n",
            "2025-12-23 00:03:50.391152: Epoch 347\n",
            "2025-12-23 00:03:50.391328: Current learning rate: 0.00681\n",
            "2025-12-23 00:04:12.845727: train_loss -0.9691\n",
            "2025-12-23 00:04:12.846044: val_loss -0.9846\n",
            "2025-12-23 00:04:12.846137: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 00:04:12.846263: Epoch time: 22.46 s\n",
            "2025-12-23 00:04:14.232367: \n",
            "2025-12-23 00:04:14.232564: Epoch 348\n",
            "2025-12-23 00:04:14.232692: Current learning rate: 0.0068\n",
            "2025-12-23 00:04:36.689053: train_loss -0.9697\n",
            "2025-12-23 00:04:36.689414: val_loss -0.9829\n",
            "2025-12-23 00:04:36.689522: Pseudo dice [np.float32(0.9873)]\n",
            "2025-12-23 00:04:36.689614: Epoch time: 22.46 s\n",
            "2025-12-23 00:04:38.069088: \n",
            "2025-12-23 00:04:38.069478: Epoch 349\n",
            "2025-12-23 00:04:38.069626: Current learning rate: 0.0068\n",
            "2025-12-23 00:05:00.489141: train_loss -0.9689\n",
            "2025-12-23 00:05:00.489449: val_loss -0.9847\n",
            "2025-12-23 00:05:00.489549: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 00:05:00.489640: Epoch time: 22.42 s\n",
            "2025-12-23 00:05:02.327439: \n",
            "2025-12-23 00:05:02.327746: Epoch 350\n",
            "2025-12-23 00:05:02.327903: Current learning rate: 0.00679\n",
            "2025-12-23 00:05:24.799818: train_loss -0.9694\n",
            "2025-12-23 00:05:24.800243: val_loss -0.984\n",
            "2025-12-23 00:05:24.800363: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 00:05:24.800464: Epoch time: 22.47 s\n",
            "2025-12-23 00:05:26.176292: \n",
            "2025-12-23 00:05:26.176459: Epoch 351\n",
            "2025-12-23 00:05:26.176581: Current learning rate: 0.00678\n",
            "2025-12-23 00:05:48.625088: train_loss -0.97\n",
            "2025-12-23 00:05:48.625325: val_loss -0.9814\n",
            "2025-12-23 00:05:48.625428: Pseudo dice [np.float32(0.9879)]\n",
            "2025-12-23 00:05:48.625531: Epoch time: 22.45 s\n",
            "2025-12-23 00:05:48.625607: Yayy! New best EMA pseudo Dice: 0.9873999953269958\n",
            "2025-12-23 00:05:50.474282: \n",
            "2025-12-23 00:05:50.474648: Epoch 352\n",
            "2025-12-23 00:05:50.474787: Current learning rate: 0.00677\n",
            "2025-12-23 00:06:12.932883: train_loss -0.9692\n",
            "2025-12-23 00:06:12.933098: val_loss -0.9832\n",
            "2025-12-23 00:06:12.933194: Pseudo dice [np.float32(0.9879)]\n",
            "2025-12-23 00:06:12.933329: Epoch time: 22.46 s\n",
            "2025-12-23 00:06:12.933512: Yayy! New best EMA pseudo Dice: 0.9873999953269958\n",
            "2025-12-23 00:06:14.767960: \n",
            "2025-12-23 00:06:14.768308: Epoch 353\n",
            "2025-12-23 00:06:14.768443: Current learning rate: 0.00676\n",
            "2025-12-23 00:06:37.204491: train_loss -0.9703\n",
            "2025-12-23 00:06:37.204691: val_loss -0.982\n",
            "2025-12-23 00:06:37.204785: Pseudo dice [np.float32(0.9873)]\n",
            "2025-12-23 00:06:37.204877: Epoch time: 22.44 s\n",
            "2025-12-23 00:06:38.613402: \n",
            "2025-12-23 00:06:38.613773: Epoch 354\n",
            "2025-12-23 00:06:38.613930: Current learning rate: 0.00675\n",
            "2025-12-23 00:07:01.055713: train_loss -0.971\n",
            "2025-12-23 00:07:01.056053: val_loss -0.9831\n",
            "2025-12-23 00:07:01.056278: Pseudo dice [np.float32(0.9868)]\n",
            "2025-12-23 00:07:01.056457: Epoch time: 22.44 s\n",
            "2025-12-23 00:07:02.464087: \n",
            "2025-12-23 00:07:02.464305: Epoch 355\n",
            "2025-12-23 00:07:02.464437: Current learning rate: 0.00674\n",
            "2025-12-23 00:07:24.921930: train_loss -0.9706\n",
            "2025-12-23 00:07:24.922271: val_loss -0.982\n",
            "2025-12-23 00:07:24.922389: Pseudo dice [np.float32(0.9868)]\n",
            "2025-12-23 00:07:24.922519: Epoch time: 22.46 s\n",
            "2025-12-23 00:07:26.334996: \n",
            "2025-12-23 00:07:26.335354: Epoch 356\n",
            "2025-12-23 00:07:26.335505: Current learning rate: 0.00673\n",
            "2025-12-23 00:07:48.843652: train_loss -0.9696\n",
            "2025-12-23 00:07:48.843887: val_loss -0.9836\n",
            "2025-12-23 00:07:48.843976: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 00:07:48.844065: Epoch time: 22.51 s\n",
            "2025-12-23 00:07:50.229601: \n",
            "2025-12-23 00:07:50.229753: Epoch 357\n",
            "2025-12-23 00:07:50.230084: Current learning rate: 0.00672\n",
            "2025-12-23 00:08:12.714101: train_loss -0.967\n",
            "2025-12-23 00:08:12.714407: val_loss -0.9823\n",
            "2025-12-23 00:08:12.714512: Pseudo dice [np.float32(0.9869)]\n",
            "2025-12-23 00:08:12.714604: Epoch time: 22.49 s\n",
            "2025-12-23 00:08:14.808198: \n",
            "2025-12-23 00:08:14.808660: Epoch 358\n",
            "2025-12-23 00:08:14.808817: Current learning rate: 0.00671\n",
            "2025-12-23 00:08:37.327170: train_loss -0.9648\n",
            "2025-12-23 00:08:37.327483: val_loss -0.9804\n",
            "2025-12-23 00:08:37.327598: Pseudo dice [np.float32(0.9861)]\n",
            "2025-12-23 00:08:37.327693: Epoch time: 22.52 s\n",
            "2025-12-23 00:08:38.698340: \n",
            "2025-12-23 00:08:38.698585: Epoch 359\n",
            "2025-12-23 00:08:38.698719: Current learning rate: 0.0067\n",
            "2025-12-23 00:09:01.231040: train_loss -0.9567\n",
            "2025-12-23 00:09:01.231347: val_loss -0.9741\n",
            "2025-12-23 00:09:01.231446: Pseudo dice [np.float32(0.9782)]\n",
            "2025-12-23 00:09:01.231541: Epoch time: 22.53 s\n",
            "2025-12-23 00:09:02.612051: \n",
            "2025-12-23 00:09:02.612316: Epoch 360\n",
            "2025-12-23 00:09:02.612449: Current learning rate: 0.00669\n",
            "2025-12-23 00:09:25.067763: train_loss -0.9633\n",
            "2025-12-23 00:09:25.068007: val_loss -0.9822\n",
            "2025-12-23 00:09:25.068097: Pseudo dice [np.float32(0.9865)]\n",
            "2025-12-23 00:09:25.068186: Epoch time: 22.46 s\n",
            "2025-12-23 00:09:26.449564: \n",
            "2025-12-23 00:09:26.449953: Epoch 361\n",
            "2025-12-23 00:09:26.450085: Current learning rate: 0.00668\n",
            "2025-12-23 00:09:48.962620: train_loss -0.9635\n",
            "2025-12-23 00:09:48.962861: val_loss -0.9785\n",
            "2025-12-23 00:09:48.962956: Pseudo dice [np.float32(0.9835)]\n",
            "2025-12-23 00:09:48.963045: Epoch time: 22.51 s\n",
            "2025-12-23 00:09:50.374277: \n",
            "2025-12-23 00:09:50.374601: Epoch 362\n",
            "2025-12-23 00:09:50.374748: Current learning rate: 0.00667\n",
            "2025-12-23 00:10:12.850961: train_loss -0.9627\n",
            "2025-12-23 00:10:12.851192: val_loss -0.9807\n",
            "2025-12-23 00:10:12.851324: Pseudo dice [np.float32(0.9863)]\n",
            "2025-12-23 00:10:12.851628: Epoch time: 22.48 s\n",
            "2025-12-23 00:10:14.232849: \n",
            "2025-12-23 00:10:14.233073: Epoch 363\n",
            "2025-12-23 00:10:14.233235: Current learning rate: 0.00666\n",
            "2025-12-23 00:10:36.748862: train_loss -0.9659\n",
            "2025-12-23 00:10:36.749093: val_loss -0.9817\n",
            "2025-12-23 00:10:36.749192: Pseudo dice [np.float32(0.9859)]\n",
            "2025-12-23 00:10:36.749336: Epoch time: 22.52 s\n",
            "2025-12-23 00:10:38.182893: \n",
            "2025-12-23 00:10:38.183187: Epoch 364\n",
            "2025-12-23 00:10:38.183358: Current learning rate: 0.00665\n",
            "2025-12-23 00:11:00.641933: train_loss -0.9675\n",
            "2025-12-23 00:11:00.642374: val_loss -0.982\n",
            "2025-12-23 00:11:00.642476: Pseudo dice [np.float32(0.9876)]\n",
            "2025-12-23 00:11:00.642580: Epoch time: 22.46 s\n",
            "2025-12-23 00:11:02.018160: \n",
            "2025-12-23 00:11:02.018459: Epoch 365\n",
            "2025-12-23 00:11:02.018597: Current learning rate: 0.00665\n",
            "2025-12-23 00:11:24.457573: train_loss -0.9675\n",
            "2025-12-23 00:11:24.457853: val_loss -0.9825\n",
            "2025-12-23 00:11:24.457953: Pseudo dice [np.float32(0.9874)]\n",
            "2025-12-23 00:11:24.458044: Epoch time: 22.44 s\n",
            "2025-12-23 00:11:25.853904: \n",
            "2025-12-23 00:11:25.854180: Epoch 366\n",
            "2025-12-23 00:11:25.854369: Current learning rate: 0.00664\n",
            "2025-12-23 00:11:48.303949: train_loss -0.9673\n",
            "2025-12-23 00:11:48.304398: val_loss -0.9831\n",
            "2025-12-23 00:11:48.304624: Pseudo dice [np.float32(0.9877)]\n",
            "2025-12-23 00:11:48.304824: Epoch time: 22.45 s\n",
            "2025-12-23 00:11:49.684550: \n",
            "2025-12-23 00:11:49.684951: Epoch 367\n",
            "2025-12-23 00:11:49.685138: Current learning rate: 0.00663\n",
            "2025-12-23 00:12:12.175998: train_loss -0.969\n",
            "2025-12-23 00:12:12.176348: val_loss -0.9827\n",
            "2025-12-23 00:12:12.176452: Pseudo dice [np.float32(0.9866)]\n",
            "2025-12-23 00:12:12.176543: Epoch time: 22.49 s\n",
            "2025-12-23 00:12:13.541608: \n",
            "2025-12-23 00:12:13.541943: Epoch 368\n",
            "2025-12-23 00:12:13.542074: Current learning rate: 0.00662\n",
            "2025-12-23 00:12:35.966168: train_loss -0.9679\n",
            "2025-12-23 00:12:35.966413: val_loss -0.9816\n",
            "2025-12-23 00:12:35.966513: Pseudo dice [np.float32(0.9867)]\n",
            "2025-12-23 00:12:35.966606: Epoch time: 22.43 s\n",
            "2025-12-23 00:12:37.352921: \n",
            "2025-12-23 00:12:37.353179: Epoch 369\n",
            "2025-12-23 00:12:37.353348: Current learning rate: 0.00661\n",
            "2025-12-23 00:12:59.804400: train_loss -0.9687\n",
            "2025-12-23 00:12:59.804605: val_loss -0.9843\n",
            "2025-12-23 00:12:59.804695: Pseudo dice [np.float32(0.988)]\n",
            "2025-12-23 00:12:59.804803: Epoch time: 22.45 s\n",
            "2025-12-23 00:13:01.183584: \n",
            "2025-12-23 00:13:01.183760: Epoch 370\n",
            "2025-12-23 00:13:01.183888: Current learning rate: 0.0066\n",
            "2025-12-23 00:13:23.659731: train_loss -0.9688\n",
            "2025-12-23 00:13:23.660144: val_loss -0.9835\n",
            "2025-12-23 00:13:23.660327: Pseudo dice [np.float32(0.9875)]\n",
            "2025-12-23 00:13:23.660498: Epoch time: 22.48 s\n",
            "2025-12-23 00:13:25.044600: \n",
            "2025-12-23 00:13:25.044866: Epoch 371\n",
            "2025-12-23 00:13:25.044993: Current learning rate: 0.00659\n",
            "2025-12-23 00:13:47.481871: train_loss -0.9703\n",
            "2025-12-23 00:13:47.482087: val_loss -0.9829\n",
            "2025-12-23 00:13:47.482172: Pseudo dice [np.float32(0.9871)]\n",
            "2025-12-23 00:13:47.482301: Epoch time: 22.44 s\n",
            "2025-12-23 00:13:48.861504: \n",
            "2025-12-23 00:13:48.861719: Epoch 372\n",
            "2025-12-23 00:13:48.861849: Current learning rate: 0.00658\n",
            "2025-12-23 00:14:11.339667: train_loss -0.9684\n",
            "2025-12-23 00:14:11.339955: val_loss -0.9838\n",
            "2025-12-23 00:14:11.340052: Pseudo dice [np.float32(0.9877)]\n",
            "2025-12-23 00:14:11.340148: Epoch time: 22.48 s\n",
            "2025-12-23 00:14:12.736675: \n",
            "2025-12-23 00:14:12.736864: Epoch 373\n",
            "2025-12-23 00:14:12.737028: Current learning rate: 0.00657\n",
            "2025-12-23 00:14:35.218559: train_loss -0.9695\n",
            "2025-12-23 00:14:35.218908: val_loss -0.9836\n",
            "2025-12-23 00:14:35.219017: Pseudo dice [np.float32(0.9871)]\n",
            "2025-12-23 00:14:35.219112: Epoch time: 22.48 s\n",
            "2025-12-23 00:14:36.603408: \n",
            "2025-12-23 00:14:36.603622: Epoch 374\n",
            "2025-12-23 00:14:36.603761: Current learning rate: 0.00656\n",
            "2025-12-23 00:14:59.014522: train_loss -0.9708\n",
            "2025-12-23 00:14:59.014757: val_loss -0.9837\n",
            "2025-12-23 00:14:59.014936: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 00:14:59.015035: Epoch time: 22.41 s\n",
            "2025-12-23 00:15:01.063972: \n",
            "2025-12-23 00:15:01.064284: Epoch 375\n",
            "2025-12-23 00:15:01.064435: Current learning rate: 0.00655\n",
            "2025-12-23 00:15:23.552341: train_loss -0.9689\n",
            "2025-12-23 00:15:23.552571: val_loss -0.9821\n",
            "2025-12-23 00:15:23.552698: Pseudo dice [np.float32(0.9871)]\n",
            "2025-12-23 00:15:23.552827: Epoch time: 22.49 s\n",
            "2025-12-23 00:15:24.906724: \n",
            "2025-12-23 00:15:24.907069: Epoch 376\n",
            "2025-12-23 00:15:24.907198: Current learning rate: 0.00654\n",
            "2025-12-23 00:15:47.376314: train_loss -0.9624\n",
            "2025-12-23 00:15:47.376553: val_loss -0.9762\n",
            "2025-12-23 00:15:47.376642: Pseudo dice [np.float32(0.9834)]\n",
            "2025-12-23 00:15:47.376734: Epoch time: 22.47 s\n",
            "2025-12-23 00:15:48.740753: \n",
            "2025-12-23 00:15:48.740990: Epoch 377\n",
            "2025-12-23 00:15:48.741114: Current learning rate: 0.00653\n",
            "2025-12-23 00:16:11.215883: train_loss -0.9573\n",
            "2025-12-23 00:16:11.216133: val_loss -0.975\n",
            "2025-12-23 00:16:11.216303: Pseudo dice [np.float32(0.9827)]\n",
            "2025-12-23 00:16:11.216426: Epoch time: 22.48 s\n",
            "2025-12-23 00:16:12.609915: \n",
            "2025-12-23 00:16:12.610281: Epoch 378\n",
            "2025-12-23 00:16:12.610440: Current learning rate: 0.00652\n",
            "2025-12-23 00:16:35.083773: train_loss -0.9578\n",
            "2025-12-23 00:16:35.084166: val_loss -0.9709\n",
            "2025-12-23 00:16:35.084358: Pseudo dice [np.float32(0.9779)]\n",
            "2025-12-23 00:16:35.084523: Epoch time: 22.48 s\n",
            "2025-12-23 00:16:36.454941: \n",
            "2025-12-23 00:16:36.455211: Epoch 379\n",
            "2025-12-23 00:16:36.455381: Current learning rate: 0.00651\n",
            "2025-12-23 00:16:58.950041: train_loss -0.962\n",
            "2025-12-23 00:16:58.950516: val_loss -0.9765\n",
            "2025-12-23 00:16:58.950718: Pseudo dice [np.float32(0.9822)]\n",
            "2025-12-23 00:16:58.950893: Epoch time: 22.5 s\n",
            "2025-12-23 00:17:00.322441: \n",
            "2025-12-23 00:17:00.322766: Epoch 380\n",
            "2025-12-23 00:17:00.322898: Current learning rate: 0.0065\n",
            "2025-12-23 00:17:22.841698: train_loss -0.9643\n",
            "2025-12-23 00:17:22.841970: val_loss -0.9802\n",
            "2025-12-23 00:17:22.842084: Pseudo dice [np.float32(0.9857)]\n",
            "2025-12-23 00:17:22.842201: Epoch time: 22.52 s\n",
            "2025-12-23 00:17:24.252064: \n",
            "2025-12-23 00:17:24.252373: Epoch 381\n",
            "2025-12-23 00:17:24.252526: Current learning rate: 0.00649\n",
            "2025-12-23 00:17:46.721767: train_loss -0.9603\n",
            "2025-12-23 00:17:46.722040: val_loss -0.9807\n",
            "2025-12-23 00:17:46.722136: Pseudo dice [np.float32(0.9849)]\n",
            "2025-12-23 00:17:46.722250: Epoch time: 22.47 s\n",
            "2025-12-23 00:17:48.131811: \n",
            "2025-12-23 00:17:48.132205: Epoch 382\n",
            "2025-12-23 00:17:48.132363: Current learning rate: 0.00648\n",
            "2025-12-23 00:18:10.589776: train_loss -0.9625\n",
            "2025-12-23 00:18:10.589983: val_loss -0.9816\n",
            "2025-12-23 00:18:10.590073: Pseudo dice [np.float32(0.9857)]\n",
            "2025-12-23 00:18:10.590203: Epoch time: 22.46 s\n",
            "2025-12-23 00:18:11.967208: \n",
            "2025-12-23 00:18:11.967483: Epoch 383\n",
            "2025-12-23 00:18:11.967621: Current learning rate: 0.00648\n",
            "2025-12-23 00:18:34.434309: train_loss -0.9659\n",
            "2025-12-23 00:18:34.434747: val_loss -0.9825\n",
            "2025-12-23 00:18:34.434914: Pseudo dice [np.float32(0.9868)]\n",
            "2025-12-23 00:18:34.435030: Epoch time: 22.47 s\n",
            "2025-12-23 00:18:35.842063: \n",
            "2025-12-23 00:18:35.842271: Epoch 384\n",
            "2025-12-23 00:18:35.842428: Current learning rate: 0.00647\n",
            "2025-12-23 00:18:58.348928: train_loss -0.9645\n",
            "2025-12-23 00:18:58.349144: val_loss -0.982\n",
            "2025-12-23 00:18:58.349345: Pseudo dice [np.float32(0.9869)]\n",
            "2025-12-23 00:18:58.349480: Epoch time: 22.51 s\n",
            "2025-12-23 00:18:59.736427: \n",
            "2025-12-23 00:18:59.736668: Epoch 385\n",
            "2025-12-23 00:18:59.736821: Current learning rate: 0.00646\n",
            "2025-12-23 00:19:22.239358: train_loss -0.9661\n",
            "2025-12-23 00:19:22.239578: val_loss -0.9755\n",
            "2025-12-23 00:19:22.239666: Pseudo dice [np.float32(0.9821)]\n",
            "2025-12-23 00:19:22.239763: Epoch time: 22.5 s\n",
            "2025-12-23 00:19:23.614652: \n",
            "2025-12-23 00:19:23.614856: Epoch 386\n",
            "2025-12-23 00:19:23.614982: Current learning rate: 0.00645\n",
            "2025-12-23 00:19:46.030312: train_loss -0.9639\n",
            "2025-12-23 00:19:46.030596: val_loss -0.9817\n",
            "2025-12-23 00:19:46.030721: Pseudo dice [np.float32(0.9863)]\n",
            "2025-12-23 00:19:46.030816: Epoch time: 22.42 s\n",
            "2025-12-23 00:19:47.428444: \n",
            "2025-12-23 00:19:47.428725: Epoch 387\n",
            "2025-12-23 00:19:47.428879: Current learning rate: 0.00644\n",
            "2025-12-23 00:20:09.924970: train_loss -0.9661\n",
            "2025-12-23 00:20:09.925172: val_loss -0.983\n",
            "2025-12-23 00:20:09.925292: Pseudo dice [np.float32(0.9877)]\n",
            "2025-12-23 00:20:09.925395: Epoch time: 22.5 s\n",
            "2025-12-23 00:20:11.322871: \n",
            "2025-12-23 00:20:11.323103: Epoch 388\n",
            "2025-12-23 00:20:11.323252: Current learning rate: 0.00643\n",
            "2025-12-23 00:20:33.694727: train_loss -0.9681\n",
            "2025-12-23 00:20:33.694957: val_loss -0.9838\n",
            "2025-12-23 00:20:33.695048: Pseudo dice [np.float32(0.9876)]\n",
            "2025-12-23 00:20:33.695175: Epoch time: 22.37 s\n",
            "2025-12-23 00:20:35.125536: \n",
            "2025-12-23 00:20:35.125812: Epoch 389\n",
            "2025-12-23 00:20:35.125947: Current learning rate: 0.00642\n",
            "2025-12-23 00:20:57.552644: train_loss -0.9699\n",
            "2025-12-23 00:20:57.552842: val_loss -0.9839\n",
            "2025-12-23 00:20:57.552932: Pseudo dice [np.float32(0.988)]\n",
            "2025-12-23 00:20:57.553173: Epoch time: 22.43 s\n",
            "2025-12-23 00:20:58.956661: \n",
            "2025-12-23 00:20:58.956995: Epoch 390\n",
            "2025-12-23 00:20:58.957129: Current learning rate: 0.00641\n",
            "2025-12-23 00:21:21.374317: train_loss -0.9709\n",
            "2025-12-23 00:21:21.374638: val_loss -0.9828\n",
            "2025-12-23 00:21:21.374844: Pseudo dice [np.float32(0.9873)]\n",
            "2025-12-23 00:21:21.375056: Epoch time: 22.42 s\n",
            "2025-12-23 00:21:22.778511: \n",
            "2025-12-23 00:21:22.778787: Epoch 391\n",
            "2025-12-23 00:21:22.778935: Current learning rate: 0.0064\n",
            "2025-12-23 00:21:45.163663: train_loss -0.97\n",
            "2025-12-23 00:21:45.163912: val_loss -0.9848\n",
            "2025-12-23 00:21:45.164018: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 00:21:45.164106: Epoch time: 22.39 s\n",
            "2025-12-23 00:21:47.247671: \n",
            "2025-12-23 00:21:47.247960: Epoch 392\n",
            "2025-12-23 00:21:47.248138: Current learning rate: 0.00639\n",
            "2025-12-23 00:22:09.747111: train_loss -0.971\n",
            "2025-12-23 00:22:09.747587: val_loss -0.9828\n",
            "2025-12-23 00:22:09.747748: Pseudo dice [np.float32(0.9859)]\n",
            "2025-12-23 00:22:09.747881: Epoch time: 22.5 s\n",
            "2025-12-23 00:22:11.136014: \n",
            "2025-12-23 00:22:11.136384: Epoch 393\n",
            "2025-12-23 00:22:11.136550: Current learning rate: 0.00638\n",
            "2025-12-23 00:22:33.592145: train_loss -0.9706\n",
            "2025-12-23 00:22:33.592576: val_loss -0.9839\n",
            "2025-12-23 00:22:33.592712: Pseudo dice [np.float32(0.9877)]\n",
            "2025-12-23 00:22:33.592836: Epoch time: 22.46 s\n",
            "2025-12-23 00:22:34.963829: \n",
            "2025-12-23 00:22:34.964205: Epoch 394\n",
            "2025-12-23 00:22:34.964374: Current learning rate: 0.00637\n",
            "2025-12-23 00:22:57.463089: train_loss -0.9691\n",
            "2025-12-23 00:22:57.463336: val_loss -0.9849\n",
            "2025-12-23 00:22:57.463453: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 00:22:57.463574: Epoch time: 22.5 s\n",
            "2025-12-23 00:22:58.863959: \n",
            "2025-12-23 00:22:58.864181: Epoch 395\n",
            "2025-12-23 00:22:58.864345: Current learning rate: 0.00636\n",
            "2025-12-23 00:23:21.359275: train_loss -0.9709\n",
            "2025-12-23 00:23:21.359744: val_loss -0.9832\n",
            "2025-12-23 00:23:21.359930: Pseudo dice [np.float32(0.9874)]\n",
            "2025-12-23 00:23:21.360124: Epoch time: 22.5 s\n",
            "2025-12-23 00:23:22.750580: \n",
            "2025-12-23 00:23:22.750959: Epoch 396\n",
            "2025-12-23 00:23:22.751113: Current learning rate: 0.00635\n",
            "2025-12-23 00:23:45.194888: train_loss -0.9702\n",
            "2025-12-23 00:23:45.195184: val_loss -0.9836\n",
            "2025-12-23 00:23:45.195304: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 00:23:45.195396: Epoch time: 22.45 s\n",
            "2025-12-23 00:23:46.609417: \n",
            "2025-12-23 00:23:46.609725: Epoch 397\n",
            "2025-12-23 00:23:46.609910: Current learning rate: 0.00634\n",
            "2025-12-23 00:24:09.108587: train_loss -0.9707\n",
            "2025-12-23 00:24:09.108796: val_loss -0.9847\n",
            "2025-12-23 00:24:09.108888: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 00:24:09.108978: Epoch time: 22.5 s\n",
            "2025-12-23 00:24:10.507422: \n",
            "2025-12-23 00:24:10.507795: Epoch 398\n",
            "2025-12-23 00:24:10.507933: Current learning rate: 0.00633\n",
            "2025-12-23 00:24:32.901801: train_loss -0.9696\n",
            "2025-12-23 00:24:32.902064: val_loss -0.9836\n",
            "2025-12-23 00:24:32.902183: Pseudo dice [np.float32(0.9875)]\n",
            "2025-12-23 00:24:32.902400: Epoch time: 22.4 s\n",
            "2025-12-23 00:24:34.299610: \n",
            "2025-12-23 00:24:34.299966: Epoch 399\n",
            "2025-12-23 00:24:34.300117: Current learning rate: 0.00632\n",
            "2025-12-23 00:24:56.738507: train_loss -0.9693\n",
            "2025-12-23 00:24:56.738720: val_loss -0.983\n",
            "2025-12-23 00:24:56.738894: Pseudo dice [np.float32(0.9865)]\n",
            "2025-12-23 00:24:56.739093: Epoch time: 22.44 s\n",
            "2025-12-23 00:24:58.642988: \n",
            "2025-12-23 00:24:58.643199: Epoch 400\n",
            "2025-12-23 00:24:58.643362: Current learning rate: 0.00631\n",
            "2025-12-23 00:25:21.095778: train_loss -0.9707\n",
            "2025-12-23 00:25:21.096020: val_loss -0.984\n",
            "2025-12-23 00:25:21.096197: Pseudo dice [np.float32(0.9869)]\n",
            "2025-12-23 00:25:21.096402: Epoch time: 22.45 s\n",
            "2025-12-23 00:25:22.525468: \n",
            "2025-12-23 00:25:22.525771: Epoch 401\n",
            "2025-12-23 00:25:22.525901: Current learning rate: 0.0063\n",
            "2025-12-23 00:25:44.938782: train_loss -0.9708\n",
            "2025-12-23 00:25:44.939015: val_loss -0.9833\n",
            "2025-12-23 00:25:44.939111: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 00:25:44.939209: Epoch time: 22.41 s\n",
            "2025-12-23 00:25:46.345078: \n",
            "2025-12-23 00:25:46.345305: Epoch 402\n",
            "2025-12-23 00:25:46.345447: Current learning rate: 0.0063\n",
            "2025-12-23 00:26:08.799018: train_loss -0.9713\n",
            "2025-12-23 00:26:08.799252: val_loss -0.9837\n",
            "2025-12-23 00:26:08.799364: Pseudo dice [np.float32(0.9871)]\n",
            "2025-12-23 00:26:08.799457: Epoch time: 22.46 s\n",
            "2025-12-23 00:26:10.190771: \n",
            "2025-12-23 00:26:10.191097: Epoch 403\n",
            "2025-12-23 00:26:10.191239: Current learning rate: 0.00629\n",
            "2025-12-23 00:26:32.673794: train_loss -0.9704\n",
            "2025-12-23 00:26:32.674003: val_loss -0.9832\n",
            "2025-12-23 00:26:32.674156: Pseudo dice [np.float32(0.9869)]\n",
            "2025-12-23 00:26:32.674276: Epoch time: 22.48 s\n",
            "2025-12-23 00:26:34.038287: \n",
            "2025-12-23 00:26:34.038450: Epoch 404\n",
            "2025-12-23 00:26:34.038612: Current learning rate: 0.00628\n",
            "2025-12-23 00:26:56.494115: train_loss -0.9727\n",
            "2025-12-23 00:26:56.494378: val_loss -0.9846\n",
            "2025-12-23 00:26:56.494468: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 00:26:56.494559: Epoch time: 22.46 s\n",
            "2025-12-23 00:26:57.896290: \n",
            "2025-12-23 00:26:57.896463: Epoch 405\n",
            "2025-12-23 00:26:57.896640: Current learning rate: 0.00627\n",
            "2025-12-23 00:27:20.343261: train_loss -0.9721\n",
            "2025-12-23 00:27:20.343529: val_loss -0.9855\n",
            "2025-12-23 00:27:20.343639: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 00:27:20.343732: Epoch time: 22.45 s\n",
            "2025-12-23 00:27:21.744384: \n",
            "2025-12-23 00:27:21.744634: Epoch 406\n",
            "2025-12-23 00:27:21.744763: Current learning rate: 0.00626\n",
            "2025-12-23 00:27:44.177601: train_loss -0.9713\n",
            "2025-12-23 00:27:44.177798: val_loss -0.9842\n",
            "2025-12-23 00:27:44.177884: Pseudo dice [np.float32(0.988)]\n",
            "2025-12-23 00:27:44.177981: Epoch time: 22.43 s\n",
            "2025-12-23 00:27:44.178057: Yayy! New best EMA pseudo Dice: 0.987500011920929\n",
            "2025-12-23 00:27:46.017341: \n",
            "2025-12-23 00:27:46.017523: Epoch 407\n",
            "2025-12-23 00:27:46.017652: Current learning rate: 0.00625\n",
            "2025-12-23 00:28:08.460106: train_loss -0.9713\n",
            "2025-12-23 00:28:08.460319: val_loss -0.9836\n",
            "2025-12-23 00:28:08.460435: Pseudo dice [np.float32(0.9876)]\n",
            "2025-12-23 00:28:08.460563: Epoch time: 22.44 s\n",
            "2025-12-23 00:28:08.460768: Yayy! New best EMA pseudo Dice: 0.987500011920929\n",
            "2025-12-23 00:28:10.974709: \n",
            "2025-12-23 00:28:10.975011: Epoch 408\n",
            "2025-12-23 00:28:10.975171: Current learning rate: 0.00624\n",
            "2025-12-23 00:28:33.471909: train_loss -0.9709\n",
            "2025-12-23 00:28:33.472150: val_loss -0.9838\n",
            "2025-12-23 00:28:33.472335: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 00:28:33.472442: Epoch time: 22.5 s\n",
            "2025-12-23 00:28:33.472564: Yayy! New best EMA pseudo Dice: 0.9876000285148621\n",
            "2025-12-23 00:28:35.299679: \n",
            "2025-12-23 00:28:35.299984: Epoch 409\n",
            "2025-12-23 00:28:35.300137: Current learning rate: 0.00623\n",
            "2025-12-23 00:28:57.799286: train_loss -0.9723\n",
            "2025-12-23 00:28:57.799534: val_loss -0.9841\n",
            "2025-12-23 00:28:57.799625: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 00:28:57.799715: Epoch time: 22.5 s\n",
            "2025-12-23 00:28:57.799790: Yayy! New best EMA pseudo Dice: 0.9878000020980835\n",
            "2025-12-23 00:28:59.674432: \n",
            "2025-12-23 00:28:59.674755: Epoch 410\n",
            "2025-12-23 00:28:59.674960: Current learning rate: 0.00622\n",
            "2025-12-23 00:29:22.143380: train_loss -0.9709\n",
            "2025-12-23 00:29:22.143665: val_loss -0.9847\n",
            "2025-12-23 00:29:22.143759: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 00:29:22.143847: Epoch time: 22.47 s\n",
            "2025-12-23 00:29:22.143921: Yayy! New best EMA pseudo Dice: 0.9879000186920166\n",
            "2025-12-23 00:29:23.957611: \n",
            "2025-12-23 00:29:23.957874: Epoch 411\n",
            "2025-12-23 00:29:23.958016: Current learning rate: 0.00621\n",
            "2025-12-23 00:29:46.403082: train_loss -0.9703\n",
            "2025-12-23 00:29:46.403313: val_loss -0.984\n",
            "2025-12-23 00:29:46.403404: Pseudo dice [np.float32(0.9876)]\n",
            "2025-12-23 00:29:46.403566: Epoch time: 22.45 s\n",
            "2025-12-23 00:29:47.744571: \n",
            "2025-12-23 00:29:47.744931: Epoch 412\n",
            "2025-12-23 00:29:47.745064: Current learning rate: 0.0062\n",
            "2025-12-23 00:30:10.222672: train_loss -0.9711\n",
            "2025-12-23 00:30:10.222877: val_loss -0.9841\n",
            "2025-12-23 00:30:10.222967: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 00:30:10.223064: Epoch time: 22.48 s\n",
            "2025-12-23 00:30:10.223282: Yayy! New best EMA pseudo Dice: 0.9879000186920166\n",
            "2025-12-23 00:30:12.102722: \n",
            "2025-12-23 00:30:12.103117: Epoch 413\n",
            "2025-12-23 00:30:12.103290: Current learning rate: 0.00619\n",
            "2025-12-23 00:30:34.591440: train_loss -0.9708\n",
            "2025-12-23 00:30:34.591754: val_loss -0.9825\n",
            "2025-12-23 00:30:34.591853: Pseudo dice [np.float32(0.9874)]\n",
            "2025-12-23 00:30:34.591946: Epoch time: 22.49 s\n",
            "2025-12-23 00:30:35.965540: \n",
            "2025-12-23 00:30:35.965878: Epoch 414\n",
            "2025-12-23 00:30:35.966030: Current learning rate: 0.00618\n",
            "2025-12-23 00:30:58.444063: train_loss -0.9713\n",
            "2025-12-23 00:30:58.444309: val_loss -0.9837\n",
            "2025-12-23 00:30:58.444409: Pseudo dice [np.float32(0.9879)]\n",
            "2025-12-23 00:30:58.444504: Epoch time: 22.48 s\n",
            "2025-12-23 00:30:59.839649: \n",
            "2025-12-23 00:30:59.839860: Epoch 415\n",
            "2025-12-23 00:30:59.840021: Current learning rate: 0.00617\n",
            "2025-12-23 00:31:22.261062: train_loss -0.9715\n",
            "2025-12-23 00:31:22.261282: val_loss -0.9862\n",
            "2025-12-23 00:31:22.261388: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 00:31:22.261480: Epoch time: 22.42 s\n",
            "2025-12-23 00:31:22.261560: Yayy! New best EMA pseudo Dice: 0.9879000186920166\n",
            "2025-12-23 00:31:24.127652: \n",
            "2025-12-23 00:31:24.127958: Epoch 416\n",
            "2025-12-23 00:31:24.128104: Current learning rate: 0.00616\n",
            "2025-12-23 00:31:46.567699: train_loss -0.9718\n",
            "2025-12-23 00:31:46.568081: val_loss -0.9844\n",
            "2025-12-23 00:31:46.568175: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 00:31:46.568332: Epoch time: 22.44 s\n",
            "2025-12-23 00:31:47.916648: \n",
            "2025-12-23 00:31:47.916832: Epoch 417\n",
            "2025-12-23 00:31:47.916973: Current learning rate: 0.00615\n",
            "2025-12-23 00:32:10.324033: train_loss -0.9709\n",
            "2025-12-23 00:32:10.324359: val_loss -0.9839\n",
            "2025-12-23 00:32:10.324458: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 00:32:10.324553: Epoch time: 22.41 s\n",
            "2025-12-23 00:32:10.324636: Yayy! New best EMA pseudo Dice: 0.9879999756813049\n",
            "2025-12-23 00:32:12.225912: \n",
            "2025-12-23 00:32:12.226419: Epoch 418\n",
            "2025-12-23 00:32:12.226579: Current learning rate: 0.00614\n",
            "2025-12-23 00:32:34.681282: train_loss -0.9703\n",
            "2025-12-23 00:32:34.681718: val_loss -0.984\n",
            "2025-12-23 00:32:34.681901: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 00:32:34.682049: Epoch time: 22.46 s\n",
            "2025-12-23 00:32:34.682163: Yayy! New best EMA pseudo Dice: 0.9879999756813049\n",
            "2025-12-23 00:32:36.540425: \n",
            "2025-12-23 00:32:36.540749: Epoch 419\n",
            "2025-12-23 00:32:36.540879: Current learning rate: 0.00613\n",
            "2025-12-23 00:32:58.969291: train_loss -0.9714\n",
            "2025-12-23 00:32:58.969584: val_loss -0.9838\n",
            "2025-12-23 00:32:58.969679: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 00:32:58.969770: Epoch time: 22.43 s\n",
            "2025-12-23 00:32:58.969857: Yayy! New best EMA pseudo Dice: 0.988099992275238\n",
            "2025-12-23 00:33:00.793128: \n",
            "2025-12-23 00:33:00.793293: Epoch 420\n",
            "2025-12-23 00:33:00.793418: Current learning rate: 0.00612\n",
            "2025-12-23 00:33:23.260412: train_loss -0.9709\n",
            "2025-12-23 00:33:23.260624: val_loss -0.9855\n",
            "2025-12-23 00:33:23.260734: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 00:33:23.260830: Epoch time: 22.47 s\n",
            "2025-12-23 00:33:23.260998: Yayy! New best EMA pseudo Dice: 0.9882000088691711\n",
            "2025-12-23 00:33:25.102139: \n",
            "2025-12-23 00:33:25.102330: Epoch 421\n",
            "2025-12-23 00:33:25.102592: Current learning rate: 0.00612\n",
            "2025-12-23 00:33:47.556766: train_loss -0.972\n",
            "2025-12-23 00:33:47.557023: val_loss -0.9834\n",
            "2025-12-23 00:33:47.557142: Pseudo dice [np.float32(0.9876)]\n",
            "2025-12-23 00:33:47.557272: Epoch time: 22.46 s\n",
            "2025-12-23 00:33:48.918385: \n",
            "2025-12-23 00:33:48.918564: Epoch 422\n",
            "2025-12-23 00:33:48.918690: Current learning rate: 0.00611\n",
            "2025-12-23 00:34:11.354303: train_loss -0.9726\n",
            "2025-12-23 00:34:11.354531: val_loss -0.9831\n",
            "2025-12-23 00:34:11.354622: Pseudo dice [np.float32(0.988)]\n",
            "2025-12-23 00:34:11.354721: Epoch time: 22.44 s\n",
            "2025-12-23 00:34:12.731772: \n",
            "2025-12-23 00:34:12.732054: Epoch 423\n",
            "2025-12-23 00:34:12.732199: Current learning rate: 0.0061\n",
            "2025-12-23 00:34:35.191511: train_loss -0.9727\n",
            "2025-12-23 00:34:35.191705: val_loss -0.985\n",
            "2025-12-23 00:34:35.191795: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 00:34:35.191884: Epoch time: 22.46 s\n",
            "2025-12-23 00:34:35.191957: Yayy! New best EMA pseudo Dice: 0.9882000088691711\n",
            "2025-12-23 00:34:37.025399: \n",
            "2025-12-23 00:34:37.025703: Epoch 424\n",
            "2025-12-23 00:34:37.025863: Current learning rate: 0.00609\n",
            "2025-12-23 00:34:59.472127: train_loss -0.9718\n",
            "2025-12-23 00:34:59.472341: val_loss -0.9835\n",
            "2025-12-23 00:34:59.472430: Pseudo dice [np.float32(0.9873)]\n",
            "2025-12-23 00:34:59.472529: Epoch time: 22.45 s\n",
            "2025-12-23 00:35:00.830056: \n",
            "2025-12-23 00:35:00.830368: Epoch 425\n",
            "2025-12-23 00:35:00.830503: Current learning rate: 0.00608\n",
            "2025-12-23 00:35:23.233721: train_loss -0.9723\n",
            "2025-12-23 00:35:23.234099: val_loss -0.9847\n",
            "2025-12-23 00:35:23.234239: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 00:35:23.234363: Epoch time: 22.4 s\n",
            "2025-12-23 00:35:25.212611: \n",
            "2025-12-23 00:35:25.212937: Epoch 426\n",
            "2025-12-23 00:35:25.213108: Current learning rate: 0.00607\n",
            "2025-12-23 00:35:47.656507: train_loss -0.9724\n",
            "2025-12-23 00:35:47.656711: val_loss -0.9847\n",
            "2025-12-23 00:35:47.656831: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 00:35:47.656935: Epoch time: 22.45 s\n",
            "2025-12-23 00:35:47.657012: Yayy! New best EMA pseudo Dice: 0.9883000254631042\n",
            "2025-12-23 00:35:49.454349: \n",
            "2025-12-23 00:35:49.454741: Epoch 427\n",
            "2025-12-23 00:35:49.454892: Current learning rate: 0.00606\n",
            "2025-12-23 00:36:11.906656: train_loss -0.9717\n",
            "2025-12-23 00:36:11.906954: val_loss -0.984\n",
            "2025-12-23 00:36:11.907138: Pseudo dice [np.float32(0.988)]\n",
            "2025-12-23 00:36:11.907271: Epoch time: 22.45 s\n",
            "2025-12-23 00:36:13.236737: \n",
            "2025-12-23 00:36:13.237033: Epoch 428\n",
            "2025-12-23 00:36:13.237204: Current learning rate: 0.00605\n",
            "2025-12-23 00:36:35.681801: train_loss -0.9723\n",
            "2025-12-23 00:36:35.682037: val_loss -0.9843\n",
            "2025-12-23 00:36:35.682126: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 00:36:35.682230: Epoch time: 22.45 s\n",
            "2025-12-23 00:36:37.049269: \n",
            "2025-12-23 00:36:37.049566: Epoch 429\n",
            "2025-12-23 00:36:37.049698: Current learning rate: 0.00604\n",
            "2025-12-23 00:36:59.537200: train_loss -0.9723\n",
            "2025-12-23 00:36:59.537466: val_loss -0.9849\n",
            "2025-12-23 00:36:59.537564: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 00:36:59.537656: Epoch time: 22.49 s\n",
            "2025-12-23 00:37:00.887745: \n",
            "2025-12-23 00:37:00.888078: Epoch 430\n",
            "2025-12-23 00:37:00.888211: Current learning rate: 0.00603\n",
            "2025-12-23 00:37:23.392877: train_loss -0.9714\n",
            "2025-12-23 00:37:23.393144: val_loss -0.9851\n",
            "2025-12-23 00:37:23.393284: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 00:37:23.393402: Epoch time: 22.51 s\n",
            "2025-12-23 00:37:24.741674: \n",
            "2025-12-23 00:37:24.741951: Epoch 431\n",
            "2025-12-23 00:37:24.742080: Current learning rate: 0.00602\n",
            "2025-12-23 00:37:47.215209: train_loss -0.9721\n",
            "2025-12-23 00:37:47.215499: val_loss -0.9849\n",
            "2025-12-23 00:37:47.215608: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 00:37:47.215719: Epoch time: 22.47 s\n",
            "2025-12-23 00:37:48.583924: \n",
            "2025-12-23 00:37:48.584308: Epoch 432\n",
            "2025-12-23 00:37:48.584483: Current learning rate: 0.00601\n",
            "2025-12-23 00:38:11.062148: train_loss -0.9713\n",
            "2025-12-23 00:38:11.062409: val_loss -0.9854\n",
            "2025-12-23 00:38:11.062501: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 00:38:11.062607: Epoch time: 22.48 s\n",
            "2025-12-23 00:38:11.062704: Yayy! New best EMA pseudo Dice: 0.9883999824523926\n",
            "2025-12-23 00:38:12.876392: \n",
            "2025-12-23 00:38:12.876672: Epoch 433\n",
            "2025-12-23 00:38:12.876804: Current learning rate: 0.006\n",
            "2025-12-23 00:38:35.414089: train_loss -0.9727\n",
            "2025-12-23 00:38:35.414344: val_loss -0.9859\n",
            "2025-12-23 00:38:35.414516: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 00:38:35.414620: Epoch time: 22.54 s\n",
            "2025-12-23 00:38:35.414698: Yayy! New best EMA pseudo Dice: 0.9884999990463257\n",
            "2025-12-23 00:38:37.296611: \n",
            "2025-12-23 00:38:37.296888: Epoch 434\n",
            "2025-12-23 00:38:37.297022: Current learning rate: 0.00599\n",
            "2025-12-23 00:38:59.749456: train_loss -0.9725\n",
            "2025-12-23 00:38:59.749735: val_loss -0.9836\n",
            "2025-12-23 00:38:59.749827: Pseudo dice [np.float32(0.9874)]\n",
            "2025-12-23 00:38:59.749918: Epoch time: 22.45 s\n",
            "2025-12-23 00:39:01.073185: \n",
            "2025-12-23 00:39:01.073574: Epoch 435\n",
            "2025-12-23 00:39:01.073708: Current learning rate: 0.00598\n",
            "2025-12-23 00:39:23.519522: train_loss -0.9706\n",
            "2025-12-23 00:39:23.519792: val_loss -0.9842\n",
            "2025-12-23 00:39:23.519886: Pseudo dice [np.float32(0.9877)]\n",
            "2025-12-23 00:39:23.519976: Epoch time: 22.45 s\n",
            "2025-12-23 00:39:24.903136: \n",
            "2025-12-23 00:39:24.903323: Epoch 436\n",
            "2025-12-23 00:39:24.903465: Current learning rate: 0.00597\n",
            "2025-12-23 00:39:47.340885: train_loss -0.9696\n",
            "2025-12-23 00:39:47.341113: val_loss -0.9836\n",
            "2025-12-23 00:39:47.341209: Pseudo dice [np.float32(0.9873)]\n",
            "2025-12-23 00:39:47.341319: Epoch time: 22.44 s\n",
            "2025-12-23 00:39:48.688614: \n",
            "2025-12-23 00:39:48.688854: Epoch 437\n",
            "2025-12-23 00:39:48.688981: Current learning rate: 0.00596\n",
            "2025-12-23 00:40:11.102088: train_loss -0.9711\n",
            "2025-12-23 00:40:11.102520: val_loss -0.9825\n",
            "2025-12-23 00:40:11.102629: Pseudo dice [np.float32(0.9868)]\n",
            "2025-12-23 00:40:11.102737: Epoch time: 22.41 s\n",
            "2025-12-23 00:40:12.463611: \n",
            "2025-12-23 00:40:12.464004: Epoch 438\n",
            "2025-12-23 00:40:12.464152: Current learning rate: 0.00595\n",
            "2025-12-23 00:40:34.890501: train_loss -0.9686\n",
            "2025-12-23 00:40:34.890693: val_loss -0.9839\n",
            "2025-12-23 00:40:34.890785: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 00:40:34.890874: Epoch time: 22.43 s\n",
            "2025-12-23 00:40:36.238155: \n",
            "2025-12-23 00:40:36.238423: Epoch 439\n",
            "2025-12-23 00:40:36.238560: Current learning rate: 0.00594\n",
            "2025-12-23 00:40:58.649834: train_loss -0.9681\n",
            "2025-12-23 00:40:58.650036: val_loss -0.9823\n",
            "2025-12-23 00:40:58.650126: Pseudo dice [np.float32(0.9874)]\n",
            "2025-12-23 00:40:58.650234: Epoch time: 22.41 s\n",
            "2025-12-23 00:40:59.988324: \n",
            "2025-12-23 00:40:59.988508: Epoch 440\n",
            "2025-12-23 00:40:59.988642: Current learning rate: 0.00593\n",
            "2025-12-23 00:41:22.405194: train_loss -0.9682\n",
            "2025-12-23 00:41:22.405458: val_loss -0.9801\n",
            "2025-12-23 00:41:22.405557: Pseudo dice [np.float32(0.9854)]\n",
            "2025-12-23 00:41:22.405654: Epoch time: 22.42 s\n",
            "2025-12-23 00:41:23.757651: \n",
            "2025-12-23 00:41:23.758041: Epoch 441\n",
            "2025-12-23 00:41:23.758178: Current learning rate: 0.00592\n",
            "2025-12-23 00:41:46.191004: train_loss -0.9614\n",
            "2025-12-23 00:41:46.191198: val_loss -0.9753\n",
            "2025-12-23 00:41:46.191338: Pseudo dice [np.float32(0.9801)]\n",
            "2025-12-23 00:41:46.191435: Epoch time: 22.43 s\n",
            "2025-12-23 00:41:47.577268: \n",
            "2025-12-23 00:41:47.577523: Epoch 442\n",
            "2025-12-23 00:41:47.577703: Current learning rate: 0.00592\n",
            "2025-12-23 00:42:10.010644: train_loss -0.9616\n",
            "2025-12-23 00:42:10.011058: val_loss -0.9809\n",
            "2025-12-23 00:42:10.011247: Pseudo dice [np.float32(0.986)]\n",
            "2025-12-23 00:42:10.011357: Epoch time: 22.43 s\n",
            "2025-12-23 00:42:11.334223: \n",
            "2025-12-23 00:42:11.334527: Epoch 443\n",
            "2025-12-23 00:42:11.334657: Current learning rate: 0.00591\n",
            "2025-12-23 00:42:33.778966: train_loss -0.967\n",
            "2025-12-23 00:42:33.779161: val_loss -0.9825\n",
            "2025-12-23 00:42:33.779283: Pseudo dice [np.float32(0.9879)]\n",
            "2025-12-23 00:42:33.779391: Epoch time: 22.45 s\n",
            "2025-12-23 00:42:35.791947: \n",
            "2025-12-23 00:42:35.792262: Epoch 444\n",
            "2025-12-23 00:42:35.792408: Current learning rate: 0.0059\n",
            "2025-12-23 00:42:58.276087: train_loss -0.9701\n",
            "2025-12-23 00:42:58.276342: val_loss -0.9841\n",
            "2025-12-23 00:42:58.276443: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 00:42:58.276544: Epoch time: 22.49 s\n",
            "2025-12-23 00:42:59.601773: \n",
            "2025-12-23 00:42:59.602116: Epoch 445\n",
            "2025-12-23 00:42:59.602274: Current learning rate: 0.00589\n",
            "2025-12-23 00:43:22.016160: train_loss -0.9691\n",
            "2025-12-23 00:43:22.016583: val_loss -0.9805\n",
            "2025-12-23 00:43:22.016688: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 00:43:22.016792: Epoch time: 22.42 s\n",
            "2025-12-23 00:43:23.337613: \n",
            "2025-12-23 00:43:23.337941: Epoch 446\n",
            "2025-12-23 00:43:23.338079: Current learning rate: 0.00588\n",
            "2025-12-23 00:43:45.789146: train_loss -0.9673\n",
            "2025-12-23 00:43:45.789383: val_loss -0.9786\n",
            "2025-12-23 00:43:45.789482: Pseudo dice [np.float32(0.9837)]\n",
            "2025-12-23 00:43:45.789582: Epoch time: 22.45 s\n",
            "2025-12-23 00:43:47.105056: \n",
            "2025-12-23 00:43:47.105325: Epoch 447\n",
            "2025-12-23 00:43:47.105547: Current learning rate: 0.00587\n",
            "2025-12-23 00:44:09.525586: train_loss -0.9645\n",
            "2025-12-23 00:44:09.525804: val_loss -0.9797\n",
            "2025-12-23 00:44:09.525924: Pseudo dice [np.float32(0.9843)]\n",
            "2025-12-23 00:44:09.526019: Epoch time: 22.42 s\n",
            "2025-12-23 00:44:10.907001: \n",
            "2025-12-23 00:44:10.907266: Epoch 448\n",
            "2025-12-23 00:44:10.907402: Current learning rate: 0.00586\n",
            "2025-12-23 00:44:33.348838: train_loss -0.9669\n",
            "2025-12-23 00:44:33.349172: val_loss -0.9823\n",
            "2025-12-23 00:44:33.349330: Pseudo dice [np.float32(0.9875)]\n",
            "2025-12-23 00:44:33.349446: Epoch time: 22.44 s\n",
            "2025-12-23 00:44:34.726853: \n",
            "2025-12-23 00:44:34.727201: Epoch 449\n",
            "2025-12-23 00:44:34.727387: Current learning rate: 0.00585\n",
            "2025-12-23 00:44:57.187966: train_loss -0.9689\n",
            "2025-12-23 00:44:57.188171: val_loss -0.983\n",
            "2025-12-23 00:44:57.188302: Pseudo dice [np.float32(0.9875)]\n",
            "2025-12-23 00:44:57.188459: Epoch time: 22.46 s\n",
            "2025-12-23 00:44:59.064762: \n",
            "2025-12-23 00:44:59.065164: Epoch 450\n",
            "2025-12-23 00:44:59.065356: Current learning rate: 0.00584\n",
            "2025-12-23 00:45:21.557706: train_loss -0.9691\n",
            "2025-12-23 00:45:21.557954: val_loss -0.9839\n",
            "2025-12-23 00:45:21.558080: Pseudo dice [np.float32(0.988)]\n",
            "2025-12-23 00:45:21.558256: Epoch time: 22.49 s\n",
            "2025-12-23 00:45:22.936732: \n",
            "2025-12-23 00:45:22.937044: Epoch 451\n",
            "2025-12-23 00:45:22.937250: Current learning rate: 0.00583\n",
            "2025-12-23 00:45:45.374552: train_loss -0.9656\n",
            "2025-12-23 00:45:45.374833: val_loss -0.9748\n",
            "2025-12-23 00:45:45.374974: Pseudo dice [np.float32(0.9789)]\n",
            "2025-12-23 00:45:45.375116: Epoch time: 22.44 s\n",
            "2025-12-23 00:45:46.720703: \n",
            "2025-12-23 00:45:46.721064: Epoch 452\n",
            "2025-12-23 00:45:46.721212: Current learning rate: 0.00582\n",
            "2025-12-23 00:46:09.127722: train_loss -0.9511\n",
            "2025-12-23 00:46:09.128010: val_loss -0.9766\n",
            "2025-12-23 00:46:09.128183: Pseudo dice [np.float32(0.9819)]\n",
            "2025-12-23 00:46:09.128335: Epoch time: 22.41 s\n",
            "2025-12-23 00:46:10.506191: \n",
            "2025-12-23 00:46:10.506456: Epoch 453\n",
            "2025-12-23 00:46:10.506603: Current learning rate: 0.00581\n",
            "2025-12-23 00:46:32.937566: train_loss -0.9608\n",
            "2025-12-23 00:46:32.937923: val_loss -0.9804\n",
            "2025-12-23 00:46:32.938022: Pseudo dice [np.float32(0.9858)]\n",
            "2025-12-23 00:46:32.938114: Epoch time: 22.43 s\n",
            "2025-12-23 00:46:34.268549: \n",
            "2025-12-23 00:46:34.268746: Epoch 454\n",
            "2025-12-23 00:46:34.268948: Current learning rate: 0.0058\n",
            "2025-12-23 00:46:56.677632: train_loss -0.965\n",
            "2025-12-23 00:46:56.677872: val_loss -0.9818\n",
            "2025-12-23 00:46:56.677982: Pseudo dice [np.float32(0.9862)]\n",
            "2025-12-23 00:46:56.678103: Epoch time: 22.41 s\n",
            "2025-12-23 00:46:58.048293: \n",
            "2025-12-23 00:46:58.048606: Epoch 455\n",
            "2025-12-23 00:46:58.048749: Current learning rate: 0.00579\n",
            "2025-12-23 00:47:20.475151: train_loss -0.9677\n",
            "2025-12-23 00:47:20.475401: val_loss -0.9843\n",
            "2025-12-23 00:47:20.475525: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 00:47:20.475621: Epoch time: 22.43 s\n",
            "2025-12-23 00:47:21.826286: \n",
            "2025-12-23 00:47:21.826578: Epoch 456\n",
            "2025-12-23 00:47:21.826715: Current learning rate: 0.00578\n",
            "2025-12-23 00:47:44.253152: train_loss -0.97\n",
            "2025-12-23 00:47:44.253414: val_loss -0.9851\n",
            "2025-12-23 00:47:44.253585: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 00:47:44.253706: Epoch time: 22.43 s\n",
            "2025-12-23 00:47:45.575834: \n",
            "2025-12-23 00:47:45.576125: Epoch 457\n",
            "2025-12-23 00:47:45.576269: Current learning rate: 0.00577\n",
            "2025-12-23 00:48:08.005421: train_loss -0.9698\n",
            "2025-12-23 00:48:08.005633: val_loss -0.9834\n",
            "2025-12-23 00:48:08.005721: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 00:48:08.005822: Epoch time: 22.43 s\n",
            "2025-12-23 00:48:09.345692: \n",
            "2025-12-23 00:48:09.345953: Epoch 458\n",
            "2025-12-23 00:48:09.346091: Current learning rate: 0.00576\n",
            "2025-12-23 00:48:31.762733: train_loss -0.9684\n",
            "2025-12-23 00:48:31.762996: val_loss -0.9832\n",
            "2025-12-23 00:48:31.763098: Pseudo dice [np.float32(0.9877)]\n",
            "2025-12-23 00:48:31.763190: Epoch time: 22.42 s\n",
            "2025-12-23 00:48:33.124072: \n",
            "2025-12-23 00:48:33.124290: Epoch 459\n",
            "2025-12-23 00:48:33.124427: Current learning rate: 0.00575\n",
            "2025-12-23 00:48:55.538063: train_loss -0.9688\n",
            "2025-12-23 00:48:55.538287: val_loss -0.9827\n",
            "2025-12-23 00:48:55.538409: Pseudo dice [np.float32(0.9872)]\n",
            "2025-12-23 00:48:55.538500: Epoch time: 22.42 s\n",
            "2025-12-23 00:48:56.872257: \n",
            "2025-12-23 00:48:56.872429: Epoch 460\n",
            "2025-12-23 00:48:56.872605: Current learning rate: 0.00574\n",
            "2025-12-23 00:49:19.297535: train_loss -0.9685\n",
            "2025-12-23 00:49:19.297837: val_loss -0.9843\n",
            "2025-12-23 00:49:19.297934: Pseudo dice [np.float32(0.9879)]\n",
            "2025-12-23 00:49:19.298026: Epoch time: 22.43 s\n",
            "2025-12-23 00:49:20.639490: \n",
            "2025-12-23 00:49:20.639818: Epoch 461\n",
            "2025-12-23 00:49:20.639985: Current learning rate: 0.00573\n",
            "2025-12-23 00:49:43.033901: train_loss -0.9687\n",
            "2025-12-23 00:49:43.034301: val_loss -0.9826\n",
            "2025-12-23 00:49:43.034417: Pseudo dice [np.float32(0.9868)]\n",
            "2025-12-23 00:49:43.034528: Epoch time: 22.4 s\n",
            "2025-12-23 00:49:44.355257: \n",
            "2025-12-23 00:49:44.355538: Epoch 462\n",
            "2025-12-23 00:49:44.355674: Current learning rate: 0.00572\n",
            "2025-12-23 00:50:06.758600: train_loss -0.9688\n",
            "2025-12-23 00:50:06.758935: val_loss -0.9839\n",
            "2025-12-23 00:50:06.759057: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 00:50:06.759179: Epoch time: 22.4 s\n",
            "2025-12-23 00:50:08.796430: \n",
            "2025-12-23 00:50:08.796792: Epoch 463\n",
            "2025-12-23 00:50:08.796993: Current learning rate: 0.00571\n",
            "2025-12-23 00:50:31.265636: train_loss -0.9633\n",
            "2025-12-23 00:50:31.265852: val_loss -0.9817\n",
            "2025-12-23 00:50:31.265943: Pseudo dice [np.float32(0.9861)]\n",
            "2025-12-23 00:50:31.266031: Epoch time: 22.47 s\n",
            "2025-12-23 00:50:32.580255: \n",
            "2025-12-23 00:50:32.580539: Epoch 464\n",
            "2025-12-23 00:50:32.580674: Current learning rate: 0.0057\n",
            "2025-12-23 00:50:55.088585: train_loss -0.9665\n",
            "2025-12-23 00:50:55.088786: val_loss -0.9828\n",
            "2025-12-23 00:50:55.088892: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 00:50:55.088980: Epoch time: 22.51 s\n",
            "2025-12-23 00:50:56.408244: \n",
            "2025-12-23 00:50:56.408602: Epoch 465\n",
            "2025-12-23 00:50:56.408744: Current learning rate: 0.0057\n",
            "2025-12-23 00:51:18.886927: train_loss -0.969\n",
            "2025-12-23 00:51:18.887183: val_loss -0.9831\n",
            "2025-12-23 00:51:18.887298: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 00:51:18.887391: Epoch time: 22.48 s\n",
            "2025-12-23 00:51:20.215015: \n",
            "2025-12-23 00:51:20.215388: Epoch 466\n",
            "2025-12-23 00:51:20.215557: Current learning rate: 0.00569\n",
            "2025-12-23 00:51:42.647864: train_loss -0.969\n",
            "2025-12-23 00:51:42.648066: val_loss -0.9817\n",
            "2025-12-23 00:51:42.648152: Pseudo dice [np.float32(0.9868)]\n",
            "2025-12-23 00:51:42.648273: Epoch time: 22.43 s\n",
            "2025-12-23 00:51:43.988051: \n",
            "2025-12-23 00:51:43.988311: Epoch 467\n",
            "2025-12-23 00:51:43.988465: Current learning rate: 0.00568\n",
            "2025-12-23 00:52:06.422078: train_loss -0.9706\n",
            "2025-12-23 00:52:06.422347: val_loss -0.9843\n",
            "2025-12-23 00:52:06.422496: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 00:52:06.422672: Epoch time: 22.44 s\n",
            "2025-12-23 00:52:07.785487: \n",
            "2025-12-23 00:52:07.785728: Epoch 468\n",
            "2025-12-23 00:52:07.785860: Current learning rate: 0.00567\n",
            "2025-12-23 00:52:30.350678: train_loss -0.9693\n",
            "2025-12-23 00:52:30.350933: val_loss -0.9837\n",
            "2025-12-23 00:52:30.351051: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 00:52:30.351143: Epoch time: 22.57 s\n",
            "2025-12-23 00:52:31.682276: \n",
            "2025-12-23 00:52:31.682596: Epoch 469\n",
            "2025-12-23 00:52:31.682754: Current learning rate: 0.00566\n",
            "2025-12-23 00:52:54.137137: train_loss -0.9695\n",
            "2025-12-23 00:52:54.137432: val_loss -0.9839\n",
            "2025-12-23 00:52:54.137600: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 00:52:54.137700: Epoch time: 22.46 s\n",
            "2025-12-23 00:52:55.499614: \n",
            "2025-12-23 00:52:55.499876: Epoch 470\n",
            "2025-12-23 00:52:55.500008: Current learning rate: 0.00565\n",
            "2025-12-23 00:53:17.968312: train_loss -0.9712\n",
            "2025-12-23 00:53:17.968537: val_loss -0.9833\n",
            "2025-12-23 00:53:17.968629: Pseudo dice [np.float32(0.9871)]\n",
            "2025-12-23 00:53:17.968721: Epoch time: 22.47 s\n",
            "2025-12-23 00:53:19.311106: \n",
            "2025-12-23 00:53:19.311514: Epoch 471\n",
            "2025-12-23 00:53:19.311678: Current learning rate: 0.00564\n",
            "2025-12-23 00:53:41.781635: train_loss -0.9708\n",
            "2025-12-23 00:53:41.781983: val_loss -0.9849\n",
            "2025-12-23 00:53:41.782082: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 00:53:41.782177: Epoch time: 22.47 s\n",
            "2025-12-23 00:53:43.124813: \n",
            "2025-12-23 00:53:43.125056: Epoch 472\n",
            "2025-12-23 00:53:43.125188: Current learning rate: 0.00563\n",
            "2025-12-23 00:54:05.552437: train_loss -0.9714\n",
            "2025-12-23 00:54:05.552702: val_loss -0.9853\n",
            "2025-12-23 00:54:05.552793: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 00:54:05.552887: Epoch time: 22.43 s\n",
            "2025-12-23 00:54:06.897118: \n",
            "2025-12-23 00:54:06.897299: Epoch 473\n",
            "2025-12-23 00:54:06.897445: Current learning rate: 0.00562\n",
            "2025-12-23 00:54:29.299785: train_loss -0.9716\n",
            "2025-12-23 00:54:29.300028: val_loss -0.9853\n",
            "2025-12-23 00:54:29.300117: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 00:54:29.300205: Epoch time: 22.4 s\n",
            "2025-12-23 00:54:30.645060: \n",
            "2025-12-23 00:54:30.645406: Epoch 474\n",
            "2025-12-23 00:54:30.645575: Current learning rate: 0.00561\n",
            "2025-12-23 00:54:53.083189: train_loss -0.9712\n",
            "2025-12-23 00:54:53.083408: val_loss -0.9829\n",
            "2025-12-23 00:54:53.083515: Pseudo dice [np.float32(0.9857)]\n",
            "2025-12-23 00:54:53.083608: Epoch time: 22.44 s\n",
            "2025-12-23 00:54:54.431812: \n",
            "2025-12-23 00:54:54.432017: Epoch 475\n",
            "2025-12-23 00:54:54.432154: Current learning rate: 0.0056\n",
            "2025-12-23 00:55:16.864159: train_loss -0.9705\n",
            "2025-12-23 00:55:16.864417: val_loss -0.9834\n",
            "2025-12-23 00:55:16.864508: Pseudo dice [np.float32(0.9877)]\n",
            "2025-12-23 00:55:16.864601: Epoch time: 22.43 s\n",
            "2025-12-23 00:55:18.186054: \n",
            "2025-12-23 00:55:18.186392: Epoch 476\n",
            "2025-12-23 00:55:18.186642: Current learning rate: 0.00559\n",
            "2025-12-23 00:55:40.657589: train_loss -0.9725\n",
            "2025-12-23 00:55:40.657808: val_loss -0.9843\n",
            "2025-12-23 00:55:40.657899: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 00:55:40.658033: Epoch time: 22.47 s\n",
            "2025-12-23 00:55:41.994883: \n",
            "2025-12-23 00:55:41.995087: Epoch 477\n",
            "2025-12-23 00:55:41.995269: Current learning rate: 0.00558\n",
            "2025-12-23 00:56:04.434991: train_loss -0.9718\n",
            "2025-12-23 00:56:04.435268: val_loss -0.9845\n",
            "2025-12-23 00:56:04.435366: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 00:56:04.435457: Epoch time: 22.44 s\n",
            "2025-12-23 00:56:05.774757: \n",
            "2025-12-23 00:56:05.774974: Epoch 478\n",
            "2025-12-23 00:56:05.775106: Current learning rate: 0.00557\n",
            "2025-12-23 00:56:28.204405: train_loss -0.9695\n",
            "2025-12-23 00:56:28.204661: val_loss -0.9854\n",
            "2025-12-23 00:56:28.204818: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 00:56:28.205032: Epoch time: 22.43 s\n",
            "2025-12-23 00:56:29.559068: \n",
            "2025-12-23 00:56:29.559685: Epoch 479\n",
            "2025-12-23 00:56:29.559841: Current learning rate: 0.00556\n",
            "2025-12-23 00:56:51.959778: train_loss -0.9706\n",
            "2025-12-23 00:56:51.960153: val_loss -0.9838\n",
            "2025-12-23 00:56:51.960336: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 00:56:51.960476: Epoch time: 22.4 s\n",
            "2025-12-23 00:56:53.362152: \n",
            "2025-12-23 00:56:53.362538: Epoch 480\n",
            "2025-12-23 00:56:53.362714: Current learning rate: 0.00555\n",
            "2025-12-23 00:57:15.757725: train_loss -0.9696\n",
            "2025-12-23 00:57:15.757956: val_loss -0.9837\n",
            "2025-12-23 00:57:15.758046: Pseudo dice [np.float32(0.987)]\n",
            "2025-12-23 00:57:15.758135: Epoch time: 22.4 s\n",
            "2025-12-23 00:57:17.131115: \n",
            "2025-12-23 00:57:17.131464: Epoch 481\n",
            "2025-12-23 00:57:17.131615: Current learning rate: 0.00554\n",
            "2025-12-23 00:57:39.500513: train_loss -0.9708\n",
            "2025-12-23 00:57:39.500812: val_loss -0.9842\n",
            "2025-12-23 00:57:39.500934: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 00:57:39.501059: Epoch time: 22.37 s\n",
            "2025-12-23 00:57:41.577875: \n",
            "2025-12-23 00:57:41.578065: Epoch 482\n",
            "2025-12-23 00:57:41.578200: Current learning rate: 0.00553\n",
            "2025-12-23 00:58:04.059952: train_loss -0.9687\n",
            "2025-12-23 00:58:04.060417: val_loss -0.9808\n",
            "2025-12-23 00:58:04.060571: Pseudo dice [np.float32(0.9866)]\n",
            "2025-12-23 00:58:04.060718: Epoch time: 22.48 s\n",
            "2025-12-23 00:58:05.428493: \n",
            "2025-12-23 00:58:05.428812: Epoch 483\n",
            "2025-12-23 00:58:05.428961: Current learning rate: 0.00552\n",
            "2025-12-23 00:58:27.850324: train_loss -0.967\n",
            "2025-12-23 00:58:27.850562: val_loss -0.9831\n",
            "2025-12-23 00:58:27.850677: Pseudo dice [np.float32(0.9872)]\n",
            "2025-12-23 00:58:27.850772: Epoch time: 22.42 s\n",
            "2025-12-23 00:58:29.237363: \n",
            "2025-12-23 00:58:29.237667: Epoch 484\n",
            "2025-12-23 00:58:29.237809: Current learning rate: 0.00551\n",
            "2025-12-23 00:58:51.672262: train_loss -0.9629\n",
            "2025-12-23 00:58:51.672528: val_loss -0.9758\n",
            "2025-12-23 00:58:51.672631: Pseudo dice [np.float32(0.9817)]\n",
            "2025-12-23 00:58:51.672752: Epoch time: 22.44 s\n",
            "2025-12-23 00:58:53.057260: \n",
            "2025-12-23 00:58:53.057599: Epoch 485\n",
            "2025-12-23 00:58:53.057739: Current learning rate: 0.0055\n",
            "2025-12-23 00:59:15.482311: train_loss -0.9588\n",
            "2025-12-23 00:59:15.482568: val_loss -0.9797\n",
            "2025-12-23 00:59:15.482682: Pseudo dice [np.float32(0.9845)]\n",
            "2025-12-23 00:59:15.482833: Epoch time: 22.43 s\n",
            "2025-12-23 00:59:16.849598: \n",
            "2025-12-23 00:59:16.849934: Epoch 486\n",
            "2025-12-23 00:59:16.850085: Current learning rate: 0.00549\n",
            "2025-12-23 00:59:39.306270: train_loss -0.9654\n",
            "2025-12-23 00:59:39.306649: val_loss -0.9815\n",
            "2025-12-23 00:59:39.306750: Pseudo dice [np.float32(0.9857)]\n",
            "2025-12-23 00:59:39.306859: Epoch time: 22.46 s\n",
            "2025-12-23 00:59:40.659879: \n",
            "2025-12-23 00:59:40.660164: Epoch 487\n",
            "2025-12-23 00:59:40.660367: Current learning rate: 0.00548\n",
            "2025-12-23 01:00:03.109382: train_loss -0.9657\n",
            "2025-12-23 01:00:03.109585: val_loss -0.9827\n",
            "2025-12-23 01:00:03.109674: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 01:00:03.109772: Epoch time: 22.45 s\n",
            "2025-12-23 01:00:04.469032: \n",
            "2025-12-23 01:00:04.469303: Epoch 488\n",
            "2025-12-23 01:00:04.469554: Current learning rate: 0.00547\n",
            "2025-12-23 01:00:26.970620: train_loss -0.9676\n",
            "2025-12-23 01:00:26.970840: val_loss -0.983\n",
            "2025-12-23 01:00:26.970935: Pseudo dice [np.float32(0.9859)]\n",
            "2025-12-23 01:00:26.971034: Epoch time: 22.5 s\n",
            "2025-12-23 01:00:28.324519: \n",
            "2025-12-23 01:00:28.324825: Epoch 489\n",
            "2025-12-23 01:00:28.324957: Current learning rate: 0.00546\n",
            "2025-12-23 01:00:50.766477: train_loss -0.969\n",
            "2025-12-23 01:00:50.766747: val_loss -0.9825\n",
            "2025-12-23 01:00:50.767050: Pseudo dice [np.float32(0.9869)]\n",
            "2025-12-23 01:00:50.767146: Epoch time: 22.44 s\n",
            "2025-12-23 01:00:52.134672: \n",
            "2025-12-23 01:00:52.134868: Epoch 490\n",
            "2025-12-23 01:00:52.134996: Current learning rate: 0.00546\n",
            "2025-12-23 01:01:14.640800: train_loss -0.9688\n",
            "2025-12-23 01:01:14.641040: val_loss -0.9846\n",
            "2025-12-23 01:01:14.641138: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 01:01:14.641294: Epoch time: 22.51 s\n",
            "2025-12-23 01:01:15.984931: \n",
            "2025-12-23 01:01:15.985183: Epoch 491\n",
            "2025-12-23 01:01:15.985339: Current learning rate: 0.00545\n",
            "2025-12-23 01:01:38.404905: train_loss -0.9468\n",
            "2025-12-23 01:01:38.405231: val_loss -0.9652\n",
            "2025-12-23 01:01:38.405351: Pseudo dice [np.float32(0.9731)]\n",
            "2025-12-23 01:01:38.405445: Epoch time: 22.42 s\n",
            "2025-12-23 01:01:39.739834: \n",
            "2025-12-23 01:01:39.740109: Epoch 492\n",
            "2025-12-23 01:01:39.740259: Current learning rate: 0.00544\n",
            "2025-12-23 01:02:02.194491: train_loss -0.954\n",
            "2025-12-23 01:02:02.194692: val_loss -0.9752\n",
            "2025-12-23 01:02:02.194779: Pseudo dice [np.float32(0.9798)]\n",
            "2025-12-23 01:02:02.194872: Epoch time: 22.46 s\n",
            "2025-12-23 01:02:03.543255: \n",
            "2025-12-23 01:02:03.543590: Epoch 493\n",
            "2025-12-23 01:02:03.543756: Current learning rate: 0.00543\n",
            "2025-12-23 01:02:25.946849: train_loss -0.9487\n",
            "2025-12-23 01:02:25.947191: val_loss -0.9774\n",
            "2025-12-23 01:02:25.947342: Pseudo dice [np.float32(0.9833)]\n",
            "2025-12-23 01:02:25.947498: Epoch time: 22.4 s\n",
            "2025-12-23 01:02:27.300685: \n",
            "2025-12-23 01:02:27.301023: Epoch 494\n",
            "2025-12-23 01:02:27.301148: Current learning rate: 0.00542\n",
            "2025-12-23 01:02:49.746902: train_loss -0.9621\n",
            "2025-12-23 01:02:49.747263: val_loss -0.9828\n",
            "2025-12-23 01:02:49.747372: Pseudo dice [np.float32(0.9872)]\n",
            "2025-12-23 01:02:49.747464: Epoch time: 22.45 s\n",
            "2025-12-23 01:02:51.094136: \n",
            "2025-12-23 01:02:51.094360: Epoch 495\n",
            "2025-12-23 01:02:51.094495: Current learning rate: 0.00541\n",
            "2025-12-23 01:03:13.493276: train_loss -0.9649\n",
            "2025-12-23 01:03:13.493485: val_loss -0.9697\n",
            "2025-12-23 01:03:13.493603: Pseudo dice [np.float32(0.9766)]\n",
            "2025-12-23 01:03:13.493701: Epoch time: 22.4 s\n",
            "2025-12-23 01:03:14.849133: \n",
            "2025-12-23 01:03:14.849362: Epoch 496\n",
            "2025-12-23 01:03:14.849511: Current learning rate: 0.0054\n",
            "2025-12-23 01:03:37.281542: train_loss -0.9614\n",
            "2025-12-23 01:03:37.281824: val_loss -0.9813\n",
            "2025-12-23 01:03:37.281973: Pseudo dice [np.float32(0.9856)]\n",
            "2025-12-23 01:03:37.282133: Epoch time: 22.43 s\n",
            "2025-12-23 01:03:38.616625: \n",
            "2025-12-23 01:03:38.616839: Epoch 497\n",
            "2025-12-23 01:03:38.616971: Current learning rate: 0.00539\n",
            "2025-12-23 01:04:01.031373: train_loss -0.9667\n",
            "2025-12-23 01:04:01.031744: val_loss -0.9818\n",
            "2025-12-23 01:04:01.031843: Pseudo dice [np.float32(0.9865)]\n",
            "2025-12-23 01:04:01.031936: Epoch time: 22.42 s\n",
            "2025-12-23 01:04:02.357638: \n",
            "2025-12-23 01:04:02.357956: Epoch 498\n",
            "2025-12-23 01:04:02.358204: Current learning rate: 0.00538\n",
            "2025-12-23 01:04:24.770358: train_loss -0.9698\n",
            "2025-12-23 01:04:24.770561: val_loss -0.9832\n",
            "2025-12-23 01:04:24.770645: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 01:04:24.770733: Epoch time: 22.41 s\n",
            "2025-12-23 01:04:26.111977: \n",
            "2025-12-23 01:04:26.112140: Epoch 499\n",
            "2025-12-23 01:04:26.112278: Current learning rate: 0.00537\n",
            "2025-12-23 01:04:48.564356: train_loss -0.9684\n",
            "2025-12-23 01:04:48.564608: val_loss -0.9835\n",
            "2025-12-23 01:04:48.564728: Pseudo dice [np.float32(0.9874)]\n",
            "2025-12-23 01:04:48.564824: Epoch time: 22.45 s\n",
            "2025-12-23 01:04:51.119204: \n",
            "2025-12-23 01:04:51.119555: Epoch 500\n",
            "2025-12-23 01:04:51.119685: Current learning rate: 0.00536\n",
            "2025-12-23 01:05:13.601502: train_loss -0.9684\n",
            "2025-12-23 01:05:13.601898: val_loss -0.9837\n",
            "2025-12-23 01:05:13.602029: Pseudo dice [np.float32(0.9876)]\n",
            "2025-12-23 01:05:13.602134: Epoch time: 22.48 s\n",
            "2025-12-23 01:05:14.945652: \n",
            "2025-12-23 01:05:14.945944: Epoch 501\n",
            "2025-12-23 01:05:14.946164: Current learning rate: 0.00535\n",
            "2025-12-23 01:05:37.456721: train_loss -0.9688\n",
            "2025-12-23 01:05:37.456952: val_loss -0.9845\n",
            "2025-12-23 01:05:37.457041: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 01:05:37.457187: Epoch time: 22.51 s\n",
            "2025-12-23 01:05:38.807540: \n",
            "2025-12-23 01:05:38.807887: Epoch 502\n",
            "2025-12-23 01:05:38.808036: Current learning rate: 0.00534\n",
            "2025-12-23 01:06:01.294986: train_loss -0.9689\n",
            "2025-12-23 01:06:01.295316: val_loss -0.9852\n",
            "2025-12-23 01:06:01.295516: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 01:06:01.295696: Epoch time: 22.49 s\n",
            "2025-12-23 01:06:02.636250: \n",
            "2025-12-23 01:06:02.636489: Epoch 503\n",
            "2025-12-23 01:06:02.636621: Current learning rate: 0.00533\n",
            "2025-12-23 01:06:25.089773: train_loss -0.9681\n",
            "2025-12-23 01:06:25.090018: val_loss -0.9822\n",
            "2025-12-23 01:06:25.090180: Pseudo dice [np.float32(0.9856)]\n",
            "2025-12-23 01:06:25.090343: Epoch time: 22.45 s\n",
            "2025-12-23 01:06:26.449041: \n",
            "2025-12-23 01:06:26.449354: Epoch 504\n",
            "2025-12-23 01:06:26.449492: Current learning rate: 0.00532\n",
            "2025-12-23 01:06:48.991966: train_loss -0.9696\n",
            "2025-12-23 01:06:48.992190: val_loss -0.9846\n",
            "2025-12-23 01:06:48.992338: Pseudo dice [np.float32(0.9879)]\n",
            "2025-12-23 01:06:48.992703: Epoch time: 22.54 s\n",
            "2025-12-23 01:06:50.338733: \n",
            "2025-12-23 01:06:50.338984: Epoch 505\n",
            "2025-12-23 01:06:50.339114: Current learning rate: 0.00531\n",
            "2025-12-23 01:07:12.789943: train_loss -0.9702\n",
            "2025-12-23 01:07:12.790131: val_loss -0.9843\n",
            "2025-12-23 01:07:12.790234: Pseudo dice [np.float32(0.9876)]\n",
            "2025-12-23 01:07:12.790353: Epoch time: 22.45 s\n",
            "2025-12-23 01:07:14.125115: \n",
            "2025-12-23 01:07:14.125336: Epoch 506\n",
            "2025-12-23 01:07:14.125534: Current learning rate: 0.0053\n",
            "2025-12-23 01:07:36.619823: train_loss -0.9698\n",
            "2025-12-23 01:07:36.620084: val_loss -0.9821\n",
            "2025-12-23 01:07:36.620178: Pseudo dice [np.float32(0.987)]\n",
            "2025-12-23 01:07:36.620284: Epoch time: 22.5 s\n",
            "2025-12-23 01:07:37.981938: \n",
            "2025-12-23 01:07:37.982205: Epoch 507\n",
            "2025-12-23 01:07:37.982386: Current learning rate: 0.00529\n",
            "2025-12-23 01:08:00.439619: train_loss -0.97\n",
            "2025-12-23 01:08:00.439917: val_loss -0.9856\n",
            "2025-12-23 01:08:00.440052: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 01:08:00.440149: Epoch time: 22.46 s\n",
            "2025-12-23 01:08:01.776461: \n",
            "2025-12-23 01:08:01.776850: Epoch 508\n",
            "2025-12-23 01:08:01.777022: Current learning rate: 0.00528\n",
            "2025-12-23 01:08:24.296666: train_loss -0.9698\n",
            "2025-12-23 01:08:24.297129: val_loss -0.9843\n",
            "2025-12-23 01:08:24.297340: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 01:08:24.297544: Epoch time: 22.52 s\n",
            "2025-12-23 01:08:25.638304: \n",
            "2025-12-23 01:08:25.638609: Epoch 509\n",
            "2025-12-23 01:08:25.638742: Current learning rate: 0.00527\n",
            "2025-12-23 01:08:48.073827: train_loss -0.9701\n",
            "2025-12-23 01:08:48.074244: val_loss -0.9848\n",
            "2025-12-23 01:08:48.074427: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 01:08:48.074583: Epoch time: 22.44 s\n",
            "2025-12-23 01:08:49.456411: \n",
            "2025-12-23 01:08:49.456666: Epoch 510\n",
            "2025-12-23 01:08:49.456807: Current learning rate: 0.00526\n",
            "2025-12-23 01:09:11.912503: train_loss -0.9703\n",
            "2025-12-23 01:09:11.912756: val_loss -0.9857\n",
            "2025-12-23 01:09:11.912852: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 01:09:11.912941: Epoch time: 22.46 s\n",
            "2025-12-23 01:09:13.265796: \n",
            "2025-12-23 01:09:13.265983: Epoch 511\n",
            "2025-12-23 01:09:13.266111: Current learning rate: 0.00525\n",
            "2025-12-23 01:09:35.733713: train_loss -0.9698\n",
            "2025-12-23 01:09:35.733967: val_loss -0.9847\n",
            "2025-12-23 01:09:35.734082: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 01:09:35.734200: Epoch time: 22.47 s\n",
            "2025-12-23 01:09:37.066929: \n",
            "2025-12-23 01:09:37.067237: Epoch 512\n",
            "2025-12-23 01:09:37.067396: Current learning rate: 0.00524\n",
            "2025-12-23 01:09:59.510898: train_loss -0.9722\n",
            "2025-12-23 01:09:59.511160: val_loss -0.9838\n",
            "2025-12-23 01:09:59.511294: Pseudo dice [np.float32(0.988)]\n",
            "2025-12-23 01:09:59.511419: Epoch time: 22.45 s\n",
            "2025-12-23 01:10:00.864553: \n",
            "2025-12-23 01:10:00.864804: Epoch 513\n",
            "2025-12-23 01:10:00.864940: Current learning rate: 0.00523\n",
            "2025-12-23 01:10:23.334337: train_loss -0.9715\n",
            "2025-12-23 01:10:23.334601: val_loss -0.9837\n",
            "2025-12-23 01:10:23.334783: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 01:10:23.334976: Epoch time: 22.47 s\n",
            "2025-12-23 01:10:24.717470: \n",
            "2025-12-23 01:10:24.717643: Epoch 514\n",
            "2025-12-23 01:10:24.717864: Current learning rate: 0.00522\n",
            "2025-12-23 01:10:47.195660: train_loss -0.9708\n",
            "2025-12-23 01:10:47.195963: val_loss -0.9849\n",
            "2025-12-23 01:10:47.196101: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 01:10:47.196201: Epoch time: 22.48 s\n",
            "2025-12-23 01:10:48.586073: \n",
            "2025-12-23 01:10:48.586464: Epoch 515\n",
            "2025-12-23 01:10:48.586603: Current learning rate: 0.00521\n",
            "2025-12-23 01:11:11.044690: train_loss -0.9716\n",
            "2025-12-23 01:11:11.044896: val_loss -0.9851\n",
            "2025-12-23 01:11:11.044984: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 01:11:11.045075: Epoch time: 22.46 s\n",
            "2025-12-23 01:11:12.416414: \n",
            "2025-12-23 01:11:12.416709: Epoch 516\n",
            "2025-12-23 01:11:12.416849: Current learning rate: 0.0052\n",
            "2025-12-23 01:11:34.823508: train_loss -0.9708\n",
            "2025-12-23 01:11:34.823925: val_loss -0.986\n",
            "2025-12-23 01:11:34.824076: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 01:11:34.824204: Epoch time: 22.41 s\n",
            "2025-12-23 01:11:36.227655: \n",
            "2025-12-23 01:11:36.227981: Epoch 517\n",
            "2025-12-23 01:11:36.228114: Current learning rate: 0.00519\n",
            "2025-12-23 01:11:58.642178: train_loss -0.9725\n",
            "2025-12-23 01:11:58.642391: val_loss -0.9854\n",
            "2025-12-23 01:11:58.642482: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 01:11:58.642642: Epoch time: 22.42 s\n",
            "2025-12-23 01:12:00.707698: \n",
            "2025-12-23 01:12:00.707983: Epoch 518\n",
            "2025-12-23 01:12:00.708129: Current learning rate: 0.00518\n",
            "2025-12-23 01:12:23.233512: train_loss -0.9723\n",
            "2025-12-23 01:12:23.233739: val_loss -0.9859\n",
            "2025-12-23 01:12:23.233845: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 01:12:23.233936: Epoch time: 22.53 s\n",
            "2025-12-23 01:12:24.592927: \n",
            "2025-12-23 01:12:24.593197: Epoch 519\n",
            "2025-12-23 01:12:24.593343: Current learning rate: 0.00518\n",
            "2025-12-23 01:12:47.044093: train_loss -0.9727\n",
            "2025-12-23 01:12:47.044346: val_loss -0.9851\n",
            "2025-12-23 01:12:47.044441: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 01:12:47.044532: Epoch time: 22.45 s\n",
            "2025-12-23 01:12:48.382506: \n",
            "2025-12-23 01:12:48.382810: Epoch 520\n",
            "2025-12-23 01:12:48.382944: Current learning rate: 0.00517\n",
            "2025-12-23 01:13:10.825085: train_loss -0.9718\n",
            "2025-12-23 01:13:10.825344: val_loss -0.9868\n",
            "2025-12-23 01:13:10.825445: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 01:13:10.825536: Epoch time: 22.44 s\n",
            "2025-12-23 01:13:12.213518: \n",
            "2025-12-23 01:13:12.213900: Epoch 521\n",
            "2025-12-23 01:13:12.214033: Current learning rate: 0.00516\n",
            "2025-12-23 01:13:34.661128: train_loss -0.9715\n",
            "2025-12-23 01:13:34.661384: val_loss -0.9856\n",
            "2025-12-23 01:13:34.661483: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 01:13:34.661582: Epoch time: 22.45 s\n",
            "2025-12-23 01:13:36.068647: \n",
            "2025-12-23 01:13:36.068861: Epoch 522\n",
            "2025-12-23 01:13:36.068988: Current learning rate: 0.00515\n",
            "2025-12-23 01:13:58.527395: train_loss -0.9709\n",
            "2025-12-23 01:13:58.527861: val_loss -0.9848\n",
            "2025-12-23 01:13:58.527958: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 01:13:58.528080: Epoch time: 22.46 s\n",
            "2025-12-23 01:13:59.895682: \n",
            "2025-12-23 01:13:59.895972: Epoch 523\n",
            "2025-12-23 01:13:59.896128: Current learning rate: 0.00514\n",
            "2025-12-23 01:14:22.321736: train_loss -0.9722\n",
            "2025-12-23 01:14:22.321987: val_loss -0.9846\n",
            "2025-12-23 01:14:22.322074: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 01:14:22.322163: Epoch time: 22.43 s\n",
            "2025-12-23 01:14:23.678195: \n",
            "2025-12-23 01:14:23.678512: Epoch 524\n",
            "2025-12-23 01:14:23.678671: Current learning rate: 0.00513\n",
            "2025-12-23 01:14:46.157630: train_loss -0.9707\n",
            "2025-12-23 01:14:46.157853: val_loss -0.9841\n",
            "2025-12-23 01:14:46.157942: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 01:14:46.158034: Epoch time: 22.48 s\n",
            "2025-12-23 01:14:47.508046: \n",
            "2025-12-23 01:14:47.508212: Epoch 525\n",
            "2025-12-23 01:14:47.508397: Current learning rate: 0.00512\n",
            "2025-12-23 01:15:09.989987: train_loss -0.9716\n",
            "2025-12-23 01:15:09.990315: val_loss -0.9837\n",
            "2025-12-23 01:15:09.990434: Pseudo dice [np.float32(0.9877)]\n",
            "2025-12-23 01:15:09.990563: Epoch time: 22.48 s\n",
            "2025-12-23 01:15:11.338127: \n",
            "2025-12-23 01:15:11.338526: Epoch 526\n",
            "2025-12-23 01:15:11.338668: Current learning rate: 0.00511\n",
            "2025-12-23 01:15:33.796058: train_loss -0.9713\n",
            "2025-12-23 01:15:33.796334: val_loss -0.9854\n",
            "2025-12-23 01:15:33.796433: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 01:15:33.796525: Epoch time: 22.46 s\n",
            "2025-12-23 01:15:35.189986: \n",
            "2025-12-23 01:15:35.190269: Epoch 527\n",
            "2025-12-23 01:15:35.190421: Current learning rate: 0.0051\n",
            "2025-12-23 01:15:57.644974: train_loss -0.9723\n",
            "2025-12-23 01:15:57.645411: val_loss -0.9858\n",
            "2025-12-23 01:15:57.645513: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 01:15:57.645622: Epoch time: 22.46 s\n",
            "2025-12-23 01:15:58.997031: \n",
            "2025-12-23 01:15:58.997260: Epoch 528\n",
            "2025-12-23 01:15:58.997457: Current learning rate: 0.00509\n",
            "2025-12-23 01:16:21.454154: train_loss -0.9712\n",
            "2025-12-23 01:16:21.454374: val_loss -0.9838\n",
            "2025-12-23 01:16:21.454591: Pseudo dice [np.float32(0.9874)]\n",
            "2025-12-23 01:16:21.454701: Epoch time: 22.46 s\n",
            "2025-12-23 01:16:22.795330: \n",
            "2025-12-23 01:16:22.795603: Epoch 529\n",
            "2025-12-23 01:16:22.795738: Current learning rate: 0.00508\n",
            "2025-12-23 01:16:45.228011: train_loss -0.9722\n",
            "2025-12-23 01:16:45.228246: val_loss -0.9849\n",
            "2025-12-23 01:16:45.228365: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 01:16:45.228459: Epoch time: 22.43 s\n",
            "2025-12-23 01:16:46.557250: \n",
            "2025-12-23 01:16:46.557516: Epoch 530\n",
            "2025-12-23 01:16:46.557651: Current learning rate: 0.00507\n",
            "2025-12-23 01:17:08.996561: train_loss -0.9714\n",
            "2025-12-23 01:17:08.996870: val_loss -0.9836\n",
            "2025-12-23 01:17:08.996976: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 01:17:08.997068: Epoch time: 22.44 s\n",
            "2025-12-23 01:17:10.349344: \n",
            "2025-12-23 01:17:10.349635: Epoch 531\n",
            "2025-12-23 01:17:10.349956: Current learning rate: 0.00506\n",
            "2025-12-23 01:17:32.772042: train_loss -0.9723\n",
            "2025-12-23 01:17:32.772324: val_loss -0.985\n",
            "2025-12-23 01:17:32.772447: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 01:17:32.772551: Epoch time: 22.42 s\n",
            "2025-12-23 01:17:34.157109: \n",
            "2025-12-23 01:17:34.157438: Epoch 532\n",
            "2025-12-23 01:17:34.157606: Current learning rate: 0.00505\n",
            "2025-12-23 01:17:56.644451: train_loss -0.9713\n",
            "2025-12-23 01:17:56.644679: val_loss -0.9847\n",
            "2025-12-23 01:17:56.644763: Pseudo dice [np.float32(0.9879)]\n",
            "2025-12-23 01:17:56.644869: Epoch time: 22.49 s\n",
            "2025-12-23 01:17:57.987490: \n",
            "2025-12-23 01:17:57.987747: Epoch 533\n",
            "2025-12-23 01:17:57.987922: Current learning rate: 0.00504\n",
            "2025-12-23 01:18:20.450728: train_loss -0.9709\n",
            "2025-12-23 01:18:20.450940: val_loss -0.9844\n",
            "2025-12-23 01:18:20.451029: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 01:18:20.451118: Epoch time: 22.46 s\n",
            "2025-12-23 01:18:21.817905: \n",
            "2025-12-23 01:18:21.818152: Epoch 534\n",
            "2025-12-23 01:18:21.818295: Current learning rate: 0.00503\n",
            "2025-12-23 01:18:44.230568: train_loss -0.9718\n",
            "2025-12-23 01:18:44.230769: val_loss -0.9845\n",
            "2025-12-23 01:18:44.230860: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 01:18:44.230959: Epoch time: 22.41 s\n",
            "2025-12-23 01:18:45.573699: \n",
            "2025-12-23 01:18:45.574013: Epoch 535\n",
            "2025-12-23 01:18:45.574193: Current learning rate: 0.00502\n",
            "2025-12-23 01:19:07.994127: train_loss -0.9722\n",
            "2025-12-23 01:19:07.994456: val_loss -0.9846\n",
            "2025-12-23 01:19:07.994579: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 01:19:07.994699: Epoch time: 22.42 s\n",
            "2025-12-23 01:19:10.049184: \n",
            "2025-12-23 01:19:10.049470: Epoch 536\n",
            "2025-12-23 01:19:10.049650: Current learning rate: 0.00501\n",
            "2025-12-23 01:19:32.495220: train_loss -0.973\n",
            "2025-12-23 01:19:32.495472: val_loss -0.9833\n",
            "2025-12-23 01:19:32.495568: Pseudo dice [np.float32(0.9871)]\n",
            "2025-12-23 01:19:32.495670: Epoch time: 22.45 s\n",
            "2025-12-23 01:19:33.832427: \n",
            "2025-12-23 01:19:33.832720: Epoch 537\n",
            "2025-12-23 01:19:33.832917: Current learning rate: 0.005\n",
            "2025-12-23 01:19:56.288200: train_loss -0.9715\n",
            "2025-12-23 01:19:56.288511: val_loss -0.9843\n",
            "2025-12-23 01:19:56.288611: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 01:19:56.288702: Epoch time: 22.46 s\n",
            "2025-12-23 01:19:57.604209: \n",
            "2025-12-23 01:19:57.604438: Epoch 538\n",
            "2025-12-23 01:19:57.604583: Current learning rate: 0.00499\n",
            "2025-12-23 01:20:20.054111: train_loss -0.9724\n",
            "2025-12-23 01:20:20.054442: val_loss -0.985\n",
            "2025-12-23 01:20:20.054549: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 01:20:20.054639: Epoch time: 22.45 s\n",
            "2025-12-23 01:20:21.407865: \n",
            "2025-12-23 01:20:21.408177: Epoch 539\n",
            "2025-12-23 01:20:21.408346: Current learning rate: 0.00498\n",
            "2025-12-23 01:20:43.881266: train_loss -0.9712\n",
            "2025-12-23 01:20:43.881665: val_loss -0.9854\n",
            "2025-12-23 01:20:43.881861: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 01:20:43.881958: Epoch time: 22.47 s\n",
            "2025-12-23 01:20:45.246068: \n",
            "2025-12-23 01:20:45.246423: Epoch 540\n",
            "2025-12-23 01:20:45.246570: Current learning rate: 0.00497\n",
            "2025-12-23 01:21:07.692498: train_loss -0.9727\n",
            "2025-12-23 01:21:07.692719: val_loss -0.9861\n",
            "2025-12-23 01:21:07.692812: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 01:21:07.692903: Epoch time: 22.45 s\n",
            "2025-12-23 01:21:09.034160: \n",
            "2025-12-23 01:21:09.034537: Epoch 541\n",
            "2025-12-23 01:21:09.034689: Current learning rate: 0.00496\n",
            "2025-12-23 01:21:31.483964: train_loss -0.9724\n",
            "2025-12-23 01:21:31.484235: val_loss -0.986\n",
            "2025-12-23 01:21:31.484358: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 01:21:31.484473: Epoch time: 22.45 s\n",
            "2025-12-23 01:21:32.817303: \n",
            "2025-12-23 01:21:32.817635: Epoch 542\n",
            "2025-12-23 01:21:32.817794: Current learning rate: 0.00495\n",
            "2025-12-23 01:21:55.276839: train_loss -0.9725\n",
            "2025-12-23 01:21:55.277089: val_loss -0.985\n",
            "2025-12-23 01:21:55.277390: Pseudo dice [np.float32(0.9864)]\n",
            "2025-12-23 01:21:55.277509: Epoch time: 22.46 s\n",
            "2025-12-23 01:21:56.621605: \n",
            "2025-12-23 01:21:56.621836: Epoch 543\n",
            "2025-12-23 01:21:56.622026: Current learning rate: 0.00494\n",
            "2025-12-23 01:22:19.064520: train_loss -0.9722\n",
            "2025-12-23 01:22:19.064762: val_loss -0.9852\n",
            "2025-12-23 01:22:19.064876: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 01:22:19.064991: Epoch time: 22.44 s\n",
            "2025-12-23 01:22:20.410307: \n",
            "2025-12-23 01:22:20.410658: Epoch 544\n",
            "2025-12-23 01:22:20.410791: Current learning rate: 0.00493\n",
            "2025-12-23 01:22:42.829645: train_loss -0.9732\n",
            "2025-12-23 01:22:42.829983: val_loss -0.9841\n",
            "2025-12-23 01:22:42.830208: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 01:22:42.830391: Epoch time: 22.42 s\n",
            "2025-12-23 01:22:44.194117: \n",
            "2025-12-23 01:22:44.194328: Epoch 545\n",
            "2025-12-23 01:22:44.194540: Current learning rate: 0.00492\n",
            "2025-12-23 01:23:06.672985: train_loss -0.9734\n",
            "2025-12-23 01:23:06.673481: val_loss -0.9844\n",
            "2025-12-23 01:23:06.673666: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 01:23:06.673860: Epoch time: 22.48 s\n",
            "2025-12-23 01:23:08.015645: \n",
            "2025-12-23 01:23:08.015954: Epoch 546\n",
            "2025-12-23 01:23:08.016118: Current learning rate: 0.00491\n",
            "2025-12-23 01:23:30.485616: train_loss -0.9725\n",
            "2025-12-23 01:23:30.485832: val_loss -0.9848\n",
            "2025-12-23 01:23:30.485920: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 01:23:30.486011: Epoch time: 22.47 s\n",
            "2025-12-23 01:23:31.811325: \n",
            "2025-12-23 01:23:31.811616: Epoch 547\n",
            "2025-12-23 01:23:31.811743: Current learning rate: 0.0049\n",
            "2025-12-23 01:23:54.235871: train_loss -0.9735\n",
            "2025-12-23 01:23:54.236073: val_loss -0.9865\n",
            "2025-12-23 01:23:54.236161: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 01:23:54.236311: Epoch time: 22.43 s\n",
            "2025-12-23 01:23:54.236440: Yayy! New best EMA pseudo Dice: 0.9886000156402588\n",
            "2025-12-23 01:23:56.192374: \n",
            "2025-12-23 01:23:56.192601: Epoch 548\n",
            "2025-12-23 01:23:56.192788: Current learning rate: 0.00489\n",
            "2025-12-23 01:24:18.711003: train_loss -0.9736\n",
            "2025-12-23 01:24:18.711443: val_loss -0.9857\n",
            "2025-12-23 01:24:18.711599: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 01:24:18.711724: Epoch time: 22.52 s\n",
            "2025-12-23 01:24:18.711822: Yayy! New best EMA pseudo Dice: 0.9886000156402588\n",
            "2025-12-23 01:24:20.626198: \n",
            "2025-12-23 01:24:20.626494: Epoch 549\n",
            "2025-12-23 01:24:20.626664: Current learning rate: 0.00488\n",
            "2025-12-23 01:24:43.125802: train_loss -0.9734\n",
            "2025-12-23 01:24:43.126152: val_loss -0.9856\n",
            "2025-12-23 01:24:43.126316: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 01:24:43.126476: Epoch time: 22.5 s\n",
            "2025-12-23 01:24:44.998057: \n",
            "2025-12-23 01:24:44.998334: Epoch 550\n",
            "2025-12-23 01:24:44.998483: Current learning rate: 0.00487\n",
            "2025-12-23 01:25:07.410541: train_loss -0.9733\n",
            "2025-12-23 01:25:07.410777: val_loss -0.9859\n",
            "2025-12-23 01:25:07.410869: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 01:25:07.410962: Epoch time: 22.41 s\n",
            "2025-12-23 01:25:07.411040: Yayy! New best EMA pseudo Dice: 0.9886000156402588\n",
            "2025-12-23 01:25:09.271322: \n",
            "2025-12-23 01:25:09.271643: Epoch 551\n",
            "2025-12-23 01:25:09.271781: Current learning rate: 0.00486\n",
            "2025-12-23 01:25:31.751373: train_loss -0.9725\n",
            "2025-12-23 01:25:31.751572: val_loss -0.9856\n",
            "2025-12-23 01:25:31.751657: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 01:25:31.751748: Epoch time: 22.48 s\n",
            "2025-12-23 01:25:31.751832: Yayy! New best EMA pseudo Dice: 0.9886999726295471\n",
            "2025-12-23 01:25:33.596843: \n",
            "2025-12-23 01:25:33.597168: Epoch 552\n",
            "2025-12-23 01:25:33.597320: Current learning rate: 0.00485\n",
            "2025-12-23 01:25:56.024298: train_loss -0.9715\n",
            "2025-12-23 01:25:56.024549: val_loss -0.9853\n",
            "2025-12-23 01:25:56.024643: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 01:25:56.024741: Epoch time: 22.43 s\n",
            "2025-12-23 01:25:56.024817: Yayy! New best EMA pseudo Dice: 0.9886999726295471\n",
            "2025-12-23 01:25:58.527613: \n",
            "2025-12-23 01:25:58.528062: Epoch 553\n",
            "2025-12-23 01:25:58.528211: Current learning rate: 0.00484\n",
            "2025-12-23 01:26:21.082675: train_loss -0.9716\n",
            "2025-12-23 01:26:21.082897: val_loss -0.9836\n",
            "2025-12-23 01:26:21.083018: Pseudo dice [np.float32(0.988)]\n",
            "2025-12-23 01:26:21.083128: Epoch time: 22.56 s\n",
            "2025-12-23 01:26:22.443208: \n",
            "2025-12-23 01:26:22.443460: Epoch 554\n",
            "2025-12-23 01:26:22.443593: Current learning rate: 0.00484\n",
            "2025-12-23 01:26:44.891466: train_loss -0.9728\n",
            "2025-12-23 01:26:44.891815: val_loss -0.9851\n",
            "2025-12-23 01:26:44.891937: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 01:26:44.892067: Epoch time: 22.45 s\n",
            "2025-12-23 01:26:46.223631: \n",
            "2025-12-23 01:26:46.223974: Epoch 555\n",
            "2025-12-23 01:26:46.224108: Current learning rate: 0.00483\n",
            "2025-12-23 01:27:08.711367: train_loss -0.9719\n",
            "2025-12-23 01:27:08.711918: val_loss -0.9845\n",
            "2025-12-23 01:27:08.712063: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 01:27:08.712179: Epoch time: 22.49 s\n",
            "2025-12-23 01:27:10.058607: \n",
            "2025-12-23 01:27:10.058835: Epoch 556\n",
            "2025-12-23 01:27:10.059024: Current learning rate: 0.00482\n",
            "2025-12-23 01:27:32.505378: train_loss -0.9713\n",
            "2025-12-23 01:27:32.505586: val_loss -0.985\n",
            "2025-12-23 01:27:32.505677: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 01:27:32.505769: Epoch time: 22.45 s\n",
            "2025-12-23 01:27:33.857615: \n",
            "2025-12-23 01:27:33.857898: Epoch 557\n",
            "2025-12-23 01:27:33.858027: Current learning rate: 0.00481\n",
            "2025-12-23 01:27:56.326885: train_loss -0.9729\n",
            "2025-12-23 01:27:56.327092: val_loss -0.9865\n",
            "2025-12-23 01:27:56.327179: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 01:27:56.327350: Epoch time: 22.47 s\n",
            "2025-12-23 01:27:57.689979: \n",
            "2025-12-23 01:27:57.690185: Epoch 558\n",
            "2025-12-23 01:27:57.690363: Current learning rate: 0.0048\n",
            "2025-12-23 01:28:20.173774: train_loss -0.9734\n",
            "2025-12-23 01:28:20.173974: val_loss -0.9857\n",
            "2025-12-23 01:28:20.174062: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 01:28:20.174150: Epoch time: 22.49 s\n",
            "2025-12-23 01:28:21.542526: \n",
            "2025-12-23 01:28:21.542855: Epoch 559\n",
            "2025-12-23 01:28:21.543118: Current learning rate: 0.00479\n",
            "2025-12-23 01:28:44.020139: train_loss -0.9719\n",
            "2025-12-23 01:28:44.020487: val_loss -0.9849\n",
            "2025-12-23 01:28:44.020615: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 01:28:44.020730: Epoch time: 22.48 s\n",
            "2025-12-23 01:28:45.404071: \n",
            "2025-12-23 01:28:45.404392: Epoch 560\n",
            "2025-12-23 01:28:45.404563: Current learning rate: 0.00478\n",
            "2025-12-23 01:29:07.855426: train_loss -0.9733\n",
            "2025-12-23 01:29:07.855716: val_loss -0.986\n",
            "2025-12-23 01:29:07.855809: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 01:29:07.855967: Epoch time: 22.45 s\n",
            "2025-12-23 01:29:07.856066: Yayy! New best EMA pseudo Dice: 0.9887999892234802\n",
            "2025-12-23 01:29:09.811279: \n",
            "2025-12-23 01:29:09.811573: Epoch 561\n",
            "2025-12-23 01:29:09.811728: Current learning rate: 0.00477\n",
            "2025-12-23 01:29:32.274451: train_loss -0.9731\n",
            "2025-12-23 01:29:32.274761: val_loss -0.9858\n",
            "2025-12-23 01:29:32.274989: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 01:29:32.275201: Epoch time: 22.46 s\n",
            "2025-12-23 01:29:32.275425: Yayy! New best EMA pseudo Dice: 0.9887999892234802\n",
            "2025-12-23 01:29:34.186185: \n",
            "2025-12-23 01:29:34.186523: Epoch 562\n",
            "2025-12-23 01:29:34.186667: Current learning rate: 0.00476\n",
            "2025-12-23 01:29:56.701823: train_loss -0.9727\n",
            "2025-12-23 01:29:56.702170: val_loss -0.9836\n",
            "2025-12-23 01:29:56.702312: Pseudo dice [np.float32(0.9874)]\n",
            "2025-12-23 01:29:56.702410: Epoch time: 22.52 s\n",
            "2025-12-23 01:29:58.073109: \n",
            "2025-12-23 01:29:58.073310: Epoch 563\n",
            "2025-12-23 01:29:58.073440: Current learning rate: 0.00475\n",
            "2025-12-23 01:30:20.538405: train_loss -0.9723\n",
            "2025-12-23 01:30:20.538751: val_loss -0.9851\n",
            "2025-12-23 01:30:20.538962: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 01:30:20.539131: Epoch time: 22.47 s\n",
            "2025-12-23 01:30:21.896507: \n",
            "2025-12-23 01:30:21.896922: Epoch 564\n",
            "2025-12-23 01:30:21.897084: Current learning rate: 0.00474\n",
            "2025-12-23 01:30:44.342896: train_loss -0.9722\n",
            "2025-12-23 01:30:44.343331: val_loss -0.9862\n",
            "2025-12-23 01:30:44.343481: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 01:30:44.343595: Epoch time: 22.45 s\n",
            "2025-12-23 01:30:45.706968: \n",
            "2025-12-23 01:30:45.707295: Epoch 565\n",
            "2025-12-23 01:30:45.707441: Current learning rate: 0.00473\n",
            "2025-12-23 01:31:08.134174: train_loss -0.9735\n",
            "2025-12-23 01:31:08.134460: val_loss -0.9837\n",
            "2025-12-23 01:31:08.134708: Pseudo dice [np.float32(0.988)]\n",
            "2025-12-23 01:31:08.134869: Epoch time: 22.43 s\n",
            "2025-12-23 01:31:09.503260: \n",
            "2025-12-23 01:31:09.503451: Epoch 566\n",
            "2025-12-23 01:31:09.503580: Current learning rate: 0.00472\n",
            "2025-12-23 01:31:31.954363: train_loss -0.9733\n",
            "2025-12-23 01:31:31.954578: val_loss -0.9856\n",
            "2025-12-23 01:31:31.954699: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 01:31:31.954851: Epoch time: 22.45 s\n",
            "2025-12-23 01:31:33.323703: \n",
            "2025-12-23 01:31:33.324033: Epoch 567\n",
            "2025-12-23 01:31:33.324169: Current learning rate: 0.00471\n",
            "2025-12-23 01:31:55.755838: train_loss -0.9726\n",
            "2025-12-23 01:31:55.756153: val_loss -0.9849\n",
            "2025-12-23 01:31:55.756419: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 01:31:55.756612: Epoch time: 22.43 s\n",
            "2025-12-23 01:31:57.102417: \n",
            "2025-12-23 01:31:57.102578: Epoch 568\n",
            "2025-12-23 01:31:57.102707: Current learning rate: 0.0047\n",
            "2025-12-23 01:32:19.538370: train_loss -0.973\n",
            "2025-12-23 01:32:19.538567: val_loss -0.985\n",
            "2025-12-23 01:32:19.538668: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 01:32:19.538778: Epoch time: 22.44 s\n",
            "2025-12-23 01:32:20.876622: \n",
            "2025-12-23 01:32:20.876828: Epoch 569\n",
            "2025-12-23 01:32:20.876958: Current learning rate: 0.00469\n",
            "2025-12-23 01:32:43.302154: train_loss -0.9732\n",
            "2025-12-23 01:32:43.302448: val_loss -0.9845\n",
            "2025-12-23 01:32:43.302586: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 01:32:43.302696: Epoch time: 22.43 s\n",
            "2025-12-23 01:32:44.669119: \n",
            "2025-12-23 01:32:44.669459: Epoch 570\n",
            "2025-12-23 01:32:44.669596: Current learning rate: 0.00468\n",
            "2025-12-23 01:33:07.087422: train_loss -0.9732\n",
            "2025-12-23 01:33:07.087647: val_loss -0.986\n",
            "2025-12-23 01:33:07.087769: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 01:33:07.087981: Epoch time: 22.42 s\n",
            "2025-12-23 01:33:09.101310: \n",
            "2025-12-23 01:33:09.101565: Epoch 571\n",
            "2025-12-23 01:33:09.101699: Current learning rate: 0.00467\n",
            "2025-12-23 01:33:31.618868: train_loss -0.9732\n",
            "2025-12-23 01:33:31.619103: val_loss -0.9842\n",
            "2025-12-23 01:33:31.619210: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 01:33:31.619318: Epoch time: 22.52 s\n",
            "2025-12-23 01:33:32.945068: \n",
            "2025-12-23 01:33:32.945289: Epoch 572\n",
            "2025-12-23 01:33:32.945458: Current learning rate: 0.00466\n",
            "2025-12-23 01:33:55.404499: train_loss -0.972\n",
            "2025-12-23 01:33:55.404720: val_loss -0.9853\n",
            "2025-12-23 01:33:55.404838: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 01:33:55.404960: Epoch time: 22.46 s\n",
            "2025-12-23 01:33:56.720366: \n",
            "2025-12-23 01:33:56.720611: Epoch 573\n",
            "2025-12-23 01:33:56.720746: Current learning rate: 0.00465\n",
            "2025-12-23 01:34:19.185208: train_loss -0.973\n",
            "2025-12-23 01:34:19.185440: val_loss -0.9849\n",
            "2025-12-23 01:34:19.185543: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 01:34:19.185634: Epoch time: 22.47 s\n",
            "2025-12-23 01:34:20.541614: \n",
            "2025-12-23 01:34:20.541952: Epoch 574\n",
            "2025-12-23 01:34:20.542089: Current learning rate: 0.00464\n",
            "2025-12-23 01:34:43.076132: train_loss -0.9728\n",
            "2025-12-23 01:34:43.076445: val_loss -0.9845\n",
            "2025-12-23 01:34:43.076595: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 01:34:43.076693: Epoch time: 22.54 s\n",
            "2025-12-23 01:34:44.443535: \n",
            "2025-12-23 01:34:44.443859: Epoch 575\n",
            "2025-12-23 01:34:44.444020: Current learning rate: 0.00463\n",
            "2025-12-23 01:35:06.909554: train_loss -0.9737\n",
            "2025-12-23 01:35:06.909833: val_loss -0.9856\n",
            "2025-12-23 01:35:06.909989: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 01:35:06.910115: Epoch time: 22.47 s\n",
            "2025-12-23 01:35:08.288907: \n",
            "2025-12-23 01:35:08.289095: Epoch 576\n",
            "2025-12-23 01:35:08.289269: Current learning rate: 0.00462\n",
            "2025-12-23 01:35:30.757664: train_loss -0.9728\n",
            "2025-12-23 01:35:30.757881: val_loss -0.9841\n",
            "2025-12-23 01:35:30.757998: Pseudo dice [np.float32(0.9876)]\n",
            "2025-12-23 01:35:30.758115: Epoch time: 22.47 s\n",
            "2025-12-23 01:35:32.113962: \n",
            "2025-12-23 01:35:32.114264: Epoch 577\n",
            "2025-12-23 01:35:32.114411: Current learning rate: 0.00461\n",
            "2025-12-23 01:35:54.600782: train_loss -0.9733\n",
            "2025-12-23 01:35:54.601091: val_loss -0.9855\n",
            "2025-12-23 01:35:54.601255: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 01:35:54.601387: Epoch time: 22.49 s\n",
            "2025-12-23 01:35:55.975526: \n",
            "2025-12-23 01:35:55.975831: Epoch 578\n",
            "2025-12-23 01:35:55.975974: Current learning rate: 0.0046\n",
            "2025-12-23 01:36:18.434426: train_loss -0.9712\n",
            "2025-12-23 01:36:18.434871: val_loss -0.9842\n",
            "2025-12-23 01:36:18.435026: Pseudo dice [np.float32(0.9866)]\n",
            "2025-12-23 01:36:18.435147: Epoch time: 22.46 s\n",
            "2025-12-23 01:36:19.796500: \n",
            "2025-12-23 01:36:19.796692: Epoch 579\n",
            "2025-12-23 01:36:19.796821: Current learning rate: 0.00459\n",
            "2025-12-23 01:36:42.245394: train_loss -0.9642\n",
            "2025-12-23 01:36:42.245665: val_loss -0.9826\n",
            "2025-12-23 01:36:42.245778: Pseudo dice [np.float32(0.9864)]\n",
            "2025-12-23 01:36:42.245900: Epoch time: 22.45 s\n",
            "2025-12-23 01:36:43.610529: \n",
            "2025-12-23 01:36:43.610855: Epoch 580\n",
            "2025-12-23 01:36:43.610990: Current learning rate: 0.00458\n",
            "2025-12-23 01:37:06.070707: train_loss -0.9682\n",
            "2025-12-23 01:37:06.070920: val_loss -0.9838\n",
            "2025-12-23 01:37:06.071031: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 01:37:06.071146: Epoch time: 22.46 s\n",
            "2025-12-23 01:37:07.408529: \n",
            "2025-12-23 01:37:07.408816: Epoch 581\n",
            "2025-12-23 01:37:07.408973: Current learning rate: 0.00457\n",
            "2025-12-23 01:37:29.842877: train_loss -0.9699\n",
            "2025-12-23 01:37:29.843086: val_loss -0.9848\n",
            "2025-12-23 01:37:29.843250: Pseudo dice [np.float32(0.9877)]\n",
            "2025-12-23 01:37:29.843367: Epoch time: 22.44 s\n",
            "2025-12-23 01:37:31.232413: \n",
            "2025-12-23 01:37:31.232719: Epoch 582\n",
            "2025-12-23 01:37:31.232851: Current learning rate: 0.00456\n",
            "2025-12-23 01:37:53.694032: train_loss -0.9664\n",
            "2025-12-23 01:37:53.694343: val_loss -0.9819\n",
            "2025-12-23 01:37:53.694474: Pseudo dice [np.float32(0.9866)]\n",
            "2025-12-23 01:37:53.694633: Epoch time: 22.46 s\n",
            "2025-12-23 01:37:55.061062: \n",
            "2025-12-23 01:37:55.061270: Epoch 583\n",
            "2025-12-23 01:37:55.061439: Current learning rate: 0.00455\n",
            "2025-12-23 01:38:17.517154: train_loss -0.9679\n",
            "2025-12-23 01:38:17.517396: val_loss -0.9838\n",
            "2025-12-23 01:38:17.517512: Pseudo dice [np.float32(0.9876)]\n",
            "2025-12-23 01:38:17.517627: Epoch time: 22.46 s\n",
            "2025-12-23 01:38:18.908175: \n",
            "2025-12-23 01:38:18.908536: Epoch 584\n",
            "2025-12-23 01:38:18.908695: Current learning rate: 0.00454\n",
            "2025-12-23 01:38:41.340731: train_loss -0.9712\n",
            "2025-12-23 01:38:41.341034: val_loss -0.984\n",
            "2025-12-23 01:38:41.341143: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 01:38:41.341341: Epoch time: 22.43 s\n",
            "2025-12-23 01:38:42.703848: \n",
            "2025-12-23 01:38:42.704152: Epoch 585\n",
            "2025-12-23 01:38:42.704296: Current learning rate: 0.00453\n",
            "2025-12-23 01:39:05.126720: train_loss -0.9729\n",
            "2025-12-23 01:39:05.126951: val_loss -0.9846\n",
            "2025-12-23 01:39:05.127064: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 01:39:05.127199: Epoch time: 22.42 s\n",
            "2025-12-23 01:39:06.488406: \n",
            "2025-12-23 01:39:06.488749: Epoch 586\n",
            "2025-12-23 01:39:06.488894: Current learning rate: 0.00452\n",
            "2025-12-23 01:39:28.940507: train_loss -0.9722\n",
            "2025-12-23 01:39:28.940746: val_loss -0.9856\n",
            "2025-12-23 01:39:28.940887: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 01:39:28.940994: Epoch time: 22.45 s\n",
            "2025-12-23 01:39:30.286072: \n",
            "2025-12-23 01:39:30.286291: Epoch 587\n",
            "2025-12-23 01:39:30.286449: Current learning rate: 0.00451\n",
            "2025-12-23 01:39:52.757181: train_loss -0.973\n",
            "2025-12-23 01:39:52.757501: val_loss -0.9855\n",
            "2025-12-23 01:39:52.757609: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 01:39:52.757702: Epoch time: 22.47 s\n",
            "2025-12-23 01:39:54.139519: \n",
            "2025-12-23 01:39:54.139820: Epoch 588\n",
            "2025-12-23 01:39:54.139950: Current learning rate: 0.0045\n",
            "2025-12-23 01:40:16.557927: train_loss -0.9719\n",
            "2025-12-23 01:40:16.558153: val_loss -0.9853\n",
            "2025-12-23 01:40:16.558281: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 01:40:16.558601: Epoch time: 22.42 s\n",
            "2025-12-23 01:40:18.614629: \n",
            "2025-12-23 01:40:18.614978: Epoch 589\n",
            "2025-12-23 01:40:18.615125: Current learning rate: 0.00449\n",
            "2025-12-23 01:40:41.074935: train_loss -0.9727\n",
            "2025-12-23 01:40:41.075178: val_loss -0.9865\n",
            "2025-12-23 01:40:41.075311: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 01:40:41.075414: Epoch time: 22.46 s\n",
            "2025-12-23 01:40:42.390512: \n",
            "2025-12-23 01:40:42.390822: Epoch 590\n",
            "2025-12-23 01:40:42.390972: Current learning rate: 0.00448\n",
            "2025-12-23 01:41:04.880034: train_loss -0.9718\n",
            "2025-12-23 01:41:04.880341: val_loss -0.9847\n",
            "2025-12-23 01:41:04.880489: Pseudo dice [np.float32(0.9879)]\n",
            "2025-12-23 01:41:04.880648: Epoch time: 22.49 s\n",
            "2025-12-23 01:41:06.203393: \n",
            "2025-12-23 01:41:06.203756: Epoch 591\n",
            "2025-12-23 01:41:06.203892: Current learning rate: 0.00447\n",
            "2025-12-23 01:41:28.693022: train_loss -0.9727\n",
            "2025-12-23 01:41:28.693300: val_loss -0.9854\n",
            "2025-12-23 01:41:28.693404: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 01:41:28.693497: Epoch time: 22.49 s\n",
            "2025-12-23 01:41:30.043779: \n",
            "2025-12-23 01:41:30.044082: Epoch 592\n",
            "2025-12-23 01:41:30.044209: Current learning rate: 0.00446\n",
            "2025-12-23 01:41:52.521087: train_loss -0.9721\n",
            "2025-12-23 01:41:52.521475: val_loss -0.986\n",
            "2025-12-23 01:41:52.521577: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 01:41:52.521678: Epoch time: 22.48 s\n",
            "2025-12-23 01:41:53.876133: \n",
            "2025-12-23 01:41:53.876464: Epoch 593\n",
            "2025-12-23 01:41:53.876602: Current learning rate: 0.00445\n",
            "2025-12-23 01:42:16.349586: train_loss -0.9721\n",
            "2025-12-23 01:42:16.349888: val_loss -0.9844\n",
            "2025-12-23 01:42:16.350025: Pseudo dice [np.float32(0.9874)]\n",
            "2025-12-23 01:42:16.350179: Epoch time: 22.47 s\n",
            "2025-12-23 01:42:17.726490: \n",
            "2025-12-23 01:42:17.726892: Epoch 594\n",
            "2025-12-23 01:42:17.727026: Current learning rate: 0.00444\n",
            "2025-12-23 01:42:40.249960: train_loss -0.9728\n",
            "2025-12-23 01:42:40.250182: val_loss -0.9849\n",
            "2025-12-23 01:42:40.250331: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 01:42:40.250445: Epoch time: 22.52 s\n",
            "2025-12-23 01:42:41.634212: \n",
            "2025-12-23 01:42:41.634562: Epoch 595\n",
            "2025-12-23 01:42:41.634721: Current learning rate: 0.00443\n",
            "2025-12-23 01:43:04.140003: train_loss -0.9728\n",
            "2025-12-23 01:43:04.140327: val_loss -0.9855\n",
            "2025-12-23 01:43:04.140532: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 01:43:04.140709: Epoch time: 22.51 s\n",
            "2025-12-23 01:43:05.544549: \n",
            "2025-12-23 01:43:05.544833: Epoch 596\n",
            "2025-12-23 01:43:05.544970: Current learning rate: 0.00442\n",
            "2025-12-23 01:43:28.018785: train_loss -0.9708\n",
            "2025-12-23 01:43:28.019237: val_loss -0.9838\n",
            "2025-12-23 01:43:28.019404: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 01:43:28.019500: Epoch time: 22.48 s\n",
            "2025-12-23 01:43:29.406582: \n",
            "2025-12-23 01:43:29.406931: Epoch 597\n",
            "2025-12-23 01:43:29.407072: Current learning rate: 0.00441\n",
            "2025-12-23 01:43:51.828846: train_loss -0.964\n",
            "2025-12-23 01:43:51.829298: val_loss -0.9833\n",
            "2025-12-23 01:43:51.829410: Pseudo dice [np.float32(0.987)]\n",
            "2025-12-23 01:43:51.829512: Epoch time: 22.42 s\n",
            "2025-12-23 01:43:53.234855: \n",
            "2025-12-23 01:43:53.235146: Epoch 598\n",
            "2025-12-23 01:43:53.235295: Current learning rate: 0.0044\n",
            "2025-12-23 01:44:15.675902: train_loss -0.9683\n",
            "2025-12-23 01:44:15.676272: val_loss -0.982\n",
            "2025-12-23 01:44:15.676512: Pseudo dice [np.float32(0.9869)]\n",
            "2025-12-23 01:44:15.676740: Epoch time: 22.44 s\n",
            "2025-12-23 01:44:17.041240: \n",
            "2025-12-23 01:44:17.041589: Epoch 599\n",
            "2025-12-23 01:44:17.041770: Current learning rate: 0.00439\n",
            "2025-12-23 01:44:39.525596: train_loss -0.9679\n",
            "2025-12-23 01:44:39.525817: val_loss -0.9818\n",
            "2025-12-23 01:44:39.525908: Pseudo dice [np.float32(0.9871)]\n",
            "2025-12-23 01:44:39.526005: Epoch time: 22.49 s\n",
            "2025-12-23 01:44:41.497549: \n",
            "2025-12-23 01:44:41.497764: Epoch 600\n",
            "2025-12-23 01:44:41.497901: Current learning rate: 0.00438\n",
            "2025-12-23 01:45:03.967175: train_loss -0.9705\n",
            "2025-12-23 01:45:03.967541: val_loss -0.9853\n",
            "2025-12-23 01:45:03.967767: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 01:45:03.967883: Epoch time: 22.47 s\n",
            "2025-12-23 01:45:05.337092: \n",
            "2025-12-23 01:45:05.337358: Epoch 601\n",
            "2025-12-23 01:45:05.337497: Current learning rate: 0.00437\n",
            "2025-12-23 01:45:27.846764: train_loss -0.9714\n",
            "2025-12-23 01:45:27.846972: val_loss -0.9824\n",
            "2025-12-23 01:45:27.847087: Pseudo dice [np.float32(0.9869)]\n",
            "2025-12-23 01:45:27.847276: Epoch time: 22.51 s\n",
            "2025-12-23 01:45:29.236196: \n",
            "2025-12-23 01:45:29.236491: Epoch 602\n",
            "2025-12-23 01:45:29.236630: Current learning rate: 0.00436\n",
            "2025-12-23 01:45:51.628627: train_loss -0.9716\n",
            "2025-12-23 01:45:51.628837: val_loss -0.9833\n",
            "2025-12-23 01:45:51.629027: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 01:45:51.629125: Epoch time: 22.39 s\n",
            "2025-12-23 01:45:53.027986: \n",
            "2025-12-23 01:45:53.028350: Epoch 603\n",
            "2025-12-23 01:45:53.028487: Current learning rate: 0.00435\n",
            "2025-12-23 01:46:15.426068: train_loss -0.9709\n",
            "2025-12-23 01:46:15.426352: val_loss -0.9837\n",
            "2025-12-23 01:46:15.426467: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 01:46:15.426588: Epoch time: 22.4 s\n",
            "2025-12-23 01:46:16.818299: \n",
            "2025-12-23 01:46:16.818682: Epoch 604\n",
            "2025-12-23 01:46:16.818825: Current learning rate: 0.00434\n",
            "2025-12-23 01:46:39.238896: train_loss -0.9712\n",
            "2025-12-23 01:46:39.239112: val_loss -0.9851\n",
            "2025-12-23 01:46:39.239201: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 01:46:39.239335: Epoch time: 22.42 s\n",
            "2025-12-23 01:46:40.623096: \n",
            "2025-12-23 01:46:40.623405: Epoch 605\n",
            "2025-12-23 01:46:40.623569: Current learning rate: 0.00433\n",
            "2025-12-23 01:47:03.047276: train_loss -0.9719\n",
            "2025-12-23 01:47:03.047549: val_loss -0.9849\n",
            "2025-12-23 01:47:03.047715: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 01:47:03.047945: Epoch time: 22.43 s\n",
            "2025-12-23 01:47:04.422242: \n",
            "2025-12-23 01:47:04.422580: Epoch 606\n",
            "2025-12-23 01:47:04.422740: Current learning rate: 0.00432\n",
            "2025-12-23 01:47:26.831529: train_loss -0.9713\n",
            "2025-12-23 01:47:26.831742: val_loss -0.9856\n",
            "2025-12-23 01:47:26.831836: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 01:47:26.831935: Epoch time: 22.41 s\n",
            "2025-12-23 01:47:28.888546: \n",
            "2025-12-23 01:47:28.888836: Epoch 607\n",
            "2025-12-23 01:47:28.889071: Current learning rate: 0.00431\n",
            "2025-12-23 01:47:51.424799: train_loss -0.9733\n",
            "2025-12-23 01:47:51.425156: val_loss -0.9852\n",
            "2025-12-23 01:47:51.425330: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 01:47:51.425435: Epoch time: 22.54 s\n",
            "2025-12-23 01:47:52.779579: \n",
            "2025-12-23 01:47:52.779912: Epoch 608\n",
            "2025-12-23 01:47:52.780075: Current learning rate: 0.0043\n",
            "2025-12-23 01:48:15.269945: train_loss -0.9696\n",
            "2025-12-23 01:48:15.270255: val_loss -0.9832\n",
            "2025-12-23 01:48:15.270377: Pseudo dice [np.float32(0.9871)]\n",
            "2025-12-23 01:48:15.270528: Epoch time: 22.49 s\n",
            "2025-12-23 01:48:16.618528: \n",
            "2025-12-23 01:48:16.618885: Epoch 609\n",
            "2025-12-23 01:48:16.619021: Current learning rate: 0.00429\n",
            "2025-12-23 01:48:39.064136: train_loss -0.9664\n",
            "2025-12-23 01:48:39.064465: val_loss -0.9829\n",
            "2025-12-23 01:48:39.064593: Pseudo dice [np.float32(0.9866)]\n",
            "2025-12-23 01:48:39.064697: Epoch time: 22.45 s\n",
            "2025-12-23 01:48:40.423760: \n",
            "2025-12-23 01:48:40.424190: Epoch 610\n",
            "2025-12-23 01:48:40.424372: Current learning rate: 0.00429\n",
            "2025-12-23 01:49:02.907962: train_loss -0.9675\n",
            "2025-12-23 01:49:02.908189: val_loss -0.9824\n",
            "2025-12-23 01:49:02.908334: Pseudo dice [np.float32(0.9868)]\n",
            "2025-12-23 01:49:02.908433: Epoch time: 22.49 s\n",
            "2025-12-23 01:49:04.251503: \n",
            "2025-12-23 01:49:04.251806: Epoch 611\n",
            "2025-12-23 01:49:04.251948: Current learning rate: 0.00428\n",
            "2025-12-23 01:49:26.742698: train_loss -0.971\n",
            "2025-12-23 01:49:26.742988: val_loss -0.9842\n",
            "2025-12-23 01:49:26.743138: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 01:49:26.743312: Epoch time: 22.49 s\n",
            "2025-12-23 01:49:28.106301: \n",
            "2025-12-23 01:49:28.106518: Epoch 612\n",
            "2025-12-23 01:49:28.106644: Current learning rate: 0.00427\n",
            "2025-12-23 01:49:50.535520: train_loss -0.9727\n",
            "2025-12-23 01:49:50.535893: val_loss -0.9857\n",
            "2025-12-23 01:49:50.536052: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 01:49:50.536198: Epoch time: 22.43 s\n",
            "2025-12-23 01:49:51.907109: \n",
            "2025-12-23 01:49:51.907419: Epoch 613\n",
            "2025-12-23 01:49:51.907578: Current learning rate: 0.00426\n",
            "2025-12-23 01:50:14.356940: train_loss -0.9719\n",
            "2025-12-23 01:50:14.357242: val_loss -0.9829\n",
            "2025-12-23 01:50:14.357429: Pseudo dice [np.float32(0.9872)]\n",
            "2025-12-23 01:50:14.357543: Epoch time: 22.45 s\n",
            "2025-12-23 01:50:15.745936: \n",
            "2025-12-23 01:50:15.746224: Epoch 614\n",
            "2025-12-23 01:50:15.746360: Current learning rate: 0.00425\n",
            "2025-12-23 01:50:38.297410: train_loss -0.9709\n",
            "2025-12-23 01:50:38.297678: val_loss -0.9848\n",
            "2025-12-23 01:50:38.297871: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 01:50:38.298045: Epoch time: 22.55 s\n",
            "2025-12-23 01:50:39.676837: \n",
            "2025-12-23 01:50:39.677043: Epoch 615\n",
            "2025-12-23 01:50:39.677172: Current learning rate: 0.00424\n",
            "2025-12-23 01:51:02.152291: train_loss -0.9681\n",
            "2025-12-23 01:51:02.152484: val_loss -0.9834\n",
            "2025-12-23 01:51:02.152580: Pseudo dice [np.float32(0.9876)]\n",
            "2025-12-23 01:51:02.152701: Epoch time: 22.48 s\n",
            "2025-12-23 01:51:03.530153: \n",
            "2025-12-23 01:51:03.530477: Epoch 616\n",
            "2025-12-23 01:51:03.530617: Current learning rate: 0.00423\n",
            "2025-12-23 01:51:25.988307: train_loss -0.9692\n",
            "2025-12-23 01:51:25.988634: val_loss -0.9846\n",
            "2025-12-23 01:51:25.988782: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 01:51:25.988902: Epoch time: 22.46 s\n",
            "2025-12-23 01:51:27.362635: \n",
            "2025-12-23 01:51:27.362947: Epoch 617\n",
            "2025-12-23 01:51:27.363080: Current learning rate: 0.00422\n",
            "2025-12-23 01:51:49.825190: train_loss -0.9701\n",
            "2025-12-23 01:51:49.825524: val_loss -0.9843\n",
            "2025-12-23 01:51:49.825663: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 01:51:49.825772: Epoch time: 22.46 s\n",
            "2025-12-23 01:51:51.197952: \n",
            "2025-12-23 01:51:51.198253: Epoch 618\n",
            "2025-12-23 01:51:51.198405: Current learning rate: 0.00421\n",
            "2025-12-23 01:52:13.719856: train_loss -0.9716\n",
            "2025-12-23 01:52:13.720140: val_loss -0.9854\n",
            "2025-12-23 01:52:13.720403: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 01:52:13.720654: Epoch time: 22.52 s\n",
            "2025-12-23 01:52:15.074941: \n",
            "2025-12-23 01:52:15.075133: Epoch 619\n",
            "2025-12-23 01:52:15.075278: Current learning rate: 0.0042\n",
            "2025-12-23 01:52:37.476943: train_loss -0.9715\n",
            "2025-12-23 01:52:37.477175: val_loss -0.9841\n",
            "2025-12-23 01:52:37.477308: Pseudo dice [np.float32(0.9867)]\n",
            "2025-12-23 01:52:37.477410: Epoch time: 22.4 s\n",
            "2025-12-23 01:52:38.811364: \n",
            "2025-12-23 01:52:38.811623: Epoch 620\n",
            "2025-12-23 01:52:38.811772: Current learning rate: 0.00419\n",
            "2025-12-23 01:53:01.238130: train_loss -0.9725\n",
            "2025-12-23 01:53:01.238383: val_loss -0.9861\n",
            "2025-12-23 01:53:01.238561: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 01:53:01.238704: Epoch time: 22.43 s\n",
            "2025-12-23 01:53:02.584250: \n",
            "2025-12-23 01:53:02.584523: Epoch 621\n",
            "2025-12-23 01:53:02.584654: Current learning rate: 0.00418\n",
            "2025-12-23 01:53:25.008799: train_loss -0.9722\n",
            "2025-12-23 01:53:25.009139: val_loss -0.9852\n",
            "2025-12-23 01:53:25.009262: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 01:53:25.009391: Epoch time: 22.43 s\n",
            "2025-12-23 01:53:26.379031: \n",
            "2025-12-23 01:53:26.379308: Epoch 622\n",
            "2025-12-23 01:53:26.379462: Current learning rate: 0.00417\n",
            "2025-12-23 01:53:48.817427: train_loss -0.972\n",
            "2025-12-23 01:53:48.817643: val_loss -0.9838\n",
            "2025-12-23 01:53:48.817735: Pseudo dice [np.float32(0.988)]\n",
            "2025-12-23 01:53:48.817828: Epoch time: 22.44 s\n",
            "2025-12-23 01:53:50.181437: \n",
            "2025-12-23 01:53:50.181766: Epoch 623\n",
            "2025-12-23 01:53:50.181900: Current learning rate: 0.00416\n",
            "2025-12-23 01:54:12.575852: train_loss -0.9712\n",
            "2025-12-23 01:54:12.576098: val_loss -0.9859\n",
            "2025-12-23 01:54:12.576188: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 01:54:12.576317: Epoch time: 22.4 s\n",
            "2025-12-23 01:54:13.939174: \n",
            "2025-12-23 01:54:13.939405: Epoch 624\n",
            "2025-12-23 01:54:13.939538: Current learning rate: 0.00415\n",
            "2025-12-23 01:54:36.375305: train_loss -0.9718\n",
            "2025-12-23 01:54:36.375536: val_loss -0.9856\n",
            "2025-12-23 01:54:36.375637: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 01:54:36.375725: Epoch time: 22.44 s\n",
            "2025-12-23 01:54:38.511847: \n",
            "2025-12-23 01:54:38.512067: Epoch 625\n",
            "2025-12-23 01:54:38.512253: Current learning rate: 0.00414\n",
            "2025-12-23 01:55:00.966482: train_loss -0.9708\n",
            "2025-12-23 01:55:00.966685: val_loss -0.9854\n",
            "2025-12-23 01:55:00.966775: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 01:55:00.966863: Epoch time: 22.46 s\n",
            "2025-12-23 01:55:02.308492: \n",
            "2025-12-23 01:55:02.308843: Epoch 626\n",
            "2025-12-23 01:55:02.308982: Current learning rate: 0.00413\n",
            "2025-12-23 01:55:24.813638: train_loss -0.9723\n",
            "2025-12-23 01:55:24.813962: val_loss -0.9855\n",
            "2025-12-23 01:55:24.814068: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 01:55:24.814159: Epoch time: 22.51 s\n",
            "2025-12-23 01:55:26.183863: \n",
            "2025-12-23 01:55:26.184152: Epoch 627\n",
            "2025-12-23 01:55:26.184306: Current learning rate: 0.00412\n",
            "2025-12-23 01:55:48.653742: train_loss -0.9745\n",
            "2025-12-23 01:55:48.653960: val_loss -0.986\n",
            "2025-12-23 01:55:48.654048: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 01:55:48.654138: Epoch time: 22.47 s\n",
            "2025-12-23 01:55:50.005687: \n",
            "2025-12-23 01:55:50.006026: Epoch 628\n",
            "2025-12-23 01:55:50.006159: Current learning rate: 0.00411\n",
            "2025-12-23 01:56:12.495409: train_loss -0.9732\n",
            "2025-12-23 01:56:12.495695: val_loss -0.9851\n",
            "2025-12-23 01:56:12.495789: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 01:56:12.495883: Epoch time: 22.49 s\n",
            "2025-12-23 01:56:13.829520: \n",
            "2025-12-23 01:56:13.829891: Epoch 629\n",
            "2025-12-23 01:56:13.830034: Current learning rate: 0.0041\n",
            "2025-12-23 01:56:36.333244: train_loss -0.9734\n",
            "2025-12-23 01:56:36.333461: val_loss -0.9852\n",
            "2025-12-23 01:56:36.333559: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 01:56:36.333653: Epoch time: 22.5 s\n",
            "2025-12-23 01:56:37.700494: \n",
            "2025-12-23 01:56:37.700893: Epoch 630\n",
            "2025-12-23 01:56:37.701021: Current learning rate: 0.00409\n",
            "2025-12-23 01:57:00.205517: train_loss -0.974\n",
            "2025-12-23 01:57:00.205746: val_loss -0.9829\n",
            "2025-12-23 01:57:00.205868: Pseudo dice [np.float32(0.9875)]\n",
            "2025-12-23 01:57:00.206040: Epoch time: 22.51 s\n",
            "2025-12-23 01:57:01.586202: \n",
            "2025-12-23 01:57:01.586458: Epoch 631\n",
            "2025-12-23 01:57:01.586592: Current learning rate: 0.00408\n",
            "2025-12-23 01:57:24.048990: train_loss -0.9729\n",
            "2025-12-23 01:57:24.049228: val_loss -0.9848\n",
            "2025-12-23 01:57:24.049352: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 01:57:24.049448: Epoch time: 22.46 s\n",
            "2025-12-23 01:57:25.413767: \n",
            "2025-12-23 01:57:25.414028: Epoch 632\n",
            "2025-12-23 01:57:25.414160: Current learning rate: 0.00407\n",
            "2025-12-23 01:57:47.872342: train_loss -0.9725\n",
            "2025-12-23 01:57:47.872617: val_loss -0.9853\n",
            "2025-12-23 01:57:47.872715: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 01:57:47.872889: Epoch time: 22.46 s\n",
            "2025-12-23 01:57:49.278250: \n",
            "2025-12-23 01:57:49.278576: Epoch 633\n",
            "2025-12-23 01:57:49.278726: Current learning rate: 0.00406\n",
            "2025-12-23 01:58:11.764573: train_loss -0.9735\n",
            "2025-12-23 01:58:11.764795: val_loss -0.9844\n",
            "2025-12-23 01:58:11.764929: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 01:58:11.765056: Epoch time: 22.49 s\n",
            "2025-12-23 01:58:13.137657: \n",
            "2025-12-23 01:58:13.138047: Epoch 634\n",
            "2025-12-23 01:58:13.138185: Current learning rate: 0.00405\n",
            "2025-12-23 01:58:35.572368: train_loss -0.9733\n",
            "2025-12-23 01:58:35.572782: val_loss -0.9842\n",
            "2025-12-23 01:58:35.572876: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 01:58:35.572971: Epoch time: 22.44 s\n",
            "2025-12-23 01:58:36.954328: \n",
            "2025-12-23 01:58:36.954504: Epoch 635\n",
            "2025-12-23 01:58:36.954629: Current learning rate: 0.00404\n",
            "2025-12-23 01:58:59.371776: train_loss -0.9732\n",
            "2025-12-23 01:58:59.372046: val_loss -0.9848\n",
            "2025-12-23 01:58:59.372195: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 01:58:59.372324: Epoch time: 22.42 s\n",
            "2025-12-23 01:59:00.763590: \n",
            "2025-12-23 01:59:00.763971: Epoch 636\n",
            "2025-12-23 01:59:00.764128: Current learning rate: 0.00403\n",
            "2025-12-23 01:59:23.216726: train_loss -0.973\n",
            "2025-12-23 01:59:23.217138: val_loss -0.9856\n",
            "2025-12-23 01:59:23.217271: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 01:59:23.217387: Epoch time: 22.45 s\n",
            "2025-12-23 01:59:24.600272: \n",
            "2025-12-23 01:59:24.600654: Epoch 637\n",
            "2025-12-23 01:59:24.600793: Current learning rate: 0.00402\n",
            "2025-12-23 01:59:47.019590: train_loss -0.9743\n",
            "2025-12-23 01:59:47.019909: val_loss -0.9863\n",
            "2025-12-23 01:59:47.020007: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 01:59:47.020098: Epoch time: 22.42 s\n",
            "2025-12-23 01:59:48.383255: \n",
            "2025-12-23 01:59:48.383578: Epoch 638\n",
            "2025-12-23 01:59:48.383790: Current learning rate: 0.00401\n",
            "2025-12-23 02:00:10.811555: train_loss -0.974\n",
            "2025-12-23 02:00:10.811833: val_loss -0.9856\n",
            "2025-12-23 02:00:10.811960: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 02:00:10.812085: Epoch time: 22.43 s\n",
            "2025-12-23 02:00:12.205936: \n",
            "2025-12-23 02:00:12.206200: Epoch 639\n",
            "2025-12-23 02:00:12.206436: Current learning rate: 0.004\n",
            "2025-12-23 02:00:34.693147: train_loss -0.9736\n",
            "2025-12-23 02:00:34.693424: val_loss -0.9862\n",
            "2025-12-23 02:00:34.693520: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 02:00:34.693612: Epoch time: 22.49 s\n",
            "2025-12-23 02:00:36.059637: \n",
            "2025-12-23 02:00:36.060026: Epoch 640\n",
            "2025-12-23 02:00:36.060260: Current learning rate: 0.00399\n",
            "2025-12-23 02:00:58.451933: train_loss -0.9739\n",
            "2025-12-23 02:00:58.452176: val_loss -0.9847\n",
            "2025-12-23 02:00:58.452325: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 02:00:58.452444: Epoch time: 22.39 s\n",
            "2025-12-23 02:00:59.826745: \n",
            "2025-12-23 02:00:59.827081: Epoch 641\n",
            "2025-12-23 02:00:59.827313: Current learning rate: 0.00398\n",
            "2025-12-23 02:01:22.217991: train_loss -0.9734\n",
            "2025-12-23 02:01:22.218236: val_loss -0.9852\n",
            "2025-12-23 02:01:22.218345: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 02:01:22.218439: Epoch time: 22.39 s\n",
            "2025-12-23 02:01:23.594374: \n",
            "2025-12-23 02:01:23.594642: Epoch 642\n",
            "2025-12-23 02:01:23.594779: Current learning rate: 0.00397\n",
            "2025-12-23 02:01:45.975037: train_loss -0.9731\n",
            "2025-12-23 02:01:45.975278: val_loss -0.9852\n",
            "2025-12-23 02:01:45.975372: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 02:01:45.975461: Epoch time: 22.38 s\n",
            "2025-12-23 02:01:47.999341: \n",
            "2025-12-23 02:01:47.999573: Epoch 643\n",
            "2025-12-23 02:01:47.999732: Current learning rate: 0.00396\n",
            "2025-12-23 02:02:10.525452: train_loss -0.9726\n",
            "2025-12-23 02:02:10.525836: val_loss -0.9839\n",
            "2025-12-23 02:02:10.526063: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 02:02:10.526272: Epoch time: 22.53 s\n",
            "2025-12-23 02:02:11.872152: \n",
            "2025-12-23 02:02:11.872441: Epoch 644\n",
            "2025-12-23 02:02:11.872606: Current learning rate: 0.00395\n",
            "2025-12-23 02:02:34.326790: train_loss -0.9733\n",
            "2025-12-23 02:02:34.327045: val_loss -0.9847\n",
            "2025-12-23 02:02:34.327137: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 02:02:34.327251: Epoch time: 22.46 s\n",
            "2025-12-23 02:02:35.667689: \n",
            "2025-12-23 02:02:35.668025: Epoch 645\n",
            "2025-12-23 02:02:35.668183: Current learning rate: 0.00394\n",
            "2025-12-23 02:02:58.149846: train_loss -0.9733\n",
            "2025-12-23 02:02:58.150061: val_loss -0.9844\n",
            "2025-12-23 02:02:58.150150: Pseudo dice [np.float32(0.988)]\n",
            "2025-12-23 02:02:58.150260: Epoch time: 22.48 s\n",
            "2025-12-23 02:02:59.484617: \n",
            "2025-12-23 02:02:59.484900: Epoch 646\n",
            "2025-12-23 02:02:59.485044: Current learning rate: 0.00393\n",
            "2025-12-23 02:03:21.958022: train_loss -0.9732\n",
            "2025-12-23 02:03:21.958398: val_loss -0.9854\n",
            "2025-12-23 02:03:21.958608: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 02:03:21.958753: Epoch time: 22.47 s\n",
            "2025-12-23 02:03:23.346910: \n",
            "2025-12-23 02:03:23.347144: Epoch 647\n",
            "2025-12-23 02:03:23.347410: Current learning rate: 0.00392\n",
            "2025-12-23 02:03:45.808619: train_loss -0.9742\n",
            "2025-12-23 02:03:45.808831: val_loss -0.985\n",
            "2025-12-23 02:03:45.808927: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 02:03:45.809021: Epoch time: 22.46 s\n",
            "2025-12-23 02:03:47.156277: \n",
            "2025-12-23 02:03:47.156557: Epoch 648\n",
            "2025-12-23 02:03:47.156682: Current learning rate: 0.00391\n",
            "2025-12-23 02:04:09.632730: train_loss -0.9734\n",
            "2025-12-23 02:04:09.632943: val_loss -0.9858\n",
            "2025-12-23 02:04:09.633033: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 02:04:09.633122: Epoch time: 22.48 s\n",
            "2025-12-23 02:04:11.012964: \n",
            "2025-12-23 02:04:11.013156: Epoch 649\n",
            "2025-12-23 02:04:11.013298: Current learning rate: 0.0039\n",
            "2025-12-23 02:04:33.527843: train_loss -0.9742\n",
            "2025-12-23 02:04:33.528072: val_loss -0.9861\n",
            "2025-12-23 02:04:33.528169: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 02:04:33.528318: Epoch time: 22.52 s\n",
            "2025-12-23 02:04:34.138052: Yayy! New best EMA pseudo Dice: 0.9889000058174133\n",
            "2025-12-23 02:04:36.077783: \n",
            "2025-12-23 02:04:36.078094: Epoch 650\n",
            "2025-12-23 02:04:36.078249: Current learning rate: 0.00389\n",
            "2025-12-23 02:04:58.570446: train_loss -0.9737\n",
            "2025-12-23 02:04:58.570724: val_loss -0.9845\n",
            "2025-12-23 02:04:58.570898: Pseudo dice [np.float32(0.9879)]\n",
            "2025-12-23 02:04:58.571032: Epoch time: 22.49 s\n",
            "2025-12-23 02:04:59.947553: \n",
            "2025-12-23 02:04:59.947739: Epoch 651\n",
            "2025-12-23 02:04:59.947863: Current learning rate: 0.00388\n",
            "2025-12-23 02:05:22.636445: train_loss -0.9732\n",
            "2025-12-23 02:05:22.636694: val_loss -0.987\n",
            "2025-12-23 02:05:22.636786: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 02:05:22.636904: Epoch time: 22.69 s\n",
            "2025-12-23 02:05:22.637078: Yayy! New best EMA pseudo Dice: 0.9889000058174133\n",
            "2025-12-23 02:05:24.537808: \n",
            "2025-12-23 02:05:24.538084: Epoch 652\n",
            "2025-12-23 02:05:24.538230: Current learning rate: 0.00387\n",
            "2025-12-23 02:05:47.021600: train_loss -0.9731\n",
            "2025-12-23 02:05:47.021832: val_loss -0.9846\n",
            "2025-12-23 02:05:47.021928: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 02:05:47.022018: Epoch time: 22.49 s\n",
            "2025-12-23 02:05:48.405005: \n",
            "2025-12-23 02:05:48.405385: Epoch 653\n",
            "2025-12-23 02:05:48.405542: Current learning rate: 0.00386\n",
            "2025-12-23 02:06:10.826935: train_loss -0.9563\n",
            "2025-12-23 02:06:10.827150: val_loss -0.972\n",
            "2025-12-23 02:06:10.827264: Pseudo dice [np.float32(0.9806)]\n",
            "2025-12-23 02:06:10.827373: Epoch time: 22.42 s\n",
            "2025-12-23 02:06:12.195734: \n",
            "2025-12-23 02:06:12.196160: Epoch 654\n",
            "2025-12-23 02:06:12.196341: Current learning rate: 0.00385\n",
            "2025-12-23 02:06:34.627424: train_loss -0.9561\n",
            "2025-12-23 02:06:34.627644: val_loss -0.9782\n",
            "2025-12-23 02:06:34.627823: Pseudo dice [np.float32(0.9833)]\n",
            "2025-12-23 02:06:34.627937: Epoch time: 22.43 s\n",
            "2025-12-23 02:06:35.986980: \n",
            "2025-12-23 02:06:35.987247: Epoch 655\n",
            "2025-12-23 02:06:35.987382: Current learning rate: 0.00384\n",
            "2025-12-23 02:06:58.437638: train_loss -0.9655\n",
            "2025-12-23 02:06:58.437891: val_loss -0.9817\n",
            "2025-12-23 02:06:58.438002: Pseudo dice [np.float32(0.9867)]\n",
            "2025-12-23 02:06:58.438132: Epoch time: 22.45 s\n",
            "2025-12-23 02:06:59.784949: \n",
            "2025-12-23 02:06:59.785236: Epoch 656\n",
            "2025-12-23 02:06:59.785390: Current learning rate: 0.00383\n",
            "2025-12-23 02:07:22.239441: train_loss -0.9663\n",
            "2025-12-23 02:07:22.239730: val_loss -0.9842\n",
            "2025-12-23 02:07:22.239835: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 02:07:22.239996: Epoch time: 22.46 s\n",
            "2025-12-23 02:07:23.588073: \n",
            "2025-12-23 02:07:23.588307: Epoch 657\n",
            "2025-12-23 02:07:23.588475: Current learning rate: 0.00382\n",
            "2025-12-23 02:07:46.015789: train_loss -0.969\n",
            "2025-12-23 02:07:46.016098: val_loss -0.9808\n",
            "2025-12-23 02:07:46.016203: Pseudo dice [np.float32(0.9851)]\n",
            "2025-12-23 02:07:46.016330: Epoch time: 22.43 s\n",
            "2025-12-23 02:07:47.352426: \n",
            "2025-12-23 02:07:47.352737: Epoch 658\n",
            "2025-12-23 02:07:47.352873: Current learning rate: 0.00381\n",
            "2025-12-23 02:08:09.801172: train_loss -0.9703\n",
            "2025-12-23 02:08:09.801510: val_loss -0.9841\n",
            "2025-12-23 02:08:09.801609: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 02:08:09.801701: Epoch time: 22.45 s\n",
            "2025-12-23 02:08:11.170684: \n",
            "2025-12-23 02:08:11.170971: Epoch 659\n",
            "2025-12-23 02:08:11.171107: Current learning rate: 0.0038\n",
            "2025-12-23 02:08:33.611794: train_loss -0.9713\n",
            "2025-12-23 02:08:33.611999: val_loss -0.9838\n",
            "2025-12-23 02:08:33.612087: Pseudo dice [np.float32(0.9874)]\n",
            "2025-12-23 02:08:33.612176: Epoch time: 22.44 s\n",
            "2025-12-23 02:08:35.669577: \n",
            "2025-12-23 02:08:35.669796: Epoch 660\n",
            "2025-12-23 02:08:35.669987: Current learning rate: 0.00379\n",
            "2025-12-23 02:08:58.229110: train_loss -0.9723\n",
            "2025-12-23 02:08:58.229372: val_loss -0.985\n",
            "2025-12-23 02:08:58.229488: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 02:08:58.229666: Epoch time: 22.56 s\n",
            "2025-12-23 02:08:59.568300: \n",
            "2025-12-23 02:08:59.568662: Epoch 661\n",
            "2025-12-23 02:08:59.568797: Current learning rate: 0.00378\n",
            "2025-12-23 02:09:22.040657: train_loss -0.9732\n",
            "2025-12-23 02:09:22.041042: val_loss -0.9867\n",
            "2025-12-23 02:09:22.041197: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 02:09:22.041367: Epoch time: 22.47 s\n",
            "2025-12-23 02:09:23.397077: \n",
            "2025-12-23 02:09:23.397392: Epoch 662\n",
            "2025-12-23 02:09:23.397531: Current learning rate: 0.00377\n",
            "2025-12-23 02:09:45.902778: train_loss -0.973\n",
            "2025-12-23 02:09:45.903029: val_loss -0.9856\n",
            "2025-12-23 02:09:45.903117: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 02:09:45.903270: Epoch time: 22.51 s\n",
            "2025-12-23 02:09:47.256960: \n",
            "2025-12-23 02:09:47.257394: Epoch 663\n",
            "2025-12-23 02:09:47.257550: Current learning rate: 0.00376\n",
            "2025-12-23 02:10:09.759356: train_loss -0.971\n",
            "2025-12-23 02:10:09.759613: val_loss -0.9847\n",
            "2025-12-23 02:10:09.759718: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 02:10:09.759814: Epoch time: 22.5 s\n",
            "2025-12-23 02:10:11.124164: \n",
            "2025-12-23 02:10:11.124527: Epoch 664\n",
            "2025-12-23 02:10:11.124660: Current learning rate: 0.00375\n",
            "2025-12-23 02:10:33.644887: train_loss -0.9698\n",
            "2025-12-23 02:10:33.645211: val_loss -0.9845\n",
            "2025-12-23 02:10:33.645353: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 02:10:33.645450: Epoch time: 22.52 s\n",
            "2025-12-23 02:10:34.992016: \n",
            "2025-12-23 02:10:34.992234: Epoch 665\n",
            "2025-12-23 02:10:34.992409: Current learning rate: 0.00374\n",
            "2025-12-23 02:10:57.721824: train_loss -0.9726\n",
            "2025-12-23 02:10:57.722135: val_loss -0.9854\n",
            "2025-12-23 02:10:57.722307: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 02:10:57.722468: Epoch time: 22.73 s\n",
            "2025-12-23 02:10:59.105418: \n",
            "2025-12-23 02:10:59.105711: Epoch 666\n",
            "2025-12-23 02:10:59.105850: Current learning rate: 0.00373\n",
            "2025-12-23 02:11:21.635409: train_loss -0.9732\n",
            "2025-12-23 02:11:21.635663: val_loss -0.9844\n",
            "2025-12-23 02:11:21.635754: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 02:11:21.635853: Epoch time: 22.53 s\n",
            "2025-12-23 02:11:22.994527: \n",
            "2025-12-23 02:11:22.994817: Epoch 667\n",
            "2025-12-23 02:11:22.994953: Current learning rate: 0.00372\n",
            "2025-12-23 02:11:45.431002: train_loss -0.972\n",
            "2025-12-23 02:11:45.431375: val_loss -0.9858\n",
            "2025-12-23 02:11:45.431541: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 02:11:45.431658: Epoch time: 22.44 s\n",
            "2025-12-23 02:11:46.788013: \n",
            "2025-12-23 02:11:46.788181: Epoch 668\n",
            "2025-12-23 02:11:46.788321: Current learning rate: 0.00371\n",
            "2025-12-23 02:12:09.535026: train_loss -0.9726\n",
            "2025-12-23 02:12:09.535281: val_loss -0.9858\n",
            "2025-12-23 02:12:09.535410: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 02:12:09.535540: Epoch time: 22.75 s\n",
            "2025-12-23 02:12:10.925240: \n",
            "2025-12-23 02:12:10.925423: Epoch 669\n",
            "2025-12-23 02:12:10.925583: Current learning rate: 0.0037\n",
            "2025-12-23 02:12:33.387971: train_loss -0.9728\n",
            "2025-12-23 02:12:33.388178: val_loss -0.9857\n",
            "2025-12-23 02:12:33.388323: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 02:12:33.388520: Epoch time: 22.46 s\n",
            "2025-12-23 02:12:34.784344: \n",
            "2025-12-23 02:12:34.784659: Epoch 670\n",
            "2025-12-23 02:12:34.784801: Current learning rate: 0.00369\n",
            "2025-12-23 02:12:57.483661: train_loss -0.9703\n",
            "2025-12-23 02:12:57.483898: val_loss -0.9859\n",
            "2025-12-23 02:12:57.484049: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 02:12:57.484207: Epoch time: 22.7 s\n",
            "2025-12-23 02:12:58.864940: \n",
            "2025-12-23 02:12:58.865177: Epoch 671\n",
            "2025-12-23 02:12:58.865323: Current learning rate: 0.00368\n",
            "2025-12-23 02:13:21.580599: train_loss -0.9683\n",
            "2025-12-23 02:13:21.581015: val_loss -0.9829\n",
            "2025-12-23 02:13:21.581162: Pseudo dice [np.float32(0.987)]\n",
            "2025-12-23 02:13:21.581303: Epoch time: 22.72 s\n",
            "2025-12-23 02:13:22.977541: \n",
            "2025-12-23 02:13:22.977763: Epoch 672\n",
            "2025-12-23 02:13:22.977928: Current learning rate: 0.00367\n",
            "2025-12-23 02:13:45.383338: train_loss -0.9671\n",
            "2025-12-23 02:13:45.383530: val_loss -0.9839\n",
            "2025-12-23 02:13:45.383620: Pseudo dice [np.float32(0.9879)]\n",
            "2025-12-23 02:13:45.383840: Epoch time: 22.41 s\n",
            "2025-12-23 02:13:46.747835: \n",
            "2025-12-23 02:13:46.748090: Epoch 673\n",
            "2025-12-23 02:13:46.748252: Current learning rate: 0.00366\n",
            "2025-12-23 02:14:09.184574: train_loss -0.9699\n",
            "2025-12-23 02:14:09.184783: val_loss -0.9846\n",
            "2025-12-23 02:14:09.184874: Pseudo dice [np.float32(0.9877)]\n",
            "2025-12-23 02:14:09.184963: Epoch time: 22.44 s\n",
            "2025-12-23 02:14:10.558472: \n",
            "2025-12-23 02:14:10.558849: Epoch 674\n",
            "2025-12-23 02:14:10.558995: Current learning rate: 0.00365\n",
            "2025-12-23 02:14:32.970033: train_loss -0.9715\n",
            "2025-12-23 02:14:32.970270: val_loss -0.9854\n",
            "2025-12-23 02:14:32.970395: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 02:14:32.970494: Epoch time: 22.41 s\n",
            "2025-12-23 02:14:34.377099: \n",
            "2025-12-23 02:14:34.377358: Epoch 675\n",
            "2025-12-23 02:14:34.377499: Current learning rate: 0.00364\n",
            "2025-12-23 02:14:56.767303: train_loss -0.9714\n",
            "2025-12-23 02:14:56.767509: val_loss -0.9859\n",
            "2025-12-23 02:14:56.767630: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 02:14:56.767868: Epoch time: 22.39 s\n",
            "2025-12-23 02:14:58.201530: \n",
            "2025-12-23 02:14:58.201815: Epoch 676\n",
            "2025-12-23 02:14:58.201966: Current learning rate: 0.00363\n",
            "2025-12-23 02:15:20.625733: train_loss -0.9723\n",
            "2025-12-23 02:15:20.626029: val_loss -0.9843\n",
            "2025-12-23 02:15:20.626134: Pseudo dice [np.float32(0.9875)]\n",
            "2025-12-23 02:15:20.626256: Epoch time: 22.43 s\n",
            "2025-12-23 02:15:22.716028: \n",
            "2025-12-23 02:15:22.716356: Epoch 677\n",
            "2025-12-23 02:15:22.716537: Current learning rate: 0.00362\n",
            "2025-12-23 02:15:45.270871: train_loss -0.9725\n",
            "2025-12-23 02:15:45.271174: val_loss -0.9843\n",
            "2025-12-23 02:15:45.271326: Pseudo dice [np.float32(0.9873)]\n",
            "2025-12-23 02:15:45.271483: Epoch time: 22.56 s\n",
            "2025-12-23 02:15:46.651882: \n",
            "2025-12-23 02:15:46.652229: Epoch 678\n",
            "2025-12-23 02:15:46.652531: Current learning rate: 0.00361\n",
            "2025-12-23 02:16:09.119641: train_loss -0.9733\n",
            "2025-12-23 02:16:09.119893: val_loss -0.9837\n",
            "2025-12-23 02:16:09.120011: Pseudo dice [np.float32(0.988)]\n",
            "2025-12-23 02:16:09.120126: Epoch time: 22.47 s\n",
            "2025-12-23 02:16:10.512660: \n",
            "2025-12-23 02:16:10.512995: Epoch 679\n",
            "2025-12-23 02:16:10.513174: Current learning rate: 0.0036\n",
            "2025-12-23 02:16:32.981925: train_loss -0.9731\n",
            "2025-12-23 02:16:32.982272: val_loss -0.9859\n",
            "2025-12-23 02:16:32.982487: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 02:16:32.982707: Epoch time: 22.47 s\n",
            "2025-12-23 02:16:34.352830: \n",
            "2025-12-23 02:16:34.353030: Epoch 680\n",
            "2025-12-23 02:16:34.353153: Current learning rate: 0.00359\n",
            "2025-12-23 02:16:56.878435: train_loss -0.9733\n",
            "2025-12-23 02:16:56.878670: val_loss -0.9851\n",
            "2025-12-23 02:16:56.878783: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 02:16:56.878875: Epoch time: 22.53 s\n",
            "2025-12-23 02:16:58.283318: \n",
            "2025-12-23 02:16:58.283512: Epoch 681\n",
            "2025-12-23 02:16:58.283758: Current learning rate: 0.00358\n",
            "2025-12-23 02:17:20.748276: train_loss -0.9726\n",
            "2025-12-23 02:17:20.748709: val_loss -0.9856\n",
            "2025-12-23 02:17:20.748860: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 02:17:20.748994: Epoch time: 22.47 s\n",
            "2025-12-23 02:17:22.146167: \n",
            "2025-12-23 02:17:22.146559: Epoch 682\n",
            "2025-12-23 02:17:22.146704: Current learning rate: 0.00357\n",
            "2025-12-23 02:17:44.625372: train_loss -0.9732\n",
            "2025-12-23 02:17:44.625599: val_loss -0.9855\n",
            "2025-12-23 02:17:44.625783: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 02:17:44.625900: Epoch time: 22.48 s\n",
            "2025-12-23 02:17:46.037745: \n",
            "2025-12-23 02:17:46.038000: Epoch 683\n",
            "2025-12-23 02:17:46.038164: Current learning rate: 0.00356\n",
            "2025-12-23 02:18:08.492931: train_loss -0.9722\n",
            "2025-12-23 02:18:08.493206: val_loss -0.984\n",
            "2025-12-23 02:18:08.493327: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 02:18:08.493420: Epoch time: 22.46 s\n",
            "2025-12-23 02:18:09.916678: \n",
            "2025-12-23 02:18:09.917008: Epoch 684\n",
            "2025-12-23 02:18:09.917154: Current learning rate: 0.00355\n",
            "2025-12-23 02:18:32.364745: train_loss -0.9729\n",
            "2025-12-23 02:18:32.365254: val_loss -0.9864\n",
            "2025-12-23 02:18:32.365384: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 02:18:32.365494: Epoch time: 22.45 s\n",
            "2025-12-23 02:18:33.756005: \n",
            "2025-12-23 02:18:33.756284: Epoch 685\n",
            "2025-12-23 02:18:33.756437: Current learning rate: 0.00354\n",
            "2025-12-23 02:18:56.195945: train_loss -0.9741\n",
            "2025-12-23 02:18:56.196338: val_loss -0.9852\n",
            "2025-12-23 02:18:56.196473: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 02:18:56.196613: Epoch time: 22.44 s\n",
            "2025-12-23 02:18:57.551935: \n",
            "2025-12-23 02:18:57.552311: Epoch 686\n",
            "2025-12-23 02:18:57.552462: Current learning rate: 0.00353\n",
            "2025-12-23 02:19:20.014096: train_loss -0.9739\n",
            "2025-12-23 02:19:20.014321: val_loss -0.985\n",
            "2025-12-23 02:19:20.014499: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 02:19:20.014686: Epoch time: 22.46 s\n",
            "2025-12-23 02:19:21.416380: \n",
            "2025-12-23 02:19:21.416769: Epoch 687\n",
            "2025-12-23 02:19:21.416908: Current learning rate: 0.00352\n",
            "2025-12-23 02:19:43.922748: train_loss -0.9734\n",
            "2025-12-23 02:19:43.923006: val_loss -0.985\n",
            "2025-12-23 02:19:43.923179: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 02:19:43.923389: Epoch time: 22.51 s\n",
            "2025-12-23 02:19:45.292482: \n",
            "2025-12-23 02:19:45.292673: Epoch 688\n",
            "2025-12-23 02:19:45.292798: Current learning rate: 0.00351\n",
            "2025-12-23 02:20:07.772779: train_loss -0.9735\n",
            "2025-12-23 02:20:07.773027: val_loss -0.9864\n",
            "2025-12-23 02:20:07.773197: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 02:20:07.773332: Epoch time: 22.48 s\n",
            "2025-12-23 02:20:09.135950: \n",
            "2025-12-23 02:20:09.136161: Epoch 689\n",
            "2025-12-23 02:20:09.136303: Current learning rate: 0.0035\n",
            "2025-12-23 02:20:31.574251: train_loss -0.9734\n",
            "2025-12-23 02:20:31.574478: val_loss -0.986\n",
            "2025-12-23 02:20:31.574570: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 02:20:31.574660: Epoch time: 22.44 s\n",
            "2025-12-23 02:20:32.961575: \n",
            "2025-12-23 02:20:32.961912: Epoch 690\n",
            "2025-12-23 02:20:32.962053: Current learning rate: 0.00349\n",
            "2025-12-23 02:20:55.415920: train_loss -0.973\n",
            "2025-12-23 02:20:55.416197: val_loss -0.9844\n",
            "2025-12-23 02:20:55.416372: Pseudo dice [np.float32(0.9879)]\n",
            "2025-12-23 02:20:55.416475: Epoch time: 22.46 s\n",
            "2025-12-23 02:20:56.808847: \n",
            "2025-12-23 02:20:56.809154: Epoch 691\n",
            "2025-12-23 02:20:56.809308: Current learning rate: 0.00348\n",
            "2025-12-23 02:21:19.290622: train_loss -0.9731\n",
            "2025-12-23 02:21:19.290846: val_loss -0.9849\n",
            "2025-12-23 02:21:19.290935: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 02:21:19.291023: Epoch time: 22.48 s\n",
            "2025-12-23 02:21:20.664489: \n",
            "2025-12-23 02:21:20.664916: Epoch 692\n",
            "2025-12-23 02:21:20.665133: Current learning rate: 0.00346\n",
            "2025-12-23 02:21:43.102038: train_loss -0.9727\n",
            "2025-12-23 02:21:43.102322: val_loss -0.9863\n",
            "2025-12-23 02:21:43.102443: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 02:21:43.102565: Epoch time: 22.44 s\n",
            "2025-12-23 02:21:44.469693: \n",
            "2025-12-23 02:21:44.469983: Epoch 693\n",
            "2025-12-23 02:21:44.470114: Current learning rate: 0.00345\n",
            "2025-12-23 02:22:07.078656: train_loss -0.9727\n",
            "2025-12-23 02:22:07.078954: val_loss -0.9848\n",
            "2025-12-23 02:22:07.079074: Pseudo dice [np.float32(0.9876)]\n",
            "2025-12-23 02:22:07.079169: Epoch time: 22.61 s\n",
            "2025-12-23 02:22:08.452696: \n",
            "2025-12-23 02:22:08.453009: Epoch 694\n",
            "2025-12-23 02:22:08.453153: Current learning rate: 0.00344\n",
            "2025-12-23 02:22:30.851117: train_loss -0.9747\n",
            "2025-12-23 02:22:30.851344: val_loss -0.9865\n",
            "2025-12-23 02:22:30.851496: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 02:22:30.851616: Epoch time: 22.4 s\n",
            "2025-12-23 02:22:32.879957: \n",
            "2025-12-23 02:22:32.880387: Epoch 695\n",
            "2025-12-23 02:22:32.880544: Current learning rate: 0.00343\n",
            "2025-12-23 02:22:55.376091: train_loss -0.9728\n",
            "2025-12-23 02:22:55.376544: val_loss -0.9855\n",
            "2025-12-23 02:22:55.376725: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 02:22:55.376828: Epoch time: 22.5 s\n",
            "2025-12-23 02:22:56.751469: \n",
            "2025-12-23 02:22:56.751917: Epoch 696\n",
            "2025-12-23 02:22:56.752064: Current learning rate: 0.00342\n",
            "2025-12-23 02:23:19.292505: train_loss -0.9731\n",
            "2025-12-23 02:23:19.292710: val_loss -0.9868\n",
            "2025-12-23 02:23:19.292799: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 02:23:19.292894: Epoch time: 22.54 s\n",
            "2025-12-23 02:23:19.293140: Yayy! New best EMA pseudo Dice: 0.9890000224113464\n",
            "2025-12-23 02:23:21.192764: \n",
            "2025-12-23 02:23:21.192964: Epoch 697\n",
            "2025-12-23 02:23:21.193089: Current learning rate: 0.00341\n",
            "2025-12-23 02:23:43.692093: train_loss -0.9738\n",
            "2025-12-23 02:23:43.692352: val_loss -0.9857\n",
            "2025-12-23 02:23:43.692473: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 02:23:43.692640: Epoch time: 22.5 s\n",
            "2025-12-23 02:23:45.071997: \n",
            "2025-12-23 02:23:45.072330: Epoch 698\n",
            "2025-12-23 02:23:45.072469: Current learning rate: 0.0034\n",
            "2025-12-23 02:24:07.551586: train_loss -0.9736\n",
            "2025-12-23 02:24:07.551851: val_loss -0.9863\n",
            "2025-12-23 02:24:07.552017: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 02:24:07.552154: Epoch time: 22.48 s\n",
            "2025-12-23 02:24:08.943552: \n",
            "2025-12-23 02:24:08.943902: Epoch 699\n",
            "2025-12-23 02:24:08.944049: Current learning rate: 0.00339\n",
            "2025-12-23 02:24:31.394184: train_loss -0.9736\n",
            "2025-12-23 02:24:31.394461: val_loss -0.9851\n",
            "2025-12-23 02:24:31.394589: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 02:24:31.394693: Epoch time: 22.45 s\n",
            "2025-12-23 02:24:33.336956: \n",
            "2025-12-23 02:24:33.337250: Epoch 700\n",
            "2025-12-23 02:24:33.337401: Current learning rate: 0.00338\n",
            "2025-12-23 02:24:55.839954: train_loss -0.9742\n",
            "2025-12-23 02:24:55.840339: val_loss -0.9849\n",
            "2025-12-23 02:24:55.840464: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 02:24:55.840596: Epoch time: 22.5 s\n",
            "2025-12-23 02:24:57.221099: \n",
            "2025-12-23 02:24:57.221357: Epoch 701\n",
            "2025-12-23 02:24:57.221516: Current learning rate: 0.00337\n",
            "2025-12-23 02:25:19.703413: train_loss -0.9753\n",
            "2025-12-23 02:25:19.703628: val_loss -0.9867\n",
            "2025-12-23 02:25:19.703718: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 02:25:19.703813: Epoch time: 22.48 s\n",
            "2025-12-23 02:25:21.071540: \n",
            "2025-12-23 02:25:21.071839: Epoch 702\n",
            "2025-12-23 02:25:21.071970: Current learning rate: 0.00336\n",
            "2025-12-23 02:25:43.542063: train_loss -0.9739\n",
            "2025-12-23 02:25:43.542520: val_loss -0.9866\n",
            "2025-12-23 02:25:43.542681: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 02:25:43.542843: Epoch time: 22.47 s\n",
            "2025-12-23 02:25:44.944366: \n",
            "2025-12-23 02:25:44.944755: Epoch 703\n",
            "2025-12-23 02:25:44.944902: Current learning rate: 0.00335\n",
            "2025-12-23 02:26:07.468270: train_loss -0.9748\n",
            "2025-12-23 02:26:07.468475: val_loss -0.9858\n",
            "2025-12-23 02:26:07.468591: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 02:26:07.468696: Epoch time: 22.53 s\n",
            "2025-12-23 02:26:08.885359: \n",
            "2025-12-23 02:26:08.885554: Epoch 704\n",
            "2025-12-23 02:26:08.885686: Current learning rate: 0.00334\n",
            "2025-12-23 02:26:31.295826: train_loss -0.9739\n",
            "2025-12-23 02:26:31.296026: val_loss -0.9857\n",
            "2025-12-23 02:26:31.296117: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 02:26:31.296207: Epoch time: 22.41 s\n",
            "2025-12-23 02:26:31.296300: Yayy! New best EMA pseudo Dice: 0.9890000224113464\n",
            "2025-12-23 02:26:33.206552: \n",
            "2025-12-23 02:26:33.206865: Epoch 705\n",
            "2025-12-23 02:26:33.207000: Current learning rate: 0.00333\n",
            "2025-12-23 02:26:55.659399: train_loss -0.9751\n",
            "2025-12-23 02:26:55.659812: val_loss -0.9851\n",
            "2025-12-23 02:26:55.659911: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 02:26:55.660009: Epoch time: 22.45 s\n",
            "2025-12-23 02:26:57.047622: \n",
            "2025-12-23 02:26:57.047800: Epoch 706\n",
            "2025-12-23 02:26:57.047962: Current learning rate: 0.00332\n",
            "2025-12-23 02:27:19.508208: train_loss -0.974\n",
            "2025-12-23 02:27:19.508662: val_loss -0.9853\n",
            "2025-12-23 02:27:19.508864: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 02:27:19.509079: Epoch time: 22.46 s\n",
            "2025-12-23 02:27:20.896061: \n",
            "2025-12-23 02:27:20.896370: Epoch 707\n",
            "2025-12-23 02:27:20.896515: Current learning rate: 0.00331\n",
            "2025-12-23 02:27:43.400009: train_loss -0.9734\n",
            "2025-12-23 02:27:43.400277: val_loss -0.9862\n",
            "2025-12-23 02:27:43.400393: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 02:27:43.400509: Epoch time: 22.51 s\n",
            "2025-12-23 02:27:44.781092: \n",
            "2025-12-23 02:27:44.781441: Epoch 708\n",
            "2025-12-23 02:27:44.781595: Current learning rate: 0.0033\n",
            "2025-12-23 02:28:07.186582: train_loss -0.9738\n",
            "2025-12-23 02:28:07.186885: val_loss -0.9864\n",
            "2025-12-23 02:28:07.186983: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 02:28:07.187073: Epoch time: 22.41 s\n",
            "2025-12-23 02:28:08.533086: \n",
            "2025-12-23 02:28:08.533400: Epoch 709\n",
            "2025-12-23 02:28:08.533539: Current learning rate: 0.00329\n",
            "2025-12-23 02:28:30.902100: train_loss -0.9736\n",
            "2025-12-23 02:28:30.902323: val_loss -0.9868\n",
            "2025-12-23 02:28:30.902415: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 02:28:30.902515: Epoch time: 22.37 s\n",
            "2025-12-23 02:28:30.902592: Yayy! New best EMA pseudo Dice: 0.9890000224113464\n",
            "2025-12-23 02:28:32.784093: \n",
            "2025-12-23 02:28:32.784481: Epoch 710\n",
            "2025-12-23 02:28:32.784628: Current learning rate: 0.00328\n",
            "2025-12-23 02:28:55.223414: train_loss -0.9735\n",
            "2025-12-23 02:28:55.223709: val_loss -0.9866\n",
            "2025-12-23 02:28:55.223803: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 02:28:55.223895: Epoch time: 22.44 s\n",
            "2025-12-23 02:28:55.223969: Yayy! New best EMA pseudo Dice: 0.9890999794006348\n",
            "2025-12-23 02:28:57.176520: \n",
            "2025-12-23 02:28:57.176809: Epoch 711\n",
            "2025-12-23 02:28:57.176945: Current learning rate: 0.00327\n",
            "2025-12-23 02:29:19.635614: train_loss -0.9738\n",
            "2025-12-23 02:29:19.635841: val_loss -0.9857\n",
            "2025-12-23 02:29:19.635940: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 02:29:19.636075: Epoch time: 22.46 s\n",
            "2025-12-23 02:29:21.691163: \n",
            "2025-12-23 02:29:21.691485: Epoch 712\n",
            "2025-12-23 02:29:21.691643: Current learning rate: 0.00326\n",
            "2025-12-23 02:29:44.215155: train_loss -0.9739\n",
            "2025-12-23 02:29:44.215388: val_loss -0.9858\n",
            "2025-12-23 02:29:44.215486: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 02:29:44.215582: Epoch time: 22.53 s\n",
            "2025-12-23 02:29:45.586366: \n",
            "2025-12-23 02:29:45.586598: Epoch 713\n",
            "2025-12-23 02:29:45.586735: Current learning rate: 0.00325\n",
            "2025-12-23 02:30:08.054114: train_loss -0.974\n",
            "2025-12-23 02:30:08.054335: val_loss -0.9863\n",
            "2025-12-23 02:30:08.054429: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 02:30:08.054519: Epoch time: 22.47 s\n",
            "2025-12-23 02:30:09.384585: \n",
            "2025-12-23 02:30:09.384945: Epoch 714\n",
            "2025-12-23 02:30:09.385087: Current learning rate: 0.00324\n",
            "2025-12-23 02:30:31.851589: train_loss -0.9746\n",
            "2025-12-23 02:30:31.852032: val_loss -0.9843\n",
            "2025-12-23 02:30:31.852188: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 02:30:31.852353: Epoch time: 22.47 s\n",
            "2025-12-23 02:30:33.229850: \n",
            "2025-12-23 02:30:33.230130: Epoch 715\n",
            "2025-12-23 02:30:33.230301: Current learning rate: 0.00323\n",
            "2025-12-23 02:30:55.733570: train_loss -0.9737\n",
            "2025-12-23 02:30:55.733764: val_loss -0.9856\n",
            "2025-12-23 02:30:55.733853: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 02:30:55.733940: Epoch time: 22.51 s\n",
            "2025-12-23 02:30:57.131591: \n",
            "2025-12-23 02:30:57.131913: Epoch 716\n",
            "2025-12-23 02:30:57.132064: Current learning rate: 0.00322\n",
            "2025-12-23 02:31:19.551210: train_loss -0.9741\n",
            "2025-12-23 02:31:19.551512: val_loss -0.9856\n",
            "2025-12-23 02:31:19.551613: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 02:31:19.551702: Epoch time: 22.42 s\n",
            "2025-12-23 02:31:20.913821: \n",
            "2025-12-23 02:31:20.914012: Epoch 717\n",
            "2025-12-23 02:31:20.914135: Current learning rate: 0.00321\n",
            "2025-12-23 02:31:43.326869: train_loss -0.9743\n",
            "2025-12-23 02:31:43.327258: val_loss -0.9865\n",
            "2025-12-23 02:31:43.327443: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 02:31:43.327617: Epoch time: 22.41 s\n",
            "2025-12-23 02:31:44.733852: \n",
            "2025-12-23 02:31:44.734137: Epoch 718\n",
            "2025-12-23 02:31:44.734283: Current learning rate: 0.0032\n",
            "2025-12-23 02:32:07.188580: train_loss -0.975\n",
            "2025-12-23 02:32:07.188797: val_loss -0.9861\n",
            "2025-12-23 02:32:07.188888: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 02:32:07.188977: Epoch time: 22.46 s\n",
            "2025-12-23 02:32:08.571276: \n",
            "2025-12-23 02:32:08.571616: Epoch 719\n",
            "2025-12-23 02:32:08.571762: Current learning rate: 0.00319\n",
            "2025-12-23 02:32:31.060092: train_loss -0.9747\n",
            "2025-12-23 02:32:31.060516: val_loss -0.9863\n",
            "2025-12-23 02:32:31.060623: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 02:32:31.060723: Epoch time: 22.49 s\n",
            "2025-12-23 02:32:32.470869: \n",
            "2025-12-23 02:32:32.471183: Epoch 720\n",
            "2025-12-23 02:32:32.471349: Current learning rate: 0.00318\n",
            "2025-12-23 02:32:54.866464: train_loss -0.9738\n",
            "2025-12-23 02:32:54.866678: val_loss -0.986\n",
            "2025-12-23 02:32:54.866766: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 02:32:54.866859: Epoch time: 22.4 s\n",
            "2025-12-23 02:32:54.866938: Yayy! New best EMA pseudo Dice: 0.9890999794006348\n",
            "2025-12-23 02:32:56.824209: \n",
            "2025-12-23 02:32:56.824408: Epoch 721\n",
            "2025-12-23 02:32:56.824541: Current learning rate: 0.00317\n",
            "2025-12-23 02:33:19.304793: train_loss -0.9734\n",
            "2025-12-23 02:33:19.305097: val_loss -0.985\n",
            "2025-12-23 02:33:19.305201: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 02:33:19.305342: Epoch time: 22.48 s\n",
            "2025-12-23 02:33:20.727488: \n",
            "2025-12-23 02:33:20.727659: Epoch 722\n",
            "2025-12-23 02:33:20.727847: Current learning rate: 0.00316\n",
            "2025-12-23 02:33:43.186287: train_loss -0.9718\n",
            "2025-12-23 02:33:43.186653: val_loss -0.9844\n",
            "2025-12-23 02:33:43.186786: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 02:33:43.186921: Epoch time: 22.46 s\n",
            "2025-12-23 02:33:44.569571: \n",
            "2025-12-23 02:33:44.569872: Epoch 723\n",
            "2025-12-23 02:33:44.570013: Current learning rate: 0.00315\n",
            "2025-12-23 02:34:06.982756: train_loss -0.9694\n",
            "2025-12-23 02:34:06.983016: val_loss -0.9839\n",
            "2025-12-23 02:34:06.983165: Pseudo dice [np.float32(0.9878)]\n",
            "2025-12-23 02:34:06.983320: Epoch time: 22.41 s\n",
            "2025-12-23 02:34:08.391160: \n",
            "2025-12-23 02:34:08.391494: Epoch 724\n",
            "2025-12-23 02:34:08.391630: Current learning rate: 0.00314\n",
            "2025-12-23 02:34:30.852582: train_loss -0.972\n",
            "2025-12-23 02:34:30.852862: val_loss -0.9837\n",
            "2025-12-23 02:34:30.852989: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 02:34:30.853117: Epoch time: 22.46 s\n",
            "2025-12-23 02:34:32.267738: \n",
            "2025-12-23 02:34:32.268052: Epoch 725\n",
            "2025-12-23 02:34:32.268195: Current learning rate: 0.00313\n",
            "2025-12-23 02:34:54.674829: train_loss -0.9742\n",
            "2025-12-23 02:34:54.675203: val_loss -0.985\n",
            "2025-12-23 02:34:54.675352: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 02:34:54.675481: Epoch time: 22.41 s\n",
            "2025-12-23 02:34:56.056972: \n",
            "2025-12-23 02:34:56.057256: Epoch 726\n",
            "2025-12-23 02:34:56.057429: Current learning rate: 0.00312\n",
            "2025-12-23 02:35:18.491703: train_loss -0.9741\n",
            "2025-12-23 02:35:18.492005: val_loss -0.9858\n",
            "2025-12-23 02:35:18.492108: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 02:35:18.492200: Epoch time: 22.44 s\n",
            "2025-12-23 02:35:19.868763: \n",
            "2025-12-23 02:35:19.869121: Epoch 727\n",
            "2025-12-23 02:35:19.869274: Current learning rate: 0.00311\n",
            "2025-12-23 02:35:42.282711: train_loss -0.9739\n",
            "2025-12-23 02:35:42.282925: val_loss -0.9862\n",
            "2025-12-23 02:35:42.283014: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 02:35:42.283103: Epoch time: 22.42 s\n",
            "2025-12-23 02:35:43.670738: \n",
            "2025-12-23 02:35:43.671013: Epoch 728\n",
            "2025-12-23 02:35:43.671154: Current learning rate: 0.0031\n",
            "2025-12-23 02:36:06.100051: train_loss -0.973\n",
            "2025-12-23 02:36:06.100270: val_loss -0.985\n",
            "2025-12-23 02:36:06.100374: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 02:36:06.100498: Epoch time: 22.43 s\n",
            "2025-12-23 02:36:08.176026: \n",
            "2025-12-23 02:36:08.176470: Epoch 729\n",
            "2025-12-23 02:36:08.176673: Current learning rate: 0.00309\n",
            "2025-12-23 02:36:30.673605: train_loss -0.9719\n",
            "2025-12-23 02:36:30.673804: val_loss -0.9836\n",
            "2025-12-23 02:36:30.673892: Pseudo dice [np.float32(0.9876)]\n",
            "2025-12-23 02:36:30.673982: Epoch time: 22.5 s\n",
            "2025-12-23 02:36:32.032583: \n",
            "2025-12-23 02:36:32.032979: Epoch 730\n",
            "2025-12-23 02:36:32.033123: Current learning rate: 0.00308\n",
            "2025-12-23 02:36:54.539710: train_loss -0.9728\n",
            "2025-12-23 02:36:54.539962: val_loss -0.9861\n",
            "2025-12-23 02:36:54.540129: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 02:36:54.540259: Epoch time: 22.51 s\n",
            "2025-12-23 02:36:55.920429: \n",
            "2025-12-23 02:36:55.920672: Epoch 731\n",
            "2025-12-23 02:36:55.920837: Current learning rate: 0.00307\n",
            "2025-12-23 02:37:18.403502: train_loss -0.972\n",
            "2025-12-23 02:37:18.403857: val_loss -0.9854\n",
            "2025-12-23 02:37:18.404026: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 02:37:18.404171: Epoch time: 22.48 s\n",
            "2025-12-23 02:37:19.756356: \n",
            "2025-12-23 02:37:19.756692: Epoch 732\n",
            "2025-12-23 02:37:19.756841: Current learning rate: 0.00306\n",
            "2025-12-23 02:37:42.226845: train_loss -0.9721\n",
            "2025-12-23 02:37:42.227198: val_loss -0.9856\n",
            "2025-12-23 02:37:42.227343: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 02:37:42.227458: Epoch time: 22.47 s\n",
            "2025-12-23 02:37:43.589172: \n",
            "2025-12-23 02:37:43.589365: Epoch 733\n",
            "2025-12-23 02:37:43.589514: Current learning rate: 0.00305\n",
            "2025-12-23 02:38:06.098497: train_loss -0.9727\n",
            "2025-12-23 02:38:06.098763: val_loss -0.9849\n",
            "2025-12-23 02:38:06.098858: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 02:38:06.098949: Epoch time: 22.51 s\n",
            "2025-12-23 02:38:07.482182: \n",
            "2025-12-23 02:38:07.482367: Epoch 734\n",
            "2025-12-23 02:38:07.482504: Current learning rate: 0.00304\n",
            "2025-12-23 02:38:29.952569: train_loss -0.9723\n",
            "2025-12-23 02:38:29.952822: val_loss -0.9852\n",
            "2025-12-23 02:38:29.952914: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 02:38:29.953001: Epoch time: 22.47 s\n",
            "2025-12-23 02:38:31.313418: \n",
            "2025-12-23 02:38:31.313664: Epoch 735\n",
            "2025-12-23 02:38:31.313792: Current learning rate: 0.00303\n",
            "2025-12-23 02:38:53.758671: train_loss -0.9732\n",
            "2025-12-23 02:38:53.758879: val_loss -0.9863\n",
            "2025-12-23 02:38:53.758991: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 02:38:53.759083: Epoch time: 22.45 s\n",
            "2025-12-23 02:38:55.166239: \n",
            "2025-12-23 02:38:55.166449: Epoch 736\n",
            "2025-12-23 02:38:55.166609: Current learning rate: 0.00302\n",
            "2025-12-23 02:39:17.597386: train_loss -0.9726\n",
            "2025-12-23 02:39:17.597592: val_loss -0.9852\n",
            "2025-12-23 02:39:17.597710: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 02:39:17.597816: Epoch time: 22.43 s\n",
            "2025-12-23 02:39:18.968168: \n",
            "2025-12-23 02:39:18.968489: Epoch 737\n",
            "2025-12-23 02:39:18.968623: Current learning rate: 0.00301\n",
            "2025-12-23 02:39:41.441457: train_loss -0.9737\n",
            "2025-12-23 02:39:41.441666: val_loss -0.9856\n",
            "2025-12-23 02:39:41.441752: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 02:39:41.441847: Epoch time: 22.47 s\n",
            "2025-12-23 02:39:42.817350: \n",
            "2025-12-23 02:39:42.817653: Epoch 738\n",
            "2025-12-23 02:39:42.817811: Current learning rate: 0.003\n",
            "2025-12-23 02:40:05.268890: train_loss -0.9741\n",
            "2025-12-23 02:40:05.269124: val_loss -0.9853\n",
            "2025-12-23 02:40:05.269246: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 02:40:05.269378: Epoch time: 22.45 s\n",
            "2025-12-23 02:40:06.638602: \n",
            "2025-12-23 02:40:06.638758: Epoch 739\n",
            "2025-12-23 02:40:06.638888: Current learning rate: 0.00299\n",
            "2025-12-23 02:40:29.096709: train_loss -0.9742\n",
            "2025-12-23 02:40:29.097047: val_loss -0.9865\n",
            "2025-12-23 02:40:29.097157: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 02:40:29.097274: Epoch time: 22.46 s\n",
            "2025-12-23 02:40:30.447802: \n",
            "2025-12-23 02:40:30.448161: Epoch 740\n",
            "2025-12-23 02:40:30.448308: Current learning rate: 0.00297\n",
            "2025-12-23 02:40:52.888923: train_loss -0.9732\n",
            "2025-12-23 02:40:52.889127: val_loss -0.987\n",
            "2025-12-23 02:40:52.889232: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 02:40:52.889348: Epoch time: 22.44 s\n",
            "2025-12-23 02:40:54.276321: \n",
            "2025-12-23 02:40:54.276618: Epoch 741\n",
            "2025-12-23 02:40:54.276747: Current learning rate: 0.00296\n",
            "2025-12-23 02:41:16.742930: train_loss -0.9725\n",
            "2025-12-23 02:41:16.743136: val_loss -0.9847\n",
            "2025-12-23 02:41:16.743255: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 02:41:16.743426: Epoch time: 22.47 s\n",
            "2025-12-23 02:41:18.148439: \n",
            "2025-12-23 02:41:18.148724: Epoch 742\n",
            "2025-12-23 02:41:18.148863: Current learning rate: 0.00295\n",
            "2025-12-23 02:41:40.598558: train_loss -0.9716\n",
            "2025-12-23 02:41:40.598757: val_loss -0.9776\n",
            "2025-12-23 02:41:40.598853: Pseudo dice [np.float32(0.9819)]\n",
            "2025-12-23 02:41:40.598943: Epoch time: 22.45 s\n",
            "2025-12-23 02:41:41.954384: \n",
            "2025-12-23 02:41:41.954617: Epoch 743\n",
            "2025-12-23 02:41:41.954743: Current learning rate: 0.00294\n",
            "2025-12-23 02:42:04.400698: train_loss -0.9729\n",
            "2025-12-23 02:42:04.400942: val_loss -0.986\n",
            "2025-12-23 02:42:04.401186: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 02:42:04.401397: Epoch time: 22.45 s\n",
            "2025-12-23 02:42:05.762949: \n",
            "2025-12-23 02:42:05.763250: Epoch 744\n",
            "2025-12-23 02:42:05.763381: Current learning rate: 0.00293\n",
            "2025-12-23 02:42:28.180260: train_loss -0.9742\n",
            "2025-12-23 02:42:28.180509: val_loss -0.9856\n",
            "2025-12-23 02:42:28.180625: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 02:42:28.180725: Epoch time: 22.42 s\n",
            "2025-12-23 02:42:29.540244: \n",
            "2025-12-23 02:42:29.540429: Epoch 745\n",
            "2025-12-23 02:42:29.540554: Current learning rate: 0.00292\n",
            "2025-12-23 02:42:51.954386: train_loss -0.9739\n",
            "2025-12-23 02:42:51.954691: val_loss -0.9862\n",
            "2025-12-23 02:42:51.954813: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 02:42:51.955035: Epoch time: 22.42 s\n",
            "2025-12-23 02:42:53.991610: \n",
            "2025-12-23 02:42:53.991977: Epoch 746\n",
            "2025-12-23 02:42:53.992108: Current learning rate: 0.00291\n",
            "2025-12-23 02:43:16.479761: train_loss -0.9743\n",
            "2025-12-23 02:43:16.480157: val_loss -0.9865\n",
            "2025-12-23 02:43:16.480331: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 02:43:16.480463: Epoch time: 22.49 s\n",
            "2025-12-23 02:43:17.826907: \n",
            "2025-12-23 02:43:17.827251: Epoch 747\n",
            "2025-12-23 02:43:17.827384: Current learning rate: 0.0029\n",
            "2025-12-23 02:43:40.327651: train_loss -0.9737\n",
            "2025-12-23 02:43:40.327873: val_loss -0.9857\n",
            "2025-12-23 02:43:40.327963: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 02:43:40.328053: Epoch time: 22.5 s\n",
            "2025-12-23 02:43:41.714383: \n",
            "2025-12-23 02:43:41.714609: Epoch 748\n",
            "2025-12-23 02:43:41.714767: Current learning rate: 0.00289\n",
            "2025-12-23 02:44:04.191863: train_loss -0.9742\n",
            "2025-12-23 02:44:04.192131: val_loss -0.9853\n",
            "2025-12-23 02:44:04.192323: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 02:44:04.192421: Epoch time: 22.48 s\n",
            "2025-12-23 02:44:05.517534: \n",
            "2025-12-23 02:44:05.517900: Epoch 749\n",
            "2025-12-23 02:44:05.518037: Current learning rate: 0.00288\n",
            "2025-12-23 02:44:28.008198: train_loss -0.974\n",
            "2025-12-23 02:44:28.008418: val_loss -0.9866\n",
            "2025-12-23 02:44:28.008506: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 02:44:28.008606: Epoch time: 22.49 s\n",
            "2025-12-23 02:44:29.868034: \n",
            "2025-12-23 02:44:29.868250: Epoch 750\n",
            "2025-12-23 02:44:29.868378: Current learning rate: 0.00287\n",
            "2025-12-23 02:44:52.356638: train_loss -0.9744\n",
            "2025-12-23 02:44:52.357287: val_loss -0.9859\n",
            "2025-12-23 02:44:52.357394: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 02:44:52.357501: Epoch time: 22.49 s\n",
            "2025-12-23 02:44:53.717524: \n",
            "2025-12-23 02:44:53.717872: Epoch 751\n",
            "2025-12-23 02:44:53.718007: Current learning rate: 0.00286\n",
            "2025-12-23 02:45:16.172766: train_loss -0.9752\n",
            "2025-12-23 02:45:16.172976: val_loss -0.9868\n",
            "2025-12-23 02:45:16.173088: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 02:45:16.173204: Epoch time: 22.46 s\n",
            "2025-12-23 02:45:17.539737: \n",
            "2025-12-23 02:45:17.539932: Epoch 752\n",
            "2025-12-23 02:45:17.540110: Current learning rate: 0.00285\n",
            "2025-12-23 02:45:39.954954: train_loss -0.9748\n",
            "2025-12-23 02:45:39.955189: val_loss -0.987\n",
            "2025-12-23 02:45:39.955332: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 02:45:39.955427: Epoch time: 22.42 s\n",
            "2025-12-23 02:45:41.351202: \n",
            "2025-12-23 02:45:41.351511: Epoch 753\n",
            "2025-12-23 02:45:41.351649: Current learning rate: 0.00284\n",
            "2025-12-23 02:46:03.802692: train_loss -0.9743\n",
            "2025-12-23 02:46:03.802921: val_loss -0.987\n",
            "2025-12-23 02:46:03.803019: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 02:46:03.803111: Epoch time: 22.45 s\n",
            "2025-12-23 02:46:05.189018: \n",
            "2025-12-23 02:46:05.189422: Epoch 754\n",
            "2025-12-23 02:46:05.189590: Current learning rate: 0.00283\n",
            "2025-12-23 02:46:27.622834: train_loss -0.9747\n",
            "2025-12-23 02:46:27.623037: val_loss -0.9859\n",
            "2025-12-23 02:46:27.623123: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 02:46:27.623210: Epoch time: 22.44 s\n",
            "2025-12-23 02:46:28.991358: \n",
            "2025-12-23 02:46:28.991546: Epoch 755\n",
            "2025-12-23 02:46:28.991670: Current learning rate: 0.00282\n",
            "2025-12-23 02:46:51.401121: train_loss -0.9743\n",
            "2025-12-23 02:46:51.401660: val_loss -0.9861\n",
            "2025-12-23 02:46:51.401811: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 02:46:51.401944: Epoch time: 22.41 s\n",
            "2025-12-23 02:46:52.800395: \n",
            "2025-12-23 02:46:52.800656: Epoch 756\n",
            "2025-12-23 02:46:52.800812: Current learning rate: 0.00281\n",
            "2025-12-23 02:47:15.186445: train_loss -0.9754\n",
            "2025-12-23 02:47:15.186716: val_loss -0.9862\n",
            "2025-12-23 02:47:15.186821: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 02:47:15.186913: Epoch time: 22.39 s\n",
            "2025-12-23 02:47:16.608754: \n",
            "2025-12-23 02:47:16.609071: Epoch 757\n",
            "2025-12-23 02:47:16.609201: Current learning rate: 0.0028\n",
            "2025-12-23 02:47:38.993098: train_loss -0.9733\n",
            "2025-12-23 02:47:38.993479: val_loss -0.9862\n",
            "2025-12-23 02:47:38.993665: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 02:47:38.993818: Epoch time: 22.39 s\n",
            "2025-12-23 02:47:38.993930: Yayy! New best EMA pseudo Dice: 0.9890999794006348\n",
            "2025-12-23 02:47:40.933752: \n",
            "2025-12-23 02:47:40.934098: Epoch 758\n",
            "2025-12-23 02:47:40.934288: Current learning rate: 0.00279\n",
            "2025-12-23 02:48:03.374812: train_loss -0.9743\n",
            "2025-12-23 02:48:03.375039: val_loss -0.9858\n",
            "2025-12-23 02:48:03.375139: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 02:48:03.375256: Epoch time: 22.44 s\n",
            "2025-12-23 02:48:04.799470: \n",
            "2025-12-23 02:48:04.799801: Epoch 759\n",
            "2025-12-23 02:48:04.799941: Current learning rate: 0.00278\n",
            "2025-12-23 02:48:27.221855: train_loss -0.9728\n",
            "2025-12-23 02:48:27.222103: val_loss -0.9862\n",
            "2025-12-23 02:48:27.222314: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 02:48:27.222481: Epoch time: 22.42 s\n",
            "2025-12-23 02:48:28.617734: \n",
            "2025-12-23 02:48:28.618081: Epoch 760\n",
            "2025-12-23 02:48:28.618228: Current learning rate: 0.00277\n",
            "2025-12-23 02:48:51.040021: train_loss -0.9748\n",
            "2025-12-23 02:48:51.040272: val_loss -0.9855\n",
            "2025-12-23 02:48:51.040589: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 02:48:51.040733: Epoch time: 22.42 s\n",
            "2025-12-23 02:48:52.430970: \n",
            "2025-12-23 02:48:52.431277: Epoch 761\n",
            "2025-12-23 02:48:52.431483: Current learning rate: 0.00276\n",
            "2025-12-23 02:49:14.832597: train_loss -0.9753\n",
            "2025-12-23 02:49:14.832848: val_loss -0.9874\n",
            "2025-12-23 02:49:14.833048: Pseudo dice [np.float32(0.9901)]\n",
            "2025-12-23 02:49:14.833147: Epoch time: 22.4 s\n",
            "2025-12-23 02:49:16.237865: \n",
            "2025-12-23 02:49:16.238137: Epoch 762\n",
            "2025-12-23 02:49:16.238288: Current learning rate: 0.00275\n",
            "2025-12-23 02:49:38.676997: train_loss -0.9756\n",
            "2025-12-23 02:49:38.677252: val_loss -0.9854\n",
            "2025-12-23 02:49:38.677366: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 02:49:38.677459: Epoch time: 22.44 s\n",
            "2025-12-23 02:49:40.744610: \n",
            "2025-12-23 02:49:40.744821: Epoch 763\n",
            "2025-12-23 02:49:40.744948: Current learning rate: 0.00274\n",
            "2025-12-23 02:50:03.269498: train_loss -0.975\n",
            "2025-12-23 02:50:03.269740: val_loss -0.9864\n",
            "2025-12-23 02:50:03.269850: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 02:50:03.269943: Epoch time: 22.53 s\n",
            "2025-12-23 02:50:03.270016: Yayy! New best EMA pseudo Dice: 0.9891999959945679\n",
            "2025-12-23 02:50:05.179837: \n",
            "2025-12-23 02:50:05.180119: Epoch 764\n",
            "2025-12-23 02:50:05.180269: Current learning rate: 0.00273\n",
            "2025-12-23 02:50:27.673756: train_loss -0.9751\n",
            "2025-12-23 02:50:27.673957: val_loss -0.9853\n",
            "2025-12-23 02:50:27.674045: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 02:50:27.674131: Epoch time: 22.5 s\n",
            "2025-12-23 02:50:29.027643: \n",
            "2025-12-23 02:50:29.027970: Epoch 765\n",
            "2025-12-23 02:50:29.028109: Current learning rate: 0.00272\n",
            "2025-12-23 02:50:51.427208: train_loss -0.9748\n",
            "2025-12-23 02:50:51.427440: val_loss -0.9874\n",
            "2025-12-23 02:50:51.427545: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 02:50:51.427635: Epoch time: 22.4 s\n",
            "2025-12-23 02:50:51.427712: Yayy! New best EMA pseudo Dice: 0.9891999959945679\n",
            "2025-12-23 02:50:53.290545: \n",
            "2025-12-23 02:50:53.290849: Epoch 766\n",
            "2025-12-23 02:50:53.290978: Current learning rate: 0.00271\n",
            "2025-12-23 02:51:15.758913: train_loss -0.9744\n",
            "2025-12-23 02:51:15.759171: val_loss -0.9852\n",
            "2025-12-23 02:51:15.759298: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 02:51:15.759399: Epoch time: 22.47 s\n",
            "2025-12-23 02:51:17.190755: \n",
            "2025-12-23 02:51:17.190965: Epoch 767\n",
            "2025-12-23 02:51:17.191124: Current learning rate: 0.0027\n",
            "2025-12-23 02:51:39.628690: train_loss -0.9743\n",
            "2025-12-23 02:51:39.628993: val_loss -0.9872\n",
            "2025-12-23 02:51:39.629169: Pseudo dice [np.float32(0.9903)]\n",
            "2025-12-23 02:51:39.629381: Epoch time: 22.44 s\n",
            "2025-12-23 02:51:39.629610: Yayy! New best EMA pseudo Dice: 0.989300012588501\n",
            "2025-12-23 02:51:41.570027: \n",
            "2025-12-23 02:51:41.570435: Epoch 768\n",
            "2025-12-23 02:51:41.570596: Current learning rate: 0.00268\n",
            "2025-12-23 02:52:04.030349: train_loss -0.975\n",
            "2025-12-23 02:52:04.030717: val_loss -0.9859\n",
            "2025-12-23 02:52:04.030911: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 02:52:04.031132: Epoch time: 22.46 s\n",
            "2025-12-23 02:52:05.470390: \n",
            "2025-12-23 02:52:05.470666: Epoch 769\n",
            "2025-12-23 02:52:05.470827: Current learning rate: 0.00267\n",
            "2025-12-23 02:52:27.882565: train_loss -0.9758\n",
            "2025-12-23 02:52:27.882761: val_loss -0.9867\n",
            "2025-12-23 02:52:27.882862: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 02:52:27.882953: Epoch time: 22.41 s\n",
            "2025-12-23 02:52:27.883032: Yayy! New best EMA pseudo Dice: 0.9894000291824341\n",
            "2025-12-23 02:52:29.819110: \n",
            "2025-12-23 02:52:29.819520: Epoch 770\n",
            "2025-12-23 02:52:29.819684: Current learning rate: 0.00266\n",
            "2025-12-23 02:52:52.278589: train_loss -0.9747\n",
            "2025-12-23 02:52:52.278864: val_loss -0.9853\n",
            "2025-12-23 02:52:52.278963: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 02:52:52.279053: Epoch time: 22.46 s\n",
            "2025-12-23 02:52:52.279127: Yayy! New best EMA pseudo Dice: 0.9894000291824341\n",
            "2025-12-23 02:52:54.208122: \n",
            "2025-12-23 02:52:54.208310: Epoch 771\n",
            "2025-12-23 02:52:54.208435: Current learning rate: 0.00265\n",
            "2025-12-23 02:53:16.696202: train_loss -0.9745\n",
            "2025-12-23 02:53:16.696560: val_loss -0.9857\n",
            "2025-12-23 02:53:16.696784: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 02:53:16.696929: Epoch time: 22.49 s\n",
            "2025-12-23 02:53:18.104336: \n",
            "2025-12-23 02:53:18.104700: Epoch 772\n",
            "2025-12-23 02:53:18.104854: Current learning rate: 0.00264\n",
            "2025-12-23 02:53:40.511417: train_loss -0.9754\n",
            "2025-12-23 02:53:40.511783: val_loss -0.9861\n",
            "2025-12-23 02:53:40.511890: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 02:53:40.511982: Epoch time: 22.41 s\n",
            "2025-12-23 02:53:41.938605: \n",
            "2025-12-23 02:53:41.938877: Epoch 773\n",
            "2025-12-23 02:53:41.939037: Current learning rate: 0.00263\n",
            "2025-12-23 02:54:04.378117: train_loss -0.9744\n",
            "2025-12-23 02:54:04.378472: val_loss -0.9872\n",
            "2025-12-23 02:54:04.378602: Pseudo dice [np.float32(0.9901)]\n",
            "2025-12-23 02:54:04.378736: Epoch time: 22.44 s\n",
            "2025-12-23 02:54:04.378830: Yayy! New best EMA pseudo Dice: 0.9894000291824341\n",
            "2025-12-23 02:54:06.384733: \n",
            "2025-12-23 02:54:06.384898: Epoch 774\n",
            "2025-12-23 02:54:06.385030: Current learning rate: 0.00262\n",
            "2025-12-23 02:54:28.811643: train_loss -0.9746\n",
            "2025-12-23 02:54:28.811990: val_loss -0.9858\n",
            "2025-12-23 02:54:28.812105: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 02:54:28.812245: Epoch time: 22.43 s\n",
            "2025-12-23 02:54:30.222335: \n",
            "2025-12-23 02:54:30.222606: Epoch 775\n",
            "2025-12-23 02:54:30.222749: Current learning rate: 0.00261\n",
            "2025-12-23 02:54:52.628653: train_loss -0.975\n",
            "2025-12-23 02:54:52.628884: val_loss -0.9866\n",
            "2025-12-23 02:54:52.628983: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 02:54:52.629080: Epoch time: 22.41 s\n",
            "2025-12-23 02:54:54.057827: \n",
            "2025-12-23 02:54:54.058128: Epoch 776\n",
            "2025-12-23 02:54:54.058286: Current learning rate: 0.0026\n",
            "2025-12-23 02:55:16.432595: train_loss -0.9739\n",
            "2025-12-23 02:55:16.432881: val_loss -0.9863\n",
            "2025-12-23 02:55:16.432973: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 02:55:16.433064: Epoch time: 22.38 s\n",
            "2025-12-23 02:55:17.843143: \n",
            "2025-12-23 02:55:17.843408: Epoch 777\n",
            "2025-12-23 02:55:17.843544: Current learning rate: 0.00259\n",
            "2025-12-23 02:55:40.262317: train_loss -0.9752\n",
            "2025-12-23 02:55:40.262529: val_loss -0.9844\n",
            "2025-12-23 02:55:40.262732: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 02:55:40.262929: Epoch time: 22.42 s\n",
            "2025-12-23 02:55:41.664897: \n",
            "2025-12-23 02:55:41.665209: Epoch 778\n",
            "2025-12-23 02:55:41.665381: Current learning rate: 0.00258\n",
            "2025-12-23 02:56:04.038917: train_loss -0.9746\n",
            "2025-12-23 02:56:04.039248: val_loss -0.9855\n",
            "2025-12-23 02:56:04.039361: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 02:56:04.039453: Epoch time: 22.38 s\n",
            "2025-12-23 02:56:06.136951: \n",
            "2025-12-23 02:56:06.137266: Epoch 779\n",
            "2025-12-23 02:56:06.137418: Current learning rate: 0.00257\n",
            "2025-12-23 02:56:28.630620: train_loss -0.9751\n",
            "2025-12-23 02:56:28.630823: val_loss -0.9864\n",
            "2025-12-23 02:56:28.630914: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 02:56:28.631002: Epoch time: 22.49 s\n",
            "2025-12-23 02:56:30.019554: \n",
            "2025-12-23 02:56:30.019951: Epoch 780\n",
            "2025-12-23 02:56:30.020088: Current learning rate: 0.00256\n",
            "2025-12-23 02:56:52.465117: train_loss -0.9755\n",
            "2025-12-23 02:56:52.465554: val_loss -0.9858\n",
            "2025-12-23 02:56:52.465737: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 02:56:52.465899: Epoch time: 22.45 s\n",
            "2025-12-23 02:56:53.857498: \n",
            "2025-12-23 02:56:53.857991: Epoch 781\n",
            "2025-12-23 02:56:53.858146: Current learning rate: 0.00255\n",
            "2025-12-23 02:57:16.337826: train_loss -0.9754\n",
            "2025-12-23 02:57:16.338116: val_loss -0.9864\n",
            "2025-12-23 02:57:16.338212: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 02:57:16.338372: Epoch time: 22.48 s\n",
            "2025-12-23 02:57:17.709503: \n",
            "2025-12-23 02:57:17.709766: Epoch 782\n",
            "2025-12-23 02:57:17.709948: Current learning rate: 0.00254\n",
            "2025-12-23 02:57:40.156113: train_loss -0.9754\n",
            "2025-12-23 02:57:40.156453: val_loss -0.986\n",
            "2025-12-23 02:57:40.156567: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 02:57:40.156662: Epoch time: 22.45 s\n",
            "2025-12-23 02:57:41.541626: \n",
            "2025-12-23 02:57:41.542032: Epoch 783\n",
            "2025-12-23 02:57:41.542181: Current learning rate: 0.00253\n",
            "2025-12-23 02:58:03.977603: train_loss -0.9756\n",
            "2025-12-23 02:58:03.977873: val_loss -0.9854\n",
            "2025-12-23 02:58:03.977966: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 02:58:03.978055: Epoch time: 22.44 s\n",
            "2025-12-23 02:58:05.444475: \n",
            "2025-12-23 02:58:05.444736: Epoch 784\n",
            "2025-12-23 02:58:05.444881: Current learning rate: 0.00252\n",
            "2025-12-23 02:58:27.865215: train_loss -0.9744\n",
            "2025-12-23 02:58:27.865490: val_loss -0.9871\n",
            "2025-12-23 02:58:27.865585: Pseudo dice [np.float32(0.9903)]\n",
            "2025-12-23 02:58:27.865674: Epoch time: 22.42 s\n",
            "2025-12-23 02:58:27.865759: Yayy! New best EMA pseudo Dice: 0.9894999861717224\n",
            "2025-12-23 02:58:29.800914: \n",
            "2025-12-23 02:58:29.801250: Epoch 785\n",
            "2025-12-23 02:58:29.801388: Current learning rate: 0.00251\n",
            "2025-12-23 02:58:52.301774: train_loss -0.975\n",
            "2025-12-23 02:58:52.302027: val_loss -0.9847\n",
            "2025-12-23 02:58:52.302119: Pseudo dice [np.float32(0.9881)]\n",
            "2025-12-23 02:58:52.302211: Epoch time: 22.5 s\n",
            "2025-12-23 02:58:53.691624: \n",
            "2025-12-23 02:58:53.692054: Epoch 786\n",
            "2025-12-23 02:58:53.692211: Current learning rate: 0.0025\n",
            "2025-12-23 02:59:16.146399: train_loss -0.9735\n",
            "2025-12-23 02:59:16.146653: val_loss -0.9853\n",
            "2025-12-23 02:59:16.146772: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 02:59:16.146947: Epoch time: 22.46 s\n",
            "2025-12-23 02:59:17.536092: \n",
            "2025-12-23 02:59:17.536438: Epoch 787\n",
            "2025-12-23 02:59:17.536603: Current learning rate: 0.00249\n",
            "2025-12-23 02:59:40.068039: train_loss -0.9757\n",
            "2025-12-23 02:59:40.068289: val_loss -0.9857\n",
            "2025-12-23 02:59:40.068397: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 02:59:40.068486: Epoch time: 22.53 s\n",
            "2025-12-23 02:59:41.448391: \n",
            "2025-12-23 02:59:41.448690: Epoch 788\n",
            "2025-12-23 02:59:41.448821: Current learning rate: 0.00248\n",
            "2025-12-23 03:00:03.867147: train_loss -0.9757\n",
            "2025-12-23 03:00:03.867380: val_loss -0.9859\n",
            "2025-12-23 03:00:03.867487: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 03:00:03.867579: Epoch time: 22.42 s\n",
            "2025-12-23 03:00:05.267064: \n",
            "2025-12-23 03:00:05.267400: Epoch 789\n",
            "2025-12-23 03:00:05.267541: Current learning rate: 0.00247\n",
            "2025-12-23 03:00:27.683439: train_loss -0.9758\n",
            "2025-12-23 03:00:27.683661: val_loss -0.9863\n",
            "2025-12-23 03:00:27.683749: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:00:27.683851: Epoch time: 22.42 s\n",
            "2025-12-23 03:00:29.061798: \n",
            "2025-12-23 03:00:29.062108: Epoch 790\n",
            "2025-12-23 03:00:29.062258: Current learning rate: 0.00245\n",
            "2025-12-23 03:00:51.521813: train_loss -0.9753\n",
            "2025-12-23 03:00:51.522012: val_loss -0.9859\n",
            "2025-12-23 03:00:51.522100: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 03:00:51.522404: Epoch time: 22.46 s\n",
            "2025-12-23 03:00:52.876337: \n",
            "2025-12-23 03:00:52.876592: Epoch 791\n",
            "2025-12-23 03:00:52.876721: Current learning rate: 0.00244\n",
            "2025-12-23 03:01:15.288598: train_loss -0.9764\n",
            "2025-12-23 03:01:15.289077: val_loss -0.9857\n",
            "2025-12-23 03:01:15.289255: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 03:01:15.289403: Epoch time: 22.41 s\n",
            "2025-12-23 03:01:16.707919: \n",
            "2025-12-23 03:01:16.708145: Epoch 792\n",
            "2025-12-23 03:01:16.708358: Current learning rate: 0.00243\n",
            "2025-12-23 03:01:39.129477: train_loss -0.975\n",
            "2025-12-23 03:01:39.129746: val_loss -0.9864\n",
            "2025-12-23 03:01:39.129896: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 03:01:39.129991: Epoch time: 22.42 s\n",
            "2025-12-23 03:01:40.534239: \n",
            "2025-12-23 03:01:40.534464: Epoch 793\n",
            "2025-12-23 03:01:40.534633: Current learning rate: 0.00242\n",
            "2025-12-23 03:02:02.990040: train_loss -0.9755\n",
            "2025-12-23 03:02:02.990275: val_loss -0.9855\n",
            "2025-12-23 03:02:02.990388: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 03:02:02.990502: Epoch time: 22.46 s\n",
            "2025-12-23 03:02:04.408195: \n",
            "2025-12-23 03:02:04.408387: Epoch 794\n",
            "2025-12-23 03:02:04.408514: Current learning rate: 0.00241\n",
            "2025-12-23 03:02:26.836315: train_loss -0.9757\n",
            "2025-12-23 03:02:26.836593: val_loss -0.9865\n",
            "2025-12-23 03:02:26.836808: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:02:26.836954: Epoch time: 22.43 s\n",
            "2025-12-23 03:02:28.239053: \n",
            "2025-12-23 03:02:28.239469: Epoch 795\n",
            "2025-12-23 03:02:28.239609: Current learning rate: 0.0024\n",
            "2025-12-23 03:02:50.625712: train_loss -0.9733\n",
            "2025-12-23 03:02:50.625931: val_loss -0.9845\n",
            "2025-12-23 03:02:50.626054: Pseudo dice [np.float32(0.9879)]\n",
            "2025-12-23 03:02:50.626165: Epoch time: 22.39 s\n",
            "2025-12-23 03:02:52.705607: \n",
            "2025-12-23 03:02:52.705809: Epoch 796\n",
            "2025-12-23 03:02:52.705952: Current learning rate: 0.00239\n",
            "2025-12-23 03:03:15.262695: train_loss -0.9732\n",
            "2025-12-23 03:03:15.262901: val_loss -0.9845\n",
            "2025-12-23 03:03:15.262992: Pseudo dice [np.float32(0.9867)]\n",
            "2025-12-23 03:03:15.263105: Epoch time: 22.56 s\n",
            "2025-12-23 03:03:16.644208: \n",
            "2025-12-23 03:03:16.644563: Epoch 797\n",
            "2025-12-23 03:03:16.644722: Current learning rate: 0.00238\n",
            "2025-12-23 03:03:39.141664: train_loss -0.974\n",
            "2025-12-23 03:03:39.142195: val_loss -0.9852\n",
            "2025-12-23 03:03:39.142353: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 03:03:39.142447: Epoch time: 22.5 s\n",
            "2025-12-23 03:03:40.511355: \n",
            "2025-12-23 03:03:40.511596: Epoch 798\n",
            "2025-12-23 03:03:40.511779: Current learning rate: 0.00237\n",
            "2025-12-23 03:04:02.997642: train_loss -0.9754\n",
            "2025-12-23 03:04:02.997935: val_loss -0.9852\n",
            "2025-12-23 03:04:02.998040: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 03:04:02.998133: Epoch time: 22.49 s\n",
            "2025-12-23 03:04:04.370447: \n",
            "2025-12-23 03:04:04.370736: Epoch 799\n",
            "2025-12-23 03:04:04.370873: Current learning rate: 0.00236\n",
            "2025-12-23 03:04:26.862057: train_loss -0.9746\n",
            "2025-12-23 03:04:26.862282: val_loss -0.9865\n",
            "2025-12-23 03:04:26.862399: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 03:04:26.862535: Epoch time: 22.49 s\n",
            "2025-12-23 03:04:28.735677: \n",
            "2025-12-23 03:04:28.735976: Epoch 800\n",
            "2025-12-23 03:04:28.736120: Current learning rate: 0.00235\n",
            "2025-12-23 03:04:51.207877: train_loss -0.9762\n",
            "2025-12-23 03:04:51.208071: val_loss -0.9861\n",
            "2025-12-23 03:04:51.208154: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:04:51.208269: Epoch time: 22.47 s\n",
            "2025-12-23 03:04:52.572234: \n",
            "2025-12-23 03:04:52.572444: Epoch 801\n",
            "2025-12-23 03:04:52.572599: Current learning rate: 0.00234\n",
            "2025-12-23 03:05:15.029118: train_loss -0.9749\n",
            "2025-12-23 03:05:15.029339: val_loss -0.9858\n",
            "2025-12-23 03:05:15.029480: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:05:15.029619: Epoch time: 22.46 s\n",
            "2025-12-23 03:05:16.409405: \n",
            "2025-12-23 03:05:16.409621: Epoch 802\n",
            "2025-12-23 03:05:16.409817: Current learning rate: 0.00233\n",
            "2025-12-23 03:05:38.871611: train_loss -0.9761\n",
            "2025-12-23 03:05:38.871895: val_loss -0.9855\n",
            "2025-12-23 03:05:38.871989: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 03:05:38.872079: Epoch time: 22.46 s\n",
            "2025-12-23 03:05:40.258335: \n",
            "2025-12-23 03:05:40.258610: Epoch 803\n",
            "2025-12-23 03:05:40.258752: Current learning rate: 0.00232\n",
            "2025-12-23 03:06:02.723114: train_loss -0.9752\n",
            "2025-12-23 03:06:02.723540: val_loss -0.9861\n",
            "2025-12-23 03:06:02.723709: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 03:06:02.723854: Epoch time: 22.47 s\n",
            "2025-12-23 03:06:04.132888: \n",
            "2025-12-23 03:06:04.133113: Epoch 804\n",
            "2025-12-23 03:06:04.133279: Current learning rate: 0.00231\n",
            "2025-12-23 03:06:26.596115: train_loss -0.9753\n",
            "2025-12-23 03:06:26.596349: val_loss -0.9849\n",
            "2025-12-23 03:06:26.596444: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 03:06:26.596691: Epoch time: 22.46 s\n",
            "2025-12-23 03:06:28.003549: \n",
            "2025-12-23 03:06:28.003789: Epoch 805\n",
            "2025-12-23 03:06:28.003931: Current learning rate: 0.0023\n",
            "2025-12-23 03:06:50.399643: train_loss -0.9755\n",
            "2025-12-23 03:06:50.399845: val_loss -0.9861\n",
            "2025-12-23 03:06:50.399959: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 03:06:50.400115: Epoch time: 22.4 s\n",
            "2025-12-23 03:06:51.770486: \n",
            "2025-12-23 03:06:51.770662: Epoch 806\n",
            "2025-12-23 03:06:51.770785: Current learning rate: 0.00229\n",
            "2025-12-23 03:07:14.166586: train_loss -0.9747\n",
            "2025-12-23 03:07:14.166854: val_loss -0.9865\n",
            "2025-12-23 03:07:14.166957: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 03:07:14.167049: Epoch time: 22.4 s\n",
            "2025-12-23 03:07:15.556787: \n",
            "2025-12-23 03:07:15.557064: Epoch 807\n",
            "2025-12-23 03:07:15.557201: Current learning rate: 0.00228\n",
            "2025-12-23 03:07:38.017871: train_loss -0.9759\n",
            "2025-12-23 03:07:38.018085: val_loss -0.9861\n",
            "2025-12-23 03:07:38.018171: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 03:07:38.018274: Epoch time: 22.46 s\n",
            "2025-12-23 03:07:39.403698: \n",
            "2025-12-23 03:07:39.403982: Epoch 808\n",
            "2025-12-23 03:07:39.404133: Current learning rate: 0.00226\n",
            "2025-12-23 03:08:01.828974: train_loss -0.975\n",
            "2025-12-23 03:08:01.829199: val_loss -0.9856\n",
            "2025-12-23 03:08:01.829350: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:08:01.829464: Epoch time: 22.43 s\n",
            "2025-12-23 03:08:03.250936: \n",
            "2025-12-23 03:08:03.251143: Epoch 809\n",
            "2025-12-23 03:08:03.251324: Current learning rate: 0.00225\n",
            "2025-12-23 03:08:25.701694: train_loss -0.9751\n",
            "2025-12-23 03:08:25.701917: val_loss -0.9852\n",
            "2025-12-23 03:08:25.702007: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 03:08:25.702096: Epoch time: 22.45 s\n",
            "2025-12-23 03:08:27.095562: \n",
            "2025-12-23 03:08:27.095822: Epoch 810\n",
            "2025-12-23 03:08:27.095961: Current learning rate: 0.00224\n",
            "2025-12-23 03:08:49.519995: train_loss -0.9752\n",
            "2025-12-23 03:08:49.520273: val_loss -0.9868\n",
            "2025-12-23 03:08:49.520440: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 03:08:49.520539: Epoch time: 22.43 s\n",
            "2025-12-23 03:08:50.907452: \n",
            "2025-12-23 03:08:50.907659: Epoch 811\n",
            "2025-12-23 03:08:50.907792: Current learning rate: 0.00223\n",
            "2025-12-23 03:09:13.356110: train_loss -0.9758\n",
            "2025-12-23 03:09:13.356380: val_loss -0.9871\n",
            "2025-12-23 03:09:13.356487: Pseudo dice [np.float32(0.9907)]\n",
            "2025-12-23 03:09:13.356577: Epoch time: 22.45 s\n",
            "2025-12-23 03:09:14.756770: \n",
            "2025-12-23 03:09:14.756924: Epoch 812\n",
            "2025-12-23 03:09:14.757053: Current learning rate: 0.00222\n",
            "2025-12-23 03:09:37.162788: train_loss -0.9744\n",
            "2025-12-23 03:09:37.163028: val_loss -0.9854\n",
            "2025-12-23 03:09:37.163185: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 03:09:37.163386: Epoch time: 22.41 s\n",
            "2025-12-23 03:09:39.285626: \n",
            "2025-12-23 03:09:39.285909: Epoch 813\n",
            "2025-12-23 03:09:39.286054: Current learning rate: 0.00221\n",
            "2025-12-23 03:10:01.820297: train_loss -0.9759\n",
            "2025-12-23 03:10:01.820568: val_loss -0.985\n",
            "2025-12-23 03:10:01.820665: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 03:10:01.820753: Epoch time: 22.54 s\n",
            "2025-12-23 03:10:03.201566: \n",
            "2025-12-23 03:10:03.201907: Epoch 814\n",
            "2025-12-23 03:10:03.202048: Current learning rate: 0.0022\n",
            "2025-12-23 03:10:25.636400: train_loss -0.976\n",
            "2025-12-23 03:10:25.636715: val_loss -0.9873\n",
            "2025-12-23 03:10:25.636828: Pseudo dice [np.float32(0.9905)]\n",
            "2025-12-23 03:10:25.636953: Epoch time: 22.44 s\n",
            "2025-12-23 03:10:27.040372: \n",
            "2025-12-23 03:10:27.040598: Epoch 815\n",
            "2025-12-23 03:10:27.040728: Current learning rate: 0.00219\n",
            "2025-12-23 03:10:49.557299: train_loss -0.9757\n",
            "2025-12-23 03:10:49.557574: val_loss -0.9865\n",
            "2025-12-23 03:10:49.557707: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 03:10:49.557829: Epoch time: 22.52 s\n",
            "2025-12-23 03:10:50.944294: \n",
            "2025-12-23 03:10:50.944650: Epoch 816\n",
            "2025-12-23 03:10:50.944806: Current learning rate: 0.00218\n",
            "2025-12-23 03:11:13.444422: train_loss -0.9763\n",
            "2025-12-23 03:11:13.444685: val_loss -0.9865\n",
            "2025-12-23 03:11:13.444791: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 03:11:13.444886: Epoch time: 22.5 s\n",
            "2025-12-23 03:11:13.444962: Yayy! New best EMA pseudo Dice: 0.9894999861717224\n",
            "2025-12-23 03:11:15.419553: \n",
            "2025-12-23 03:11:15.419883: Epoch 817\n",
            "2025-12-23 03:11:15.420018: Current learning rate: 0.00217\n",
            "2025-12-23 03:11:37.953794: train_loss -0.9757\n",
            "2025-12-23 03:11:37.954022: val_loss -0.9862\n",
            "2025-12-23 03:11:37.954145: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 03:11:37.954272: Epoch time: 22.54 s\n",
            "2025-12-23 03:11:39.391888: \n",
            "2025-12-23 03:11:39.392082: Epoch 818\n",
            "2025-12-23 03:11:39.392209: Current learning rate: 0.00216\n",
            "2025-12-23 03:12:01.853397: train_loss -0.9755\n",
            "2025-12-23 03:12:01.853676: val_loss -0.9864\n",
            "2025-12-23 03:12:01.853781: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 03:12:01.853875: Epoch time: 22.46 s\n",
            "2025-12-23 03:12:03.271494: \n",
            "2025-12-23 03:12:03.271698: Epoch 819\n",
            "2025-12-23 03:12:03.271831: Current learning rate: 0.00215\n",
            "2025-12-23 03:12:25.707425: train_loss -0.9755\n",
            "2025-12-23 03:12:25.707681: val_loss -0.9856\n",
            "2025-12-23 03:12:25.707839: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 03:12:25.708012: Epoch time: 22.44 s\n",
            "2025-12-23 03:12:27.094887: \n",
            "2025-12-23 03:12:27.095288: Epoch 820\n",
            "2025-12-23 03:12:27.095435: Current learning rate: 0.00214\n",
            "2025-12-23 03:12:49.578521: train_loss -0.9755\n",
            "2025-12-23 03:12:49.578734: val_loss -0.9859\n",
            "2025-12-23 03:12:49.578855: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 03:12:49.578969: Epoch time: 22.48 s\n",
            "2025-12-23 03:12:50.965872: \n",
            "2025-12-23 03:12:50.966285: Epoch 821\n",
            "2025-12-23 03:12:50.966461: Current learning rate: 0.00213\n",
            "2025-12-23 03:13:13.455010: train_loss -0.975\n",
            "2025-12-23 03:13:13.455455: val_loss -0.9856\n",
            "2025-12-23 03:13:13.455614: Pseudo dice [np.float32(0.9884)]\n",
            "2025-12-23 03:13:13.455721: Epoch time: 22.49 s\n",
            "2025-12-23 03:13:14.812700: \n",
            "2025-12-23 03:13:14.813027: Epoch 822\n",
            "2025-12-23 03:13:14.813166: Current learning rate: 0.00212\n",
            "2025-12-23 03:13:37.284304: train_loss -0.9757\n",
            "2025-12-23 03:13:37.284580: val_loss -0.9867\n",
            "2025-12-23 03:13:37.284682: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 03:13:37.284790: Epoch time: 22.47 s\n",
            "2025-12-23 03:13:38.666494: \n",
            "2025-12-23 03:13:38.666803: Epoch 823\n",
            "2025-12-23 03:13:38.666936: Current learning rate: 0.0021\n",
            "2025-12-23 03:14:01.070416: train_loss -0.9753\n",
            "2025-12-23 03:14:01.070661: val_loss -0.9861\n",
            "2025-12-23 03:14:01.070777: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:14:01.070894: Epoch time: 22.41 s\n",
            "2025-12-23 03:14:02.426762: \n",
            "2025-12-23 03:14:02.427050: Epoch 824\n",
            "2025-12-23 03:14:02.427243: Current learning rate: 0.00209\n",
            "2025-12-23 03:14:24.918479: train_loss -0.9755\n",
            "2025-12-23 03:14:24.918785: val_loss -0.9861\n",
            "2025-12-23 03:14:24.918914: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 03:14:24.919103: Epoch time: 22.49 s\n",
            "2025-12-23 03:14:26.262886: \n",
            "2025-12-23 03:14:26.263195: Epoch 825\n",
            "2025-12-23 03:14:26.263352: Current learning rate: 0.00208\n",
            "2025-12-23 03:14:48.697953: train_loss -0.9759\n",
            "2025-12-23 03:14:48.698161: val_loss -0.9852\n",
            "2025-12-23 03:14:48.698274: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:14:48.698398: Epoch time: 22.44 s\n",
            "2025-12-23 03:14:50.056593: \n",
            "2025-12-23 03:14:50.056864: Epoch 826\n",
            "2025-12-23 03:14:50.057000: Current learning rate: 0.00207\n",
            "2025-12-23 03:15:12.535506: train_loss -0.9751\n",
            "2025-12-23 03:15:12.535740: val_loss -0.9865\n",
            "2025-12-23 03:15:12.535839: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:15:12.535931: Epoch time: 22.48 s\n",
            "2025-12-23 03:15:13.874207: \n",
            "2025-12-23 03:15:13.874399: Epoch 827\n",
            "2025-12-23 03:15:13.874603: Current learning rate: 0.00206\n",
            "2025-12-23 03:15:36.294476: train_loss -0.9763\n",
            "2025-12-23 03:15:36.294762: val_loss -0.985\n",
            "2025-12-23 03:15:36.294861: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 03:15:36.294955: Epoch time: 22.42 s\n",
            "2025-12-23 03:15:37.625088: \n",
            "2025-12-23 03:15:37.625397: Epoch 828\n",
            "2025-12-23 03:15:37.625536: Current learning rate: 0.00205\n",
            "2025-12-23 03:16:00.006803: train_loss -0.9758\n",
            "2025-12-23 03:16:00.007074: val_loss -0.9871\n",
            "2025-12-23 03:16:00.007212: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 03:16:00.007350: Epoch time: 22.38 s\n",
            "2025-12-23 03:16:01.338500: \n",
            "2025-12-23 03:16:01.338735: Epoch 829\n",
            "2025-12-23 03:16:01.338944: Current learning rate: 0.00204\n",
            "2025-12-23 03:16:23.766446: train_loss -0.9755\n",
            "2025-12-23 03:16:23.766814: val_loss -0.9858\n",
            "2025-12-23 03:16:23.766915: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 03:16:23.767007: Epoch time: 22.43 s\n",
            "2025-12-23 03:16:25.775966: \n",
            "2025-12-23 03:16:25.776232: Epoch 830\n",
            "2025-12-23 03:16:25.776381: Current learning rate: 0.00203\n",
            "2025-12-23 03:16:48.302907: train_loss -0.9769\n",
            "2025-12-23 03:16:48.303186: val_loss -0.9863\n",
            "2025-12-23 03:16:48.303367: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:16:48.303511: Epoch time: 22.53 s\n",
            "2025-12-23 03:16:49.635587: \n",
            "2025-12-23 03:16:49.635912: Epoch 831\n",
            "2025-12-23 03:16:49.636049: Current learning rate: 0.00202\n",
            "2025-12-23 03:17:12.097346: train_loss -0.9754\n",
            "2025-12-23 03:17:12.097546: val_loss -0.9857\n",
            "2025-12-23 03:17:12.097640: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 03:17:12.097742: Epoch time: 22.46 s\n",
            "2025-12-23 03:17:13.426065: \n",
            "2025-12-23 03:17:13.426402: Epoch 832\n",
            "2025-12-23 03:17:13.426608: Current learning rate: 0.00201\n",
            "2025-12-23 03:17:35.930909: train_loss -0.9756\n",
            "2025-12-23 03:17:35.931142: val_loss -0.9854\n",
            "2025-12-23 03:17:35.931261: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 03:17:35.931369: Epoch time: 22.51 s\n",
            "2025-12-23 03:17:37.235564: \n",
            "2025-12-23 03:17:37.235830: Epoch 833\n",
            "2025-12-23 03:17:37.235959: Current learning rate: 0.002\n",
            "2025-12-23 03:17:59.724079: train_loss -0.9754\n",
            "2025-12-23 03:17:59.724306: val_loss -0.9851\n",
            "2025-12-23 03:17:59.724440: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 03:17:59.724775: Epoch time: 22.49 s\n",
            "2025-12-23 03:18:01.032849: \n",
            "2025-12-23 03:18:01.033159: Epoch 834\n",
            "2025-12-23 03:18:01.033300: Current learning rate: 0.00199\n",
            "2025-12-23 03:18:23.517077: train_loss -0.9754\n",
            "2025-12-23 03:18:23.517413: val_loss -0.9861\n",
            "2025-12-23 03:18:23.517592: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 03:18:23.517702: Epoch time: 22.49 s\n",
            "2025-12-23 03:18:24.856900: \n",
            "2025-12-23 03:18:24.857242: Epoch 835\n",
            "2025-12-23 03:18:24.857477: Current learning rate: 0.00198\n",
            "2025-12-23 03:18:47.322500: train_loss -0.9768\n",
            "2025-12-23 03:18:47.322768: val_loss -0.9867\n",
            "2025-12-23 03:18:47.322862: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:18:47.322953: Epoch time: 22.47 s\n",
            "2025-12-23 03:18:48.667946: \n",
            "2025-12-23 03:18:48.668229: Epoch 836\n",
            "2025-12-23 03:18:48.668386: Current learning rate: 0.00196\n",
            "2025-12-23 03:19:11.155122: train_loss -0.9754\n",
            "2025-12-23 03:19:11.155541: val_loss -0.986\n",
            "2025-12-23 03:19:11.155641: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 03:19:11.155741: Epoch time: 22.49 s\n",
            "2025-12-23 03:19:12.500196: \n",
            "2025-12-23 03:19:12.500382: Epoch 837\n",
            "2025-12-23 03:19:12.500571: Current learning rate: 0.00195\n",
            "2025-12-23 03:19:34.959251: train_loss -0.9758\n",
            "2025-12-23 03:19:34.959473: val_loss -0.9863\n",
            "2025-12-23 03:19:34.959565: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 03:19:34.959657: Epoch time: 22.46 s\n",
            "2025-12-23 03:19:36.291757: \n",
            "2025-12-23 03:19:36.292035: Epoch 838\n",
            "2025-12-23 03:19:36.292166: Current learning rate: 0.00194\n",
            "2025-12-23 03:19:58.783748: train_loss -0.9765\n",
            "2025-12-23 03:19:58.783996: val_loss -0.9872\n",
            "2025-12-23 03:19:58.784086: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 03:19:58.784176: Epoch time: 22.49 s\n",
            "2025-12-23 03:20:00.122017: \n",
            "2025-12-23 03:20:00.122225: Epoch 839\n",
            "2025-12-23 03:20:00.122385: Current learning rate: 0.00193\n",
            "2025-12-23 03:20:22.568092: train_loss -0.9758\n",
            "2025-12-23 03:20:22.568404: val_loss -0.986\n",
            "2025-12-23 03:20:22.568522: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 03:20:22.568640: Epoch time: 22.45 s\n",
            "2025-12-23 03:20:23.906952: \n",
            "2025-12-23 03:20:23.907243: Epoch 840\n",
            "2025-12-23 03:20:23.907392: Current learning rate: 0.00192\n",
            "2025-12-23 03:20:46.333041: train_loss -0.9761\n",
            "2025-12-23 03:20:46.333346: val_loss -0.9857\n",
            "2025-12-23 03:20:46.333454: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 03:20:46.333545: Epoch time: 22.43 s\n",
            "2025-12-23 03:20:47.677213: \n",
            "2025-12-23 03:20:47.677526: Epoch 841\n",
            "2025-12-23 03:20:47.677657: Current learning rate: 0.00191\n",
            "2025-12-23 03:21:10.105014: train_loss -0.9754\n",
            "2025-12-23 03:21:10.105250: val_loss -0.9864\n",
            "2025-12-23 03:21:10.105420: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 03:21:10.105542: Epoch time: 22.43 s\n",
            "2025-12-23 03:21:11.422595: \n",
            "2025-12-23 03:21:11.422855: Epoch 842\n",
            "2025-12-23 03:21:11.423014: Current learning rate: 0.0019\n",
            "2025-12-23 03:21:33.856695: train_loss -0.9754\n",
            "2025-12-23 03:21:33.856889: val_loss -0.9855\n",
            "2025-12-23 03:21:33.856978: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 03:21:33.857068: Epoch time: 22.44 s\n",
            "2025-12-23 03:21:35.171350: \n",
            "2025-12-23 03:21:35.171683: Epoch 843\n",
            "2025-12-23 03:21:35.171864: Current learning rate: 0.00189\n",
            "2025-12-23 03:21:57.654018: train_loss -0.9763\n",
            "2025-12-23 03:21:57.654240: val_loss -0.9856\n",
            "2025-12-23 03:21:57.654393: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 03:21:57.654490: Epoch time: 22.48 s\n",
            "2025-12-23 03:21:58.967597: \n",
            "2025-12-23 03:21:58.967801: Epoch 844\n",
            "2025-12-23 03:21:58.967927: Current learning rate: 0.00188\n",
            "2025-12-23 03:22:21.433213: train_loss -0.9756\n",
            "2025-12-23 03:22:21.433444: val_loss -0.9864\n",
            "2025-12-23 03:22:21.433533: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 03:22:21.433628: Epoch time: 22.47 s\n",
            "2025-12-23 03:22:22.771323: \n",
            "2025-12-23 03:22:22.771634: Epoch 845\n",
            "2025-12-23 03:22:22.771804: Current learning rate: 0.00187\n",
            "2025-12-23 03:22:45.191769: train_loss -0.9763\n",
            "2025-12-23 03:22:45.192013: val_loss -0.9865\n",
            "2025-12-23 03:22:45.192107: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:22:45.192202: Epoch time: 22.42 s\n",
            "2025-12-23 03:22:46.568443: \n",
            "2025-12-23 03:22:46.568637: Epoch 846\n",
            "2025-12-23 03:22:46.568764: Current learning rate: 0.00186\n",
            "2025-12-23 03:23:09.060656: train_loss -0.976\n",
            "2025-12-23 03:23:09.060869: val_loss -0.9873\n",
            "2025-12-23 03:23:09.060958: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:23:09.061050: Epoch time: 22.49 s\n",
            "2025-12-23 03:23:10.405032: \n",
            "2025-12-23 03:23:10.405226: Epoch 847\n",
            "2025-12-23 03:23:10.405359: Current learning rate: 0.00185\n",
            "2025-12-23 03:23:32.848877: train_loss -0.976\n",
            "2025-12-23 03:23:32.849072: val_loss -0.9862\n",
            "2025-12-23 03:23:32.849258: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 03:23:32.849399: Epoch time: 22.45 s\n",
            "2025-12-23 03:23:34.909979: \n",
            "2025-12-23 03:23:34.910158: Epoch 848\n",
            "2025-12-23 03:23:34.910347: Current learning rate: 0.00184\n",
            "2025-12-23 03:23:57.445355: train_loss -0.9761\n",
            "2025-12-23 03:23:57.445577: val_loss -0.9862\n",
            "2025-12-23 03:23:57.445680: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:23:57.445772: Epoch time: 22.54 s\n",
            "2025-12-23 03:23:58.763469: \n",
            "2025-12-23 03:23:58.763800: Epoch 849\n",
            "2025-12-23 03:23:58.763933: Current learning rate: 0.00182\n",
            "2025-12-23 03:24:21.203081: train_loss -0.9768\n",
            "2025-12-23 03:24:21.203389: val_loss -0.9869\n",
            "2025-12-23 03:24:21.203503: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 03:24:21.203594: Epoch time: 22.44 s\n",
            "2025-12-23 03:24:23.082527: \n",
            "2025-12-23 03:24:23.082936: Epoch 850\n",
            "2025-12-23 03:24:23.083083: Current learning rate: 0.00181\n",
            "2025-12-23 03:24:45.576607: train_loss -0.9771\n",
            "2025-12-23 03:24:45.576837: val_loss -0.9862\n",
            "2025-12-23 03:24:45.576924: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:24:45.577012: Epoch time: 22.5 s\n",
            "2025-12-23 03:24:46.884487: \n",
            "2025-12-23 03:24:46.884785: Epoch 851\n",
            "2025-12-23 03:24:46.884984: Current learning rate: 0.0018\n",
            "2025-12-23 03:25:09.373299: train_loss -0.9762\n",
            "2025-12-23 03:25:09.373611: val_loss -0.9856\n",
            "2025-12-23 03:25:09.373939: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 03:25:09.374096: Epoch time: 22.49 s\n",
            "2025-12-23 03:25:10.741561: \n",
            "2025-12-23 03:25:10.741914: Epoch 852\n",
            "2025-12-23 03:25:10.742052: Current learning rate: 0.00179\n",
            "2025-12-23 03:25:33.207003: train_loss -0.976\n",
            "2025-12-23 03:25:33.207211: val_loss -0.9873\n",
            "2025-12-23 03:25:33.207326: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 03:25:33.207418: Epoch time: 22.47 s\n",
            "2025-12-23 03:25:34.539886: \n",
            "2025-12-23 03:25:34.540101: Epoch 853\n",
            "2025-12-23 03:25:34.540288: Current learning rate: 0.00178\n",
            "2025-12-23 03:25:56.973167: train_loss -0.9756\n",
            "2025-12-23 03:25:56.973471: val_loss -0.9855\n",
            "2025-12-23 03:25:56.973565: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 03:25:56.973679: Epoch time: 22.43 s\n",
            "2025-12-23 03:25:58.348397: \n",
            "2025-12-23 03:25:58.348827: Epoch 854\n",
            "2025-12-23 03:25:58.348974: Current learning rate: 0.00177\n",
            "2025-12-23 03:26:20.814315: train_loss -0.9756\n",
            "2025-12-23 03:26:20.814613: val_loss -0.9861\n",
            "2025-12-23 03:26:20.814710: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:26:20.814800: Epoch time: 22.47 s\n",
            "2025-12-23 03:26:22.132644: \n",
            "2025-12-23 03:26:22.133019: Epoch 855\n",
            "2025-12-23 03:26:22.133153: Current learning rate: 0.00176\n",
            "2025-12-23 03:26:44.561352: train_loss -0.9767\n",
            "2025-12-23 03:26:44.561559: val_loss -0.986\n",
            "2025-12-23 03:26:44.561710: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 03:26:44.561957: Epoch time: 22.43 s\n",
            "2025-12-23 03:26:45.912521: \n",
            "2025-12-23 03:26:45.912884: Epoch 856\n",
            "2025-12-23 03:26:45.913035: Current learning rate: 0.00175\n",
            "2025-12-23 03:27:08.330827: train_loss -0.9757\n",
            "2025-12-23 03:27:08.331139: val_loss -0.9854\n",
            "2025-12-23 03:27:08.331266: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 03:27:08.331550: Epoch time: 22.42 s\n",
            "2025-12-23 03:27:09.676093: \n",
            "2025-12-23 03:27:09.676400: Epoch 857\n",
            "2025-12-23 03:27:09.676540: Current learning rate: 0.00174\n",
            "2025-12-23 03:27:32.124420: train_loss -0.9759\n",
            "2025-12-23 03:27:32.124752: val_loss -0.9868\n",
            "2025-12-23 03:27:32.125032: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:27:32.125267: Epoch time: 22.45 s\n",
            "2025-12-23 03:27:33.452670: \n",
            "2025-12-23 03:27:33.452982: Epoch 858\n",
            "2025-12-23 03:27:33.453116: Current learning rate: 0.00173\n",
            "2025-12-23 03:27:55.859449: train_loss -0.9764\n",
            "2025-12-23 03:27:55.859718: val_loss -0.9871\n",
            "2025-12-23 03:27:55.859821: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:27:55.859921: Epoch time: 22.41 s\n",
            "2025-12-23 03:27:57.186177: \n",
            "2025-12-23 03:27:57.186510: Epoch 859\n",
            "2025-12-23 03:27:57.186668: Current learning rate: 0.00172\n",
            "2025-12-23 03:28:19.576683: train_loss -0.9762\n",
            "2025-12-23 03:28:19.576895: val_loss -0.9869\n",
            "2025-12-23 03:28:19.577012: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:28:19.577106: Epoch time: 22.39 s\n",
            "2025-12-23 03:28:20.896758: \n",
            "2025-12-23 03:28:20.897004: Epoch 860\n",
            "2025-12-23 03:28:20.897141: Current learning rate: 0.0017\n",
            "2025-12-23 03:28:43.378552: train_loss -0.9763\n",
            "2025-12-23 03:28:43.378900: val_loss -0.9867\n",
            "2025-12-23 03:28:43.379067: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:28:43.379179: Epoch time: 22.48 s\n",
            "2025-12-23 03:28:44.682180: \n",
            "2025-12-23 03:28:44.682445: Epoch 861\n",
            "2025-12-23 03:28:44.682576: Current learning rate: 0.00169\n",
            "2025-12-23 03:29:07.094146: train_loss -0.9756\n",
            "2025-12-23 03:29:07.094520: val_loss -0.9865\n",
            "2025-12-23 03:29:07.094651: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 03:29:07.094779: Epoch time: 22.41 s\n",
            "2025-12-23 03:29:08.433561: \n",
            "2025-12-23 03:29:08.433851: Epoch 862\n",
            "2025-12-23 03:29:08.434005: Current learning rate: 0.00168\n",
            "2025-12-23 03:29:30.893502: train_loss -0.9754\n",
            "2025-12-23 03:29:30.893720: val_loss -0.9846\n",
            "2025-12-23 03:29:30.893839: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 03:29:30.893953: Epoch time: 22.46 s\n",
            "2025-12-23 03:29:32.238511: \n",
            "2025-12-23 03:29:32.238847: Epoch 863\n",
            "2025-12-23 03:29:32.238989: Current learning rate: 0.00167\n",
            "2025-12-23 03:29:54.679262: train_loss -0.976\n",
            "2025-12-23 03:29:54.679590: val_loss -0.9857\n",
            "2025-12-23 03:29:54.679725: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 03:29:54.679881: Epoch time: 22.44 s\n",
            "2025-12-23 03:29:55.997970: \n",
            "2025-12-23 03:29:55.998332: Epoch 864\n",
            "2025-12-23 03:29:55.998477: Current learning rate: 0.00166\n",
            "2025-12-23 03:30:18.493150: train_loss -0.9763\n",
            "2025-12-23 03:30:18.493491: val_loss -0.9844\n",
            "2025-12-23 03:30:18.493605: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 03:30:18.493698: Epoch time: 22.5 s\n",
            "2025-12-23 03:30:19.815087: \n",
            "2025-12-23 03:30:19.815293: Epoch 865\n",
            "2025-12-23 03:30:19.815465: Current learning rate: 0.00165\n",
            "2025-12-23 03:30:42.238372: train_loss -0.9756\n",
            "2025-12-23 03:30:42.238567: val_loss -0.9867\n",
            "2025-12-23 03:30:42.238657: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:30:42.238747: Epoch time: 22.42 s\n",
            "2025-12-23 03:30:43.556940: \n",
            "2025-12-23 03:30:43.557280: Epoch 866\n",
            "2025-12-23 03:30:43.557419: Current learning rate: 0.00164\n",
            "2025-12-23 03:31:05.974774: train_loss -0.9764\n",
            "2025-12-23 03:31:05.974990: val_loss -0.9865\n",
            "2025-12-23 03:31:05.975077: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:31:05.975164: Epoch time: 22.42 s\n",
            "2025-12-23 03:31:07.924026: \n",
            "2025-12-23 03:31:07.924386: Epoch 867\n",
            "2025-12-23 03:31:07.924537: Current learning rate: 0.00163\n",
            "2025-12-23 03:31:30.457814: train_loss -0.976\n",
            "2025-12-23 03:31:30.458044: val_loss -0.9858\n",
            "2025-12-23 03:31:30.458131: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 03:31:30.458238: Epoch time: 22.54 s\n",
            "2025-12-23 03:31:31.768205: \n",
            "2025-12-23 03:31:31.768575: Epoch 868\n",
            "2025-12-23 03:31:31.768723: Current learning rate: 0.00162\n",
            "2025-12-23 03:31:54.193201: train_loss -0.9766\n",
            "2025-12-23 03:31:54.193506: val_loss -0.9868\n",
            "2025-12-23 03:31:54.193617: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 03:31:54.193717: Epoch time: 22.43 s\n",
            "2025-12-23 03:31:55.498076: \n",
            "2025-12-23 03:31:55.498428: Epoch 869\n",
            "2025-12-23 03:31:55.498584: Current learning rate: 0.00161\n",
            "2025-12-23 03:32:17.938660: train_loss -0.9766\n",
            "2025-12-23 03:32:17.939075: val_loss -0.9865\n",
            "2025-12-23 03:32:17.939180: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:32:17.939316: Epoch time: 22.44 s\n",
            "2025-12-23 03:32:19.240851: \n",
            "2025-12-23 03:32:19.241279: Epoch 870\n",
            "2025-12-23 03:32:19.241455: Current learning rate: 0.00159\n",
            "2025-12-23 03:32:41.667922: train_loss -0.9762\n",
            "2025-12-23 03:32:41.668156: val_loss -0.9838\n",
            "2025-12-23 03:32:41.668262: Pseudo dice [np.float32(0.9882)]\n",
            "2025-12-23 03:32:41.668354: Epoch time: 22.43 s\n",
            "2025-12-23 03:32:43.004606: \n",
            "2025-12-23 03:32:43.004805: Epoch 871\n",
            "2025-12-23 03:32:43.004949: Current learning rate: 0.00158\n",
            "2025-12-23 03:33:05.474776: train_loss -0.9759\n",
            "2025-12-23 03:33:05.474992: val_loss -0.9859\n",
            "2025-12-23 03:33:05.475105: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 03:33:05.475235: Epoch time: 22.47 s\n",
            "2025-12-23 03:33:06.798924: \n",
            "2025-12-23 03:33:06.799211: Epoch 872\n",
            "2025-12-23 03:33:06.799367: Current learning rate: 0.00157\n",
            "2025-12-23 03:33:29.237864: train_loss -0.9771\n",
            "2025-12-23 03:33:29.238115: val_loss -0.9857\n",
            "2025-12-23 03:33:29.238208: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 03:33:29.238339: Epoch time: 22.44 s\n",
            "2025-12-23 03:33:30.563593: \n",
            "2025-12-23 03:33:30.563913: Epoch 873\n",
            "2025-12-23 03:33:30.564052: Current learning rate: 0.00156\n",
            "2025-12-23 03:33:53.019735: train_loss -0.9765\n",
            "2025-12-23 03:33:53.019945: val_loss -0.9858\n",
            "2025-12-23 03:33:53.020035: Pseudo dice [np.float32(0.989)]\n",
            "2025-12-23 03:33:53.020124: Epoch time: 22.46 s\n",
            "2025-12-23 03:33:54.360052: \n",
            "2025-12-23 03:33:54.360339: Epoch 874\n",
            "2025-12-23 03:33:54.360490: Current learning rate: 0.00155\n",
            "2025-12-23 03:34:16.831505: train_loss -0.9761\n",
            "2025-12-23 03:34:16.831734: val_loss -0.9855\n",
            "2025-12-23 03:34:16.831845: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 03:34:16.832044: Epoch time: 22.47 s\n",
            "2025-12-23 03:34:18.165982: \n",
            "2025-12-23 03:34:18.166302: Epoch 875\n",
            "2025-12-23 03:34:18.166459: Current learning rate: 0.00154\n",
            "2025-12-23 03:34:40.631557: train_loss -0.9757\n",
            "2025-12-23 03:34:40.631752: val_loss -0.9861\n",
            "2025-12-23 03:34:40.631839: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 03:34:40.631962: Epoch time: 22.47 s\n",
            "2025-12-23 03:34:41.970867: \n",
            "2025-12-23 03:34:41.971127: Epoch 876\n",
            "2025-12-23 03:34:41.971286: Current learning rate: 0.00153\n",
            "2025-12-23 03:35:04.413626: train_loss -0.9759\n",
            "2025-12-23 03:35:04.413847: val_loss -0.9865\n",
            "2025-12-23 03:35:04.413984: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:35:04.414082: Epoch time: 22.44 s\n",
            "2025-12-23 03:35:05.739259: \n",
            "2025-12-23 03:35:05.739605: Epoch 877\n",
            "2025-12-23 03:35:05.739738: Current learning rate: 0.00152\n",
            "2025-12-23 03:35:28.182842: train_loss -0.9763\n",
            "2025-12-23 03:35:28.183353: val_loss -0.9863\n",
            "2025-12-23 03:35:28.183511: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 03:35:28.183709: Epoch time: 22.44 s\n",
            "2025-12-23 03:35:29.532912: \n",
            "2025-12-23 03:35:29.533302: Epoch 878\n",
            "2025-12-23 03:35:29.533461: Current learning rate: 0.00151\n",
            "2025-12-23 03:35:52.002177: train_loss -0.9766\n",
            "2025-12-23 03:35:52.002517: val_loss -0.9869\n",
            "2025-12-23 03:35:52.002746: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 03:35:52.002918: Epoch time: 22.47 s\n",
            "2025-12-23 03:35:53.345544: \n",
            "2025-12-23 03:35:53.345881: Epoch 879\n",
            "2025-12-23 03:35:53.346022: Current learning rate: 0.00149\n",
            "2025-12-23 03:36:15.768929: train_loss -0.9764\n",
            "2025-12-23 03:36:15.769209: val_loss -0.9869\n",
            "2025-12-23 03:36:15.769343: Pseudo dice [np.float32(0.9901)]\n",
            "2025-12-23 03:36:15.769438: Epoch time: 22.42 s\n",
            "2025-12-23 03:36:17.089121: \n",
            "2025-12-23 03:36:17.089311: Epoch 880\n",
            "2025-12-23 03:36:17.089443: Current learning rate: 0.00148\n",
            "2025-12-23 03:36:39.567735: train_loss -0.9764\n",
            "2025-12-23 03:36:39.568088: val_loss -0.9868\n",
            "2025-12-23 03:36:39.568255: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 03:36:39.568401: Epoch time: 22.48 s\n",
            "2025-12-23 03:36:40.938523: \n",
            "2025-12-23 03:36:40.938731: Epoch 881\n",
            "2025-12-23 03:36:40.938868: Current learning rate: 0.00147\n",
            "2025-12-23 03:37:03.373385: train_loss -0.9767\n",
            "2025-12-23 03:37:03.373652: val_loss -0.9863\n",
            "2025-12-23 03:37:03.373759: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:37:03.373858: Epoch time: 22.44 s\n",
            "2025-12-23 03:37:04.716512: \n",
            "2025-12-23 03:37:04.716714: Epoch 882\n",
            "2025-12-23 03:37:04.716848: Current learning rate: 0.00146\n",
            "2025-12-23 03:37:27.113951: train_loss -0.9765\n",
            "2025-12-23 03:37:27.114312: val_loss -0.9868\n",
            "2025-12-23 03:37:27.114547: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 03:37:27.114716: Epoch time: 22.4 s\n",
            "2025-12-23 03:37:28.476796: \n",
            "2025-12-23 03:37:28.477103: Epoch 883\n",
            "2025-12-23 03:37:28.477289: Current learning rate: 0.00145\n",
            "2025-12-23 03:37:50.897650: train_loss -0.9762\n",
            "2025-12-23 03:37:50.897879: val_loss -0.9866\n",
            "2025-12-23 03:37:50.898044: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:37:50.898145: Epoch time: 22.42 s\n",
            "2025-12-23 03:37:50.898257: Yayy! New best EMA pseudo Dice: 0.9894999861717224\n",
            "2025-12-23 03:37:52.767832: \n",
            "2025-12-23 03:37:52.768051: Epoch 884\n",
            "2025-12-23 03:37:52.768184: Current learning rate: 0.00144\n",
            "2025-12-23 03:38:15.195867: train_loss -0.9762\n",
            "2025-12-23 03:38:15.196069: val_loss -0.9859\n",
            "2025-12-23 03:38:15.196200: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 03:38:15.196428: Epoch time: 22.43 s\n",
            "2025-12-23 03:38:15.196552: Yayy! New best EMA pseudo Dice: 0.9894999861717224\n",
            "2025-12-23 03:38:17.062614: \n",
            "2025-12-23 03:38:17.062971: Epoch 885\n",
            "2025-12-23 03:38:17.063154: Current learning rate: 0.00143\n",
            "2025-12-23 03:38:39.524298: train_loss -0.9756\n",
            "2025-12-23 03:38:39.524760: val_loss -0.9868\n",
            "2025-12-23 03:38:39.524874: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 03:38:39.524961: Epoch time: 22.46 s\n",
            "2025-12-23 03:38:39.525036: Yayy! New best EMA pseudo Dice: 0.9896000027656555\n",
            "2025-12-23 03:38:42.069669: \n",
            "2025-12-23 03:38:42.069921: Epoch 886\n",
            "2025-12-23 03:38:42.070097: Current learning rate: 0.00142\n",
            "2025-12-23 03:39:04.517931: train_loss -0.9763\n",
            "2025-12-23 03:39:04.518252: val_loss -0.985\n",
            "2025-12-23 03:39:04.518422: Pseudo dice [np.float32(0.9883)]\n",
            "2025-12-23 03:39:04.518631: Epoch time: 22.45 s\n",
            "2025-12-23 03:39:05.844674: \n",
            "2025-12-23 03:39:05.844947: Epoch 887\n",
            "2025-12-23 03:39:05.845087: Current learning rate: 0.00141\n",
            "2025-12-23 03:39:28.286754: train_loss -0.9772\n",
            "2025-12-23 03:39:28.287019: val_loss -0.9869\n",
            "2025-12-23 03:39:28.287124: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 03:39:28.287260: Epoch time: 22.44 s\n",
            "2025-12-23 03:39:29.643483: \n",
            "2025-12-23 03:39:29.643806: Epoch 888\n",
            "2025-12-23 03:39:29.643948: Current learning rate: 0.00139\n",
            "2025-12-23 03:39:52.134508: train_loss -0.9758\n",
            "2025-12-23 03:39:52.134742: val_loss -0.9864\n",
            "2025-12-23 03:39:52.134841: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 03:39:52.134930: Epoch time: 22.49 s\n",
            "2025-12-23 03:39:53.479037: \n",
            "2025-12-23 03:39:53.479423: Epoch 889\n",
            "2025-12-23 03:39:53.479569: Current learning rate: 0.00138\n",
            "2025-12-23 03:40:15.916953: train_loss -0.9768\n",
            "2025-12-23 03:40:15.917470: val_loss -0.9856\n",
            "2025-12-23 03:40:15.917629: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 03:40:15.917781: Epoch time: 22.44 s\n",
            "2025-12-23 03:40:17.282547: \n",
            "2025-12-23 03:40:17.282725: Epoch 890\n",
            "2025-12-23 03:40:17.282854: Current learning rate: 0.00137\n",
            "2025-12-23 03:40:39.753669: train_loss -0.9766\n",
            "2025-12-23 03:40:39.754138: val_loss -0.9862\n",
            "2025-12-23 03:40:39.754277: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 03:40:39.754390: Epoch time: 22.47 s\n",
            "2025-12-23 03:40:41.094579: \n",
            "2025-12-23 03:40:41.094936: Epoch 891\n",
            "2025-12-23 03:40:41.095092: Current learning rate: 0.00136\n",
            "2025-12-23 03:41:03.587350: train_loss -0.9768\n",
            "2025-12-23 03:41:03.587601: val_loss -0.9864\n",
            "2025-12-23 03:41:03.587887: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:41:03.588179: Epoch time: 22.49 s\n",
            "2025-12-23 03:41:04.953304: \n",
            "2025-12-23 03:41:04.953651: Epoch 892\n",
            "2025-12-23 03:41:04.953792: Current learning rate: 0.00135\n",
            "2025-12-23 03:41:27.404792: train_loss -0.9767\n",
            "2025-12-23 03:41:27.405009: val_loss -0.9849\n",
            "2025-12-23 03:41:27.405103: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:41:27.405265: Epoch time: 22.45 s\n",
            "2025-12-23 03:41:28.765493: \n",
            "2025-12-23 03:41:28.765735: Epoch 893\n",
            "2025-12-23 03:41:28.765929: Current learning rate: 0.00134\n",
            "2025-12-23 03:41:51.233063: train_loss -0.9764\n",
            "2025-12-23 03:41:51.233341: val_loss -0.9872\n",
            "2025-12-23 03:41:51.233536: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 03:41:51.233666: Epoch time: 22.47 s\n",
            "2025-12-23 03:41:52.570879: \n",
            "2025-12-23 03:41:52.571291: Epoch 894\n",
            "2025-12-23 03:41:52.571459: Current learning rate: 0.00133\n",
            "2025-12-23 03:42:15.004302: train_loss -0.9764\n",
            "2025-12-23 03:42:15.004525: val_loss -0.9866\n",
            "2025-12-23 03:42:15.004616: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:42:15.004707: Epoch time: 22.43 s\n",
            "2025-12-23 03:42:16.336406: \n",
            "2025-12-23 03:42:16.336790: Epoch 895\n",
            "2025-12-23 03:42:16.336937: Current learning rate: 0.00132\n",
            "2025-12-23 03:42:38.787487: train_loss -0.9765\n",
            "2025-12-23 03:42:38.787700: val_loss -0.9861\n",
            "2025-12-23 03:42:38.787877: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:42:38.787991: Epoch time: 22.45 s\n",
            "2025-12-23 03:42:40.108464: \n",
            "2025-12-23 03:42:40.108747: Epoch 896\n",
            "2025-12-23 03:42:40.108880: Current learning rate: 0.0013\n",
            "2025-12-23 03:43:02.551975: train_loss -0.9773\n",
            "2025-12-23 03:43:02.552198: val_loss -0.9864\n",
            "2025-12-23 03:43:02.552333: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:43:02.552430: Epoch time: 22.44 s\n",
            "2025-12-23 03:43:03.887952: \n",
            "2025-12-23 03:43:03.888315: Epoch 897\n",
            "2025-12-23 03:43:03.888464: Current learning rate: 0.00129\n",
            "2025-12-23 03:43:26.362810: train_loss -0.9769\n",
            "2025-12-23 03:43:26.363143: val_loss -0.9849\n",
            "2025-12-23 03:43:26.363261: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 03:43:26.363359: Epoch time: 22.48 s\n",
            "2025-12-23 03:43:27.664117: \n",
            "2025-12-23 03:43:27.664439: Epoch 898\n",
            "2025-12-23 03:43:27.664575: Current learning rate: 0.00128\n",
            "2025-12-23 03:43:50.116444: train_loss -0.9762\n",
            "2025-12-23 03:43:50.116682: val_loss -0.9863\n",
            "2025-12-23 03:43:50.116778: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:43:50.116880: Epoch time: 22.45 s\n",
            "2025-12-23 03:43:51.441280: \n",
            "2025-12-23 03:43:51.441453: Epoch 899\n",
            "2025-12-23 03:43:51.441605: Current learning rate: 0.00127\n",
            "2025-12-23 03:44:13.918764: train_loss -0.9761\n",
            "2025-12-23 03:44:13.919164: val_loss -0.9866\n",
            "2025-12-23 03:44:13.919276: Pseudo dice [np.float32(0.9901)]\n",
            "2025-12-23 03:44:13.919379: Epoch time: 22.48 s\n",
            "2025-12-23 03:44:15.834619: \n",
            "2025-12-23 03:44:15.834864: Epoch 900\n",
            "2025-12-23 03:44:15.835022: Current learning rate: 0.00126\n",
            "2025-12-23 03:44:38.311939: train_loss -0.9768\n",
            "2025-12-23 03:44:38.312299: val_loss -0.9865\n",
            "2025-12-23 03:44:38.312502: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:44:38.312652: Epoch time: 22.48 s\n",
            "2025-12-23 03:44:39.651141: \n",
            "2025-12-23 03:44:39.651437: Epoch 901\n",
            "2025-12-23 03:44:39.651601: Current learning rate: 0.00125\n",
            "2025-12-23 03:45:02.097642: train_loss -0.977\n",
            "2025-12-23 03:45:02.097866: val_loss -0.9863\n",
            "2025-12-23 03:45:02.097954: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 03:45:02.098042: Epoch time: 22.45 s\n",
            "2025-12-23 03:45:03.443993: \n",
            "2025-12-23 03:45:03.444184: Epoch 902\n",
            "2025-12-23 03:45:03.444410: Current learning rate: 0.00124\n",
            "2025-12-23 03:45:25.854780: train_loss -0.9762\n",
            "2025-12-23 03:45:25.855005: val_loss -0.9866\n",
            "2025-12-23 03:45:25.855114: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 03:45:25.855206: Epoch time: 22.41 s\n",
            "2025-12-23 03:45:27.173853: \n",
            "2025-12-23 03:45:27.174135: Epoch 903\n",
            "2025-12-23 03:45:27.174286: Current learning rate: 0.00122\n",
            "2025-12-23 03:45:49.638810: train_loss -0.9771\n",
            "2025-12-23 03:45:49.639081: val_loss -0.9862\n",
            "2025-12-23 03:45:49.639255: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:45:49.639375: Epoch time: 22.47 s\n",
            "2025-12-23 03:45:51.626356: \n",
            "2025-12-23 03:45:51.626647: Epoch 904\n",
            "2025-12-23 03:45:51.626812: Current learning rate: 0.00121\n",
            "2025-12-23 03:46:14.141428: train_loss -0.9762\n",
            "2025-12-23 03:46:14.141726: val_loss -0.9867\n",
            "2025-12-23 03:46:14.141830: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 03:46:14.141923: Epoch time: 22.52 s\n",
            "2025-12-23 03:46:15.454162: \n",
            "2025-12-23 03:46:15.454519: Epoch 905\n",
            "2025-12-23 03:46:15.454663: Current learning rate: 0.0012\n",
            "2025-12-23 03:46:37.943332: train_loss -0.9773\n",
            "2025-12-23 03:46:37.943653: val_loss -0.987\n",
            "2025-12-23 03:46:37.943754: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 03:46:37.943862: Epoch time: 22.49 s\n",
            "2025-12-23 03:46:37.943937: Yayy! New best EMA pseudo Dice: 0.9896000027656555\n",
            "2025-12-23 03:46:39.743000: \n",
            "2025-12-23 03:46:39.743297: Epoch 906\n",
            "2025-12-23 03:46:39.743432: Current learning rate: 0.00119\n",
            "2025-12-23 03:47:02.238898: train_loss -0.9772\n",
            "2025-12-23 03:47:02.239247: val_loss -0.986\n",
            "2025-12-23 03:47:02.239371: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:47:02.239517: Epoch time: 22.5 s\n",
            "2025-12-23 03:47:02.239601: Yayy! New best EMA pseudo Dice: 0.9896000027656555\n",
            "2025-12-23 03:47:04.065554: \n",
            "2025-12-23 03:47:04.065909: Epoch 907\n",
            "2025-12-23 03:47:04.066045: Current learning rate: 0.00118\n",
            "2025-12-23 03:47:26.487413: train_loss -0.9773\n",
            "2025-12-23 03:47:26.487619: val_loss -0.9865\n",
            "2025-12-23 03:47:26.487716: Pseudo dice [np.float32(0.9891)]\n",
            "2025-12-23 03:47:26.487808: Epoch time: 22.42 s\n",
            "2025-12-23 03:47:27.825043: \n",
            "2025-12-23 03:47:27.825394: Epoch 908\n",
            "2025-12-23 03:47:27.825568: Current learning rate: 0.00117\n",
            "2025-12-23 03:47:50.288313: train_loss -0.9776\n",
            "2025-12-23 03:47:50.288519: val_loss -0.9853\n",
            "2025-12-23 03:47:50.288612: Pseudo dice [np.float32(0.9886)]\n",
            "2025-12-23 03:47:50.288715: Epoch time: 22.46 s\n",
            "2025-12-23 03:47:51.619344: \n",
            "2025-12-23 03:47:51.619676: Epoch 909\n",
            "2025-12-23 03:47:51.619814: Current learning rate: 0.00116\n",
            "2025-12-23 03:48:14.072388: train_loss -0.9762\n",
            "2025-12-23 03:48:14.072620: val_loss -0.9868\n",
            "2025-12-23 03:48:14.072707: Pseudo dice [np.float32(0.9903)]\n",
            "2025-12-23 03:48:14.072795: Epoch time: 22.45 s\n",
            "2025-12-23 03:48:15.393775: \n",
            "2025-12-23 03:48:15.394132: Epoch 910\n",
            "2025-12-23 03:48:15.394275: Current learning rate: 0.00115\n",
            "2025-12-23 03:48:37.876149: train_loss -0.9764\n",
            "2025-12-23 03:48:37.876416: val_loss -0.9862\n",
            "2025-12-23 03:48:37.876516: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 03:48:37.876613: Epoch time: 22.48 s\n",
            "2025-12-23 03:48:39.180938: \n",
            "2025-12-23 03:48:39.181191: Epoch 911\n",
            "2025-12-23 03:48:39.181390: Current learning rate: 0.00113\n",
            "2025-12-23 03:49:01.656491: train_loss -0.9767\n",
            "2025-12-23 03:49:01.656752: val_loss -0.987\n",
            "2025-12-23 03:49:01.656854: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:49:01.656947: Epoch time: 22.48 s\n",
            "2025-12-23 03:49:02.985974: \n",
            "2025-12-23 03:49:02.986178: Epoch 912\n",
            "2025-12-23 03:49:02.986366: Current learning rate: 0.00112\n",
            "2025-12-23 03:49:25.435440: train_loss -0.9768\n",
            "2025-12-23 03:49:25.435735: val_loss -0.9867\n",
            "2025-12-23 03:49:25.435834: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 03:49:25.435942: Epoch time: 22.45 s\n",
            "2025-12-23 03:49:26.754043: \n",
            "2025-12-23 03:49:26.754239: Epoch 913\n",
            "2025-12-23 03:49:26.754370: Current learning rate: 0.00111\n",
            "2025-12-23 03:49:49.155557: train_loss -0.9776\n",
            "2025-12-23 03:49:49.155757: val_loss -0.987\n",
            "2025-12-23 03:49:49.155857: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 03:49:49.155948: Epoch time: 22.4 s\n",
            "2025-12-23 03:49:50.487186: \n",
            "2025-12-23 03:49:50.487525: Epoch 914\n",
            "2025-12-23 03:49:50.487664: Current learning rate: 0.0011\n",
            "2025-12-23 03:50:12.947452: train_loss -0.9766\n",
            "2025-12-23 03:50:12.947660: val_loss -0.9865\n",
            "2025-12-23 03:50:12.947747: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:50:12.947837: Epoch time: 22.46 s\n",
            "2025-12-23 03:50:14.255857: \n",
            "2025-12-23 03:50:14.256042: Epoch 915\n",
            "2025-12-23 03:50:14.256168: Current learning rate: 0.00109\n",
            "2025-12-23 03:50:36.696939: train_loss -0.9764\n",
            "2025-12-23 03:50:36.697275: val_loss -0.9871\n",
            "2025-12-23 03:50:36.697391: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:50:36.697496: Epoch time: 22.44 s\n",
            "2025-12-23 03:50:38.003167: \n",
            "2025-12-23 03:50:38.003381: Epoch 916\n",
            "2025-12-23 03:50:38.003509: Current learning rate: 0.00108\n",
            "2025-12-23 03:51:00.436620: train_loss -0.9758\n",
            "2025-12-23 03:51:00.436928: val_loss -0.9863\n",
            "2025-12-23 03:51:00.437082: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 03:51:00.437253: Epoch time: 22.43 s\n",
            "2025-12-23 03:51:01.774969: \n",
            "2025-12-23 03:51:01.775252: Epoch 917\n",
            "2025-12-23 03:51:01.775393: Current learning rate: 0.00106\n",
            "2025-12-23 03:51:24.180528: train_loss -0.9774\n",
            "2025-12-23 03:51:24.180751: val_loss -0.9847\n",
            "2025-12-23 03:51:24.180886: Pseudo dice [np.float32(0.9887)]\n",
            "2025-12-23 03:51:24.181007: Epoch time: 22.41 s\n",
            "2025-12-23 03:51:25.469100: \n",
            "2025-12-23 03:51:25.469406: Epoch 918\n",
            "2025-12-23 03:51:25.469580: Current learning rate: 0.00105\n",
            "2025-12-23 03:51:47.983822: train_loss -0.9774\n",
            "2025-12-23 03:51:47.984046: val_loss -0.9859\n",
            "2025-12-23 03:51:47.984161: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 03:51:47.984289: Epoch time: 22.52 s\n",
            "2025-12-23 03:51:49.340778: \n",
            "2025-12-23 03:51:49.341110: Epoch 919\n",
            "2025-12-23 03:51:49.341273: Current learning rate: 0.00104\n",
            "2025-12-23 03:52:11.755762: train_loss -0.9772\n",
            "2025-12-23 03:52:11.756015: val_loss -0.987\n",
            "2025-12-23 03:52:11.756327: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:52:11.756603: Epoch time: 22.42 s\n",
            "2025-12-23 03:52:13.088021: \n",
            "2025-12-23 03:52:13.088294: Epoch 920\n",
            "2025-12-23 03:52:13.088457: Current learning rate: 0.00103\n",
            "2025-12-23 03:52:35.494354: train_loss -0.9773\n",
            "2025-12-23 03:52:35.494771: val_loss -0.9859\n",
            "2025-12-23 03:52:35.494933: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:52:35.495070: Epoch time: 22.41 s\n",
            "2025-12-23 03:52:36.854928: \n",
            "2025-12-23 03:52:36.855171: Epoch 921\n",
            "2025-12-23 03:52:36.855313: Current learning rate: 0.00102\n",
            "2025-12-23 03:52:59.227514: train_loss -0.9783\n",
            "2025-12-23 03:52:59.227772: val_loss -0.9859\n",
            "2025-12-23 03:52:59.227920: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 03:52:59.228056: Epoch time: 22.37 s\n",
            "2025-12-23 03:53:00.564070: \n",
            "2025-12-23 03:53:00.564341: Epoch 922\n",
            "2025-12-23 03:53:00.564495: Current learning rate: 0.00101\n",
            "2025-12-23 03:53:22.929205: train_loss -0.9777\n",
            "2025-12-23 03:53:22.929503: val_loss -0.9865\n",
            "2025-12-23 03:53:22.929688: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 03:53:22.929805: Epoch time: 22.37 s\n",
            "2025-12-23 03:53:22.929879: Yayy! New best EMA pseudo Dice: 0.9896000027656555\n",
            "2025-12-23 03:53:25.453908: \n",
            "2025-12-23 03:53:25.454258: Epoch 923\n",
            "2025-12-23 03:53:25.454408: Current learning rate: 0.001\n",
            "2025-12-23 03:53:47.987576: train_loss -0.9769\n",
            "2025-12-23 03:53:47.987934: val_loss -0.9856\n",
            "2025-12-23 03:53:47.988156: Pseudo dice [np.float32(0.9888)]\n",
            "2025-12-23 03:53:47.988379: Epoch time: 22.53 s\n",
            "2025-12-23 03:53:49.335045: \n",
            "2025-12-23 03:53:49.335416: Epoch 924\n",
            "2025-12-23 03:53:49.335564: Current learning rate: 0.00098\n",
            "2025-12-23 03:54:11.745074: train_loss -0.9769\n",
            "2025-12-23 03:54:11.745404: val_loss -0.986\n",
            "2025-12-23 03:54:11.745568: Pseudo dice [np.float32(0.9904)]\n",
            "2025-12-23 03:54:11.745754: Epoch time: 22.41 s\n",
            "2025-12-23 03:54:11.745908: Yayy! New best EMA pseudo Dice: 0.9896000027656555\n",
            "2025-12-23 03:54:13.637914: \n",
            "2025-12-23 03:54:13.638141: Epoch 925\n",
            "2025-12-23 03:54:13.638303: Current learning rate: 0.00097\n",
            "2025-12-23 03:54:36.120918: train_loss -0.9771\n",
            "2025-12-23 03:54:36.121255: val_loss -0.9869\n",
            "2025-12-23 03:54:36.121377: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 03:54:36.121500: Epoch time: 22.48 s\n",
            "2025-12-23 03:54:37.439438: \n",
            "2025-12-23 03:54:37.439685: Epoch 926\n",
            "2025-12-23 03:54:37.439850: Current learning rate: 0.00096\n",
            "2025-12-23 03:54:59.883756: train_loss -0.9781\n",
            "2025-12-23 03:54:59.884005: val_loss -0.9858\n",
            "2025-12-23 03:54:59.884100: Pseudo dice [np.float32(0.9885)]\n",
            "2025-12-23 03:54:59.884190: Epoch time: 22.45 s\n",
            "2025-12-23 03:55:01.268242: \n",
            "2025-12-23 03:55:01.268532: Epoch 927\n",
            "2025-12-23 03:55:01.268676: Current learning rate: 0.00095\n",
            "2025-12-23 03:55:23.712909: train_loss -0.9769\n",
            "2025-12-23 03:55:23.713106: val_loss -0.986\n",
            "2025-12-23 03:55:23.713196: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:55:23.713331: Epoch time: 22.45 s\n",
            "2025-12-23 03:55:25.059495: \n",
            "2025-12-23 03:55:25.059751: Epoch 928\n",
            "2025-12-23 03:55:25.059885: Current learning rate: 0.00094\n",
            "2025-12-23 03:55:47.489060: train_loss -0.9772\n",
            "2025-12-23 03:55:47.489282: val_loss -0.9867\n",
            "2025-12-23 03:55:47.489389: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 03:55:47.489482: Epoch time: 22.43 s\n",
            "2025-12-23 03:55:48.828905: \n",
            "2025-12-23 03:55:48.829179: Epoch 929\n",
            "2025-12-23 03:55:48.829327: Current learning rate: 0.00092\n",
            "2025-12-23 03:56:11.240876: train_loss -0.9768\n",
            "2025-12-23 03:56:11.241205: val_loss -0.9879\n",
            "2025-12-23 03:56:11.241393: Pseudo dice [np.float32(0.9904)]\n",
            "2025-12-23 03:56:11.241511: Epoch time: 22.41 s\n",
            "2025-12-23 03:56:12.632680: \n",
            "2025-12-23 03:56:12.632869: Epoch 930\n",
            "2025-12-23 03:56:12.633113: Current learning rate: 0.00091\n",
            "2025-12-23 03:56:35.066042: train_loss -0.9775\n",
            "2025-12-23 03:56:35.066304: val_loss -0.9868\n",
            "2025-12-23 03:56:35.066463: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 03:56:35.066622: Epoch time: 22.43 s\n",
            "2025-12-23 03:56:35.066709: Yayy! New best EMA pseudo Dice: 0.9896000027656555\n",
            "2025-12-23 03:56:37.054302: \n",
            "2025-12-23 03:56:37.054621: Epoch 931\n",
            "2025-12-23 03:56:37.054755: Current learning rate: 0.0009\n",
            "2025-12-23 03:56:59.499118: train_loss -0.9771\n",
            "2025-12-23 03:56:59.499364: val_loss -0.987\n",
            "2025-12-23 03:56:59.499463: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 03:56:59.499562: Epoch time: 22.45 s\n",
            "2025-12-23 03:56:59.499640: Yayy! New best EMA pseudo Dice: 0.9896000027656555\n",
            "2025-12-23 03:57:01.343331: \n",
            "2025-12-23 03:57:01.343629: Epoch 932\n",
            "2025-12-23 03:57:01.343784: Current learning rate: 0.00089\n",
            "2025-12-23 03:57:23.804946: train_loss -0.9772\n",
            "2025-12-23 03:57:23.805166: val_loss -0.9856\n",
            "2025-12-23 03:57:23.805290: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 03:57:23.805391: Epoch time: 22.46 s\n",
            "2025-12-23 03:57:25.162984: \n",
            "2025-12-23 03:57:25.163379: Epoch 933\n",
            "2025-12-23 03:57:25.163516: Current learning rate: 0.00088\n",
            "2025-12-23 03:57:47.577650: train_loss -0.9774\n",
            "2025-12-23 03:57:47.577948: val_loss -0.9868\n",
            "2025-12-23 03:57:47.578148: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 03:57:47.578402: Epoch time: 22.42 s\n",
            "2025-12-23 03:57:47.578554: Yayy! New best EMA pseudo Dice: 0.9897000193595886\n",
            "2025-12-23 03:57:49.463842: \n",
            "2025-12-23 03:57:49.464163: Epoch 934\n",
            "2025-12-23 03:57:49.464322: Current learning rate: 0.00087\n",
            "2025-12-23 03:58:11.910709: train_loss -0.9781\n",
            "2025-12-23 03:58:11.910910: val_loss -0.9873\n",
            "2025-12-23 03:58:11.911027: Pseudo dice [np.float32(0.9903)]\n",
            "2025-12-23 03:58:11.911414: Epoch time: 22.45 s\n",
            "2025-12-23 03:58:11.911551: Yayy! New best EMA pseudo Dice: 0.9897000193595886\n",
            "2025-12-23 03:58:13.787474: \n",
            "2025-12-23 03:58:13.787663: Epoch 935\n",
            "2025-12-23 03:58:13.787794: Current learning rate: 0.00085\n",
            "2025-12-23 03:58:36.252969: train_loss -0.9781\n",
            "2025-12-23 03:58:36.253168: val_loss -0.9862\n",
            "2025-12-23 03:58:36.253300: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 03:58:36.253402: Epoch time: 22.47 s\n",
            "2025-12-23 03:58:37.615978: \n",
            "2025-12-23 03:58:37.616294: Epoch 936\n",
            "2025-12-23 03:58:37.616462: Current learning rate: 0.00084\n",
            "2025-12-23 03:59:00.058151: train_loss -0.9775\n",
            "2025-12-23 03:59:00.058398: val_loss -0.9872\n",
            "2025-12-23 03:59:00.058496: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 03:59:00.058587: Epoch time: 22.44 s\n",
            "2025-12-23 03:59:00.058685: Yayy! New best EMA pseudo Dice: 0.9897000193595886\n",
            "2025-12-23 03:59:01.937200: \n",
            "2025-12-23 03:59:01.937396: Epoch 937\n",
            "2025-12-23 03:59:01.937586: Current learning rate: 0.00083\n",
            "2025-12-23 03:59:24.374661: train_loss -0.9785\n",
            "2025-12-23 03:59:24.375070: val_loss -0.9879\n",
            "2025-12-23 03:59:24.375162: Pseudo dice [np.float32(0.9905)]\n",
            "2025-12-23 03:59:24.375288: Epoch time: 22.44 s\n",
            "2025-12-23 03:59:24.375380: Yayy! New best EMA pseudo Dice: 0.989799976348877\n",
            "2025-12-23 03:59:26.263168: \n",
            "2025-12-23 03:59:26.263441: Epoch 938\n",
            "2025-12-23 03:59:26.263613: Current learning rate: 0.00082\n",
            "2025-12-23 03:59:48.736020: train_loss -0.9779\n",
            "2025-12-23 03:59:48.736362: val_loss -0.9869\n",
            "2025-12-23 03:59:48.736569: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 03:59:48.736756: Epoch time: 22.47 s\n",
            "2025-12-23 03:59:48.736871: Yayy! New best EMA pseudo Dice: 0.989799976348877\n",
            "2025-12-23 03:59:50.622546: \n",
            "2025-12-23 03:59:50.622819: Epoch 939\n",
            "2025-12-23 03:59:50.623004: Current learning rate: 0.00081\n",
            "2025-12-23 04:00:13.093045: train_loss -0.9771\n",
            "2025-12-23 04:00:13.093297: val_loss -0.9879\n",
            "2025-12-23 04:00:13.093426: Pseudo dice [np.float32(0.9906)]\n",
            "2025-12-23 04:00:13.093521: Epoch time: 22.47 s\n",
            "2025-12-23 04:00:13.093610: Yayy! New best EMA pseudo Dice: 0.9898999929428101\n",
            "2025-12-23 04:00:15.593767: \n",
            "2025-12-23 04:00:15.594008: Epoch 940\n",
            "2025-12-23 04:00:15.594133: Current learning rate: 0.00079\n",
            "2025-12-23 04:00:38.059157: train_loss -0.9773\n",
            "2025-12-23 04:00:38.059502: val_loss -0.9864\n",
            "2025-12-23 04:00:38.059653: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 04:00:38.059828: Epoch time: 22.47 s\n",
            "2025-12-23 04:00:39.382192: \n",
            "2025-12-23 04:00:39.382531: Epoch 941\n",
            "2025-12-23 04:00:39.382675: Current learning rate: 0.00078\n",
            "2025-12-23 04:01:01.821895: train_loss -0.9775\n",
            "2025-12-23 04:01:01.822104: val_loss -0.9868\n",
            "2025-12-23 04:01:01.822196: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 04:01:01.822307: Epoch time: 22.44 s\n",
            "2025-12-23 04:01:01.822424: Yayy! New best EMA pseudo Dice: 0.9898999929428101\n",
            "2025-12-23 04:01:03.667093: \n",
            "2025-12-23 04:01:03.667348: Epoch 942\n",
            "2025-12-23 04:01:03.667523: Current learning rate: 0.00077\n",
            "2025-12-23 04:01:26.160418: train_loss -0.9774\n",
            "2025-12-23 04:01:26.160726: val_loss -0.9871\n",
            "2025-12-23 04:01:26.160824: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 04:01:26.160917: Epoch time: 22.49 s\n",
            "2025-12-23 04:01:27.477749: \n",
            "2025-12-23 04:01:27.477982: Epoch 943\n",
            "2025-12-23 04:01:27.478137: Current learning rate: 0.00076\n",
            "2025-12-23 04:01:49.956078: train_loss -0.978\n",
            "2025-12-23 04:01:49.956449: val_loss -0.9878\n",
            "2025-12-23 04:01:49.956672: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 04:01:49.956834: Epoch time: 22.48 s\n",
            "2025-12-23 04:01:49.956964: Yayy! New best EMA pseudo Dice: 0.9898999929428101\n",
            "2025-12-23 04:01:51.835863: \n",
            "2025-12-23 04:01:51.836282: Epoch 944\n",
            "2025-12-23 04:01:51.836428: Current learning rate: 0.00075\n",
            "2025-12-23 04:02:14.339680: train_loss -0.9765\n",
            "2025-12-23 04:02:14.340016: val_loss -0.9878\n",
            "2025-12-23 04:02:14.340241: Pseudo dice [np.float32(0.9903)]\n",
            "2025-12-23 04:02:14.340411: Epoch time: 22.51 s\n",
            "2025-12-23 04:02:14.340554: Yayy! New best EMA pseudo Dice: 0.9900000095367432\n",
            "2025-12-23 04:02:16.186213: \n",
            "2025-12-23 04:02:16.186525: Epoch 945\n",
            "2025-12-23 04:02:16.186660: Current learning rate: 0.00074\n",
            "2025-12-23 04:02:38.628359: train_loss -0.9772\n",
            "2025-12-23 04:02:38.628616: val_loss -0.9859\n",
            "2025-12-23 04:02:38.628708: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 04:02:38.628872: Epoch time: 22.44 s\n",
            "2025-12-23 04:02:39.952824: \n",
            "2025-12-23 04:02:39.953132: Epoch 946\n",
            "2025-12-23 04:02:39.953280: Current learning rate: 0.00072\n",
            "2025-12-23 04:03:02.410148: train_loss -0.9776\n",
            "2025-12-23 04:03:02.410540: val_loss -0.9871\n",
            "2025-12-23 04:03:02.410684: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 04:03:02.410816: Epoch time: 22.46 s\n",
            "2025-12-23 04:03:03.768537: \n",
            "2025-12-23 04:03:03.768735: Epoch 947\n",
            "2025-12-23 04:03:03.768861: Current learning rate: 0.00071\n",
            "2025-12-23 04:03:26.225221: train_loss -0.978\n",
            "2025-12-23 04:03:26.225454: val_loss -0.9871\n",
            "2025-12-23 04:03:26.225603: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 04:03:26.225704: Epoch time: 22.46 s\n",
            "2025-12-23 04:03:27.578540: \n",
            "2025-12-23 04:03:27.578844: Epoch 948\n",
            "2025-12-23 04:03:27.578978: Current learning rate: 0.0007\n",
            "2025-12-23 04:03:50.033211: train_loss -0.9779\n",
            "2025-12-23 04:03:50.033586: val_loss -0.9876\n",
            "2025-12-23 04:03:50.033761: Pseudo dice [np.float32(0.9903)]\n",
            "2025-12-23 04:03:50.033891: Epoch time: 22.46 s\n",
            "2025-12-23 04:03:50.034002: Yayy! New best EMA pseudo Dice: 0.9900000095367432\n",
            "2025-12-23 04:03:51.917131: \n",
            "2025-12-23 04:03:51.917457: Epoch 949\n",
            "2025-12-23 04:03:51.917593: Current learning rate: 0.00069\n",
            "2025-12-23 04:04:14.375855: train_loss -0.9782\n",
            "2025-12-23 04:04:14.376061: val_loss -0.9871\n",
            "2025-12-23 04:04:14.376147: Pseudo dice [np.float32(0.9903)]\n",
            "2025-12-23 04:04:14.376263: Epoch time: 22.46 s\n",
            "2025-12-23 04:04:14.918650: Yayy! New best EMA pseudo Dice: 0.9900000095367432\n",
            "2025-12-23 04:04:16.767728: \n",
            "2025-12-23 04:04:16.768032: Epoch 950\n",
            "2025-12-23 04:04:16.768162: Current learning rate: 0.00067\n",
            "2025-12-23 04:04:39.248709: train_loss -0.9781\n",
            "2025-12-23 04:04:39.248996: val_loss -0.9879\n",
            "2025-12-23 04:04:39.249132: Pseudo dice [np.float32(0.9905)]\n",
            "2025-12-23 04:04:39.249298: Epoch time: 22.48 s\n",
            "2025-12-23 04:04:39.249391: Yayy! New best EMA pseudo Dice: 0.9901000261306763\n",
            "2025-12-23 04:04:41.134164: \n",
            "2025-12-23 04:04:41.134439: Epoch 951\n",
            "2025-12-23 04:04:41.134581: Current learning rate: 0.00066\n",
            "2025-12-23 04:05:03.644102: train_loss -0.978\n",
            "2025-12-23 04:05:03.644509: val_loss -0.9864\n",
            "2025-12-23 04:05:03.644652: Pseudo dice [np.float32(0.9889)]\n",
            "2025-12-23 04:05:03.644771: Epoch time: 22.51 s\n",
            "2025-12-23 04:05:04.995051: \n",
            "2025-12-23 04:05:04.995285: Epoch 952\n",
            "2025-12-23 04:05:04.995426: Current learning rate: 0.00065\n",
            "2025-12-23 04:05:27.416810: train_loss -0.9776\n",
            "2025-12-23 04:05:27.417054: val_loss -0.9871\n",
            "2025-12-23 04:05:27.417173: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 04:05:27.417324: Epoch time: 22.42 s\n",
            "2025-12-23 04:05:28.802743: \n",
            "2025-12-23 04:05:28.802980: Epoch 953\n",
            "2025-12-23 04:05:28.803113: Current learning rate: 0.00064\n",
            "2025-12-23 04:05:51.212672: train_loss -0.9774\n",
            "2025-12-23 04:05:51.212926: val_loss -0.9872\n",
            "2025-12-23 04:05:51.213040: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 04:05:51.213150: Epoch time: 22.41 s\n",
            "2025-12-23 04:05:52.625954: \n",
            "2025-12-23 04:05:52.626136: Epoch 954\n",
            "2025-12-23 04:05:52.626326: Current learning rate: 0.00063\n",
            "2025-12-23 04:06:15.038008: train_loss -0.9772\n",
            "2025-12-23 04:06:15.038414: val_loss -0.9858\n",
            "2025-12-23 04:06:15.038666: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 04:06:15.038853: Epoch time: 22.41 s\n",
            "2025-12-23 04:06:16.406762: \n",
            "2025-12-23 04:06:16.406935: Epoch 955\n",
            "2025-12-23 04:06:16.407060: Current learning rate: 0.00061\n",
            "2025-12-23 04:06:38.823695: train_loss -0.9766\n",
            "2025-12-23 04:06:38.824003: val_loss -0.9864\n",
            "2025-12-23 04:06:38.824237: Pseudo dice [np.float32(0.9894)]\n",
            "2025-12-23 04:06:38.824571: Epoch time: 22.42 s\n",
            "2025-12-23 04:06:40.168160: \n",
            "2025-12-23 04:06:40.168417: Epoch 956\n",
            "2025-12-23 04:06:40.168570: Current learning rate: 0.0006\n",
            "2025-12-23 04:07:02.615892: train_loss -0.9774\n",
            "2025-12-23 04:07:02.616346: val_loss -0.9874\n",
            "2025-12-23 04:07:02.616495: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 04:07:02.616586: Epoch time: 22.45 s\n",
            "2025-12-23 04:07:03.998037: \n",
            "2025-12-23 04:07:03.998281: Epoch 957\n",
            "2025-12-23 04:07:03.998501: Current learning rate: 0.00059\n",
            "2025-12-23 04:07:27.176647: train_loss -0.9772\n",
            "2025-12-23 04:07:27.176942: val_loss -0.9873\n",
            "2025-12-23 04:07:27.177036: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 04:07:27.177134: Epoch time: 23.18 s\n",
            "2025-12-23 04:07:28.529084: \n",
            "2025-12-23 04:07:28.529345: Epoch 958\n",
            "2025-12-23 04:07:28.529544: Current learning rate: 0.00058\n",
            "2025-12-23 04:07:51.039648: train_loss -0.9776\n",
            "2025-12-23 04:07:51.039867: val_loss -0.9868\n",
            "2025-12-23 04:07:51.039978: Pseudo dice [np.float32(0.9906)]\n",
            "2025-12-23 04:07:51.040096: Epoch time: 22.51 s\n",
            "2025-12-23 04:07:52.356472: \n",
            "2025-12-23 04:07:52.356717: Epoch 959\n",
            "2025-12-23 04:07:52.356848: Current learning rate: 0.00056\n",
            "2025-12-23 04:08:14.812300: train_loss -0.9783\n",
            "2025-12-23 04:08:14.812570: val_loss -0.9869\n",
            "2025-12-23 04:08:14.812670: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 04:08:14.812769: Epoch time: 22.46 s\n",
            "2025-12-23 04:08:16.144321: \n",
            "2025-12-23 04:08:16.144668: Epoch 960\n",
            "2025-12-23 04:08:16.144830: Current learning rate: 0.00055\n",
            "2025-12-23 04:08:38.602620: train_loss -0.9779\n",
            "2025-12-23 04:08:38.602879: val_loss -0.9875\n",
            "2025-12-23 04:08:38.603043: Pseudo dice [np.float32(0.9904)]\n",
            "2025-12-23 04:08:38.603150: Epoch time: 22.46 s\n",
            "2025-12-23 04:08:39.946125: \n",
            "2025-12-23 04:08:39.946545: Epoch 961\n",
            "2025-12-23 04:08:39.946685: Current learning rate: 0.00054\n",
            "2025-12-23 04:09:02.451330: train_loss -0.9775\n",
            "2025-12-23 04:09:02.451547: val_loss -0.9863\n",
            "2025-12-23 04:09:02.451677: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 04:09:02.451789: Epoch time: 22.51 s\n",
            "2025-12-23 04:09:03.839269: \n",
            "2025-12-23 04:09:03.839558: Epoch 962\n",
            "2025-12-23 04:09:03.839698: Current learning rate: 0.00053\n",
            "2025-12-23 04:09:26.308053: train_loss -0.9778\n",
            "2025-12-23 04:09:26.308338: val_loss -0.9879\n",
            "2025-12-23 04:09:26.308489: Pseudo dice [np.float32(0.991)]\n",
            "2025-12-23 04:09:26.308656: Epoch time: 22.47 s\n",
            "2025-12-23 04:09:26.308830: Yayy! New best EMA pseudo Dice: 0.9901000261306763\n",
            "2025-12-23 04:09:28.275677: \n",
            "2025-12-23 04:09:28.275880: Epoch 963\n",
            "2025-12-23 04:09:28.276031: Current learning rate: 0.00051\n",
            "2025-12-23 04:09:50.746059: train_loss -0.9778\n",
            "2025-12-23 04:09:50.746308: val_loss -0.9874\n",
            "2025-12-23 04:09:50.746428: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 04:09:50.746558: Epoch time: 22.47 s\n",
            "2025-12-23 04:09:52.098727: \n",
            "2025-12-23 04:09:52.099056: Epoch 964\n",
            "2025-12-23 04:09:52.099191: Current learning rate: 0.0005\n",
            "2025-12-23 04:10:14.531443: train_loss -0.9775\n",
            "2025-12-23 04:10:14.531658: val_loss -0.9872\n",
            "2025-12-23 04:10:14.531749: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 04:10:14.531839: Epoch time: 22.43 s\n",
            "2025-12-23 04:10:15.856349: \n",
            "2025-12-23 04:10:15.856688: Epoch 965\n",
            "2025-12-23 04:10:15.856845: Current learning rate: 0.00049\n",
            "2025-12-23 04:10:38.283780: train_loss -0.9781\n",
            "2025-12-23 04:10:38.284118: val_loss -0.9863\n",
            "2025-12-23 04:10:38.284231: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 04:10:38.284368: Epoch time: 22.43 s\n",
            "2025-12-23 04:10:39.641208: \n",
            "2025-12-23 04:10:39.641502: Epoch 966\n",
            "2025-12-23 04:10:39.641645: Current learning rate: 0.00048\n",
            "2025-12-23 04:11:02.059392: train_loss -0.9768\n",
            "2025-12-23 04:11:02.059622: val_loss -0.9863\n",
            "2025-12-23 04:11:02.059716: Pseudo dice [np.float32(0.9892)]\n",
            "2025-12-23 04:11:02.059816: Epoch time: 22.42 s\n",
            "2025-12-23 04:11:03.418969: \n",
            "2025-12-23 04:11:03.419255: Epoch 967\n",
            "2025-12-23 04:11:03.419410: Current learning rate: 0.00046\n",
            "2025-12-23 04:11:25.857456: train_loss -0.9774\n",
            "2025-12-23 04:11:25.857735: val_loss -0.9859\n",
            "2025-12-23 04:11:25.857891: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 04:11:25.857988: Epoch time: 22.44 s\n",
            "2025-12-23 04:11:27.194338: \n",
            "2025-12-23 04:11:27.194644: Epoch 968\n",
            "2025-12-23 04:11:27.194788: Current learning rate: 0.00045\n",
            "2025-12-23 04:11:49.653898: train_loss -0.9777\n",
            "2025-12-23 04:11:49.654141: val_loss -0.9877\n",
            "2025-12-23 04:11:49.654247: Pseudo dice [np.float32(0.9905)]\n",
            "2025-12-23 04:11:49.654342: Epoch time: 22.46 s\n",
            "2025-12-23 04:11:50.992587: \n",
            "2025-12-23 04:11:50.992809: Epoch 969\n",
            "2025-12-23 04:11:50.992975: Current learning rate: 0.00044\n",
            "2025-12-23 04:12:13.417544: train_loss -0.9779\n",
            "2025-12-23 04:12:13.417806: val_loss -0.987\n",
            "2025-12-23 04:12:13.417980: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 04:12:13.418193: Epoch time: 22.43 s\n",
            "2025-12-23 04:12:14.761104: \n",
            "2025-12-23 04:12:14.761440: Epoch 970\n",
            "2025-12-23 04:12:14.761592: Current learning rate: 0.00043\n",
            "2025-12-23 04:12:37.154840: train_loss -0.9779\n",
            "2025-12-23 04:12:37.155116: val_loss -0.987\n",
            "2025-12-23 04:12:37.155292: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 04:12:37.155404: Epoch time: 22.4 s\n",
            "2025-12-23 04:12:38.499554: \n",
            "2025-12-23 04:12:38.499845: Epoch 971\n",
            "2025-12-23 04:12:38.499982: Current learning rate: 0.00041\n",
            "2025-12-23 04:13:00.952731: train_loss -0.9771\n",
            "2025-12-23 04:13:00.952943: val_loss -0.9875\n",
            "2025-12-23 04:13:00.953038: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 04:13:00.953134: Epoch time: 22.45 s\n",
            "2025-12-23 04:13:02.286339: \n",
            "2025-12-23 04:13:02.286657: Epoch 972\n",
            "2025-12-23 04:13:02.286815: Current learning rate: 0.0004\n",
            "2025-12-23 04:13:24.712806: train_loss -0.9776\n",
            "2025-12-23 04:13:24.712987: val_loss -0.9865\n",
            "2025-12-23 04:13:24.713095: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 04:13:24.713209: Epoch time: 22.43 s\n",
            "2025-12-23 04:13:26.064372: \n",
            "2025-12-23 04:13:26.064616: Epoch 973\n",
            "2025-12-23 04:13:26.064753: Current learning rate: 0.00039\n",
            "2025-12-23 04:13:48.468920: train_loss -0.9784\n",
            "2025-12-23 04:13:48.469197: val_loss -0.9872\n",
            "2025-12-23 04:13:48.469419: Pseudo dice [np.float32(0.9906)]\n",
            "2025-12-23 04:13:48.469587: Epoch time: 22.41 s\n",
            "2025-12-23 04:13:49.815523: \n",
            "2025-12-23 04:13:49.815872: Epoch 974\n",
            "2025-12-23 04:13:49.816018: Current learning rate: 0.00037\n",
            "2025-12-23 04:14:12.211477: train_loss -0.9786\n",
            "2025-12-23 04:14:12.211706: val_loss -0.9873\n",
            "2025-12-23 04:14:12.211802: Pseudo dice [np.float32(0.9903)]\n",
            "2025-12-23 04:14:12.211897: Epoch time: 22.4 s\n",
            "2025-12-23 04:14:13.536038: \n",
            "2025-12-23 04:14:13.536241: Epoch 975\n",
            "2025-12-23 04:14:13.536375: Current learning rate: 0.00036\n",
            "2025-12-23 04:14:36.008906: train_loss -0.9781\n",
            "2025-12-23 04:14:36.009277: val_loss -0.9866\n",
            "2025-12-23 04:14:36.009400: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 04:14:36.009520: Epoch time: 22.47 s\n",
            "2025-12-23 04:14:38.066811: \n",
            "2025-12-23 04:14:38.067026: Epoch 976\n",
            "2025-12-23 04:14:38.067169: Current learning rate: 0.00035\n",
            "2025-12-23 04:15:00.559428: train_loss -0.9785\n",
            "2025-12-23 04:15:00.559650: val_loss -0.9874\n",
            "2025-12-23 04:15:00.559737: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 04:15:00.559839: Epoch time: 22.49 s\n",
            "2025-12-23 04:15:01.863405: \n",
            "2025-12-23 04:15:01.863701: Epoch 977\n",
            "2025-12-23 04:15:01.863835: Current learning rate: 0.00034\n",
            "2025-12-23 04:15:24.342965: train_loss -0.9782\n",
            "2025-12-23 04:15:24.343253: val_loss -0.9873\n",
            "2025-12-23 04:15:24.343367: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 04:15:24.343462: Epoch time: 22.48 s\n",
            "2025-12-23 04:15:25.684804: \n",
            "2025-12-23 04:15:25.685136: Epoch 978\n",
            "2025-12-23 04:15:25.685291: Current learning rate: 0.00032\n",
            "2025-12-23 04:15:48.163854: train_loss -0.9778\n",
            "2025-12-23 04:15:48.164107: val_loss -0.9869\n",
            "2025-12-23 04:15:48.164196: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 04:15:48.164326: Epoch time: 22.48 s\n",
            "2025-12-23 04:15:49.466115: \n",
            "2025-12-23 04:15:49.466404: Epoch 979\n",
            "2025-12-23 04:15:49.466577: Current learning rate: 0.00031\n",
            "2025-12-23 04:16:11.942704: train_loss -0.9789\n",
            "2025-12-23 04:16:11.942933: val_loss -0.9866\n",
            "2025-12-23 04:16:11.943023: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 04:16:11.943145: Epoch time: 22.48 s\n",
            "2025-12-23 04:16:13.283639: \n",
            "2025-12-23 04:16:13.283828: Epoch 980\n",
            "2025-12-23 04:16:13.283956: Current learning rate: 0.0003\n",
            "2025-12-23 04:16:35.810985: train_loss -0.9784\n",
            "2025-12-23 04:16:35.811378: val_loss -0.9863\n",
            "2025-12-23 04:16:35.811517: Pseudo dice [np.float32(0.9893)]\n",
            "2025-12-23 04:16:35.811718: Epoch time: 22.53 s\n",
            "2025-12-23 04:16:37.171283: \n",
            "2025-12-23 04:16:37.171580: Epoch 981\n",
            "2025-12-23 04:16:37.171708: Current learning rate: 0.00028\n",
            "2025-12-23 04:16:59.669698: train_loss -0.9776\n",
            "2025-12-23 04:16:59.669899: val_loss -0.9867\n",
            "2025-12-23 04:16:59.669985: Pseudo dice [np.float32(0.9902)]\n",
            "2025-12-23 04:16:59.670072: Epoch time: 22.5 s\n",
            "2025-12-23 04:17:01.047904: \n",
            "2025-12-23 04:17:01.048114: Epoch 982\n",
            "2025-12-23 04:17:01.048270: Current learning rate: 0.00027\n",
            "2025-12-23 04:17:23.533304: train_loss -0.9781\n",
            "2025-12-23 04:17:23.533504: val_loss -0.9872\n",
            "2025-12-23 04:17:23.533603: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 04:17:23.533691: Epoch time: 22.49 s\n",
            "2025-12-23 04:17:24.859853: \n",
            "2025-12-23 04:17:24.860192: Epoch 983\n",
            "2025-12-23 04:17:24.860368: Current learning rate: 0.00026\n",
            "2025-12-23 04:17:47.307609: train_loss -0.9782\n",
            "2025-12-23 04:17:47.307859: val_loss -0.9871\n",
            "2025-12-23 04:17:47.307950: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 04:17:47.308062: Epoch time: 22.45 s\n",
            "2025-12-23 04:17:48.653699: \n",
            "2025-12-23 04:17:48.653877: Epoch 984\n",
            "2025-12-23 04:17:48.654040: Current learning rate: 0.00024\n",
            "2025-12-23 04:18:11.149267: train_loss -0.9774\n",
            "2025-12-23 04:18:11.149488: val_loss -0.987\n",
            "2025-12-23 04:18:11.149610: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 04:18:11.149710: Epoch time: 22.5 s\n",
            "2025-12-23 04:18:12.501658: \n",
            "2025-12-23 04:18:12.502016: Epoch 985\n",
            "2025-12-23 04:18:12.502166: Current learning rate: 0.00023\n",
            "2025-12-23 04:18:34.913891: train_loss -0.9781\n",
            "2025-12-23 04:18:34.914157: val_loss -0.9864\n",
            "2025-12-23 04:18:34.914317: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 04:18:34.914524: Epoch time: 22.41 s\n",
            "2025-12-23 04:18:36.287246: \n",
            "2025-12-23 04:18:36.287520: Epoch 986\n",
            "2025-12-23 04:18:36.287714: Current learning rate: 0.00021\n",
            "2025-12-23 04:18:58.716840: train_loss -0.9783\n",
            "2025-12-23 04:18:58.717056: val_loss -0.9871\n",
            "2025-12-23 04:18:58.717146: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 04:18:58.717257: Epoch time: 22.43 s\n",
            "2025-12-23 04:19:00.104540: \n",
            "2025-12-23 04:19:00.104810: Epoch 987\n",
            "2025-12-23 04:19:00.104949: Current learning rate: 0.0002\n",
            "2025-12-23 04:19:22.596869: train_loss -0.9777\n",
            "2025-12-23 04:19:22.597084: val_loss -0.9876\n",
            "2025-12-23 04:19:22.597170: Pseudo dice [np.float32(0.9899)]\n",
            "2025-12-23 04:19:22.597289: Epoch time: 22.49 s\n",
            "2025-12-23 04:19:23.941353: \n",
            "2025-12-23 04:19:23.941663: Epoch 988\n",
            "2025-12-23 04:19:23.941850: Current learning rate: 0.00019\n",
            "2025-12-23 04:19:46.413707: train_loss -0.9779\n",
            "2025-12-23 04:19:46.413999: val_loss -0.9874\n",
            "2025-12-23 04:19:46.414158: Pseudo dice [np.float32(0.9901)]\n",
            "2025-12-23 04:19:46.414329: Epoch time: 22.47 s\n",
            "2025-12-23 04:19:47.779349: \n",
            "2025-12-23 04:19:47.779684: Epoch 989\n",
            "2025-12-23 04:19:47.779817: Current learning rate: 0.00017\n",
            "2025-12-23 04:20:10.187947: train_loss -0.978\n",
            "2025-12-23 04:20:10.188195: val_loss -0.988\n",
            "2025-12-23 04:20:10.188421: Pseudo dice [np.float32(0.9904)]\n",
            "2025-12-23 04:20:10.188534: Epoch time: 22.41 s\n",
            "2025-12-23 04:20:11.560416: \n",
            "2025-12-23 04:20:11.560720: Epoch 990\n",
            "2025-12-23 04:20:11.560877: Current learning rate: 0.00016\n",
            "2025-12-23 04:20:33.992529: train_loss -0.9776\n",
            "2025-12-23 04:20:33.992788: val_loss -0.987\n",
            "2025-12-23 04:20:33.992905: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 04:20:33.993020: Epoch time: 22.43 s\n",
            "2025-12-23 04:20:35.328890: \n",
            "2025-12-23 04:20:35.329205: Epoch 991\n",
            "2025-12-23 04:20:35.329415: Current learning rate: 0.00014\n",
            "2025-12-23 04:20:57.812837: train_loss -0.9787\n",
            "2025-12-23 04:20:57.813101: val_loss -0.986\n",
            "2025-12-23 04:20:57.813195: Pseudo dice [np.float32(0.9895)]\n",
            "2025-12-23 04:20:57.813337: Epoch time: 22.49 s\n",
            "2025-12-23 04:20:59.168171: \n",
            "2025-12-23 04:20:59.168383: Epoch 992\n",
            "2025-12-23 04:20:59.168574: Current learning rate: 0.00013\n",
            "2025-12-23 04:21:21.650471: train_loss -0.978\n",
            "2025-12-23 04:21:21.650807: val_loss -0.9878\n",
            "2025-12-23 04:21:21.650954: Pseudo dice [np.float32(0.9907)]\n",
            "2025-12-23 04:21:21.651083: Epoch time: 22.48 s\n",
            "2025-12-23 04:21:23.003503: \n",
            "2025-12-23 04:21:23.003809: Epoch 993\n",
            "2025-12-23 04:21:23.003939: Current learning rate: 0.00011\n",
            "2025-12-23 04:21:45.440833: train_loss -0.9778\n",
            "2025-12-23 04:21:45.441032: val_loss -0.9869\n",
            "2025-12-23 04:21:45.441118: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 04:21:45.441208: Epoch time: 22.44 s\n",
            "2025-12-23 04:21:47.464292: \n",
            "2025-12-23 04:21:47.464673: Epoch 994\n",
            "2025-12-23 04:21:47.464823: Current learning rate: 0.0001\n",
            "2025-12-23 04:22:09.938090: train_loss -0.9788\n",
            "2025-12-23 04:22:09.938374: val_loss -0.9868\n",
            "2025-12-23 04:22:09.938592: Pseudo dice [np.float32(0.9901)]\n",
            "2025-12-23 04:22:09.938704: Epoch time: 22.48 s\n",
            "2025-12-23 04:22:11.276600: \n",
            "2025-12-23 04:22:11.276951: Epoch 995\n",
            "2025-12-23 04:22:11.277090: Current learning rate: 8e-05\n",
            "2025-12-23 04:22:33.789846: train_loss -0.9786\n",
            "2025-12-23 04:22:33.790100: val_loss -0.9865\n",
            "2025-12-23 04:22:33.790190: Pseudo dice [np.float32(0.9897)]\n",
            "2025-12-23 04:22:33.790331: Epoch time: 22.51 s\n",
            "2025-12-23 04:22:35.112874: \n",
            "2025-12-23 04:22:35.113086: Epoch 996\n",
            "2025-12-23 04:22:35.113229: Current learning rate: 7e-05\n",
            "2025-12-23 04:22:57.584316: train_loss -0.979\n",
            "2025-12-23 04:22:57.584578: val_loss -0.9866\n",
            "2025-12-23 04:22:57.584693: Pseudo dice [np.float32(0.9898)]\n",
            "2025-12-23 04:22:57.584899: Epoch time: 22.47 s\n",
            "2025-12-23 04:22:58.901665: \n",
            "2025-12-23 04:22:58.901969: Epoch 997\n",
            "2025-12-23 04:22:58.902104: Current learning rate: 5e-05\n",
            "2025-12-23 04:23:21.355298: train_loss -0.9787\n",
            "2025-12-23 04:23:21.355540: val_loss -0.9867\n",
            "2025-12-23 04:23:21.355670: Pseudo dice [np.float32(0.99)]\n",
            "2025-12-23 04:23:21.355766: Epoch time: 22.45 s\n",
            "2025-12-23 04:23:22.707287: \n",
            "2025-12-23 04:23:22.707515: Epoch 998\n",
            "2025-12-23 04:23:22.707733: Current learning rate: 4e-05\n",
            "2025-12-23 04:23:45.175051: train_loss -0.979\n",
            "2025-12-23 04:23:45.175286: val_loss -0.988\n",
            "2025-12-23 04:23:45.175398: Pseudo dice [np.float32(0.9903)]\n",
            "2025-12-23 04:23:45.175492: Epoch time: 22.47 s\n",
            "2025-12-23 04:23:46.509745: \n",
            "2025-12-23 04:23:46.509949: Epoch 999\n",
            "2025-12-23 04:23:46.510077: Current learning rate: 2e-05\n",
            "2025-12-23 04:24:09.031311: train_loss -0.9791\n",
            "2025-12-23 04:24:09.031530: val_loss -0.9865\n",
            "2025-12-23 04:24:09.031621: Pseudo dice [np.float32(0.9896)]\n",
            "2025-12-23 04:24:09.031716: Epoch time: 22.52 s\n",
            "2025-12-23 04:24:10.790586: Training done.\n",
            "2025-12-23 04:24:10.845422: Using splits from existing split file: /content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/splits_final.json\n",
            "2025-12-23 04:24:10.846611: The split file contains 5 splits.\n",
            "2025-12-23 04:24:10.846740: Desired fold for training: 0\n",
            "2025-12-23 04:24:10.846828: This split has 670 training and 168 validation cases.\n",
            "2025-12-23 04:24:10.852844: predicting case_0000\n",
            "2025-12-23 04:24:10.858293: case_0000, shape torch.Size([1, 1, 472, 398]), rank 0\n",
            "2025-12-23 04:24:38.001486: predicting case_0003\n",
            "2025-12-23 04:24:38.004021: case_0003, shape torch.Size([1, 1, 512, 432]), rank 0\n",
            "2025-12-23 04:24:38.035100: predicting case_0004\n",
            "2025-12-23 04:24:38.036722: case_0004, shape torch.Size([1, 1, 512, 432]), rank 0\n",
            "2025-12-23 04:24:38.066006: predicting case_0006\n",
            "2025-12-23 04:24:38.067906: case_0006, shape torch.Size([1, 1, 511, 400]), rank 0\n",
            "2025-12-23 04:24:38.097249: predicting case_0010\n",
            "2025-12-23 04:24:38.099161: case_0010, shape torch.Size([1, 1, 512, 432]), rank 0\n",
            "2025-12-23 04:24:38.126355: predicting case_0011\n",
            "2025-12-23 04:24:38.128359: case_0011, shape torch.Size([1, 1, 512, 432]), rank 0\n",
            "2025-12-23 04:24:38.154796: predicting case_0027\n",
            "2025-12-23 04:24:38.156865: case_0027, shape torch.Size([1, 1, 512, 432]), rank 0\n",
            "2025-12-23 04:24:38.185480: predicting case_0030\n",
            "2025-12-23 04:24:38.187508: case_0030, shape torch.Size([1, 1, 512, 432]), rank 0\n",
            "2025-12-23 04:24:38.213789: predicting case_0033\n",
            "2025-12-23 04:24:38.215519: case_0033, shape torch.Size([1, 1, 511, 432]), rank 0\n",
            "2025-12-23 04:24:38.244116: predicting case_0035\n",
            "2025-12-23 04:24:38.246094: case_0035, shape torch.Size([1, 1, 511, 431]), rank 0\n",
            "2025-12-23 04:24:38.272252: predicting case_0053\n",
            "2025-12-23 04:24:38.274323: case_0053, shape torch.Size([1, 1, 512, 432]), rank 0\n",
            "2025-12-23 04:24:38.300027: predicting case_0054\n",
            "2025-12-23 04:24:38.301764: case_0054, shape torch.Size([1, 1, 511, 432]), rank 0\n",
            "2025-12-23 04:24:38.327493: predicting case_0055\n",
            "2025-12-23 04:24:38.329031: case_0055, shape torch.Size([1, 1, 512, 432]), rank 0\n",
            "2025-12-23 04:24:38.355068: predicting case_0067\n",
            "2025-12-23 04:24:38.356618: case_0067, shape torch.Size([1, 1, 512, 432]), rank 0\n",
            "2025-12-23 04:24:38.388992: predicting case_0068\n",
            "2025-12-23 04:24:38.390672: case_0068, shape torch.Size([1, 1, 511, 432]), rank 0\n",
            "2025-12-23 04:24:38.416837: predicting case_0073\n",
            "2025-12-23 04:24:38.418355: case_0073, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:38.444176: predicting case_0075\n",
            "2025-12-23 04:24:38.445606: case_0075, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:38.470928: predicting case_0082\n",
            "2025-12-23 04:24:38.472712: case_0082, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.498566: predicting case_0087\n",
            "2025-12-23 04:24:38.500190: case_0087, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.526352: predicting case_0099\n",
            "2025-12-23 04:24:38.527975: case_0099, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.554761: predicting case_0106\n",
            "2025-12-23 04:24:38.556413: case_0106, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.583343: predicting case_0109\n",
            "2025-12-23 04:24:38.584997: case_0109, shape torch.Size([1, 1, 511, 408]), rank 0\n",
            "2025-12-23 04:24:38.617421: predicting case_0111\n",
            "2025-12-23 04:24:38.619134: case_0111, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.644879: predicting case_0115\n",
            "2025-12-23 04:24:38.646754: case_0115, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.672446: predicting case_0117\n",
            "2025-12-23 04:24:38.674632: case_0117, shape torch.Size([1, 1, 512, 407]), rank 0\n",
            "2025-12-23 04:24:38.703066: predicting case_0119\n",
            "2025-12-23 04:24:38.705207: case_0119, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.731171: predicting case_0123\n",
            "2025-12-23 04:24:38.733328: case_0123, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.760920: predicting case_0127\n",
            "2025-12-23 04:24:38.762826: case_0127, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.789437: predicting case_0130\n",
            "2025-12-23 04:24:38.791437: case_0130, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.819098: predicting case_0133\n",
            "2025-12-23 04:24:38.821362: case_0133, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.847897: predicting case_0135\n",
            "2025-12-23 04:24:38.849742: case_0135, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.875544: predicting case_0136\n",
            "2025-12-23 04:24:38.877573: case_0136, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.903896: predicting case_0138\n",
            "2025-12-23 04:24:38.905969: case_0138, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.931944: predicting case_0144\n",
            "2025-12-23 04:24:38.934038: case_0144, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.959737: predicting case_0149\n",
            "2025-12-23 04:24:38.961734: case_0149, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:38.988286: predicting case_0150\n",
            "2025-12-23 04:24:38.990155: case_0150, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:39.016608: predicting case_0158\n",
            "2025-12-23 04:24:39.018858: case_0158, shape torch.Size([1, 1, 512, 407]), rank 0\n",
            "2025-12-23 04:24:39.045970: predicting case_0164\n",
            "2025-12-23 04:24:39.047924: case_0164, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:39.074758: predicting case_0168\n",
            "2025-12-23 04:24:39.076930: case_0168, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:39.103390: predicting case_0173\n",
            "2025-12-23 04:24:39.105277: case_0173, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:39.131393: predicting case_0184\n",
            "2025-12-23 04:24:39.133479: case_0184, shape torch.Size([1, 1, 511, 408]), rank 0\n",
            "2025-12-23 04:24:39.158973: predicting case_0186\n",
            "2025-12-23 04:24:39.160984: case_0186, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:39.186676: predicting case_0187\n",
            "2025-12-23 04:24:39.188663: case_0187, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:39.219653: predicting case_0188\n",
            "2025-12-23 04:24:39.221839: case_0188, shape torch.Size([1, 1, 479, 416]), rank 0\n",
            "2025-12-23 04:24:39.250480: predicting case_0190\n",
            "2025-12-23 04:24:39.252391: case_0190, shape torch.Size([1, 1, 479, 412]), rank 0\n",
            "2025-12-23 04:24:39.278805: predicting case_0192\n",
            "2025-12-23 04:24:39.280920: case_0192, shape torch.Size([1, 1, 472, 392]), rank 0\n",
            "2025-12-23 04:24:39.306404: predicting case_0195\n",
            "2025-12-23 04:24:39.308208: case_0195, shape torch.Size([1, 1, 431, 376]), rank 0\n",
            "2025-12-23 04:24:39.333382: predicting case_0196\n",
            "2025-12-23 04:24:39.335137: case_0196, shape torch.Size([1, 1, 431, 376]), rank 0\n",
            "2025-12-23 04:24:39.360085: predicting case_0198\n",
            "2025-12-23 04:24:39.361971: case_0198, shape torch.Size([1, 1, 479, 408]), rank 0\n",
            "2025-12-23 04:24:39.386887: predicting case_0199\n",
            "2025-12-23 04:24:39.388852: case_0199, shape torch.Size([1, 1, 495, 440]), rank 0\n",
            "2025-12-23 04:24:39.414181: predicting case_0203\n",
            "2025-12-23 04:24:39.416130: case_0203, shape torch.Size([1, 1, 493, 440]), rank 0\n",
            "2025-12-23 04:24:39.442364: predicting case_0215\n",
            "2025-12-23 04:24:39.444117: case_0215, shape torch.Size([1, 1, 496, 440]), rank 0\n",
            "2025-12-23 04:24:39.469740: predicting case_0216\n",
            "2025-12-23 04:24:39.471546: case_0216, shape torch.Size([1, 1, 495, 440]), rank 0\n",
            "2025-12-23 04:24:39.498188: predicting case_0220\n",
            "2025-12-23 04:24:39.499933: case_0220, shape torch.Size([1, 1, 469, 392]), rank 0\n",
            "2025-12-23 04:24:39.525392: predicting case_0222\n",
            "2025-12-23 04:24:39.527087: case_0222, shape torch.Size([1, 1, 472, 400]), rank 0\n",
            "2025-12-23 04:24:39.552025: predicting case_0238\n",
            "2025-12-23 04:24:39.554155: case_0238, shape torch.Size([1, 1, 472, 392]), rank 0\n",
            "2025-12-23 04:24:39.579035: predicting case_0241\n",
            "2025-12-23 04:24:39.581144: case_0241, shape torch.Size([1, 1, 472, 392]), rank 0\n",
            "2025-12-23 04:24:39.606483: predicting case_0244\n",
            "2025-12-23 04:24:39.608064: case_0244, shape torch.Size([1, 1, 504, 408]), rank 0\n",
            "2025-12-23 04:24:39.633250: predicting case_0254\n",
            "2025-12-23 04:24:39.635094: case_0254, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:39.660393: predicting case_0257\n",
            "2025-12-23 04:24:39.662378: case_0257, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:39.688287: predicting case_0262\n",
            "2025-12-23 04:24:39.690051: case_0262, shape torch.Size([1, 1, 511, 407]), rank 0\n",
            "2025-12-23 04:24:39.716799: predicting case_0266\n",
            "2025-12-23 04:24:39.718857: case_0266, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:39.745181: predicting case_0270\n",
            "2025-12-23 04:24:39.747019: case_0270, shape torch.Size([1, 1, 504, 408]), rank 0\n",
            "2025-12-23 04:24:39.772034: predicting case_0280\n",
            "2025-12-23 04:24:39.773602: case_0280, shape torch.Size([1, 1, 512, 456]), rank 0\n",
            "2025-12-23 04:24:39.819375: predicting case_0281\n",
            "2025-12-23 04:24:39.820982: case_0281, shape torch.Size([1, 1, 512, 456]), rank 0\n",
            "2025-12-23 04:24:39.862046: predicting case_0284\n",
            "2025-12-23 04:24:39.863757: case_0284, shape torch.Size([1, 1, 512, 456]), rank 0\n",
            "2025-12-23 04:24:39.905312: predicting case_0296\n",
            "2025-12-23 04:24:39.907033: case_0296, shape torch.Size([1, 1, 494, 431]), rank 0\n",
            "2025-12-23 04:24:39.934053: predicting case_0298\n",
            "2025-12-23 04:24:39.935754: case_0298, shape torch.Size([1, 1, 496, 430]), rank 0\n",
            "2025-12-23 04:24:39.961182: predicting case_0300\n",
            "2025-12-23 04:24:39.962770: case_0300, shape torch.Size([1, 1, 495, 437]), rank 0\n",
            "2025-12-23 04:24:39.988385: predicting case_0305\n",
            "2025-12-23 04:24:39.989973: case_0305, shape torch.Size([1, 1, 494, 428]), rank 0\n",
            "2025-12-23 04:24:40.015143: predicting case_0311\n",
            "2025-12-23 04:24:40.016736: case_0311, shape torch.Size([1, 1, 496, 422]), rank 0\n",
            "2025-12-23 04:24:40.042670: predicting case_0314\n",
            "2025-12-23 04:24:40.044185: case_0314, shape torch.Size([1, 1, 495, 424]), rank 0\n",
            "2025-12-23 04:24:40.074872: predicting case_0322\n",
            "2025-12-23 04:24:40.076614: case_0322, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:40.102431: predicting case_0323\n",
            "2025-12-23 04:24:40.104084: case_0323, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:40.129160: predicting case_0326\n",
            "2025-12-23 04:24:40.130790: case_0326, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:40.156361: predicting case_0328\n",
            "2025-12-23 04:24:40.158005: case_0328, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:40.182849: predicting case_0330\n",
            "2025-12-23 04:24:40.184691: case_0330, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:40.210511: predicting case_0331\n",
            "2025-12-23 04:24:40.212121: case_0331, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:40.237261: predicting case_0334\n",
            "2025-12-23 04:24:40.238809: case_0334, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:40.263666: predicting case_0346\n",
            "2025-12-23 04:24:40.265317: case_0346, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:40.296202: predicting case_0358\n",
            "2025-12-23 04:24:40.298137: case_0358, shape torch.Size([1, 1, 512, 415]), rank 0\n",
            "2025-12-23 04:24:40.324410: predicting case_0359\n",
            "2025-12-23 04:24:40.326310: case_0359, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:40.351891: predicting case_0361\n",
            "2025-12-23 04:24:40.353464: case_0361, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:40.380310: predicting case_0365\n",
            "2025-12-23 04:24:40.382506: case_0365, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:40.408541: predicting case_0366\n",
            "2025-12-23 04:24:40.410385: case_0366, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:40.435848: predicting case_0373\n",
            "2025-12-23 04:24:40.437580: case_0373, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:40.463097: predicting case_0375\n",
            "2025-12-23 04:24:40.464845: case_0375, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:40.490731: predicting case_0376\n",
            "2025-12-23 04:24:40.492265: case_0376, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:40.523675: predicting case_0385\n",
            "2025-12-23 04:24:40.525159: case_0385, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:40.550859: predicting case_0388\n",
            "2025-12-23 04:24:40.552384: case_0388, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:40.578279: predicting case_0395\n",
            "2025-12-23 04:24:40.579807: case_0395, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:40.605998: predicting case_0404\n",
            "2025-12-23 04:24:40.607671: case_0404, shape torch.Size([1, 1, 512, 423]), rank 0\n",
            "2025-12-23 04:24:40.634744: predicting case_0413\n",
            "2025-12-23 04:24:40.636314: case_0413, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:40.662565: predicting case_0414\n",
            "2025-12-23 04:24:40.664097: case_0414, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:40.692179: predicting case_0416\n",
            "2025-12-23 04:24:40.694055: case_0416, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:40.720664: predicting case_0424\n",
            "2025-12-23 04:24:40.722515: case_0424, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:40.754858: predicting case_0440\n",
            "2025-12-23 04:24:40.756390: case_0440, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:40.782518: predicting case_0452\n",
            "2025-12-23 04:24:40.784388: case_0452, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:40.811738: predicting case_0453\n",
            "2025-12-23 04:24:40.813590: case_0453, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:40.838968: predicting case_0454\n",
            "2025-12-23 04:24:40.840752: case_0454, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:40.866239: predicting case_0455\n",
            "2025-12-23 04:24:40.867754: case_0455, shape torch.Size([1, 1, 512, 414]), rank 0\n",
            "2025-12-23 04:24:40.894040: predicting case_0466\n",
            "2025-12-23 04:24:40.895546: case_0466, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:40.921313: predicting case_0468\n",
            "2025-12-23 04:24:40.922882: case_0468, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:40.948355: predicting case_0469\n",
            "2025-12-23 04:24:40.949889: case_0469, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:40.980504: predicting case_0470\n",
            "2025-12-23 04:24:40.981948: case_0470, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:41.006866: predicting case_0491\n",
            "2025-12-23 04:24:41.008568: case_0491, shape torch.Size([1, 1, 512, 432]), rank 0\n",
            "2025-12-23 04:24:41.034122: predicting case_0496\n",
            "2025-12-23 04:24:41.035961: case_0496, shape torch.Size([1, 1, 512, 432]), rank 0\n",
            "2025-12-23 04:24:41.062083: predicting case_0499\n",
            "2025-12-23 04:24:41.063637: case_0499, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:41.091054: predicting case_0509\n",
            "2025-12-23 04:24:41.092855: case_0509, shape torch.Size([1, 1, 512, 415]), rank 0\n",
            "2025-12-23 04:24:41.118673: predicting case_0511\n",
            "2025-12-23 04:24:41.120195: case_0511, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:41.146131: predicting case_0521\n",
            "2025-12-23 04:24:41.148004: case_0521, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:41.174277: predicting case_0523\n",
            "2025-12-23 04:24:41.175872: case_0523, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:41.206339: predicting case_0527\n",
            "2025-12-23 04:24:41.208107: case_0527, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:41.233736: predicting case_0528\n",
            "2025-12-23 04:24:41.235612: case_0528, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:41.261253: predicting case_0534\n",
            "2025-12-23 04:24:41.263104: case_0534, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:41.288804: predicting case_0543\n",
            "2025-12-23 04:24:41.290671: case_0543, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:41.315940: predicting case_0547\n",
            "2025-12-23 04:24:41.317405: case_0547, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:41.342457: predicting case_0548\n",
            "2025-12-23 04:24:41.344125: case_0548, shape torch.Size([1, 1, 512, 408]), rank 0\n",
            "2025-12-23 04:24:41.368995: predicting case_0564\n",
            "2025-12-23 04:24:41.370754: case_0564, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:41.396905: predicting case_0566\n",
            "2025-12-23 04:24:41.398827: case_0566, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:41.429037: predicting case_0570\n",
            "2025-12-23 04:24:41.430592: case_0570, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:41.455394: predicting case_0575\n",
            "2025-12-23 04:24:41.456857: case_0575, shape torch.Size([1, 1, 472, 398]), rank 0\n",
            "2025-12-23 04:24:41.481390: predicting case_0578\n",
            "2025-12-23 04:24:41.483365: case_0578, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:41.508202: predicting case_0579\n",
            "2025-12-23 04:24:41.510021: case_0579, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:41.535103: predicting case_0581\n",
            "2025-12-23 04:24:41.536875: case_0581, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:41.561412: predicting case_0582\n",
            "2025-12-23 04:24:41.563337: case_0582, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:41.590009: predicting case_0583\n",
            "2025-12-23 04:24:41.591870: case_0583, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:41.616740: predicting case_0587\n",
            "2025-12-23 04:24:41.618593: case_0587, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:41.648915: predicting case_0590\n",
            "2025-12-23 04:24:41.650703: case_0590, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:41.675459: predicting case_0595\n",
            "2025-12-23 04:24:41.676909: case_0595, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:41.702278: predicting case_0603\n",
            "2025-12-23 04:24:41.704217: case_0603, shape torch.Size([1, 1, 512, 423]), rank 0\n",
            "2025-12-23 04:24:41.729164: predicting case_0609\n",
            "2025-12-23 04:24:41.730999: case_0609, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:41.755660: predicting case_0615\n",
            "2025-12-23 04:24:41.757448: case_0615, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:41.782762: predicting case_0617\n",
            "2025-12-23 04:24:41.784592: case_0617, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:41.811048: predicting case_0618\n",
            "2025-12-23 04:24:41.812923: case_0618, shape torch.Size([1, 1, 512, 423]), rank 0\n",
            "2025-12-23 04:24:41.838210: predicting case_0619\n",
            "2025-12-23 04:24:41.840129: case_0619, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:41.871987: predicting case_0628\n",
            "2025-12-23 04:24:41.874281: case_0628, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:41.899508: predicting case_0635\n",
            "2025-12-23 04:24:41.901583: case_0635, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:41.927047: predicting case_0644\n",
            "2025-12-23 04:24:41.928992: case_0644, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:41.954853: predicting case_0646\n",
            "2025-12-23 04:24:41.956698: case_0646, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:41.981603: predicting case_0649\n",
            "2025-12-23 04:24:41.983434: case_0649, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:42.009990: predicting case_0657\n",
            "2025-12-23 04:24:42.011484: case_0657, shape torch.Size([1, 1, 480, 408]), rank 0\n",
            "2025-12-23 04:24:42.036703: predicting case_0670\n",
            "2025-12-23 04:24:42.038150: case_0670, shape torch.Size([1, 1, 512, 368]), rank 0\n",
            "2025-12-23 04:24:42.063262: predicting case_0676\n",
            "2025-12-23 04:24:42.064736: case_0676, shape torch.Size([1, 1, 512, 432]), rank 0\n",
            "2025-12-23 04:24:42.094692: predicting case_0682\n",
            "2025-12-23 04:24:42.096305: case_0682, shape torch.Size([1, 1, 512, 424]), rank 0\n",
            "2025-12-23 04:24:42.121032: predicting case_0697\n",
            "2025-12-23 04:24:42.122517: case_0697, shape torch.Size([1, 1, 504, 392]), rank 0\n",
            "2025-12-23 04:24:42.147882: predicting case_0698\n",
            "2025-12-23 04:24:42.149372: case_0698, shape torch.Size([1, 1, 504, 392]), rank 0\n",
            "2025-12-23 04:24:42.174623: predicting case_0732\n",
            "2025-12-23 04:24:42.176161: case_0732, shape torch.Size([1, 1, 479, 432]), rank 0\n",
            "2025-12-23 04:24:42.201637: predicting case_0735\n",
            "2025-12-23 04:24:42.203137: case_0735, shape torch.Size([1, 1, 479, 430]), rank 0\n",
            "2025-12-23 04:24:42.228621: predicting case_0736\n",
            "2025-12-23 04:24:42.230023: case_0736, shape torch.Size([1, 1, 480, 424]), rank 0\n",
            "2025-12-23 04:24:42.255242: predicting case_0746\n",
            "2025-12-23 04:24:42.256622: case_0746, shape torch.Size([1, 1, 512, 416]), rank 0\n",
            "2025-12-23 04:24:42.281118: predicting case_0756\n",
            "2025-12-23 04:24:42.282562: case_0756, shape torch.Size([1, 1, 472, 368]), rank 0\n",
            "2025-12-23 04:24:42.312690: predicting case_0767\n",
            "2025-12-23 04:24:42.314119: case_0767, shape torch.Size([1, 1, 469, 368]), rank 0\n",
            "2025-12-23 04:24:42.338508: predicting case_0776\n",
            "2025-12-23 04:24:42.339911: case_0776, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:42.364439: predicting case_0781\n",
            "2025-12-23 04:24:42.365855: case_0781, shape torch.Size([1, 1, 512, 400]), rank 0\n",
            "2025-12-23 04:24:42.391981: predicting case_0799\n",
            "2025-12-23 04:24:42.393569: case_0799, shape torch.Size([1, 1, 512, 392]), rank 0\n",
            "2025-12-23 04:24:42.419084: predicting case_0800\n",
            "2025-12-23 04:24:42.420730: case_0800, shape torch.Size([1, 1, 502, 383]), rank 0\n",
            "2025-12-23 04:24:42.445533: predicting case_0802\n",
            "2025-12-23 04:24:42.446928: case_0802, shape torch.Size([1, 1, 497, 384]), rank 0\n",
            "2025-12-23 04:24:42.471715: predicting case_0803\n",
            "2025-12-23 04:24:42.472963: case_0803, shape torch.Size([1, 1, 497, 384]), rank 0\n",
            "2025-12-23 04:24:42.497576: predicting case_0804\n",
            "2025-12-23 04:24:42.499100: case_0804, shape torch.Size([1, 1, 504, 384]), rank 0\n",
            "2025-12-23 04:24:42.529027: predicting case_0805\n",
            "2025-12-23 04:24:42.530354: case_0805, shape torch.Size([1, 1, 503, 384]), rank 0\n",
            "2025-12-23 04:24:42.554910: predicting case_0806\n",
            "2025-12-23 04:24:42.556340: case_0806, shape torch.Size([1, 1, 500, 384]), rank 0\n",
            "2025-12-23 04:24:42.580515: predicting case_0812\n",
            "2025-12-23 04:24:42.581924: case_0812, shape torch.Size([1, 1, 504, 367]), rank 0\n",
            "2025-12-23 04:24:42.607889: predicting case_0813\n",
            "2025-12-23 04:24:42.609301: case_0813, shape torch.Size([1, 1, 500, 368]), rank 0\n",
            "2025-12-23 04:24:42.634190: predicting case_0814\n",
            "2025-12-23 04:24:42.635457: case_0814, shape torch.Size([1, 1, 499, 368]), rank 0\n",
            "2025-12-23 04:24:42.665539: predicting case_0830\n",
            "2025-12-23 04:24:42.666978: case_0830, shape torch.Size([1, 1, 512, 440]), rank 0\n",
            "2025-12-23 04:24:42.692100: predicting case_0833\n",
            "2025-12-23 04:24:42.693465: case_0833, shape torch.Size([1, 1, 512, 440]), rank 0\n",
            "2025-12-23 04:24:42.718911: predicting case_0835\n",
            "2025-12-23 04:24:42.720361: case_0835, shape torch.Size([1, 1, 512, 440]), rank 0\n",
            "2025-12-23 04:24:49.808137: Validation complete\n",
            "2025-12-23 04:24:49.808265: Mean Validation Dice:  0.98538243198826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls $nnUNet_results/Dataset501*/nnUNetTrainerV2__nnUNetPlans__2d/fold_0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJDsPRq_A1pg",
        "outputId": "08aaeb38-2241-4897-a6df-5d726f681c32"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/nnUNet/nnUNet_results/Dataset501*/nnUNetTrainerV2__nnUNetPlans__2d/fold_0': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $nnUNet_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG6_Wf_weiDz",
        "outputId": "b60457b4-997d-4cde-fcf0-e1bb63c1e799"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnUNet/nnUNet_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls $nnUNet_results/Dataset501_KSSD2025\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygjOd3MZewfB",
        "outputId": "e3223ba7-cc12-4450-8af4-3c569b8d64f9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/nnUNet/nnUNet_results/Dataset501_KSSD2025': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lah /content/nnUNet/nnUNet_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WspT-3XmfHa5",
        "outputId": "9b2b3f6e-eac7-44dd-f5f2-6627ca2dedac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12K\n",
            "drwxr-xr-x 3 root root 4.0K Dec 22 21:42 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 5 root root 4.0K Dec 22 21:38 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4.0K Dec 22 21:42 \u001b[01;34mDataset501_KSSD\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lah /content/nnUNet/nnUNet_results/Dataset501*\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uWqeJFcfXXh",
        "outputId": "87d0d465-986e-4271-cb37-a0a519339f05"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12K\n",
            "drwxr-xr-x 3 root root 4.0K Dec 22 21:42 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4.0K Dec 22 21:42 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4.0K Dec 22 21:42 \u001b[01;34mnnUNetTrainer__nnUNetPlans__2d\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/nnUNet/nnUNet_results/Dataset501* -maxdepth 2 -type d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec9VlmnLfcYI",
        "outputId": "828b45e9-a2b8-47ff-b7eb-45621f9f73a4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnUNet/nnUNet_results/Dataset501_KSSD\n",
            "/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d\n",
            "/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah /content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGA8lByqfgtq",
        "outputId": "6f62d533-fdd9-4bf6-8c3b-d9ace020ed38"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 513M\n",
            "drwxr-xr-x 3 root root 4.0K Dec 23 04:24 .\n",
            "drwxr-xr-x 3 root root 4.0K Dec 22 21:42 ..\n",
            "-rw-r--r-- 1 root root 256M Dec 23 04:09 checkpoint_best.pth\n",
            "-rw-r--r-- 1 root root 256M Dec 23 04:24 checkpoint_final.pth\n",
            "-rw-r--r-- 1 root root 9.1K Dec 22 21:42 debug.json\n",
            "-rw-r--r-- 1 root root 422K Dec 23 04:24 progress.png\n",
            "-rw-r--r-- 1 root root 366K Dec 23 04:24 training_log_2025_12_22_21_42_26.txt\n",
            "drwxr-xr-x 2 root root 4.0K Dec 23 04:24 validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os, glob\n",
        "\n",
        "base_dir = \"/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0/\"\n",
        "log_files = glob.glob(os.path.join(base_dir, \"training_log*.json\")) + \\\n",
        "            glob.glob(os.path.join(base_dir, \"training_log*.txt\"))\n",
        "\n",
        "if not log_files:\n",
        "    print(\"Error: No training log file found in the specified directory.\")\n",
        "    best = None\n",
        "else:\n",
        "    # Sort by modification time to get the latest file, assuming newer is better\n",
        "    log_files.sort(key=os.path.getmtime, reverse=True)\n",
        "    log_path = log_files[0]\n",
        "    print(f\"Found log file: {log_path}\")\n",
        "\n",
        "    best_dice = None\n",
        "    try:\n",
        "        # Attempt to load as JSON (for future compatibility or if nnU-Net changes output format)\n",
        "        with open(log_path, \"r\") as f:\n",
        "            log = json.load(f)\n",
        "\n",
        "        # Original logic for JSON (if 'epochs' key exists)\n",
        "        if \"epochs\" in log:\n",
        "            candidates = []\n",
        "            for e in log[\"epochs\"]:\n",
        "                for path in [\n",
        "                    (\"validation\", \"Dice\"), (\"validation\", \"mean_dice\"),\n",
        "                    (\"validation\", \"foreground_dice\"), (\"val\", \"Dice\"),\n",
        "                    (\"val\", \"mean_dice\"),\n",
        "                ]:\n",
        "                    a = e\n",
        "                    ok = True\n",
        "                    for k in path:\n",
        "                        if isinstance(a, dict) and k in a:\n",
        "                            a = a[k]\n",
        "                        else:\n",
        "                            ok = False\n",
        "                            break\n",
        "                    if ok and isinstance(a, (int, float)):\n",
        "                        candidates.append(a)\n",
        "            if candidates:\n",
        "                best_dice = max(candidates)\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        # If not JSON, try parsing as text\n",
        "        print(\"Log file is not JSON, attempting to parse as plain text...\")\n",
        "        with open(log_path, \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                if \"Yayy! New best EMA pseudo Dice:\" in line:\n",
        "                    try:\n",
        "                        best_dice = float(line.split(':')[1].strip())\n",
        "                    except (ValueError, IndexError):\n",
        "                        pass # Continue if parsing fails for a specific line\n",
        "\n",
        "    best = best_dice\n",
        "\n",
        "print(\"Best validation Dice (fold 0):\", best)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPd_aFDSfz5u",
        "outputId": "0db052ce-b3a6-4569-e4d9-187b6835287b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found log file: /content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0/training_log_2025_12_22_21_42_26.txt\n",
            "Log file is not JSON, attempting to parse as plain text...\n",
            "Best validation Dice (fold 0): 9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah /content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0 | grep -i log\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kskj8doKf_KK",
        "outputId": "2ccfea5c-5e44-4a53-b245-c48bc9a0018c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 366K Dec 23 04:24 training_log_2025_12_22_21_42_26.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0 -maxdepth 2 -type f -name \"*.json\" -print\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rKrYPi0gnEi",
        "outputId": "a0c6fbac-3432-4405-c413-cf7477153d2b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0/validation/summary.json\n",
            "/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0/debug.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "p = \"/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0/validation/summary.json\"\n",
        "with open(p, \"r\") as f:\n",
        "    s = json.load(f)\n",
        "\n",
        "print(json.dumps(s, indent=2)[:4000])  # print first part nicely\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmnbP8hAgrWD",
        "outputId": "20160202-d02c-4c13-ccd9-23c38f55559b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"foreground_mean\": {\n",
            "    \"Dice\": 0.98538243198826,\n",
            "    \"FN\": 1.244047619047619,\n",
            "    \"FP\": 1.8571428571428572,\n",
            "    \"IoU\": 0.9719722515597956,\n",
            "    \"TN\": 261976.04166666666,\n",
            "    \"TP\": 164.85714285714286,\n",
            "    \"n_pred\": 166.71428571428572,\n",
            "    \"n_ref\": 166.10119047619048\n",
            "  },\n",
            "  \"mean\": {\n",
            "    \"1\": {\n",
            "      \"Dice\": 0.98538243198826,\n",
            "      \"FN\": 1.244047619047619,\n",
            "      \"FP\": 1.8571428571428572,\n",
            "      \"IoU\": 0.9719722515597956,\n",
            "      \"TN\": 261976.04166666666,\n",
            "      \"TP\": 164.85714285714286,\n",
            "      \"n_pred\": 166.71428571428572,\n",
            "      \"n_ref\": 166.10119047619048\n",
            "    }\n",
            "  },\n",
            "  \"metric_per_case\": [\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9901960784313726,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.9805825242718447,\n",
            "          \"TN\": 262041,\n",
            "          \"TP\": 101,\n",
            "          \"n_pred\": 103,\n",
            "          \"n_ref\": 101\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0/validation/case_0000.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/gt_segmentations/case_0000.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.958904109589041,\n",
            "          \"FN\": 2,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9210526315789473,\n",
            "          \"TN\": 262106,\n",
            "          \"TP\": 35,\n",
            "          \"n_pred\": 36,\n",
            "          \"n_ref\": 37\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0/validation/case_0003.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/gt_segmentations/case_0003.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262120,\n",
            "          \"TP\": 24,\n",
            "          \"n_pred\": 24,\n",
            "          \"n_ref\": 24\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0/validation/case_0004.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/gt_segmentations/case_0004.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9333333333333333,\n",
            "          \"FN\": 1,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.875,\n",
            "          \"TN\": 262136,\n",
            "          \"TP\": 7,\n",
            "          \"n_pred\": 7,\n",
            "          \"n_ref\": 8\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0/validation/case_0006.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/gt_segmentations/case_0006.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9585798816568047,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9204545454545454,\n",
            "          \"TN\": 262056,\n",
            "          \"TP\": 81,\n",
            "          \"n_pred\": 82,\n",
            "          \"n_ref\": 87\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0/validation/case_0010.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/gt_segmentations/case_0010.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9771689497716894,\n",
            "          \"FN\": 5,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.9553571428571429,\n",
            "          \"TN\": 262032,\n",
            "          \"TP\": 107,\n",
            "          \"n_pred\": 107,\n",
            "          \"n_ref\": 112\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0/validation/case_0011.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/gt_segmentations/case_0011.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9917898193760263,\n",
            "          \"FN\": 3,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.9837133550488599,\n",
            "          \"TN\": 261837,\n",
            "          \"TP\": 302,\n",
            "          \"n_pred\": 304,\n",
            "          \"n_ref\": 305\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/nnUNet/nnUNet_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "p = \"/content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_0/validation/summary.json\"\n",
        "with open(p, \"r\") as f:\n",
        "    s = json.load(f)\n",
        "\n",
        "def find_dice(obj, path=\"\"):\n",
        "    hits = []\n",
        "    if isinstance(obj, dict):\n",
        "        for k, v in obj.items():\n",
        "            newp = f\"{path}.{k}\" if path else k\n",
        "            if isinstance(v, (int, float)) and (\"dice\" in k.lower() or \"dsc\" in k.lower()):\n",
        "                hits.append((newp, v))\n",
        "            else:\n",
        "                hits += find_dice(v, newp)\n",
        "    elif isinstance(obj, list):\n",
        "        for i, v in enumerate(obj):\n",
        "            hits += find_dice(v, f\"{path}[{i}]\")\n",
        "    return hits\n",
        "\n",
        "hits = find_dice(s)\n",
        "print(\"Dice-like fields found:\")\n",
        "for k, v in hits:\n",
        "    print(k, \"=\", v)\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8U--_XQg5vh",
        "outputId": "dbd2580f-5ddf-4d6a-9867-1968a10047d0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dice-like fields found:\n",
            "foreground_mean.Dice = 0.98538243198826\n",
            "mean.1.Dice = 0.98538243198826\n",
            "metric_per_case[0].metrics.1.Dice = 0.9901960784313726\n",
            "metric_per_case[1].metrics.1.Dice = 0.958904109589041\n",
            "metric_per_case[2].metrics.1.Dice = 1.0\n",
            "metric_per_case[3].metrics.1.Dice = 0.9333333333333333\n",
            "metric_per_case[4].metrics.1.Dice = 0.9585798816568047\n",
            "metric_per_case[5].metrics.1.Dice = 0.9771689497716894\n",
            "metric_per_case[6].metrics.1.Dice = 0.9917898193760263\n",
            "metric_per_case[7].metrics.1.Dice = 0.9896907216494846\n",
            "metric_per_case[8].metrics.1.Dice = 0.9968152866242038\n",
            "metric_per_case[9].metrics.1.Dice = 0.9758620689655172\n",
            "metric_per_case[10].metrics.1.Dice = 0.9818956336528222\n",
            "metric_per_case[11].metrics.1.Dice = 0.9898785425101214\n",
            "metric_per_case[12].metrics.1.Dice = 0.9812382739212008\n",
            "metric_per_case[13].metrics.1.Dice = 0.9923857868020305\n",
            "metric_per_case[14].metrics.1.Dice = 0.983225806451613\n",
            "metric_per_case[15].metrics.1.Dice = 0.9807280513918629\n",
            "metric_per_case[16].metrics.1.Dice = 0.9761904761904762\n",
            "metric_per_case[17].metrics.1.Dice = 0.9902912621359223\n",
            "metric_per_case[18].metrics.1.Dice = 0.9894736842105263\n",
            "metric_per_case[19].metrics.1.Dice = 0.9898373983739838\n",
            "metric_per_case[20].metrics.1.Dice = 0.9791376912378303\n",
            "metric_per_case[21].metrics.1.Dice = 0.994535519125683\n",
            "metric_per_case[22].metrics.1.Dice = 0.9877750611246944\n",
            "metric_per_case[23].metrics.1.Dice = 0.9769230769230769\n",
            "metric_per_case[24].metrics.1.Dice = 0.9770992366412213\n",
            "metric_per_case[25].metrics.1.Dice = 0.9827160493827161\n",
            "metric_per_case[26].metrics.1.Dice = 0.9938900203665988\n",
            "metric_per_case[27].metrics.1.Dice = 0.9904761904761905\n",
            "metric_per_case[28].metrics.1.Dice = 0.986013986013986\n",
            "metric_per_case[29].metrics.1.Dice = 0.9851632047477745\n",
            "metric_per_case[30].metrics.1.Dice = 0.9832775919732442\n",
            "metric_per_case[31].metrics.1.Dice = 0.9888475836431226\n",
            "metric_per_case[32].metrics.1.Dice = 0.995\n",
            "metric_per_case[33].metrics.1.Dice = 0.9740932642487047\n",
            "metric_per_case[34].metrics.1.Dice = 0.9826589595375722\n",
            "metric_per_case[35].metrics.1.Dice = 0.968944099378882\n",
            "metric_per_case[36].metrics.1.Dice = 0.9885057471264368\n",
            "metric_per_case[37].metrics.1.Dice = 0.9903846153846154\n",
            "metric_per_case[38].metrics.1.Dice = 0.9936305732484076\n",
            "metric_per_case[39].metrics.1.Dice = 0.9946524064171123\n",
            "metric_per_case[40].metrics.1.Dice = 0.9777777777777777\n",
            "metric_per_case[41].metrics.1.Dice = 0.9821428571428571\n",
            "metric_per_case[42].metrics.1.Dice = 0.918918918918919\n",
            "metric_per_case[43].metrics.1.Dice = 1.0\n",
            "metric_per_case[44].metrics.1.Dice = 0.975609756097561\n",
            "metric_per_case[45].metrics.1.Dice = 0.9883720930232558\n",
            "metric_per_case[46].metrics.1.Dice = 1.0\n",
            "metric_per_case[47].metrics.1.Dice = 1.0\n",
            "metric_per_case[48].metrics.1.Dice = 1.0\n",
            "metric_per_case[49].metrics.1.Dice = 0.9583333333333334\n",
            "metric_per_case[50].metrics.1.Dice = 0.9710144927536232\n",
            "metric_per_case[51].metrics.1.Dice = 1.0\n",
            "metric_per_case[52].metrics.1.Dice = 1.0\n",
            "metric_per_case[53].metrics.1.Dice = 0.8947368421052632\n",
            "metric_per_case[54].metrics.1.Dice = 1.0\n",
            "metric_per_case[55].metrics.1.Dice = 0.9803921568627451\n",
            "metric_per_case[56].metrics.1.Dice = 0.967741935483871\n",
            "metric_per_case[57].metrics.1.Dice = 0.9714285714285714\n",
            "metric_per_case[58].metrics.1.Dice = 0.99609375\n",
            "metric_per_case[59].metrics.1.Dice = 0.9943502824858758\n",
            "metric_per_case[60].metrics.1.Dice = 0.98989898989899\n",
            "metric_per_case[61].metrics.1.Dice = 0.994535519125683\n",
            "metric_per_case[62].metrics.1.Dice = 0.9824561403508771\n",
            "metric_per_case[63].metrics.1.Dice = 0.9375\n",
            "metric_per_case[64].metrics.1.Dice = 0.9583333333333334\n",
            "metric_per_case[65].metrics.1.Dice = 0.9866666666666667\n",
            "metric_per_case[66].metrics.1.Dice = 0.9\n",
            "metric_per_case[67].metrics.1.Dice = 0.8181818181818182\n",
            "metric_per_case[68].metrics.1.Dice = 1.0\n",
            "metric_per_case[69].metrics.1.Dice = 1.0\n",
            "metric_per_case[70].metrics.1.Dice = 1.0\n",
            "metric_per_case[71].metrics.1.Dice = 1.0\n",
            "metric_per_case[72].metrics.1.Dice = 0.9958368026644463\n",
            "metric_per_case[73].metrics.1.Dice = 0.9976284584980237\n",
            "metric_per_case[74].metrics.1.Dice = 0.9923780487804879\n",
            "metric_per_case[75].metrics.1.Dice = 0.9851411589895989\n",
            "metric_per_case[76].metrics.1.Dice = 0.9979605710401088\n",
            "metric_per_case[77].metrics.1.Dice = 0.9979879275653923\n",
            "metric_per_case[78].metrics.1.Dice = 0.9979716024340771\n",
            "metric_per_case[79].metrics.1.Dice = 0.9736842105263158\n",
            "metric_per_case[80].metrics.1.Dice = 0.9968847352024922\n",
            "metric_per_case[81].metrics.1.Dice = 0.991869918699187\n",
            "metric_per_case[82].metrics.1.Dice = 0.9903181189488244\n",
            "metric_per_case[83].metrics.1.Dice = 0.9753914988814317\n",
            "metric_per_case[84].metrics.1.Dice = 1.0\n",
            "metric_per_case[85].metrics.1.Dice = 0.9961977186311787\n",
            "metric_per_case[86].metrics.1.Dice = 0.9848484848484849\n",
            "metric_per_case[87].metrics.1.Dice = 0.9805194805194806\n",
            "metric_per_case[88].metrics.1.Dice = 0.9896907216494846\n",
            "metric_per_case[89].metrics.1.Dice = 0.9333333333333333\n",
            "metric_per_case[90].metrics.1.Dice = 0.994413407821229\n",
            "metric_per_case[91].metrics.1.Dice = 1.0\n",
            "metric_per_case[92].metrics.1.Dice = 0.9937888198757764\n",
            "metric_per_case[93].metrics.1.Dice = 1.0\n",
            "metric_per_case[94].metrics.1.Dice = 0.9945945945945946\n",
            "metric_per_case[95].metrics.1.Dice = 0.9848484848484849\n",
            "metric_per_case[96].metrics.1.Dice = 0.9865125240847784\n",
            "metric_per_case[97].metrics.1.Dice = 0.9875\n",
            "metric_per_case[98].metrics.1.Dice = 0.9942857142857143\n",
            "metric_per_case[99].metrics.1.Dice = 0.9947089947089947\n",
            "metric_per_case[100].metrics.1.Dice = 0.965034965034965\n",
            "metric_per_case[101].metrics.1.Dice = 0.9784172661870504\n",
            "metric_per_case[102].metrics.1.Dice = 0.98989898989899\n",
            "metric_per_case[103].metrics.1.Dice = 0.9850746268656716\n",
            "metric_per_case[104].metrics.1.Dice = 0.9719626168224299\n",
            "metric_per_case[105].metrics.1.Dice = 0.9809523809523809\n",
            "metric_per_case[106].metrics.1.Dice = 0.9848484848484849\n",
            "metric_per_case[107].metrics.1.Dice = 1.0\n",
            "metric_per_case[108].metrics.1.Dice = 0.9655172413793104\n",
            "metric_per_case[109].metrics.1.Dice = 0.9958437240232751\n",
            "metric_per_case[110].metrics.1.Dice = 0.9993089149965446\n",
            "metric_per_case[111].metrics.1.Dice = 0.99637943519189\n",
            "metric_per_case[112].metrics.1.Dice = 0.9962825278810409\n",
            "metric_per_case[113].metrics.1.Dice = 0.9957173447537473\n",
            "metric_per_case[114].metrics.1.Dice = 0.9850746268656716\n",
            "metric_per_case[115].metrics.1.Dice = 0.9885931558935361\n",
            "metric_per_case[116].metrics.1.Dice = 0.9965870307167235\n",
            "metric_per_case[117].metrics.1.Dice = 0.9963636363636363\n",
            "metric_per_case[118].metrics.1.Dice = 0.9934640522875817\n",
            "metric_per_case[119].metrics.1.Dice = 0.9791666666666666\n",
            "metric_per_case[120].metrics.1.Dice = 0.9936305732484076\n",
            "metric_per_case[121].metrics.1.Dice = 0.9966777408637874\n",
            "metric_per_case[122].metrics.1.Dice = 1.0\n",
            "metric_per_case[123].metrics.1.Dice = 0.967741935483871\n",
            "metric_per_case[124].metrics.1.Dice = 0.9848484848484849\n",
            "metric_per_case[125].metrics.1.Dice = 0.9868421052631579\n",
            "metric_per_case[126].metrics.1.Dice = 0.9803921568627451\n",
            "metric_per_case[127].metrics.1.Dice = 0.9916897506925207\n",
            "metric_per_case[128].metrics.1.Dice = 0.9977528089887641\n",
            "metric_per_case[129].metrics.1.Dice = 0.9938757655293088\n",
            "metric_per_case[130].metrics.1.Dice = 0.9868421052631579\n",
            "metric_per_case[131].metrics.1.Dice = 0.9959595959595959\n",
            "metric_per_case[132].metrics.1.Dice = 0.9948586118251928\n",
            "metric_per_case[133].metrics.1.Dice = 0.9951690821256038\n",
            "metric_per_case[134].metrics.1.Dice = 0.9949066213921901\n",
            "metric_per_case[135].metrics.1.Dice = 0.9964539007092199\n",
            "metric_per_case[136].metrics.1.Dice = 0.9938398357289527\n",
            "metric_per_case[137].metrics.1.Dice = 1.0\n",
            "metric_per_case[138].metrics.1.Dice = 0.9871794871794872\n",
            "metric_per_case[139].metrics.1.Dice = 0.9928057553956835\n",
            "metric_per_case[140].metrics.1.Dice = 0.9911504424778761\n",
            "metric_per_case[141].metrics.1.Dice = 1.0\n",
            "metric_per_case[142].metrics.1.Dice = 0.9696969696969697\n",
            "metric_per_case[143].metrics.1.Dice = 1.0\n",
            "metric_per_case[144].metrics.1.Dice = 1.0\n",
            "metric_per_case[145].metrics.1.Dice = 0.9965397923875432\n",
            "metric_per_case[146].metrics.1.Dice = 1.0\n",
            "metric_per_case[147].metrics.1.Dice = 1.0\n",
            "metric_per_case[148].metrics.1.Dice = 1.0\n",
            "metric_per_case[149].metrics.1.Dice = 1.0\n",
            "metric_per_case[150].metrics.1.Dice = 1.0\n",
            "metric_per_case[151].metrics.1.Dice = 0.9734513274336283\n",
            "metric_per_case[152].metrics.1.Dice = 1.0\n",
            "metric_per_case[153].metrics.1.Dice = 0.9777777777777777\n",
            "metric_per_case[154].metrics.1.Dice = 1.0\n",
            "metric_per_case[155].metrics.1.Dice = 1.0\n",
            "metric_per_case[156].metrics.1.Dice = 1.0\n",
            "metric_per_case[157].metrics.1.Dice = 0.9795918367346939\n",
            "metric_per_case[158].metrics.1.Dice = 0.9866666666666667\n",
            "metric_per_case[159].metrics.1.Dice = 0.9882352941176471\n",
            "metric_per_case[160].metrics.1.Dice = 1.0\n",
            "metric_per_case[161].metrics.1.Dice = 0.9736842105263158\n",
            "metric_per_case[162].metrics.1.Dice = 0.9883720930232558\n",
            "metric_per_case[163].metrics.1.Dice = 0.9894736842105263\n",
            "metric_per_case[164].metrics.1.Dice = 0.9882352941176471\n",
            "metric_per_case[165].metrics.1.Dice = 1.0\n",
            "metric_per_case[166].metrics.1.Dice = 0.9714285714285714\n",
            "metric_per_case[167].metrics.1.Dice = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Fold 1"
      ],
      "metadata": {
        "id": "Bvm3yRxBi6s9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train 501 2d 1 --device cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsl_3U0-jAe2",
        "outputId": "29d5fba3-655b-47ae-da1b-2717b97213e5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: nnUNetv2_train [-h] [-tr TR] [-p P]\n",
            "                      [-pretrained_weights PRETRAINED_WEIGHTS]\n",
            "                      [-num_gpus NUM_GPUS] [--npz] [--c] [--val] [--val_best]\n",
            "                      [--disable_checkpointing] [-device DEVICE]\n",
            "                      dataset_name_or_id configuration fold\n",
            "nnUNetv2_train: error: unrecognized arguments: --device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train 501 2d 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cpBgTZxcjqQm",
        "outputId": "d4f370f5-e287-4b1b-fbc5-3da70ff0f495"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2025-12-23 04:55:12.660636: Using torch.compile...\n",
            "2025-12-23 04:55:14.191850: do_dummy_2d_data_aug: False\n",
            "2025-12-23 04:55:14.194009: Using splits from existing split file: /content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/splits_final.json\n",
            "2025-12-23 04:55:14.194555: The split file contains 5 splits.\n",
            "2025-12-23 04:55:14.194623: Desired fold for training: 1\n",
            "2025-12-23 04:55:14.194667: This split has 670 training and 168 validation cases.\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "using pin_memory on device 0\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "using pin_memory on device 0\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 2d\n",
            " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 14, 'patch_size': [512, 448], 'median_image_size_in_voxels': [512.0, 416.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset501_KSSD', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 512, 416], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 237.29641723632812, 'median': 255.0, 'min': 95.0, 'percentile_00_5': 162.0, 'percentile_99_5': 255.0, 'std': 27.940317153930664}}} \n",
            "\n",
            "2025-12-23 04:55:16.674852: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2025-12-23 04:55:16.691810: \n",
            "2025-12-23 04:55:16.692256: Epoch 0\n",
            "2025-12-23 04:55:16.693943: Current learning rate: 0.01\n",
            "2025-12-23 04:56:54.343931: train_loss -0.0198\n",
            "2025-12-23 04:56:54.344197: val_loss -0.324\n",
            "2025-12-23 04:56:54.344343: Pseudo dice [np.float32(0.4745)]\n",
            "2025-12-23 04:56:54.344469: Epoch time: 97.66 s\n",
            "2025-12-23 04:56:54.344546: Yayy! New best EMA pseudo Dice: 0.47450000047683716\n",
            "2025-12-23 04:56:55.809955: \n",
            "2025-12-23 04:56:55.810315: Epoch 1\n",
            "2025-12-23 04:56:55.810474: Current learning rate: 0.00999\n",
            "2025-12-23 04:57:18.154950: train_loss -0.6092\n",
            "2025-12-23 04:57:18.155159: val_loss -0.8204\n",
            "2025-12-23 04:57:18.155272: Pseudo dice [np.float32(0.9275)]\n",
            "2025-12-23 04:57:18.155385: Epoch time: 22.35 s\n",
            "2025-12-23 04:57:18.155541: Yayy! New best EMA pseudo Dice: 0.5198000073432922\n",
            "2025-12-23 04:57:20.270233: \n",
            "2025-12-23 04:57:20.270571: Epoch 2\n",
            "2025-12-23 04:57:20.270703: Current learning rate: 0.00998\n",
            "2025-12-23 04:57:42.657857: train_loss -0.8362\n",
            "2025-12-23 04:57:42.658108: val_loss -0.8894\n",
            "2025-12-23 04:57:42.658260: Pseudo dice [np.float32(0.9485)]\n",
            "2025-12-23 04:57:42.658387: Epoch time: 22.39 s\n",
            "2025-12-23 04:57:42.658480: Yayy! New best EMA pseudo Dice: 0.5626999735832214\n",
            "2025-12-23 04:57:44.567373: \n",
            "2025-12-23 04:57:44.567671: Epoch 3\n",
            "2025-12-23 04:57:44.567876: Current learning rate: 0.00997\n",
            "2025-12-23 04:58:06.985922: train_loss -0.8519\n",
            "2025-12-23 04:58:06.986111: val_loss -0.9091\n",
            "2025-12-23 04:58:06.986225: Pseudo dice [np.float32(0.9535)]\n",
            "2025-12-23 04:58:06.986407: Epoch time: 22.42 s\n",
            "2025-12-23 04:58:06.986521: Yayy! New best EMA pseudo Dice: 0.6018000245094299\n",
            "2025-12-23 04:58:08.817426: \n",
            "2025-12-23 04:58:08.817606: Epoch 4\n",
            "2025-12-23 04:58:08.817736: Current learning rate: 0.00996\n",
            "2025-12-23 04:58:31.152844: train_loss -0.8909\n",
            "2025-12-23 04:58:31.153049: val_loss -0.923\n",
            "2025-12-23 04:58:31.153169: Pseudo dice [np.float32(0.9556)]\n",
            "2025-12-23 04:58:31.153308: Epoch time: 22.34 s\n",
            "2025-12-23 04:58:31.153404: Yayy! New best EMA pseudo Dice: 0.6371999979019165\n",
            "2025-12-23 04:58:33.017716: \n",
            "2025-12-23 04:58:33.018051: Epoch 5\n",
            "2025-12-23 04:58:33.018201: Current learning rate: 0.00995\n",
            "2025-12-23 04:58:55.419637: train_loss -0.893\n",
            "2025-12-23 04:58:55.419944: val_loss -0.9286\n",
            "2025-12-23 04:58:55.420126: Pseudo dice [np.float32(0.9513)]\n",
            "2025-12-23 04:58:55.420324: Epoch time: 22.4 s\n",
            "2025-12-23 04:58:55.420432: Yayy! New best EMA pseudo Dice: 0.6686000227928162\n",
            "2025-12-23 04:58:57.235213: \n",
            "2025-12-23 04:58:57.235497: Epoch 6\n",
            "2025-12-23 04:58:57.235629: Current learning rate: 0.00995\n",
            "2025-12-23 04:59:19.632721: train_loss -0.9095\n",
            "2025-12-23 04:59:19.633034: val_loss -0.9383\n",
            "2025-12-23 04:59:19.633183: Pseudo dice [np.float32(0.9601)]\n",
            "2025-12-23 04:59:19.633365: Epoch time: 22.4 s\n",
            "2025-12-23 04:59:19.633592: Yayy! New best EMA pseudo Dice: 0.697700023651123\n",
            "2025-12-23 04:59:21.474268: \n",
            "2025-12-23 04:59:21.474591: Epoch 7\n",
            "2025-12-23 04:59:21.474734: Current learning rate: 0.00994\n",
            "2025-12-23 04:59:43.847682: train_loss -0.9189\n",
            "2025-12-23 04:59:43.847994: val_loss -0.9468\n",
            "2025-12-23 04:59:43.848094: Pseudo dice [np.float32(0.9621)]\n",
            "2025-12-23 04:59:43.848183: Epoch time: 22.37 s\n",
            "2025-12-23 04:59:43.848300: Yayy! New best EMA pseudo Dice: 0.7242000102996826\n",
            "2025-12-23 04:59:45.765734: \n",
            "2025-12-23 04:59:45.766029: Epoch 8\n",
            "2025-12-23 04:59:45.766161: Current learning rate: 0.00993\n",
            "2025-12-23 05:00:08.189687: train_loss -0.9284\n",
            "2025-12-23 05:00:08.189938: val_loss -0.9487\n",
            "2025-12-23 05:00:08.190030: Pseudo dice [np.float32(0.9641)]\n",
            "2025-12-23 05:00:08.190124: Epoch time: 22.43 s\n",
            "2025-12-23 05:00:08.190198: Yayy! New best EMA pseudo Dice: 0.748199999332428\n",
            "2025-12-23 05:00:10.046191: \n",
            "2025-12-23 05:00:10.046394: Epoch 9\n",
            "2025-12-23 05:00:10.046532: Current learning rate: 0.00992\n",
            "2025-12-23 05:00:32.468251: train_loss -0.9353\n",
            "2025-12-23 05:00:32.468600: val_loss -0.9481\n",
            "2025-12-23 05:00:32.468785: Pseudo dice [np.float32(0.9587)]\n",
            "2025-12-23 05:00:32.469023: Epoch time: 22.42 s\n",
            "2025-12-23 05:00:32.469152: Yayy! New best EMA pseudo Dice: 0.7692000269889832\n",
            "2025-12-23 05:00:34.342773: \n",
            "2025-12-23 05:00:34.343056: Epoch 10\n",
            "2025-12-23 05:00:34.343205: Current learning rate: 0.00991\n",
            "2025-12-23 05:00:56.767841: train_loss -0.9315\n",
            "2025-12-23 05:00:56.768060: val_loss -0.9473\n",
            "2025-12-23 05:00:56.768339: Pseudo dice [np.float32(0.9594)]\n",
            "2025-12-23 05:00:56.768466: Epoch time: 22.43 s\n",
            "2025-12-23 05:00:56.768541: Yayy! New best EMA pseudo Dice: 0.7882000207901001\n",
            "2025-12-23 05:00:58.626596: \n",
            "2025-12-23 05:00:58.626843: Epoch 11\n",
            "2025-12-23 05:00:58.627022: Current learning rate: 0.0099\n",
            "2025-12-23 05:01:21.068455: train_loss -0.9369\n",
            "2025-12-23 05:01:21.068721: val_loss -0.955\n",
            "2025-12-23 05:01:21.068814: Pseudo dice [np.float32(0.9657)]\n",
            "2025-12-23 05:01:21.068904: Epoch time: 22.44 s\n",
            "2025-12-23 05:01:21.068977: Yayy! New best EMA pseudo Dice: 0.8059999942779541\n",
            "2025-12-23 05:01:22.968378: \n",
            "2025-12-23 05:01:22.968544: Epoch 12\n",
            "2025-12-23 05:01:22.968676: Current learning rate: 0.00989\n",
            "2025-12-23 05:01:45.445188: train_loss -0.9314\n",
            "2025-12-23 05:01:45.445514: val_loss -0.9277\n",
            "2025-12-23 05:01:45.445626: Pseudo dice [np.float32(0.9424)]\n",
            "2025-12-23 05:01:45.445721: Epoch time: 22.48 s\n",
            "2025-12-23 05:01:45.445808: Yayy! New best EMA pseudo Dice: 0.819599986076355\n",
            "2025-12-23 05:01:47.360276: \n",
            "2025-12-23 05:01:47.360590: Epoch 13\n",
            "2025-12-23 05:01:47.360731: Current learning rate: 0.00988\n",
            "2025-12-23 05:02:09.845623: train_loss -0.935\n",
            "2025-12-23 05:02:09.845905: val_loss -0.9519\n",
            "2025-12-23 05:02:09.846042: Pseudo dice [np.float32(0.9632)]\n",
            "2025-12-23 05:02:09.846269: Epoch time: 22.49 s\n",
            "2025-12-23 05:02:09.846437: Yayy! New best EMA pseudo Dice: 0.8339999914169312\n",
            "2025-12-23 05:02:11.733167: \n",
            "2025-12-23 05:02:11.733459: Epoch 14\n",
            "2025-12-23 05:02:11.733609: Current learning rate: 0.00987\n",
            "2025-12-23 05:02:34.209782: train_loss -0.9397\n",
            "2025-12-23 05:02:34.210066: val_loss -0.9554\n",
            "2025-12-23 05:02:34.210178: Pseudo dice [np.float32(0.9651)]\n",
            "2025-12-23 05:02:34.210306: Epoch time: 22.48 s\n",
            "2025-12-23 05:02:34.210428: Yayy! New best EMA pseudo Dice: 0.847100019454956\n",
            "2025-12-23 05:02:36.157332: \n",
            "2025-12-23 05:02:36.157499: Epoch 15\n",
            "2025-12-23 05:02:36.157700: Current learning rate: 0.00986\n",
            "2025-12-23 05:02:59.137906: train_loss -0.9386\n",
            "2025-12-23 05:02:59.138103: val_loss -0.9571\n",
            "2025-12-23 05:02:59.138189: Pseudo dice [np.float32(0.9648)]\n",
            "2025-12-23 05:02:59.138341: Epoch time: 22.98 s\n",
            "2025-12-23 05:02:59.138432: Yayy! New best EMA pseudo Dice: 0.8589000105857849\n",
            "2025-12-23 05:03:00.985201: \n",
            "2025-12-23 05:03:00.985389: Epoch 16\n",
            "2025-12-23 05:03:00.985524: Current learning rate: 0.00986\n",
            "2025-12-23 05:03:23.497868: train_loss -0.9473\n",
            "2025-12-23 05:03:23.498082: val_loss -0.9572\n",
            "2025-12-23 05:03:23.498173: Pseudo dice [np.float32(0.9649)]\n",
            "2025-12-23 05:03:23.498302: Epoch time: 22.51 s\n",
            "2025-12-23 05:03:23.498410: Yayy! New best EMA pseudo Dice: 0.8694999814033508\n",
            "2025-12-23 05:03:25.413467: \n",
            "2025-12-23 05:03:25.413774: Epoch 17\n",
            "2025-12-23 05:03:25.413913: Current learning rate: 0.00985\n",
            "2025-12-23 05:03:47.905363: train_loss -0.9488\n",
            "2025-12-23 05:03:47.905563: val_loss -0.9628\n",
            "2025-12-23 05:03:47.905649: Pseudo dice [np.float32(0.9701)]\n",
            "2025-12-23 05:03:47.905745: Epoch time: 22.49 s\n",
            "2025-12-23 05:03:47.905824: Yayy! New best EMA pseudo Dice: 0.8794999718666077\n",
            "2025-12-23 05:03:49.754450: \n",
            "2025-12-23 05:03:49.754790: Epoch 18\n",
            "2025-12-23 05:03:49.754926: Current learning rate: 0.00984\n",
            "2025-12-23 05:04:12.231957: train_loss -0.9498\n",
            "2025-12-23 05:04:12.232154: val_loss -0.9602\n",
            "2025-12-23 05:04:12.232254: Pseudo dice [np.float32(0.9687)]\n",
            "2025-12-23 05:04:12.232346: Epoch time: 22.48 s\n",
            "2025-12-23 05:04:12.232420: Yayy! New best EMA pseudo Dice: 0.8884999752044678\n",
            "2025-12-23 05:04:14.072267: \n",
            "2025-12-23 05:04:14.072462: Epoch 19\n",
            "2025-12-23 05:04:14.072590: Current learning rate: 0.00983\n",
            "2025-12-23 05:04:36.505730: train_loss -0.9496\n",
            "2025-12-23 05:04:36.505945: val_loss -0.9621\n",
            "2025-12-23 05:04:36.506125: Pseudo dice [np.float32(0.971)]\n",
            "2025-12-23 05:04:36.506272: Epoch time: 22.43 s\n",
            "2025-12-23 05:04:36.506385: Yayy! New best EMA pseudo Dice: 0.8967000246047974\n",
            "2025-12-23 05:04:38.361236: \n",
            "2025-12-23 05:04:38.361479: Epoch 20\n",
            "2025-12-23 05:04:38.361612: Current learning rate: 0.00982\n",
            "2025-12-23 05:05:00.825006: train_loss -0.9484\n",
            "2025-12-23 05:05:00.825355: val_loss -0.9653\n",
            "2025-12-23 05:05:00.825557: Pseudo dice [np.float32(0.9722)]\n",
            "2025-12-23 05:05:00.825747: Epoch time: 22.47 s\n",
            "2025-12-23 05:05:00.825945: Yayy! New best EMA pseudo Dice: 0.9042999744415283\n",
            "2025-12-23 05:05:02.701734: \n",
            "2025-12-23 05:05:02.702039: Epoch 21\n",
            "2025-12-23 05:05:02.702167: Current learning rate: 0.00981\n",
            "2025-12-23 05:05:25.134547: train_loss -0.9526\n",
            "2025-12-23 05:05:25.134748: val_loss -0.9617\n",
            "2025-12-23 05:05:25.134833: Pseudo dice [np.float32(0.9719)]\n",
            "2025-12-23 05:05:25.134920: Epoch time: 22.43 s\n",
            "2025-12-23 05:05:25.134993: Yayy! New best EMA pseudo Dice: 0.9110000133514404\n",
            "2025-12-23 05:05:27.115401: \n",
            "2025-12-23 05:05:27.115808: Epoch 22\n",
            "2025-12-23 05:05:27.115969: Current learning rate: 0.0098\n",
            "2025-12-23 05:05:49.593916: train_loss -0.9532\n",
            "2025-12-23 05:05:49.594424: val_loss -0.9646\n",
            "2025-12-23 05:05:49.594573: Pseudo dice [np.float32(0.9727)]\n",
            "2025-12-23 05:05:49.594687: Epoch time: 22.48 s\n",
            "2025-12-23 05:05:49.594780: Yayy! New best EMA pseudo Dice: 0.9172000288963318\n",
            "2025-12-23 05:05:51.421446: \n",
            "2025-12-23 05:05:51.421806: Epoch 23\n",
            "2025-12-23 05:05:51.422003: Current learning rate: 0.00979\n",
            "2025-12-23 05:06:13.885767: train_loss -0.9425\n",
            "2025-12-23 05:06:13.885977: val_loss -0.9607\n",
            "2025-12-23 05:06:13.886076: Pseudo dice [np.float32(0.9719)]\n",
            "2025-12-23 05:06:13.886167: Epoch time: 22.47 s\n",
            "2025-12-23 05:06:13.886268: Yayy! New best EMA pseudo Dice: 0.9226999878883362\n",
            "2025-12-23 05:06:15.691916: \n",
            "2025-12-23 05:06:15.692081: Epoch 24\n",
            "2025-12-23 05:06:15.692274: Current learning rate: 0.00978\n",
            "2025-12-23 05:06:38.169542: train_loss -0.9485\n",
            "2025-12-23 05:06:38.169776: val_loss -0.9654\n",
            "2025-12-23 05:06:38.169868: Pseudo dice [np.float32(0.9742)]\n",
            "2025-12-23 05:06:38.169957: Epoch time: 22.48 s\n",
            "2025-12-23 05:06:38.170066: Yayy! New best EMA pseudo Dice: 0.9277999997138977\n",
            "2025-12-23 05:06:40.009370: \n",
            "2025-12-23 05:06:40.009568: Epoch 25\n",
            "2025-12-23 05:06:40.009716: Current learning rate: 0.00977\n",
            "2025-12-23 05:07:02.509415: train_loss -0.9497\n",
            "2025-12-23 05:07:02.509604: val_loss -0.9638\n",
            "2025-12-23 05:07:02.509691: Pseudo dice [np.float32(0.9719)]\n",
            "2025-12-23 05:07:02.509887: Epoch time: 22.5 s\n",
            "2025-12-23 05:07:02.510045: Yayy! New best EMA pseudo Dice: 0.932200014591217\n",
            "2025-12-23 05:07:04.296865: \n",
            "2025-12-23 05:07:04.297167: Epoch 26\n",
            "2025-12-23 05:07:04.297315: Current learning rate: 0.00977\n",
            "2025-12-23 05:07:26.762393: train_loss -0.9523\n",
            "2025-12-23 05:07:26.762629: val_loss -0.9689\n",
            "2025-12-23 05:07:26.762722: Pseudo dice [np.float32(0.9767)]\n",
            "2025-12-23 05:07:26.762819: Epoch time: 22.47 s\n",
            "2025-12-23 05:07:26.762893: Yayy! New best EMA pseudo Dice: 0.9366999864578247\n",
            "2025-12-23 05:07:28.603171: \n",
            "2025-12-23 05:07:28.603367: Epoch 27\n",
            "2025-12-23 05:07:28.603503: Current learning rate: 0.00976\n",
            "2025-12-23 05:07:51.085265: train_loss -0.9552\n",
            "2025-12-23 05:07:51.085592: val_loss -0.9686\n",
            "2025-12-23 05:07:51.085686: Pseudo dice [np.float32(0.9753)]\n",
            "2025-12-23 05:07:51.085780: Epoch time: 22.48 s\n",
            "2025-12-23 05:07:51.085866: Yayy! New best EMA pseudo Dice: 0.940500020980835\n",
            "2025-12-23 05:07:52.917573: \n",
            "2025-12-23 05:07:52.917912: Epoch 28\n",
            "2025-12-23 05:07:52.918087: Current learning rate: 0.00975\n",
            "2025-12-23 05:08:15.416105: train_loss -0.9555\n",
            "2025-12-23 05:08:15.416355: val_loss -0.9679\n",
            "2025-12-23 05:08:15.416445: Pseudo dice [np.float32(0.9743)]\n",
            "2025-12-23 05:08:15.416539: Epoch time: 22.5 s\n",
            "2025-12-23 05:08:15.416695: Yayy! New best EMA pseudo Dice: 0.9438999891281128\n",
            "2025-12-23 05:08:17.681727: \n",
            "2025-12-23 05:08:17.682003: Epoch 29\n",
            "2025-12-23 05:08:17.682136: Current learning rate: 0.00974\n",
            "2025-12-23 05:08:40.163946: train_loss -0.9507\n",
            "2025-12-23 05:08:40.164293: val_loss -0.9657\n",
            "2025-12-23 05:08:40.164404: Pseudo dice [np.float32(0.9717)]\n",
            "2025-12-23 05:08:40.164499: Epoch time: 22.48 s\n",
            "2025-12-23 05:08:40.164586: Yayy! New best EMA pseudo Dice: 0.9466999769210815\n",
            "2025-12-23 05:08:41.986457: \n",
            "2025-12-23 05:08:41.986916: Epoch 30\n",
            "2025-12-23 05:08:41.987052: Current learning rate: 0.00973\n",
            "2025-12-23 05:09:04.422169: train_loss -0.9575\n",
            "2025-12-23 05:09:04.422414: val_loss -0.972\n",
            "2025-12-23 05:09:04.422510: Pseudo dice [np.float32(0.9782)]\n",
            "2025-12-23 05:09:04.422603: Epoch time: 22.44 s\n",
            "2025-12-23 05:09:04.422678: Yayy! New best EMA pseudo Dice: 0.9498000144958496\n",
            "2025-12-23 05:09:06.272944: \n",
            "2025-12-23 05:09:06.273127: Epoch 31\n",
            "2025-12-23 05:09:06.273306: Current learning rate: 0.00972\n",
            "2025-12-23 05:09:28.768690: train_loss -0.9596\n",
            "2025-12-23 05:09:28.768910: val_loss -0.9672\n",
            "2025-12-23 05:09:28.769030: Pseudo dice [np.float32(0.9738)]\n",
            "2025-12-23 05:09:28.769133: Epoch time: 22.5 s\n",
            "2025-12-23 05:09:28.769210: Yayy! New best EMA pseudo Dice: 0.9521999955177307\n",
            "2025-12-23 05:09:30.634776: \n",
            "2025-12-23 05:09:30.635092: Epoch 32\n",
            "2025-12-23 05:09:30.635243: Current learning rate: 0.00971\n",
            "2025-12-23 05:09:53.116812: train_loss -0.9543\n",
            "2025-12-23 05:09:53.117147: val_loss -0.973\n",
            "2025-12-23 05:09:53.117267: Pseudo dice [np.float32(0.9797)]\n",
            "2025-12-23 05:09:53.117377: Epoch time: 22.48 s\n",
            "2025-12-23 05:09:53.117491: Yayy! New best EMA pseudo Dice: 0.9549999833106995\n",
            "2025-12-23 05:09:54.983137: \n",
            "2025-12-23 05:09:54.983415: Epoch 33\n",
            "2025-12-23 05:09:54.983546: Current learning rate: 0.0097\n",
            "2025-12-23 05:10:17.471751: train_loss -0.9598\n",
            "2025-12-23 05:10:17.471954: val_loss -0.9701\n",
            "2025-12-23 05:10:17.472040: Pseudo dice [np.float32(0.9764)]\n",
            "2025-12-23 05:10:17.472126: Epoch time: 22.49 s\n",
            "2025-12-23 05:10:17.472315: Yayy! New best EMA pseudo Dice: 0.957099974155426\n",
            "2025-12-23 05:10:19.361444: \n",
            "2025-12-23 05:10:19.361644: Epoch 34\n",
            "2025-12-23 05:10:19.361790: Current learning rate: 0.00969\n",
            "2025-12-23 05:10:41.870791: train_loss -0.9608\n",
            "2025-12-23 05:10:41.870994: val_loss -0.9727\n",
            "2025-12-23 05:10:41.871123: Pseudo dice [np.float32(0.9789)]\n",
            "2025-12-23 05:10:41.871232: Epoch time: 22.51 s\n",
            "2025-12-23 05:10:41.871348: Yayy! New best EMA pseudo Dice: 0.9592999815940857\n",
            "2025-12-23 05:10:43.736122: \n",
            "2025-12-23 05:10:43.736371: Epoch 35\n",
            "2025-12-23 05:10:43.736540: Current learning rate: 0.00968\n",
            "2025-12-23 05:11:06.234065: train_loss -0.9584\n",
            "2025-12-23 05:11:06.234449: val_loss -0.9715\n",
            "2025-12-23 05:11:06.234570: Pseudo dice [np.float32(0.9785)]\n",
            "2025-12-23 05:11:06.234696: Epoch time: 22.5 s\n",
            "2025-12-23 05:11:06.234803: Yayy! New best EMA pseudo Dice: 0.9611999988555908\n",
            "2025-12-23 05:11:08.130942: \n",
            "2025-12-23 05:11:08.131227: Epoch 36\n",
            "2025-12-23 05:11:08.131368: Current learning rate: 0.00968\n",
            "2025-12-23 05:11:30.636332: train_loss -0.9542\n",
            "2025-12-23 05:11:30.636616: val_loss -0.9682\n",
            "2025-12-23 05:11:30.636768: Pseudo dice [np.float32(0.9734)]\n",
            "2025-12-23 05:11:30.636925: Epoch time: 22.51 s\n",
            "2025-12-23 05:11:30.637048: Yayy! New best EMA pseudo Dice: 0.9624000191688538\n",
            "2025-12-23 05:11:32.487027: \n",
            "2025-12-23 05:11:32.487276: Epoch 37\n",
            "2025-12-23 05:11:32.487415: Current learning rate: 0.00967\n",
            "2025-12-23 05:11:54.974053: train_loss -0.9585\n",
            "2025-12-23 05:11:54.974289: val_loss -0.971\n",
            "2025-12-23 05:11:54.974407: Pseudo dice [np.float32(0.9765)]\n",
            "2025-12-23 05:11:54.974530: Epoch time: 22.49 s\n",
            "2025-12-23 05:11:54.974653: Yayy! New best EMA pseudo Dice: 0.9638000130653381\n",
            "2025-12-23 05:11:56.858450: \n",
            "2025-12-23 05:11:56.858689: Epoch 38\n",
            "2025-12-23 05:11:56.858824: Current learning rate: 0.00966\n",
            "2025-12-23 05:12:19.264113: train_loss -0.9498\n",
            "2025-12-23 05:12:19.264339: val_loss -0.9593\n",
            "2025-12-23 05:12:19.264437: Pseudo dice [np.float32(0.9659)]\n",
            "2025-12-23 05:12:19.264537: Epoch time: 22.41 s\n",
            "2025-12-23 05:12:19.264614: Yayy! New best EMA pseudo Dice: 0.9639999866485596\n",
            "2025-12-23 05:12:21.089931: \n",
            "2025-12-23 05:12:21.090302: Epoch 39\n",
            "2025-12-23 05:12:21.090445: Current learning rate: 0.00965\n",
            "2025-12-23 05:12:43.559458: train_loss -0.9524\n",
            "2025-12-23 05:12:43.559658: val_loss -0.9684\n",
            "2025-12-23 05:12:43.559752: Pseudo dice [np.float32(0.9755)]\n",
            "2025-12-23 05:12:43.559840: Epoch time: 22.47 s\n",
            "2025-12-23 05:12:43.559914: Yayy! New best EMA pseudo Dice: 0.9652000069618225\n",
            "2025-12-23 05:12:45.414961: \n",
            "2025-12-23 05:12:45.415240: Epoch 40\n",
            "2025-12-23 05:12:45.415393: Current learning rate: 0.00964\n",
            "2025-12-23 05:13:07.897920: train_loss -0.9556\n",
            "2025-12-23 05:13:07.898191: val_loss -0.9704\n",
            "2025-12-23 05:13:07.898339: Pseudo dice [np.float32(0.9765)]\n",
            "2025-12-23 05:13:07.898442: Epoch time: 22.48 s\n",
            "2025-12-23 05:13:07.898538: Yayy! New best EMA pseudo Dice: 0.9663000106811523\n",
            "2025-12-23 05:13:09.761682: \n",
            "2025-12-23 05:13:09.761999: Epoch 41\n",
            "2025-12-23 05:13:09.762135: Current learning rate: 0.00963\n",
            "2025-12-23 05:13:32.226078: train_loss -0.9596\n",
            "2025-12-23 05:13:32.226343: val_loss -0.971\n",
            "2025-12-23 05:13:32.226460: Pseudo dice [np.float32(0.9781)]\n",
            "2025-12-23 05:13:32.226553: Epoch time: 22.47 s\n",
            "2025-12-23 05:13:32.226650: Yayy! New best EMA pseudo Dice: 0.9674999713897705\n",
            "2025-12-23 05:13:34.035781: \n",
            "2025-12-23 05:13:34.036158: Epoch 42\n",
            "2025-12-23 05:13:34.036343: Current learning rate: 0.00962\n",
            "2025-12-23 05:13:56.449924: train_loss -0.9581\n",
            "2025-12-23 05:13:56.450402: val_loss -0.9725\n",
            "2025-12-23 05:13:56.450562: Pseudo dice [np.float32(0.9783)]\n",
            "2025-12-23 05:13:56.450658: Epoch time: 22.42 s\n",
            "2025-12-23 05:13:56.450730: Yayy! New best EMA pseudo Dice: 0.9685999751091003\n",
            "2025-12-23 05:13:58.702778: \n",
            "2025-12-23 05:13:58.703087: Epoch 43\n",
            "2025-12-23 05:13:58.703238: Current learning rate: 0.00961\n",
            "2025-12-23 05:14:21.164201: train_loss -0.9572\n",
            "2025-12-23 05:14:21.164535: val_loss -0.9708\n",
            "2025-12-23 05:14:21.164631: Pseudo dice [np.float32(0.9781)]\n",
            "2025-12-23 05:14:21.164720: Epoch time: 22.46 s\n",
            "2025-12-23 05:14:21.164809: Yayy! New best EMA pseudo Dice: 0.9695000052452087\n",
            "2025-12-23 05:14:23.032291: \n",
            "2025-12-23 05:14:23.032511: Epoch 44\n",
            "2025-12-23 05:14:23.032645: Current learning rate: 0.0096\n",
            "2025-12-23 05:14:45.440922: train_loss -0.9613\n",
            "2025-12-23 05:14:45.441250: val_loss -0.9712\n",
            "2025-12-23 05:14:45.441382: Pseudo dice [np.float32(0.9778)]\n",
            "2025-12-23 05:14:45.441511: Epoch time: 22.41 s\n",
            "2025-12-23 05:14:45.441604: Yayy! New best EMA pseudo Dice: 0.9703999757766724\n",
            "2025-12-23 05:14:47.349770: \n",
            "2025-12-23 05:14:47.350090: Epoch 45\n",
            "2025-12-23 05:14:47.350234: Current learning rate: 0.00959\n",
            "2025-12-23 05:15:09.844408: train_loss -0.964\n",
            "2025-12-23 05:15:09.844611: val_loss -0.9716\n",
            "2025-12-23 05:15:09.844698: Pseudo dice [np.float32(0.9785)]\n",
            "2025-12-23 05:15:09.844784: Epoch time: 22.5 s\n",
            "2025-12-23 05:15:09.844862: Yayy! New best EMA pseudo Dice: 0.9711999893188477\n",
            "2025-12-23 05:15:11.701463: \n",
            "2025-12-23 05:15:11.701779: Epoch 46\n",
            "2025-12-23 05:15:11.701908: Current learning rate: 0.00959\n",
            "2025-12-23 05:15:34.147035: train_loss -0.9645\n",
            "2025-12-23 05:15:34.147361: val_loss -0.9731\n",
            "2025-12-23 05:15:34.147462: Pseudo dice [np.float32(0.9785)]\n",
            "2025-12-23 05:15:34.147569: Epoch time: 22.45 s\n",
            "2025-12-23 05:15:34.147659: Yayy! New best EMA pseudo Dice: 0.9718999862670898\n",
            "2025-12-23 05:15:35.960829: \n",
            "2025-12-23 05:15:35.961139: Epoch 47\n",
            "2025-12-23 05:15:35.961283: Current learning rate: 0.00958\n",
            "2025-12-23 05:15:58.413757: train_loss -0.964\n",
            "2025-12-23 05:15:58.413954: val_loss -0.9761\n",
            "2025-12-23 05:15:58.414039: Pseudo dice [np.float32(0.9808)]\n",
            "2025-12-23 05:15:58.414125: Epoch time: 22.45 s\n",
            "2025-12-23 05:15:58.414196: Yayy! New best EMA pseudo Dice: 0.9728000164031982\n",
            "2025-12-23 05:16:00.239404: \n",
            "2025-12-23 05:16:00.239723: Epoch 48\n",
            "2025-12-23 05:16:00.239860: Current learning rate: 0.00957\n",
            "2025-12-23 05:16:22.701663: train_loss -0.963\n",
            "2025-12-23 05:16:22.701869: val_loss -0.9737\n",
            "2025-12-23 05:16:22.701957: Pseudo dice [np.float32(0.9801)]\n",
            "2025-12-23 05:16:22.702046: Epoch time: 22.46 s\n",
            "2025-12-23 05:16:22.702119: Yayy! New best EMA pseudo Dice: 0.9735000133514404\n",
            "2025-12-23 05:16:24.546766: \n",
            "2025-12-23 05:16:24.547008: Epoch 49\n",
            "2025-12-23 05:16:24.547163: Current learning rate: 0.00956\n",
            "2025-12-23 05:16:47.036914: train_loss -0.9636\n",
            "2025-12-23 05:16:47.037335: val_loss -0.9752\n",
            "2025-12-23 05:16:47.037502: Pseudo dice [np.float32(0.9819)]\n",
            "2025-12-23 05:16:47.037641: Epoch time: 22.49 s\n",
            "2025-12-23 05:16:47.344716: Yayy! New best EMA pseudo Dice: 0.974399983882904\n",
            "2025-12-23 05:16:49.173016: \n",
            "2025-12-23 05:16:49.173304: Epoch 50\n",
            "2025-12-23 05:16:49.173449: Current learning rate: 0.00955\n",
            "2025-12-23 05:17:11.664741: train_loss -0.963\n",
            "2025-12-23 05:17:11.664946: val_loss -0.974\n",
            "2025-12-23 05:17:11.665089: Pseudo dice [np.float32(0.9795)]\n",
            "2025-12-23 05:17:11.665186: Epoch time: 22.49 s\n",
            "2025-12-23 05:17:11.665324: Yayy! New best EMA pseudo Dice: 0.9749000072479248\n",
            "2025-12-23 05:17:13.486762: \n",
            "2025-12-23 05:17:13.487079: Epoch 51\n",
            "2025-12-23 05:17:13.487305: Current learning rate: 0.00954\n",
            "2025-12-23 05:17:35.896086: train_loss -0.9639\n",
            "2025-12-23 05:17:35.896293: val_loss -0.9735\n",
            "2025-12-23 05:17:35.896382: Pseudo dice [np.float32(0.9791)]\n",
            "2025-12-23 05:17:35.896471: Epoch time: 22.41 s\n",
            "2025-12-23 05:17:35.896551: Yayy! New best EMA pseudo Dice: 0.9753000140190125\n",
            "2025-12-23 05:17:37.718334: \n",
            "2025-12-23 05:17:37.718528: Epoch 52\n",
            "2025-12-23 05:17:37.718656: Current learning rate: 0.00953\n",
            "2025-12-23 05:18:00.207390: train_loss -0.9645\n",
            "2025-12-23 05:18:00.207821: val_loss -0.9781\n",
            "2025-12-23 05:18:00.207954: Pseudo dice [np.float32(0.9838)]\n",
            "2025-12-23 05:18:00.208081: Epoch time: 22.49 s\n",
            "2025-12-23 05:18:00.208191: Yayy! New best EMA pseudo Dice: 0.9761999845504761\n",
            "2025-12-23 05:18:02.078082: \n",
            "2025-12-23 05:18:02.078382: Epoch 53\n",
            "2025-12-23 05:18:02.078526: Current learning rate: 0.00952\n",
            "2025-12-23 05:18:24.521604: train_loss -0.9642\n",
            "2025-12-23 05:18:24.521870: val_loss -0.9758\n",
            "2025-12-23 05:18:24.522037: Pseudo dice [np.float32(0.9816)]\n",
            "2025-12-23 05:18:24.522135: Epoch time: 22.44 s\n",
            "2025-12-23 05:18:24.522241: Yayy! New best EMA pseudo Dice: 0.9767000079154968\n",
            "2025-12-23 05:18:26.383473: \n",
            "2025-12-23 05:18:26.383752: Epoch 54\n",
            "2025-12-23 05:18:26.383890: Current learning rate: 0.00951\n",
            "2025-12-23 05:18:48.856918: train_loss -0.9634\n",
            "2025-12-23 05:18:48.857171: val_loss -0.9737\n",
            "2025-12-23 05:18:48.857302: Pseudo dice [np.float32(0.9792)]\n",
            "2025-12-23 05:18:48.857404: Epoch time: 22.47 s\n",
            "2025-12-23 05:18:48.857505: Yayy! New best EMA pseudo Dice: 0.9769999980926514\n",
            "2025-12-23 05:18:50.708192: \n",
            "2025-12-23 05:18:50.708520: Epoch 55\n",
            "2025-12-23 05:18:50.708684: Current learning rate: 0.0095\n",
            "2025-12-23 05:19:13.215692: train_loss -0.9632\n",
            "2025-12-23 05:19:13.215937: val_loss -0.9744\n",
            "2025-12-23 05:19:13.216050: Pseudo dice [np.float32(0.9806)]\n",
            "2025-12-23 05:19:13.216165: Epoch time: 22.51 s\n",
            "2025-12-23 05:19:13.216358: Yayy! New best EMA pseudo Dice: 0.9772999882698059\n",
            "2025-12-23 05:19:15.062137: \n",
            "2025-12-23 05:19:15.062337: Epoch 56\n",
            "2025-12-23 05:19:15.062481: Current learning rate: 0.00949\n",
            "2025-12-23 05:19:37.529430: train_loss -0.9643\n",
            "2025-12-23 05:19:37.529648: val_loss -0.9764\n",
            "2025-12-23 05:19:37.529773: Pseudo dice [np.float32(0.9816)]\n",
            "2025-12-23 05:19:37.529872: Epoch time: 22.47 s\n",
            "2025-12-23 05:19:37.529947: Yayy! New best EMA pseudo Dice: 0.9776999950408936\n",
            "2025-12-23 05:19:39.789177: \n",
            "2025-12-23 05:19:39.789366: Epoch 57\n",
            "2025-12-23 05:19:39.789499: Current learning rate: 0.00949\n",
            "2025-12-23 05:20:02.286669: train_loss -0.9657\n",
            "2025-12-23 05:20:02.286987: val_loss -0.9759\n",
            "2025-12-23 05:20:02.287130: Pseudo dice [np.float32(0.9808)]\n",
            "2025-12-23 05:20:02.287287: Epoch time: 22.5 s\n",
            "2025-12-23 05:20:02.287405: Yayy! New best EMA pseudo Dice: 0.9779999852180481\n",
            "2025-12-23 05:20:04.134172: \n",
            "2025-12-23 05:20:04.134510: Epoch 58\n",
            "2025-12-23 05:20:04.134655: Current learning rate: 0.00948\n",
            "2025-12-23 05:20:26.625762: train_loss -0.9648\n",
            "2025-12-23 05:20:26.625962: val_loss -0.9754\n",
            "2025-12-23 05:20:26.626049: Pseudo dice [np.float32(0.9805)]\n",
            "2025-12-23 05:20:26.626135: Epoch time: 22.49 s\n",
            "2025-12-23 05:20:26.626208: Yayy! New best EMA pseudo Dice: 0.9782999753952026\n",
            "2025-12-23 05:20:28.446260: \n",
            "2025-12-23 05:20:28.446487: Epoch 59\n",
            "2025-12-23 05:20:28.446624: Current learning rate: 0.00947\n",
            "2025-12-23 05:20:50.915753: train_loss -0.9656\n",
            "2025-12-23 05:20:50.915976: val_loss -0.9767\n",
            "2025-12-23 05:20:50.916095: Pseudo dice [np.float32(0.9832)]\n",
            "2025-12-23 05:20:50.916213: Epoch time: 22.47 s\n",
            "2025-12-23 05:20:50.916341: Yayy! New best EMA pseudo Dice: 0.9787999987602234\n",
            "2025-12-23 05:20:52.736576: \n",
            "2025-12-23 05:20:52.736899: Epoch 60\n",
            "2025-12-23 05:20:52.737062: Current learning rate: 0.00946\n",
            "2025-12-23 05:21:15.145043: train_loss -0.9657\n",
            "2025-12-23 05:21:15.145261: val_loss -0.9772\n",
            "2025-12-23 05:21:15.145375: Pseudo dice [np.float32(0.9826)]\n",
            "2025-12-23 05:21:15.145475: Epoch time: 22.41 s\n",
            "2025-12-23 05:21:15.145552: Yayy! New best EMA pseudo Dice: 0.979200005531311\n",
            "2025-12-23 05:21:16.983765: \n",
            "2025-12-23 05:21:16.984093: Epoch 61\n",
            "2025-12-23 05:21:16.984249: Current learning rate: 0.00945\n",
            "2025-12-23 05:21:39.499047: train_loss -0.9653\n",
            "2025-12-23 05:21:39.499367: val_loss -0.978\n",
            "2025-12-23 05:21:39.499474: Pseudo dice [np.float32(0.9837)]\n",
            "2025-12-23 05:21:39.499571: Epoch time: 22.52 s\n",
            "2025-12-23 05:21:39.499660: Yayy! New best EMA pseudo Dice: 0.9796000123023987\n",
            "2025-12-23 05:21:41.359208: \n",
            "2025-12-23 05:21:41.359664: Epoch 62\n",
            "2025-12-23 05:21:41.359805: Current learning rate: 0.00944\n",
            "2025-12-23 05:22:03.783561: train_loss -0.9675\n",
            "2025-12-23 05:22:03.783854: val_loss -0.9785\n",
            "2025-12-23 05:22:03.783946: Pseudo dice [np.float32(0.9845)]\n",
            "2025-12-23 05:22:03.784034: Epoch time: 22.43 s\n",
            "2025-12-23 05:22:03.784107: Yayy! New best EMA pseudo Dice: 0.9800999760627747\n",
            "2025-12-23 05:22:05.620312: \n",
            "2025-12-23 05:22:05.620676: Epoch 63\n",
            "2025-12-23 05:22:05.620815: Current learning rate: 0.00943\n",
            "2025-12-23 05:22:28.109277: train_loss -0.9655\n",
            "2025-12-23 05:22:28.109542: val_loss -0.976\n",
            "2025-12-23 05:22:28.109697: Pseudo dice [np.float32(0.9821)]\n",
            "2025-12-23 05:22:28.109854: Epoch time: 22.49 s\n",
            "2025-12-23 05:22:28.109966: Yayy! New best EMA pseudo Dice: 0.9803000092506409\n",
            "2025-12-23 05:22:29.998284: \n",
            "2025-12-23 05:22:29.998590: Epoch 64\n",
            "2025-12-23 05:22:29.998721: Current learning rate: 0.00942\n",
            "2025-12-23 05:22:52.466736: train_loss -0.9666\n",
            "2025-12-23 05:22:52.466947: val_loss -0.9767\n",
            "2025-12-23 05:22:52.467033: Pseudo dice [np.float32(0.9815)]\n",
            "2025-12-23 05:22:52.467122: Epoch time: 22.47 s\n",
            "2025-12-23 05:22:52.467199: Yayy! New best EMA pseudo Dice: 0.980400025844574\n",
            "2025-12-23 05:22:54.299374: \n",
            "2025-12-23 05:22:54.299628: Epoch 65\n",
            "2025-12-23 05:22:54.299763: Current learning rate: 0.00941\n",
            "2025-12-23 05:23:16.725639: train_loss -0.9657\n",
            "2025-12-23 05:23:16.725886: val_loss -0.9764\n",
            "2025-12-23 05:23:16.726005: Pseudo dice [np.float32(0.9826)]\n",
            "2025-12-23 05:23:16.726102: Epoch time: 22.43 s\n",
            "2025-12-23 05:23:16.726176: Yayy! New best EMA pseudo Dice: 0.9805999994277954\n",
            "2025-12-23 05:23:18.580932: \n",
            "2025-12-23 05:23:18.581235: Epoch 66\n",
            "2025-12-23 05:23:18.581393: Current learning rate: 0.0094\n",
            "2025-12-23 05:23:41.037203: train_loss -0.9664\n",
            "2025-12-23 05:23:41.037458: val_loss -0.9794\n",
            "2025-12-23 05:23:41.037584: Pseudo dice [np.float32(0.9848)]\n",
            "2025-12-23 05:23:41.037702: Epoch time: 22.46 s\n",
            "2025-12-23 05:23:41.037865: Yayy! New best EMA pseudo Dice: 0.9811000227928162\n",
            "2025-12-23 05:23:42.921073: \n",
            "2025-12-23 05:23:42.921259: Epoch 67\n",
            "2025-12-23 05:23:42.921393: Current learning rate: 0.00939\n",
            "2025-12-23 05:24:05.393449: train_loss -0.9665\n",
            "2025-12-23 05:24:05.393830: val_loss -0.977\n",
            "2025-12-23 05:24:05.393943: Pseudo dice [np.float32(0.9828)]\n",
            "2025-12-23 05:24:05.394043: Epoch time: 22.47 s\n",
            "2025-12-23 05:24:05.394116: Yayy! New best EMA pseudo Dice: 0.9811999797821045\n",
            "2025-12-23 05:24:07.247168: \n",
            "2025-12-23 05:24:07.247370: Epoch 68\n",
            "2025-12-23 05:24:07.247506: Current learning rate: 0.00939\n",
            "2025-12-23 05:24:29.748645: train_loss -0.9669\n",
            "2025-12-23 05:24:29.748892: val_loss -0.9774\n",
            "2025-12-23 05:24:29.749029: Pseudo dice [np.float32(0.9827)]\n",
            "2025-12-23 05:24:29.749127: Epoch time: 22.5 s\n",
            "2025-12-23 05:24:29.749202: Yayy! New best EMA pseudo Dice: 0.9814000129699707\n",
            "2025-12-23 05:24:31.611145: \n",
            "2025-12-23 05:24:31.611398: Epoch 69\n",
            "2025-12-23 05:24:31.611549: Current learning rate: 0.00938\n",
            "2025-12-23 05:24:54.507470: train_loss -0.9673\n",
            "2025-12-23 05:24:54.507817: val_loss -0.978\n",
            "2025-12-23 05:24:54.507976: Pseudo dice [np.float32(0.9852)]\n",
            "2025-12-23 05:24:54.508208: Epoch time: 22.9 s\n",
            "2025-12-23 05:24:54.508376: Yayy! New best EMA pseudo Dice: 0.9818000197410583\n",
            "2025-12-23 05:24:56.365109: \n",
            "2025-12-23 05:24:56.365341: Epoch 70\n",
            "2025-12-23 05:24:56.365512: Current learning rate: 0.00937\n",
            "2025-12-23 05:25:18.876442: train_loss -0.9664\n",
            "2025-12-23 05:25:18.876857: val_loss -0.9781\n",
            "2025-12-23 05:25:18.877046: Pseudo dice [np.float32(0.9839)]\n",
            "2025-12-23 05:25:18.877200: Epoch time: 22.51 s\n",
            "2025-12-23 05:25:18.877340: Yayy! New best EMA pseudo Dice: 0.9819999933242798\n",
            "2025-12-23 05:25:20.734703: \n",
            "2025-12-23 05:25:20.735080: Epoch 71\n",
            "2025-12-23 05:25:20.735234: Current learning rate: 0.00936\n",
            "2025-12-23 05:25:43.189762: train_loss -0.9673\n",
            "2025-12-23 05:25:43.190017: val_loss -0.9776\n",
            "2025-12-23 05:25:43.190106: Pseudo dice [np.float32(0.9831)]\n",
            "2025-12-23 05:25:43.190203: Epoch time: 22.46 s\n",
            "2025-12-23 05:25:43.190315: Yayy! New best EMA pseudo Dice: 0.9821000099182129\n",
            "2025-12-23 05:25:45.044250: \n",
            "2025-12-23 05:25:45.044597: Epoch 72\n",
            "2025-12-23 05:25:45.044730: Current learning rate: 0.00935\n",
            "2025-12-23 05:26:07.526045: train_loss -0.9656\n",
            "2025-12-23 05:26:07.526299: val_loss -0.9755\n",
            "2025-12-23 05:26:07.526398: Pseudo dice [np.float32(0.9791)]\n",
            "2025-12-23 05:26:07.526495: Epoch time: 22.48 s\n",
            "2025-12-23 05:26:08.876928: \n",
            "2025-12-23 05:26:08.877153: Epoch 73\n",
            "2025-12-23 05:26:08.877300: Current learning rate: 0.00934\n",
            "2025-12-23 05:26:31.346004: train_loss -0.9655\n",
            "2025-12-23 05:26:31.346413: val_loss -0.9762\n",
            "2025-12-23 05:26:31.346544: Pseudo dice [np.float32(0.9819)]\n",
            "2025-12-23 05:26:31.346670: Epoch time: 22.47 s\n",
            "2025-12-23 05:26:32.688665: \n",
            "2025-12-23 05:26:32.688938: Epoch 74\n",
            "2025-12-23 05:26:32.689096: Current learning rate: 0.00933\n",
            "2025-12-23 05:26:55.174987: train_loss -0.9655\n",
            "2025-12-23 05:26:55.175317: val_loss -0.9754\n",
            "2025-12-23 05:26:55.175420: Pseudo dice [np.float32(0.9811)]\n",
            "2025-12-23 05:26:55.175509: Epoch time: 22.49 s\n",
            "2025-12-23 05:26:56.535311: \n",
            "2025-12-23 05:26:56.535571: Epoch 75\n",
            "2025-12-23 05:26:56.535721: Current learning rate: 0.00932\n",
            "2025-12-23 05:27:19.030452: train_loss -0.9648\n",
            "2025-12-23 05:27:19.030702: val_loss -0.977\n",
            "2025-12-23 05:27:19.030828: Pseudo dice [np.float32(0.9824)]\n",
            "2025-12-23 05:27:19.031090: Epoch time: 22.5 s\n",
            "2025-12-23 05:27:20.408996: \n",
            "2025-12-23 05:27:20.409162: Epoch 76\n",
            "2025-12-23 05:27:20.409302: Current learning rate: 0.00931\n",
            "2025-12-23 05:27:42.868860: train_loss -0.9654\n",
            "2025-12-23 05:27:42.869068: val_loss -0.9792\n",
            "2025-12-23 05:27:42.869187: Pseudo dice [np.float32(0.9844)]\n",
            "2025-12-23 05:27:42.869385: Epoch time: 22.46 s\n",
            "2025-12-23 05:27:44.250227: \n",
            "2025-12-23 05:27:44.250564: Epoch 77\n",
            "2025-12-23 05:27:44.250696: Current learning rate: 0.0093\n",
            "2025-12-23 05:28:06.685343: train_loss -0.9665\n",
            "2025-12-23 05:28:06.685684: val_loss -0.9771\n",
            "2025-12-23 05:28:06.685782: Pseudo dice [np.float32(0.9831)]\n",
            "2025-12-23 05:28:06.685874: Epoch time: 22.44 s\n",
            "2025-12-23 05:28:06.685975: Yayy! New best EMA pseudo Dice: 0.982200026512146\n",
            "2025-12-23 05:28:08.553458: \n",
            "2025-12-23 05:28:08.553671: Epoch 78\n",
            "2025-12-23 05:28:08.553805: Current learning rate: 0.0093\n",
            "2025-12-23 05:28:31.037522: train_loss -0.9663\n",
            "2025-12-23 05:28:31.037765: val_loss -0.9761\n",
            "2025-12-23 05:28:31.037863: Pseudo dice [np.float32(0.9806)]\n",
            "2025-12-23 05:28:31.037990: Epoch time: 22.49 s\n",
            "2025-12-23 05:28:32.417084: \n",
            "2025-12-23 05:28:32.417343: Epoch 79\n",
            "2025-12-23 05:28:32.417484: Current learning rate: 0.00929\n",
            "2025-12-23 05:28:54.818470: train_loss -0.9633\n",
            "2025-12-23 05:28:54.818783: val_loss -0.9762\n",
            "2025-12-23 05:28:54.819025: Pseudo dice [np.float32(0.9815)]\n",
            "2025-12-23 05:28:54.819182: Epoch time: 22.4 s\n",
            "2025-12-23 05:28:56.209855: \n",
            "2025-12-23 05:28:56.210132: Epoch 80\n",
            "2025-12-23 05:28:56.210276: Current learning rate: 0.00928\n",
            "2025-12-23 05:29:18.609942: train_loss -0.9668\n",
            "2025-12-23 05:29:18.610133: val_loss -0.9787\n",
            "2025-12-23 05:29:18.610286: Pseudo dice [np.float32(0.9833)]\n",
            "2025-12-23 05:29:18.610393: Epoch time: 22.4 s\n",
            "2025-12-23 05:29:19.973179: \n",
            "2025-12-23 05:29:19.973344: Epoch 81\n",
            "2025-12-23 05:29:19.973497: Current learning rate: 0.00927\n",
            "2025-12-23 05:29:42.374481: train_loss -0.9617\n",
            "2025-12-23 05:29:42.374690: val_loss -0.9746\n",
            "2025-12-23 05:29:42.374778: Pseudo dice [np.float32(0.9822)]\n",
            "2025-12-23 05:29:42.374877: Epoch time: 22.4 s\n",
            "2025-12-23 05:29:43.738357: \n",
            "2025-12-23 05:29:43.738592: Epoch 82\n",
            "2025-12-23 05:29:43.738761: Current learning rate: 0.00926\n",
            "2025-12-23 05:30:06.166315: train_loss -0.9629\n",
            "2025-12-23 05:30:06.166580: val_loss -0.9742\n",
            "2025-12-23 05:30:06.166671: Pseudo dice [np.float32(0.983)]\n",
            "2025-12-23 05:30:06.166759: Epoch time: 22.43 s\n",
            "2025-12-23 05:30:06.166837: Yayy! New best EMA pseudo Dice: 0.982200026512146\n",
            "2025-12-23 05:30:08.481287: \n",
            "2025-12-23 05:30:08.481501: Epoch 83\n",
            "2025-12-23 05:30:08.481638: Current learning rate: 0.00925\n",
            "2025-12-23 05:30:31.025008: train_loss -0.9652\n",
            "2025-12-23 05:30:31.025499: val_loss -0.9777\n",
            "2025-12-23 05:30:31.025629: Pseudo dice [np.float32(0.9838)]\n",
            "2025-12-23 05:30:31.025716: Epoch time: 22.55 s\n",
            "2025-12-23 05:30:31.025788: Yayy! New best EMA pseudo Dice: 0.9822999835014343\n",
            "2025-12-23 05:30:32.918199: \n",
            "2025-12-23 05:30:32.918597: Epoch 84\n",
            "2025-12-23 05:30:32.918744: Current learning rate: 0.00924\n",
            "2025-12-23 05:30:55.382292: train_loss -0.9657\n",
            "2025-12-23 05:30:55.382498: val_loss -0.9767\n",
            "2025-12-23 05:30:55.382587: Pseudo dice [np.float32(0.9829)]\n",
            "2025-12-23 05:30:55.382675: Epoch time: 22.47 s\n",
            "2025-12-23 05:30:55.382749: Yayy! New best EMA pseudo Dice: 0.9824000000953674\n",
            "2025-12-23 05:30:57.231939: \n",
            "2025-12-23 05:30:57.232135: Epoch 85\n",
            "2025-12-23 05:30:57.232274: Current learning rate: 0.00923\n",
            "2025-12-23 05:31:19.738354: train_loss -0.9654\n",
            "2025-12-23 05:31:19.738625: val_loss -0.9772\n",
            "2025-12-23 05:31:19.738723: Pseudo dice [np.float32(0.9824)]\n",
            "2025-12-23 05:31:19.738842: Epoch time: 22.51 s\n",
            "2025-12-23 05:31:19.738963: Yayy! New best EMA pseudo Dice: 0.9824000000953674\n",
            "2025-12-23 05:31:21.605122: \n",
            "2025-12-23 05:31:21.605411: Epoch 86\n",
            "2025-12-23 05:31:21.605555: Current learning rate: 0.00922\n",
            "2025-12-23 05:31:44.042419: train_loss -0.9624\n",
            "2025-12-23 05:31:44.042717: val_loss -0.9743\n",
            "2025-12-23 05:31:44.042820: Pseudo dice [np.float32(0.9801)]\n",
            "2025-12-23 05:31:44.042912: Epoch time: 22.44 s\n",
            "2025-12-23 05:31:45.344796: \n",
            "2025-12-23 05:31:45.345064: Epoch 87\n",
            "2025-12-23 05:31:45.345196: Current learning rate: 0.00921\n",
            "2025-12-23 05:32:07.767743: train_loss -0.9601\n",
            "2025-12-23 05:32:07.767987: val_loss -0.9737\n",
            "2025-12-23 05:32:07.768169: Pseudo dice [np.float32(0.9802)]\n",
            "2025-12-23 05:32:07.768330: Epoch time: 22.42 s\n",
            "2025-12-23 05:32:09.116559: \n",
            "2025-12-23 05:32:09.116845: Epoch 88\n",
            "2025-12-23 05:32:09.116996: Current learning rate: 0.0092\n",
            "2025-12-23 05:32:31.578166: train_loss -0.9533\n",
            "2025-12-23 05:32:31.578474: val_loss -0.972\n",
            "2025-12-23 05:32:31.578579: Pseudo dice [np.float32(0.977)]\n",
            "2025-12-23 05:32:31.578675: Epoch time: 22.46 s\n",
            "2025-12-23 05:32:32.921628: \n",
            "2025-12-23 05:32:32.921925: Epoch 89\n",
            "2025-12-23 05:32:32.922075: Current learning rate: 0.0092\n",
            "2025-12-23 05:32:55.398344: train_loss -0.9599\n",
            "2025-12-23 05:32:55.398731: val_loss -0.9728\n",
            "2025-12-23 05:32:55.398852: Pseudo dice [np.float32(0.9807)]\n",
            "2025-12-23 05:32:55.398975: Epoch time: 22.48 s\n",
            "2025-12-23 05:32:56.747818: \n",
            "2025-12-23 05:32:56.748170: Epoch 90\n",
            "2025-12-23 05:32:56.748352: Current learning rate: 0.00919\n",
            "2025-12-23 05:33:19.188510: train_loss -0.9565\n",
            "2025-12-23 05:33:19.188736: val_loss -0.9691\n",
            "2025-12-23 05:33:19.188859: Pseudo dice [np.float32(0.976)]\n",
            "2025-12-23 05:33:19.188977: Epoch time: 22.44 s\n",
            "2025-12-23 05:33:20.513474: \n",
            "2025-12-23 05:33:20.513636: Epoch 91\n",
            "2025-12-23 05:33:20.513762: Current learning rate: 0.00918\n",
            "2025-12-23 05:33:42.954953: train_loss -0.9533\n",
            "2025-12-23 05:33:42.955162: val_loss -0.969\n",
            "2025-12-23 05:33:42.955275: Pseudo dice [np.float32(0.9767)]\n",
            "2025-12-23 05:33:42.955377: Epoch time: 22.44 s\n",
            "2025-12-23 05:33:44.253084: \n",
            "2025-12-23 05:33:44.253367: Epoch 92\n",
            "2025-12-23 05:33:44.253507: Current learning rate: 0.00917\n",
            "2025-12-23 05:34:06.675759: train_loss -0.9548\n",
            "2025-12-23 05:34:06.675966: val_loss -0.9714\n",
            "2025-12-23 05:34:06.676053: Pseudo dice [np.float32(0.9777)]\n",
            "2025-12-23 05:34:06.676145: Epoch time: 22.42 s\n",
            "2025-12-23 05:34:08.001880: \n",
            "2025-12-23 05:34:08.002085: Epoch 93\n",
            "2025-12-23 05:34:08.002236: Current learning rate: 0.00916\n",
            "2025-12-23 05:34:30.440875: train_loss -0.9584\n",
            "2025-12-23 05:34:30.441078: val_loss -0.9712\n",
            "2025-12-23 05:34:30.441165: Pseudo dice [np.float32(0.9795)]\n",
            "2025-12-23 05:34:30.441287: Epoch time: 22.44 s\n",
            "2025-12-23 05:34:31.797129: \n",
            "2025-12-23 05:34:31.797500: Epoch 94\n",
            "2025-12-23 05:34:31.797656: Current learning rate: 0.00915\n",
            "2025-12-23 05:34:54.290445: train_loss -0.9484\n",
            "2025-12-23 05:34:54.290707: val_loss -0.9627\n",
            "2025-12-23 05:34:54.290799: Pseudo dice [np.float32(0.9667)]\n",
            "2025-12-23 05:34:54.290904: Epoch time: 22.49 s\n",
            "2025-12-23 05:34:55.651726: \n",
            "2025-12-23 05:34:55.652107: Epoch 95\n",
            "2025-12-23 05:34:55.652277: Current learning rate: 0.00914\n",
            "2025-12-23 05:35:18.104424: train_loss -0.956\n",
            "2025-12-23 05:35:18.104617: val_loss -0.9699\n",
            "2025-12-23 05:35:18.104706: Pseudo dice [np.float32(0.9772)]\n",
            "2025-12-23 05:35:18.104794: Epoch time: 22.45 s\n",
            "2025-12-23 05:35:19.414637: \n",
            "2025-12-23 05:35:19.414915: Epoch 96\n",
            "2025-12-23 05:35:19.415047: Current learning rate: 0.00913\n",
            "2025-12-23 05:35:42.427762: train_loss -0.9598\n",
            "2025-12-23 05:35:42.427966: val_loss -0.9742\n",
            "2025-12-23 05:35:42.428064: Pseudo dice [np.float32(0.9808)]\n",
            "2025-12-23 05:35:42.428179: Epoch time: 23.01 s\n",
            "2025-12-23 05:35:43.720691: \n",
            "2025-12-23 05:35:43.720923: Epoch 97\n",
            "2025-12-23 05:35:43.721092: Current learning rate: 0.00912\n",
            "2025-12-23 05:36:06.236949: train_loss -0.9636\n",
            "2025-12-23 05:36:06.237159: val_loss -0.9771\n",
            "2025-12-23 05:36:06.237315: Pseudo dice [np.float32(0.9816)]\n",
            "2025-12-23 05:36:06.237473: Epoch time: 22.52 s\n",
            "2025-12-23 05:36:07.588007: \n",
            "2025-12-23 05:36:07.588318: Epoch 98\n",
            "2025-12-23 05:36:07.588454: Current learning rate: 0.00911\n",
            "2025-12-23 05:36:30.038761: train_loss -0.9647\n",
            "2025-12-23 05:36:30.039007: val_loss -0.9759\n",
            "2025-12-23 05:36:30.039102: Pseudo dice [np.float32(0.9813)]\n",
            "2025-12-23 05:36:30.039191: Epoch time: 22.45 s\n",
            "2025-12-23 05:36:31.343168: \n",
            "2025-12-23 05:36:31.343508: Epoch 99\n",
            "2025-12-23 05:36:31.343654: Current learning rate: 0.0091\n",
            "2025-12-23 05:36:53.813774: train_loss -0.9644\n",
            "2025-12-23 05:36:53.813984: val_loss -0.9764\n",
            "2025-12-23 05:36:53.814070: Pseudo dice [np.float32(0.9828)]\n",
            "2025-12-23 05:36:53.814157: Epoch time: 22.47 s\n",
            "2025-12-23 05:36:55.632986: \n",
            "2025-12-23 05:36:55.633235: Epoch 100\n",
            "2025-12-23 05:36:55.633380: Current learning rate: 0.0091\n",
            "2025-12-23 05:37:18.128866: train_loss -0.9656\n",
            "2025-12-23 05:37:18.129180: val_loss -0.9784\n",
            "2025-12-23 05:37:18.129394: Pseudo dice [np.float32(0.9846)]\n",
            "2025-12-23 05:37:18.129518: Epoch time: 22.5 s\n",
            "2025-12-23 05:37:19.465291: \n",
            "2025-12-23 05:37:19.465656: Epoch 101\n",
            "2025-12-23 05:37:19.465812: Current learning rate: 0.00909\n",
            "2025-12-23 05:37:41.991867: train_loss -0.9651\n",
            "2025-12-23 05:37:41.992082: val_loss -0.9793\n",
            "2025-12-23 05:37:41.992169: Pseudo dice [np.float32(0.9842)]\n",
            "2025-12-23 05:37:41.992301: Epoch time: 22.53 s\n",
            "2025-12-23 05:37:43.343398: \n",
            "2025-12-23 05:37:43.343765: Epoch 102\n",
            "2025-12-23 05:37:43.343918: Current learning rate: 0.00908\n",
            "2025-12-23 05:38:05.827368: train_loss -0.9662\n",
            "2025-12-23 05:38:05.827625: val_loss -0.9781\n",
            "2025-12-23 05:38:05.827715: Pseudo dice [np.float32(0.9846)]\n",
            "2025-12-23 05:38:05.827808: Epoch time: 22.49 s\n",
            "2025-12-23 05:38:07.163865: \n",
            "2025-12-23 05:38:07.164168: Epoch 103\n",
            "2025-12-23 05:38:07.164337: Current learning rate: 0.00907\n",
            "2025-12-23 05:38:29.596396: train_loss -0.9652\n",
            "2025-12-23 05:38:29.596624: val_loss -0.978\n",
            "2025-12-23 05:38:29.596735: Pseudo dice [np.float32(0.9832)]\n",
            "2025-12-23 05:38:29.596878: Epoch time: 22.43 s\n",
            "2025-12-23 05:38:30.943199: \n",
            "2025-12-23 05:38:30.943543: Epoch 104\n",
            "2025-12-23 05:38:30.943698: Current learning rate: 0.00906\n",
            "2025-12-23 05:38:53.431399: train_loss -0.9663\n",
            "2025-12-23 05:38:53.431635: val_loss -0.9798\n",
            "2025-12-23 05:38:53.431740: Pseudo dice [np.float32(0.9846)]\n",
            "2025-12-23 05:38:53.431863: Epoch time: 22.49 s\n",
            "2025-12-23 05:38:54.755343: \n",
            "2025-12-23 05:38:54.755668: Epoch 105\n",
            "2025-12-23 05:38:54.755804: Current learning rate: 0.00905\n",
            "2025-12-23 05:39:17.259520: train_loss -0.9652\n",
            "2025-12-23 05:39:17.259730: val_loss -0.9721\n",
            "2025-12-23 05:39:17.259819: Pseudo dice [np.float32(0.9777)]\n",
            "2025-12-23 05:39:17.259907: Epoch time: 22.51 s\n",
            "2025-12-23 05:39:18.584323: \n",
            "2025-12-23 05:39:18.584671: Epoch 106\n",
            "2025-12-23 05:39:18.584815: Current learning rate: 0.00904\n",
            "2025-12-23 05:39:41.017159: train_loss -0.9669\n",
            "2025-12-23 05:39:41.017395: val_loss -0.9791\n",
            "2025-12-23 05:39:41.017497: Pseudo dice [np.float32(0.9837)]\n",
            "2025-12-23 05:39:41.017617: Epoch time: 22.43 s\n",
            "2025-12-23 05:39:42.351628: \n",
            "2025-12-23 05:39:42.351832: Epoch 107\n",
            "2025-12-23 05:39:42.351964: Current learning rate: 0.00903\n",
            "2025-12-23 05:40:04.801813: train_loss -0.9666\n",
            "2025-12-23 05:40:04.802025: val_loss -0.9787\n",
            "2025-12-23 05:40:04.802112: Pseudo dice [np.float32(0.985)]\n",
            "2025-12-23 05:40:04.802198: Epoch time: 22.45 s\n",
            "2025-12-23 05:40:06.167719: \n",
            "2025-12-23 05:40:06.167999: Epoch 108\n",
            "2025-12-23 05:40:06.168127: Current learning rate: 0.00902\n",
            "2025-12-23 05:40:28.614209: train_loss -0.9622\n",
            "2025-12-23 05:40:28.614481: val_loss -0.9753\n",
            "2025-12-23 05:40:28.614591: Pseudo dice [np.float32(0.9806)]\n",
            "2025-12-23 05:40:28.614683: Epoch time: 22.45 s\n",
            "2025-12-23 05:40:29.943575: \n",
            "2025-12-23 05:40:29.943806: Epoch 109\n",
            "2025-12-23 05:40:29.943937: Current learning rate: 0.00901\n",
            "2025-12-23 05:40:52.383324: train_loss -0.9636\n",
            "2025-12-23 05:40:52.383560: val_loss -0.9774\n",
            "2025-12-23 05:40:52.383648: Pseudo dice [np.float32(0.9839)]\n",
            "2025-12-23 05:40:52.383805: Epoch time: 22.44 s\n",
            "2025-12-23 05:40:54.154611: \n",
            "2025-12-23 05:40:54.154978: Epoch 110\n",
            "2025-12-23 05:40:54.155117: Current learning rate: 0.009\n",
            "2025-12-23 05:41:16.646961: train_loss -0.9621\n",
            "2025-12-23 05:41:16.647212: val_loss -0.9767\n",
            "2025-12-23 05:41:16.647365: Pseudo dice [np.float32(0.9837)]\n",
            "2025-12-23 05:41:16.647530: Epoch time: 22.49 s\n",
            "2025-12-23 05:41:17.976656: \n",
            "2025-12-23 05:41:17.976877: Epoch 111\n",
            "2025-12-23 05:41:17.977015: Current learning rate: 0.009\n",
            "2025-12-23 05:41:40.474949: train_loss -0.9655\n",
            "2025-12-23 05:41:40.475179: val_loss -0.9773\n",
            "2025-12-23 05:41:40.475331: Pseudo dice [np.float32(0.9832)]\n",
            "2025-12-23 05:41:40.475461: Epoch time: 22.5 s\n",
            "2025-12-23 05:41:41.784395: \n",
            "2025-12-23 05:41:41.784834: Epoch 112\n",
            "2025-12-23 05:41:41.784975: Current learning rate: 0.00899\n",
            "2025-12-23 05:42:04.310521: train_loss -0.9657\n",
            "2025-12-23 05:42:04.310723: val_loss -0.9781\n",
            "2025-12-23 05:42:04.310809: Pseudo dice [np.float32(0.9845)]\n",
            "2025-12-23 05:42:04.310897: Epoch time: 22.53 s\n",
            "2025-12-23 05:42:05.629333: \n",
            "2025-12-23 05:42:05.629541: Epoch 113\n",
            "2025-12-23 05:42:05.629671: Current learning rate: 0.00898\n",
            "2025-12-23 05:42:28.130003: train_loss -0.963\n",
            "2025-12-23 05:42:28.130294: val_loss -0.9771\n",
            "2025-12-23 05:42:28.130404: Pseudo dice [np.float32(0.9839)]\n",
            "2025-12-23 05:42:28.130500: Epoch time: 22.5 s\n",
            "2025-12-23 05:42:28.130576: Yayy! New best EMA pseudo Dice: 0.9825000166893005\n",
            "2025-12-23 05:42:29.980383: \n",
            "2025-12-23 05:42:29.980644: Epoch 114\n",
            "2025-12-23 05:42:29.980778: Current learning rate: 0.00897\n",
            "2025-12-23 05:42:52.464001: train_loss -0.9652\n",
            "2025-12-23 05:42:52.464322: val_loss -0.9776\n",
            "2025-12-23 05:42:52.464435: Pseudo dice [np.float32(0.9829)]\n",
            "2025-12-23 05:42:52.464534: Epoch time: 22.48 s\n",
            "2025-12-23 05:42:52.464650: Yayy! New best EMA pseudo Dice: 0.9825999736785889\n",
            "2025-12-23 05:42:54.299312: \n",
            "2025-12-23 05:42:54.299582: Epoch 115\n",
            "2025-12-23 05:42:54.299718: Current learning rate: 0.00896\n",
            "2025-12-23 05:43:16.817976: train_loss -0.966\n",
            "2025-12-23 05:43:16.818363: val_loss -0.9801\n",
            "2025-12-23 05:43:16.818470: Pseudo dice [np.float32(0.9855)]\n",
            "2025-12-23 05:43:16.818564: Epoch time: 22.52 s\n",
            "2025-12-23 05:43:16.818647: Yayy! New best EMA pseudo Dice: 0.9829000234603882\n",
            "2025-12-23 05:43:18.681166: \n",
            "2025-12-23 05:43:18.681386: Epoch 116\n",
            "2025-12-23 05:43:18.681528: Current learning rate: 0.00895\n",
            "2025-12-23 05:43:41.214047: train_loss -0.9645\n",
            "2025-12-23 05:43:41.214300: val_loss -0.9749\n",
            "2025-12-23 05:43:41.214418: Pseudo dice [np.float32(0.982)]\n",
            "2025-12-23 05:43:41.214539: Epoch time: 22.53 s\n",
            "2025-12-23 05:43:42.570723: \n",
            "2025-12-23 05:43:42.571020: Epoch 117\n",
            "2025-12-23 05:43:42.571180: Current learning rate: 0.00894\n",
            "2025-12-23 05:44:05.075436: train_loss -0.9633\n",
            "2025-12-23 05:44:05.075649: val_loss -0.9764\n",
            "2025-12-23 05:44:05.075746: Pseudo dice [np.float32(0.9823)]\n",
            "2025-12-23 05:44:05.075848: Epoch time: 22.51 s\n",
            "2025-12-23 05:44:06.429173: \n",
            "2025-12-23 05:44:06.429567: Epoch 118\n",
            "2025-12-23 05:44:06.429712: Current learning rate: 0.00893\n",
            "2025-12-23 05:44:28.972269: train_loss -0.962\n",
            "2025-12-23 05:44:28.972467: val_loss -0.9747\n",
            "2025-12-23 05:44:28.972551: Pseudo dice [np.float32(0.9817)]\n",
            "2025-12-23 05:44:28.972640: Epoch time: 22.54 s\n",
            "2025-12-23 05:44:30.330934: \n",
            "2025-12-23 05:44:30.331279: Epoch 119\n",
            "2025-12-23 05:44:30.331434: Current learning rate: 0.00892\n",
            "2025-12-23 05:44:52.745397: train_loss -0.9628\n",
            "2025-12-23 05:44:52.745607: val_loss -0.9768\n",
            "2025-12-23 05:44:52.745713: Pseudo dice [np.float32(0.9816)]\n",
            "2025-12-23 05:44:52.745874: Epoch time: 22.42 s\n",
            "2025-12-23 05:44:54.089603: \n",
            "2025-12-23 05:44:54.089830: Epoch 120\n",
            "2025-12-23 05:44:54.090049: Current learning rate: 0.00891\n",
            "2025-12-23 05:45:16.553790: train_loss -0.9631\n",
            "2025-12-23 05:45:16.553996: val_loss -0.9761\n",
            "2025-12-23 05:45:16.554082: Pseudo dice [np.float32(0.9817)]\n",
            "2025-12-23 05:45:16.554205: Epoch time: 22.47 s\n",
            "2025-12-23 05:45:17.895395: \n",
            "2025-12-23 05:45:17.895716: Epoch 121\n",
            "2025-12-23 05:45:17.895859: Current learning rate: 0.0089\n",
            "2025-12-23 05:45:40.377341: train_loss -0.9649\n",
            "2025-12-23 05:45:40.377609: val_loss -0.9727\n",
            "2025-12-23 05:45:40.377815: Pseudo dice [np.float32(0.9794)]\n",
            "2025-12-23 05:45:40.378112: Epoch time: 22.48 s\n",
            "2025-12-23 05:45:41.711719: \n",
            "2025-12-23 05:45:41.712098: Epoch 122\n",
            "2025-12-23 05:45:41.712241: Current learning rate: 0.00889\n",
            "2025-12-23 05:46:04.140365: train_loss -0.9662\n",
            "2025-12-23 05:46:04.140575: val_loss -0.9774\n",
            "2025-12-23 05:46:04.140665: Pseudo dice [np.float32(0.9844)]\n",
            "2025-12-23 05:46:04.140750: Epoch time: 22.43 s\n",
            "2025-12-23 05:46:05.480154: \n",
            "2025-12-23 05:46:05.480480: Epoch 123\n",
            "2025-12-23 05:46:05.480661: Current learning rate: 0.00889\n",
            "2025-12-23 05:46:27.892602: train_loss -0.9663\n",
            "2025-12-23 05:46:27.892823: val_loss -0.9778\n",
            "2025-12-23 05:46:27.892910: Pseudo dice [np.float32(0.9845)]\n",
            "2025-12-23 05:46:27.892997: Epoch time: 22.41 s\n",
            "2025-12-23 05:46:29.657312: \n",
            "2025-12-23 05:46:29.657621: Epoch 124\n",
            "2025-12-23 05:46:29.657775: Current learning rate: 0.00888\n",
            "2025-12-23 05:46:52.167118: train_loss -0.9655\n",
            "2025-12-23 05:46:52.167370: val_loss -0.9776\n",
            "2025-12-23 05:46:52.167461: Pseudo dice [np.float32(0.9848)]\n",
            "2025-12-23 05:46:52.167586: Epoch time: 22.51 s\n",
            "2025-12-23 05:46:53.458926: \n",
            "2025-12-23 05:46:53.459165: Epoch 125\n",
            "2025-12-23 05:46:53.459318: Current learning rate: 0.00887\n",
            "2025-12-23 05:47:15.929777: train_loss -0.9665\n",
            "2025-12-23 05:47:15.929996: val_loss -0.9794\n",
            "2025-12-23 05:47:15.930086: Pseudo dice [np.float32(0.9846)]\n",
            "2025-12-23 05:47:15.930176: Epoch time: 22.47 s\n",
            "2025-12-23 05:47:15.930285: Yayy! New best EMA pseudo Dice: 0.9829999804496765\n",
            "2025-12-23 05:47:17.782594: \n",
            "2025-12-23 05:47:17.782882: Epoch 126\n",
            "2025-12-23 05:47:17.783013: Current learning rate: 0.00886\n",
            "2025-12-23 05:47:40.238967: train_loss -0.9667\n",
            "2025-12-23 05:47:40.239305: val_loss -0.9788\n",
            "2025-12-23 05:47:40.239542: Pseudo dice [np.float32(0.9842)]\n",
            "2025-12-23 05:47:40.239711: Epoch time: 22.46 s\n",
            "2025-12-23 05:47:40.239872: Yayy! New best EMA pseudo Dice: 0.9830999970436096\n",
            "2025-12-23 05:47:42.098041: \n",
            "2025-12-23 05:47:42.098409: Epoch 127\n",
            "2025-12-23 05:47:42.098560: Current learning rate: 0.00885\n",
            "2025-12-23 05:48:04.620834: train_loss -0.9662\n",
            "2025-12-23 05:48:04.621151: val_loss -0.9796\n",
            "2025-12-23 05:48:04.621284: Pseudo dice [np.float32(0.9852)]\n",
            "2025-12-23 05:48:04.621517: Epoch time: 22.52 s\n",
            "2025-12-23 05:48:04.621661: Yayy! New best EMA pseudo Dice: 0.983299970626831\n",
            "2025-12-23 05:48:06.489977: \n",
            "2025-12-23 05:48:06.490154: Epoch 128\n",
            "2025-12-23 05:48:06.490303: Current learning rate: 0.00884\n",
            "2025-12-23 05:48:29.002565: train_loss -0.968\n",
            "2025-12-23 05:48:29.002758: val_loss -0.9804\n",
            "2025-12-23 05:48:29.002846: Pseudo dice [np.float32(0.9852)]\n",
            "2025-12-23 05:48:29.002934: Epoch time: 22.51 s\n",
            "2025-12-23 05:48:29.003010: Yayy! New best EMA pseudo Dice: 0.9835000038146973\n",
            "2025-12-23 05:48:30.862473: \n",
            "2025-12-23 05:48:30.862845: Epoch 129\n",
            "2025-12-23 05:48:30.862996: Current learning rate: 0.00883\n",
            "2025-12-23 05:48:53.376245: train_loss -0.9677\n",
            "2025-12-23 05:48:53.376467: val_loss -0.9799\n",
            "2025-12-23 05:48:53.376560: Pseudo dice [np.float32(0.9858)]\n",
            "2025-12-23 05:48:53.376674: Epoch time: 22.52 s\n",
            "2025-12-23 05:48:53.376773: Yayy! New best EMA pseudo Dice: 0.9836999773979187\n",
            "2025-12-23 05:48:55.261110: \n",
            "2025-12-23 05:48:55.261367: Epoch 130\n",
            "2025-12-23 05:48:55.261511: Current learning rate: 0.00882\n",
            "2025-12-23 05:49:17.737928: train_loss -0.9676\n",
            "2025-12-23 05:49:17.738196: val_loss -0.9803\n",
            "2025-12-23 05:49:17.738347: Pseudo dice [np.float32(0.9857)]\n",
            "2025-12-23 05:49:17.738445: Epoch time: 22.48 s\n",
            "2025-12-23 05:49:17.738533: Yayy! New best EMA pseudo Dice: 0.9839000105857849\n",
            "2025-12-23 05:49:19.614401: \n",
            "2025-12-23 05:49:19.614652: Epoch 131\n",
            "2025-12-23 05:49:19.614786: Current learning rate: 0.00881\n",
            "2025-12-23 05:49:42.106927: train_loss -0.9676\n",
            "2025-12-23 05:49:42.107167: val_loss -0.9794\n",
            "2025-12-23 05:49:42.107275: Pseudo dice [np.float32(0.9848)]\n",
            "2025-12-23 05:49:42.107365: Epoch time: 22.49 s\n",
            "2025-12-23 05:49:42.107440: Yayy! New best EMA pseudo Dice: 0.984000027179718\n",
            "2025-12-23 05:49:43.963556: \n",
            "2025-12-23 05:49:43.963796: Epoch 132\n",
            "2025-12-23 05:49:43.963972: Current learning rate: 0.0088\n",
            "2025-12-23 05:50:06.457021: train_loss -0.9676\n",
            "2025-12-23 05:50:06.457243: val_loss -0.9799\n",
            "2025-12-23 05:50:06.457370: Pseudo dice [np.float32(0.985)]\n",
            "2025-12-23 05:50:06.457470: Epoch time: 22.49 s\n",
            "2025-12-23 05:50:06.457656: Yayy! New best EMA pseudo Dice: 0.9840999841690063\n",
            "2025-12-23 05:50:08.348822: \n",
            "2025-12-23 05:50:08.349052: Epoch 133\n",
            "2025-12-23 05:50:08.349183: Current learning rate: 0.00879\n",
            "2025-12-23 05:50:30.834622: train_loss -0.9668\n",
            "2025-12-23 05:50:30.834824: val_loss -0.9783\n",
            "2025-12-23 05:50:30.834956: Pseudo dice [np.float32(0.9838)]\n",
            "2025-12-23 05:50:30.835050: Epoch time: 22.49 s\n",
            "2025-12-23 05:50:32.166101: \n",
            "2025-12-23 05:50:32.166278: Epoch 134\n",
            "2025-12-23 05:50:32.166404: Current learning rate: 0.00879\n",
            "2025-12-23 05:50:54.601044: train_loss -0.9679\n",
            "2025-12-23 05:50:54.601315: val_loss -0.9797\n",
            "2025-12-23 05:50:54.601473: Pseudo dice [np.float32(0.9847)]\n",
            "2025-12-23 05:50:54.601607: Epoch time: 22.44 s\n",
            "2025-12-23 05:50:54.601704: Yayy! New best EMA pseudo Dice: 0.9840999841690063\n",
            "2025-12-23 05:50:56.464121: \n",
            "2025-12-23 05:50:56.464473: Epoch 135\n",
            "2025-12-23 05:50:56.464602: Current learning rate: 0.00878\n",
            "2025-12-23 05:51:18.934830: train_loss -0.9693\n",
            "2025-12-23 05:51:18.935112: val_loss -0.981\n",
            "2025-12-23 05:51:18.935207: Pseudo dice [np.float32(0.9852)]\n",
            "2025-12-23 05:51:18.935340: Epoch time: 22.47 s\n",
            "2025-12-23 05:51:18.935433: Yayy! New best EMA pseudo Dice: 0.9842000007629395\n",
            "2025-12-23 05:51:20.832851: \n",
            "2025-12-23 05:51:20.833041: Epoch 136\n",
            "2025-12-23 05:51:20.833169: Current learning rate: 0.00877\n",
            "2025-12-23 05:51:43.229353: train_loss -0.9696\n",
            "2025-12-23 05:51:43.229774: val_loss -0.9811\n",
            "2025-12-23 05:51:43.229872: Pseudo dice [np.float32(0.986)]\n",
            "2025-12-23 05:51:43.229971: Epoch time: 22.4 s\n",
            "2025-12-23 05:51:43.230042: Yayy! New best EMA pseudo Dice: 0.9843999743461609\n",
            "2025-12-23 05:51:45.100245: \n",
            "2025-12-23 05:51:45.100542: Epoch 137\n",
            "2025-12-23 05:51:45.100685: Current learning rate: 0.00876\n",
            "2025-12-23 05:52:07.587732: train_loss -0.9674\n",
            "2025-12-23 05:52:07.587954: val_loss -0.9779\n",
            "2025-12-23 05:52:07.588069: Pseudo dice [np.float32(0.9833)]\n",
            "2025-12-23 05:52:07.588186: Epoch time: 22.49 s\n",
            "2025-12-23 05:52:09.428976: \n",
            "2025-12-23 05:52:09.429296: Epoch 138\n",
            "2025-12-23 05:52:09.429451: Current learning rate: 0.00875\n",
            "2025-12-23 05:52:31.959549: train_loss -0.9674\n",
            "2025-12-23 05:52:31.959800: val_loss -0.9783\n",
            "2025-12-23 05:52:31.959904: Pseudo dice [np.float32(0.9833)]\n",
            "2025-12-23 05:52:31.960026: Epoch time: 22.53 s\n",
            "2025-12-23 05:52:33.331406: \n",
            "2025-12-23 05:52:33.331696: Epoch 139\n",
            "2025-12-23 05:52:33.331856: Current learning rate: 0.00874\n",
            "2025-12-23 05:52:55.838099: train_loss -0.9685\n",
            "2025-12-23 05:52:55.838369: val_loss -0.9794\n",
            "2025-12-23 05:52:55.838474: Pseudo dice [np.float32(0.985)]\n",
            "2025-12-23 05:52:55.838566: Epoch time: 22.51 s\n",
            "2025-12-23 05:52:57.190492: \n",
            "2025-12-23 05:52:57.190790: Epoch 140\n",
            "2025-12-23 05:52:57.190943: Current learning rate: 0.00873\n",
            "2025-12-23 05:53:19.653825: train_loss -0.9685\n",
            "2025-12-23 05:53:19.654025: val_loss -0.9792\n",
            "2025-12-23 05:53:19.654111: Pseudo dice [np.float32(0.9844)]\n",
            "2025-12-23 05:53:19.654199: Epoch time: 22.46 s\n",
            "2025-12-23 05:53:21.004412: \n",
            "2025-12-23 05:53:21.004631: Epoch 141\n",
            "2025-12-23 05:53:21.004829: Current learning rate: 0.00872\n",
            "2025-12-23 05:53:43.505777: train_loss -0.9597\n",
            "2025-12-23 05:53:43.505984: val_loss -0.9705\n",
            "2025-12-23 05:53:43.506071: Pseudo dice [np.float32(0.9784)]\n",
            "2025-12-23 05:53:43.506177: Epoch time: 22.5 s\n",
            "2025-12-23 05:53:44.880119: \n",
            "2025-12-23 05:53:44.880426: Epoch 142\n",
            "2025-12-23 05:53:44.880621: Current learning rate: 0.00871\n",
            "2025-12-23 05:54:07.393072: train_loss -0.9553\n",
            "2025-12-23 05:54:07.393317: val_loss -0.9654\n",
            "2025-12-23 05:54:07.393442: Pseudo dice [np.float32(0.9739)]\n",
            "2025-12-23 05:54:07.393540: Epoch time: 22.51 s\n",
            "2025-12-23 05:54:08.765489: \n",
            "2025-12-23 05:54:08.765699: Epoch 143\n",
            "2025-12-23 05:54:08.765832: Current learning rate: 0.0087\n",
            "2025-12-23 05:54:31.233123: train_loss -0.9458\n",
            "2025-12-23 05:54:31.233351: val_loss -0.9636\n",
            "2025-12-23 05:54:31.233447: Pseudo dice [np.float32(0.9707)]\n",
            "2025-12-23 05:54:31.233541: Epoch time: 22.47 s\n",
            "2025-12-23 05:54:32.596676: \n",
            "2025-12-23 05:54:32.596909: Epoch 144\n",
            "2025-12-23 05:54:32.597070: Current learning rate: 0.00869\n",
            "2025-12-23 05:54:55.051797: train_loss -0.9534\n",
            "2025-12-23 05:54:55.052016: val_loss -0.9735\n",
            "2025-12-23 05:54:55.052125: Pseudo dice [np.float32(0.9796)]\n",
            "2025-12-23 05:54:55.052353: Epoch time: 22.46 s\n",
            "2025-12-23 05:54:56.446877: \n",
            "2025-12-23 05:54:56.447174: Epoch 145\n",
            "2025-12-23 05:54:56.447407: Current learning rate: 0.00868\n",
            "2025-12-23 05:55:18.910546: train_loss -0.9601\n",
            "2025-12-23 05:55:18.910777: val_loss -0.9748\n",
            "2025-12-23 05:55:18.910892: Pseudo dice [np.float32(0.9818)]\n",
            "2025-12-23 05:55:18.911008: Epoch time: 22.47 s\n",
            "2025-12-23 05:55:20.316525: \n",
            "2025-12-23 05:55:20.316868: Epoch 146\n",
            "2025-12-23 05:55:20.317018: Current learning rate: 0.00868\n",
            "2025-12-23 05:55:42.785503: train_loss -0.9632\n",
            "2025-12-23 05:55:42.785712: val_loss -0.978\n",
            "2025-12-23 05:55:42.785801: Pseudo dice [np.float32(0.9844)]\n",
            "2025-12-23 05:55:42.786026: Epoch time: 22.47 s\n",
            "2025-12-23 05:55:44.193242: \n",
            "2025-12-23 05:55:44.193477: Epoch 147\n",
            "2025-12-23 05:55:44.193671: Current learning rate: 0.00867\n",
            "2025-12-23 05:56:06.663739: train_loss -0.967\n",
            "2025-12-23 05:56:06.664064: val_loss -0.9772\n",
            "2025-12-23 05:56:06.664173: Pseudo dice [np.float32(0.9818)]\n",
            "2025-12-23 05:56:06.664298: Epoch time: 22.47 s\n",
            "2025-12-23 05:56:08.038126: \n",
            "2025-12-23 05:56:08.038616: Epoch 148\n",
            "2025-12-23 05:56:08.038759: Current learning rate: 0.00866\n",
            "2025-12-23 05:56:30.458966: train_loss -0.9464\n",
            "2025-12-23 05:56:30.459156: val_loss -0.9655\n",
            "2025-12-23 05:56:30.459273: Pseudo dice [np.float32(0.9749)]\n",
            "2025-12-23 05:56:30.459384: Epoch time: 22.42 s\n",
            "2025-12-23 05:56:31.857597: \n",
            "2025-12-23 05:56:31.857923: Epoch 149\n",
            "2025-12-23 05:56:31.858052: Current learning rate: 0.00865\n",
            "2025-12-23 05:56:54.330284: train_loss -0.9481\n",
            "2025-12-23 05:56:54.330498: val_loss -0.9697\n",
            "2025-12-23 05:56:54.330851: Pseudo dice [np.float32(0.9787)]\n",
            "2025-12-23 05:56:54.331008: Epoch time: 22.47 s\n",
            "2025-12-23 05:56:56.210603: \n",
            "2025-12-23 05:56:56.210966: Epoch 150\n",
            "2025-12-23 05:56:56.211106: Current learning rate: 0.00864\n",
            "2025-12-23 05:57:18.674624: train_loss -0.9552\n",
            "2025-12-23 05:57:18.674829: val_loss -0.9719\n",
            "2025-12-23 05:57:18.674917: Pseudo dice [np.float32(0.9791)]\n",
            "2025-12-23 05:57:18.675005: Epoch time: 22.47 s\n",
            "2025-12-23 05:57:20.494672: \n",
            "2025-12-23 05:57:20.494917: Epoch 151\n",
            "2025-12-23 05:57:20.495131: Current learning rate: 0.00863\n",
            "2025-12-23 05:57:42.966784: train_loss -0.9623\n",
            "2025-12-23 05:57:42.966997: val_loss -0.9732\n",
            "2025-12-23 05:57:42.967144: Pseudo dice [np.float32(0.9807)]\n",
            "2025-12-23 05:57:42.967328: Epoch time: 22.47 s\n",
            "2025-12-23 05:57:44.333177: \n",
            "2025-12-23 05:57:44.333424: Epoch 152\n",
            "2025-12-23 05:57:44.333567: Current learning rate: 0.00862\n",
            "2025-12-23 05:58:06.785836: train_loss -0.9616\n",
            "2025-12-23 05:58:06.786076: val_loss -0.9749\n",
            "2025-12-23 05:58:06.786165: Pseudo dice [np.float32(0.9802)]\n",
            "2025-12-23 05:58:06.786284: Epoch time: 22.45 s\n",
            "2025-12-23 05:58:08.163566: \n",
            "2025-12-23 05:58:08.163889: Epoch 153\n",
            "2025-12-23 05:58:08.164028: Current learning rate: 0.00861\n",
            "2025-12-23 05:58:30.645675: train_loss -0.9614\n",
            "2025-12-23 05:58:30.645886: val_loss -0.9725\n",
            "2025-12-23 05:58:30.645976: Pseudo dice [np.float32(0.981)]\n",
            "2025-12-23 05:58:30.646064: Epoch time: 22.48 s\n",
            "2025-12-23 05:58:32.025257: \n",
            "2025-12-23 05:58:32.025689: Epoch 154\n",
            "2025-12-23 05:58:32.025841: Current learning rate: 0.0086\n",
            "2025-12-23 05:58:54.554446: train_loss -0.964\n",
            "2025-12-23 05:58:54.554687: val_loss -0.9778\n",
            "2025-12-23 05:58:54.554802: Pseudo dice [np.float32(0.9832)]\n",
            "2025-12-23 05:58:54.554919: Epoch time: 22.53 s\n",
            "2025-12-23 05:58:55.909679: \n",
            "2025-12-23 05:58:55.909935: Epoch 155\n",
            "2025-12-23 05:58:55.910094: Current learning rate: 0.00859\n",
            "2025-12-23 05:59:18.418883: train_loss -0.9612\n",
            "2025-12-23 05:59:18.419105: val_loss -0.977\n",
            "2025-12-23 05:59:18.419199: Pseudo dice [np.float32(0.9839)]\n",
            "2025-12-23 05:59:18.419327: Epoch time: 22.51 s\n",
            "2025-12-23 05:59:19.813958: \n",
            "2025-12-23 05:59:19.814279: Epoch 156\n",
            "2025-12-23 05:59:19.814432: Current learning rate: 0.00858\n",
            "2025-12-23 05:59:42.266032: train_loss -0.9664\n",
            "2025-12-23 05:59:42.266342: val_loss -0.9778\n",
            "2025-12-23 05:59:42.266501: Pseudo dice [np.float32(0.9844)]\n",
            "2025-12-23 05:59:42.266658: Epoch time: 22.45 s\n",
            "2025-12-23 05:59:43.653730: \n",
            "2025-12-23 05:59:43.654025: Epoch 157\n",
            "2025-12-23 05:59:43.654162: Current learning rate: 0.00858\n",
            "2025-12-23 06:00:06.158704: train_loss -0.9633\n",
            "2025-12-23 06:00:06.159007: val_loss -0.9726\n",
            "2025-12-23 06:00:06.159098: Pseudo dice [np.float32(0.9789)]\n",
            "2025-12-23 06:00:06.159187: Epoch time: 22.51 s\n",
            "2025-12-23 06:00:07.782231: \n",
            "2025-12-23 06:00:07.782561: Epoch 158\n",
            "2025-12-23 06:00:07.782705: Current learning rate: 0.00857\n",
            "2025-12-23 06:00:30.283383: train_loss -0.9629\n",
            "2025-12-23 06:00:30.283597: val_loss -0.9764\n",
            "2025-12-23 06:00:30.283685: Pseudo dice [np.float32(0.9816)]\n",
            "2025-12-23 06:00:30.283833: Epoch time: 22.5 s\n",
            "2025-12-23 06:00:31.677257: \n",
            "2025-12-23 06:00:31.677442: Epoch 159\n",
            "2025-12-23 06:00:31.677570: Current learning rate: 0.00856\n",
            "2025-12-23 06:00:54.149478: train_loss -0.9649\n",
            "2025-12-23 06:00:54.149694: val_loss -0.9751\n",
            "2025-12-23 06:00:54.149789: Pseudo dice [np.float32(0.9832)]\n",
            "2025-12-23 06:00:54.149966: Epoch time: 22.47 s\n",
            "2025-12-23 06:00:55.516663: \n",
            "2025-12-23 06:00:55.516983: Epoch 160\n",
            "2025-12-23 06:00:55.517119: Current learning rate: 0.00855\n",
            "2025-12-23 06:01:18.002458: train_loss -0.9663\n",
            "2025-12-23 06:01:18.002820: val_loss -0.9805\n",
            "2025-12-23 06:01:18.002972: Pseudo dice [np.float32(0.9852)]\n",
            "2025-12-23 06:01:18.003133: Epoch time: 22.49 s\n",
            "2025-12-23 06:01:19.361062: \n",
            "2025-12-23 06:01:19.361351: Epoch 161\n",
            "2025-12-23 06:01:19.361510: Current learning rate: 0.00854\n",
            "2025-12-23 06:01:41.849727: train_loss -0.9631\n",
            "2025-12-23 06:01:41.849948: val_loss -0.9771\n",
            "2025-12-23 06:01:41.850076: Pseudo dice [np.float32(0.9844)]\n",
            "2025-12-23 06:01:41.850230: Epoch time: 22.49 s\n",
            "2025-12-23 06:01:43.208095: \n",
            "2025-12-23 06:01:43.208263: Epoch 162\n",
            "2025-12-23 06:01:43.208391: Current learning rate: 0.00853\n",
            "2025-12-23 06:02:05.708020: train_loss -0.9661\n",
            "2025-12-23 06:02:05.708405: val_loss -0.9765\n",
            "2025-12-23 06:02:05.708538: Pseudo dice [np.float32(0.9808)]\n",
            "2025-12-23 06:02:05.708677: Epoch time: 22.5 s\n",
            "2025-12-23 06:02:07.096418: \n",
            "2025-12-23 06:02:07.096702: Epoch 163\n",
            "2025-12-23 06:02:07.096842: Current learning rate: 0.00852\n",
            "2025-12-23 06:02:29.564520: train_loss -0.9686\n",
            "2025-12-23 06:02:29.564812: val_loss -0.9802\n",
            "2025-12-23 06:02:29.564929: Pseudo dice [np.float32(0.9854)]\n",
            "2025-12-23 06:02:29.565047: Epoch time: 22.47 s\n",
            "2025-12-23 06:02:31.319448: \n",
            "2025-12-23 06:02:31.319793: Epoch 164\n",
            "2025-12-23 06:02:31.319945: Current learning rate: 0.00851\n",
            "2025-12-23 06:02:53.885471: train_loss -0.9694\n",
            "2025-12-23 06:02:53.885886: val_loss -0.9802\n",
            "2025-12-23 06:02:53.886076: Pseudo dice [np.float32(0.9856)]\n",
            "2025-12-23 06:02:53.886251: Epoch time: 22.57 s\n",
            "2025-12-23 06:02:55.257149: \n",
            "2025-12-23 06:02:55.257569: Epoch 165\n",
            "2025-12-23 06:02:55.257723: Current learning rate: 0.0085\n",
            "2025-12-23 06:03:17.762886: train_loss -0.965\n",
            "2025-12-23 06:03:17.763312: val_loss -0.9784\n",
            "2025-12-23 06:03:17.763515: Pseudo dice [np.float32(0.9851)]\n",
            "2025-12-23 06:03:17.763691: Epoch time: 22.51 s\n",
            "2025-12-23 06:03:19.121943: \n",
            "2025-12-23 06:03:19.122246: Epoch 166\n",
            "2025-12-23 06:03:19.122394: Current learning rate: 0.00849\n",
            "2025-12-23 06:03:41.643728: train_loss -0.9666\n",
            "2025-12-23 06:03:41.644060: val_loss -0.9798\n",
            "2025-12-23 06:03:41.644185: Pseudo dice [np.float32(0.9858)]\n",
            "2025-12-23 06:03:41.644323: Epoch time: 22.52 s\n",
            "2025-12-23 06:03:43.004964: \n",
            "2025-12-23 06:03:43.005193: Epoch 167\n",
            "2025-12-23 06:03:43.005367: Current learning rate: 0.00848\n",
            "2025-12-23 06:04:05.504725: train_loss -0.9677\n",
            "2025-12-23 06:04:05.504972: val_loss -0.9791\n",
            "2025-12-23 06:04:05.505061: Pseudo dice [np.float32(0.9838)]\n",
            "2025-12-23 06:04:05.505151: Epoch time: 22.5 s\n",
            "2025-12-23 06:04:06.854727: \n",
            "2025-12-23 06:04:06.855042: Epoch 168\n",
            "2025-12-23 06:04:06.855175: Current learning rate: 0.00847\n",
            "2025-12-23 06:04:29.357318: train_loss -0.9663\n",
            "2025-12-23 06:04:29.357661: val_loss -0.9783\n",
            "2025-12-23 06:04:29.357756: Pseudo dice [np.float32(0.9844)]\n",
            "2025-12-23 06:04:29.357850: Epoch time: 22.5 s\n",
            "2025-12-23 06:04:30.734940: \n",
            "2025-12-23 06:04:30.735182: Epoch 169\n",
            "2025-12-23 06:04:30.735341: Current learning rate: 0.00847\n",
            "2025-12-23 06:04:53.215110: train_loss -0.9667\n",
            "2025-12-23 06:04:53.215398: val_loss -0.9774\n",
            "2025-12-23 06:04:53.215489: Pseudo dice [np.float32(0.9848)]\n",
            "2025-12-23 06:04:53.215584: Epoch time: 22.48 s\n",
            "2025-12-23 06:04:54.605404: \n",
            "2025-12-23 06:04:54.605708: Epoch 170\n",
            "2025-12-23 06:04:54.605845: Current learning rate: 0.00846\n",
            "2025-12-23 06:05:17.135127: train_loss -0.9658\n",
            "2025-12-23 06:05:17.135382: val_loss -0.9803\n",
            "2025-12-23 06:05:17.135498: Pseudo dice [np.float32(0.986)]\n",
            "2025-12-23 06:05:17.135592: Epoch time: 22.53 s\n",
            "2025-12-23 06:05:18.537128: \n",
            "2025-12-23 06:05:18.537513: Epoch 171\n",
            "2025-12-23 06:05:18.537651: Current learning rate: 0.00845\n",
            "2025-12-23 06:05:40.999728: train_loss -0.9672\n",
            "2025-12-23 06:05:41.000033: val_loss -0.9779\n",
            "2025-12-23 06:05:41.000134: Pseudo dice [np.float32(0.9848)]\n",
            "2025-12-23 06:05:41.000249: Epoch time: 22.46 s\n",
            "2025-12-23 06:05:42.351842: \n",
            "2025-12-23 06:05:42.352112: Epoch 172\n",
            "2025-12-23 06:05:42.352289: Current learning rate: 0.00844\n",
            "2025-12-23 06:06:04.835897: train_loss -0.9677\n",
            "2025-12-23 06:06:04.836313: val_loss -0.978\n",
            "2025-12-23 06:06:04.836408: Pseudo dice [np.float32(0.9844)]\n",
            "2025-12-23 06:06:04.836505: Epoch time: 22.49 s\n",
            "2025-12-23 06:06:06.236609: \n",
            "2025-12-23 06:06:06.236898: Epoch 173\n",
            "2025-12-23 06:06:06.237025: Current learning rate: 0.00843\n",
            "2025-12-23 06:06:28.753909: train_loss -0.9655\n",
            "2025-12-23 06:06:28.754113: val_loss -0.97\n",
            "2025-12-23 06:06:28.754272: Pseudo dice [np.float32(0.9772)]\n",
            "2025-12-23 06:06:28.754457: Epoch time: 22.52 s\n",
            "2025-12-23 06:06:30.111754: \n",
            "2025-12-23 06:06:30.112042: Epoch 174\n",
            "2025-12-23 06:06:30.112168: Current learning rate: 0.00842\n",
            "2025-12-23 06:06:52.580799: train_loss -0.9656\n",
            "2025-12-23 06:06:52.580992: val_loss -0.9779\n",
            "2025-12-23 06:06:52.581079: Pseudo dice [np.float32(0.9814)]\n",
            "2025-12-23 06:06:52.581169: Epoch time: 22.47 s\n",
            "2025-12-23 06:06:53.926030: \n",
            "2025-12-23 06:06:53.926304: Epoch 175\n",
            "2025-12-23 06:06:53.926497: Current learning rate: 0.00841\n",
            "2025-12-23 06:07:16.417730: train_loss -0.9683\n",
            "2025-12-23 06:07:16.417937: val_loss -0.9805\n",
            "2025-12-23 06:07:16.418022: Pseudo dice [np.float32(0.985)]\n",
            "2025-12-23 06:07:16.418109: Epoch time: 22.49 s\n",
            "2025-12-23 06:07:17.769315: \n",
            "2025-12-23 06:07:17.769518: Epoch 176\n",
            "2025-12-23 06:07:17.769650: Current learning rate: 0.0084\n",
            "2025-12-23 06:07:40.266702: train_loss -0.9682\n",
            "2025-12-23 06:07:40.266968: val_loss -0.9821\n",
            "2025-12-23 06:07:40.267117: Pseudo dice [np.float32(0.9867)]\n",
            "2025-12-23 06:07:40.267290: Epoch time: 22.5 s\n",
            "2025-12-23 06:07:42.136984: \n",
            "2025-12-23 06:07:42.137311: Epoch 177\n",
            "2025-12-23 06:07:42.137450: Current learning rate: 0.00839\n",
            "2025-12-23 06:08:04.745093: train_loss -0.9669\n",
            "2025-12-23 06:08:04.745474: val_loss -0.9792\n",
            "2025-12-23 06:08:04.745781: Pseudo dice [np.float32(0.9854)]\n",
            "2025-12-23 06:08:04.746005: Epoch time: 22.61 s\n",
            "2025-12-23 06:08:06.102158: \n",
            "2025-12-23 06:08:06.102509: Epoch 178\n",
            "2025-12-23 06:08:06.102645: Current learning rate: 0.00838\n",
            "2025-12-23 06:08:28.587206: train_loss -0.9662\n",
            "2025-12-23 06:08:28.587436: val_loss -0.9753\n",
            "2025-12-23 06:08:28.587559: Pseudo dice [np.float32(0.978)]\n",
            "2025-12-23 06:08:28.587661: Epoch time: 22.49 s\n",
            "2025-12-23 06:08:29.975927: \n",
            "2025-12-23 06:08:29.976205: Epoch 179\n",
            "2025-12-23 06:08:29.976402: Current learning rate: 0.00837\n",
            "2025-12-23 06:08:52.480666: train_loss -0.9685\n",
            "2025-12-23 06:08:52.480906: val_loss -0.9792\n",
            "2025-12-23 06:08:52.481003: Pseudo dice [np.float32(0.9851)]\n",
            "2025-12-23 06:08:52.481094: Epoch time: 22.51 s\n",
            "2025-12-23 06:08:53.877281: \n",
            "2025-12-23 06:08:53.877644: Epoch 180\n",
            "2025-12-23 06:08:53.877774: Current learning rate: 0.00836\n",
            "2025-12-23 06:09:16.387458: train_loss -0.967\n",
            "2025-12-23 06:09:16.387691: val_loss -0.9802\n",
            "2025-12-23 06:09:16.387804: Pseudo dice [np.float32(0.9847)]\n",
            "2025-12-23 06:09:16.387997: Epoch time: 22.51 s\n",
            "2025-12-23 06:09:17.794038: \n",
            "2025-12-23 06:09:17.794240: Epoch 181\n",
            "2025-12-23 06:09:17.794372: Current learning rate: 0.00836\n",
            "2025-12-23 06:09:40.309073: train_loss -0.9688\n",
            "2025-12-23 06:09:40.309425: val_loss -0.9809\n",
            "2025-12-23 06:09:40.309574: Pseudo dice [np.float32(0.9855)]\n",
            "2025-12-23 06:09:40.309710: Epoch time: 22.52 s\n",
            "2025-12-23 06:09:41.689699: \n",
            "2025-12-23 06:09:41.690050: Epoch 182\n",
            "2025-12-23 06:09:41.690244: Current learning rate: 0.00835\n",
            "2025-12-23 06:10:04.208569: train_loss -0.9689\n",
            "2025-12-23 06:10:04.208794: val_loss -0.9806\n",
            "2025-12-23 06:10:04.208904: Pseudo dice [np.float32(0.9845)]\n",
            "2025-12-23 06:10:04.209020: Epoch time: 22.52 s\n",
            "2025-12-23 06:10:05.572968: \n",
            "2025-12-23 06:10:05.573345: Epoch 183\n",
            "2025-12-23 06:10:05.573586: Current learning rate: 0.00834\n",
            "2025-12-23 06:10:28.054864: train_loss -0.9696\n",
            "2025-12-23 06:10:28.055138: val_loss -0.9803\n",
            "2025-12-23 06:10:28.055240: Pseudo dice [np.float32(0.9845)]\n",
            "2025-12-23 06:10:28.055335: Epoch time: 22.48 s\n",
            "2025-12-23 06:10:29.433807: \n",
            "2025-12-23 06:10:29.434023: Epoch 184\n",
            "2025-12-23 06:10:29.434273: Current learning rate: 0.00833\n",
            "2025-12-23 06:10:51.967925: train_loss -0.9697\n",
            "2025-12-23 06:10:51.968356: val_loss -0.9799\n",
            "2025-12-23 06:10:51.968532: Pseudo dice [np.float32(0.9855)]\n",
            "2025-12-23 06:10:51.968626: Epoch time: 22.54 s\n",
            "2025-12-23 06:10:53.327910: \n",
            "2025-12-23 06:10:53.328325: Epoch 185\n",
            "2025-12-23 06:10:53.328479: Current learning rate: 0.00832\n",
            "2025-12-23 06:11:15.866113: train_loss -0.9695\n",
            "2025-12-23 06:11:15.866326: val_loss -0.9804\n",
            "2025-12-23 06:11:15.866415: Pseudo dice [np.float32(0.9858)]\n",
            "2025-12-23 06:11:15.866508: Epoch time: 22.54 s\n",
            "2025-12-23 06:11:17.246832: \n",
            "2025-12-23 06:11:17.247136: Epoch 186\n",
            "2025-12-23 06:11:17.247284: Current learning rate: 0.00831\n",
            "2025-12-23 06:11:39.826882: train_loss -0.9689\n",
            "2025-12-23 06:11:39.827310: val_loss -0.9799\n",
            "2025-12-23 06:11:39.827567: Pseudo dice [np.float32(0.9855)]\n",
            "2025-12-23 06:11:39.827731: Epoch time: 22.58 s\n",
            "2025-12-23 06:11:41.212891: \n",
            "2025-12-23 06:11:41.213239: Epoch 187\n",
            "2025-12-23 06:11:41.213369: Current learning rate: 0.0083\n",
            "2025-12-23 06:12:03.726825: train_loss -0.9693\n",
            "2025-12-23 06:12:03.727038: val_loss -0.9792\n",
            "2025-12-23 06:12:03.727129: Pseudo dice [np.float32(0.986)]\n",
            "2025-12-23 06:12:03.727232: Epoch time: 22.52 s\n",
            "2025-12-23 06:12:03.727338: Yayy! New best EMA pseudo Dice: 0.984499990940094\n",
            "2025-12-23 06:12:05.657375: \n",
            "2025-12-23 06:12:05.657765: Epoch 188\n",
            "2025-12-23 06:12:05.657923: Current learning rate: 0.00829\n",
            "2025-12-23 06:12:28.142419: train_loss -0.9678\n",
            "2025-12-23 06:12:28.142870: val_loss -0.9809\n",
            "2025-12-23 06:12:28.142967: Pseudo dice [np.float32(0.9856)]\n",
            "2025-12-23 06:12:28.143063: Epoch time: 22.49 s\n",
            "2025-12-23 06:12:28.143133: Yayy! New best EMA pseudo Dice: 0.9846000075340271\n",
            "2025-12-23 06:12:30.029275: \n",
            "2025-12-23 06:12:30.029554: Epoch 189\n",
            "2025-12-23 06:12:30.029683: Current learning rate: 0.00828\n",
            "2025-12-23 06:12:52.521903: train_loss -0.9683\n",
            "2025-12-23 06:12:52.522106: val_loss -0.9784\n",
            "2025-12-23 06:12:52.522256: Pseudo dice [np.float32(0.9809)]\n",
            "2025-12-23 06:12:52.522366: Epoch time: 22.49 s\n",
            "2025-12-23 06:12:53.894955: \n",
            "2025-12-23 06:12:53.895144: Epoch 190\n",
            "2025-12-23 06:12:53.895288: Current learning rate: 0.00827\n",
            "2025-12-23 06:13:16.918382: train_loss -0.9681\n",
            "2025-12-23 06:13:16.918588: val_loss -0.9793\n",
            "2025-12-23 06:13:16.918673: Pseudo dice [np.float32(0.9846)]\n",
            "2025-12-23 06:13:16.918767: Epoch time: 23.02 s\n",
            "2025-12-23 06:13:18.241730: \n",
            "2025-12-23 06:13:18.242011: Epoch 191\n",
            "2025-12-23 06:13:18.242144: Current learning rate: 0.00826\n",
            "2025-12-23 06:13:40.752838: train_loss -0.9669\n",
            "2025-12-23 06:13:40.753086: val_loss -0.9809\n",
            "2025-12-23 06:13:40.753178: Pseudo dice [np.float32(0.9863)]\n",
            "2025-12-23 06:13:40.753302: Epoch time: 22.51 s\n",
            "2025-12-23 06:13:42.129652: \n",
            "2025-12-23 06:13:42.129995: Epoch 192\n",
            "2025-12-23 06:13:42.130134: Current learning rate: 0.00825\n",
            "2025-12-23 06:14:04.658136: train_loss -0.9672\n",
            "2025-12-23 06:14:04.658509: val_loss -0.9794\n",
            "2025-12-23 06:14:04.658707: Pseudo dice [np.float32(0.9853)]\n",
            "2025-12-23 06:14:04.658819: Epoch time: 22.53 s\n",
            "2025-12-23 06:14:06.048537: \n",
            "2025-12-23 06:14:06.048885: Epoch 193\n",
            "2025-12-23 06:14:06.049017: Current learning rate: 0.00824\n",
            "2025-12-23 06:14:28.564360: train_loss -0.967\n",
            "2025-12-23 06:14:28.564589: val_loss -0.9792\n",
            "2025-12-23 06:14:28.564677: Pseudo dice [np.float32(0.9847)]\n",
            "2025-12-23 06:14:28.564764: Epoch time: 22.52 s\n",
            "2025-12-23 06:14:29.922333: \n",
            "2025-12-23 06:14:29.922654: Epoch 194\n",
            "2025-12-23 06:14:29.922793: Current learning rate: 0.00824\n",
            "2025-12-23 06:14:52.476459: train_loss -0.966\n",
            "2025-12-23 06:14:52.476686: val_loss -0.9792\n",
            "2025-12-23 06:14:52.476795: Pseudo dice [np.float32(0.9843)]\n",
            "2025-12-23 06:14:52.476909: Epoch time: 22.56 s\n",
            "2025-12-23 06:14:53.871593: \n",
            "2025-12-23 06:14:53.871958: Epoch 195\n",
            "2025-12-23 06:14:53.872095: Current learning rate: 0.00823\n",
            "2025-12-23 06:15:16.383675: train_loss -0.9676\n",
            "2025-12-23 06:15:16.383934: val_loss -0.98\n",
            "2025-12-23 06:15:16.384024: Pseudo dice [np.float32(0.9836)]\n",
            "2025-12-23 06:15:16.384112: Epoch time: 22.51 s\n",
            "2025-12-23 06:15:17.750084: \n",
            "2025-12-23 06:15:17.750426: Epoch 196\n",
            "2025-12-23 06:15:17.750563: Current learning rate: 0.00822\n",
            "2025-12-23 06:15:40.233381: train_loss -0.9697\n",
            "2025-12-23 06:15:40.233668: val_loss -0.9797\n",
            "2025-12-23 06:15:40.233760: Pseudo dice [np.float32(0.9851)]\n",
            "2025-12-23 06:15:40.233850: Epoch time: 22.48 s\n",
            "2025-12-23 06:15:41.605549: \n",
            "2025-12-23 06:15:41.605761: Epoch 197\n",
            "2025-12-23 06:15:41.605921: Current learning rate: 0.00821\n",
            "2025-12-23 06:16:04.165579: train_loss -0.9668\n",
            "2025-12-23 06:16:04.165838: val_loss -0.979\n",
            "2025-12-23 06:16:04.165953: Pseudo dice [np.float32(0.9852)]\n",
            "2025-12-23 06:16:04.166089: Epoch time: 22.56 s\n",
            "2025-12-23 06:16:05.550197: \n",
            "2025-12-23 06:16:05.550519: Epoch 198\n",
            "2025-12-23 06:16:05.550654: Current learning rate: 0.0082\n",
            "2025-12-23 06:16:28.036447: train_loss -0.9678\n",
            "2025-12-23 06:16:28.036673: val_loss -0.9801\n",
            "2025-12-23 06:16:28.036764: Pseudo dice [np.float32(0.9852)]\n",
            "2025-12-23 06:16:28.036864: Epoch time: 22.49 s\n",
            "2025-12-23 06:16:28.036945: Yayy! New best EMA pseudo Dice: 0.9846000075340271\n",
            "2025-12-23 06:16:29.913888: \n",
            "2025-12-23 06:16:29.914117: Epoch 199\n",
            "2025-12-23 06:16:29.914264: Current learning rate: 0.00819\n",
            "2025-12-23 06:16:52.492718: train_loss -0.9676\n",
            "2025-12-23 06:16:52.492927: val_loss -0.9798\n",
            "2025-12-23 06:16:52.493014: Pseudo dice [np.float32(0.9849)]\n",
            "2025-12-23 06:16:52.493104: Epoch time: 22.58 s\n",
            "2025-12-23 06:16:53.004480: Yayy! New best EMA pseudo Dice: 0.9847000241279602\n",
            "2025-12-23 06:16:54.873793: \n",
            "2025-12-23 06:16:54.874124: Epoch 200\n",
            "2025-12-23 06:16:54.874284: Current learning rate: 0.00818\n",
            "2025-12-23 06:17:17.397614: train_loss -0.9678\n",
            "2025-12-23 06:17:17.397799: val_loss -0.9813\n",
            "2025-12-23 06:17:17.397886: Pseudo dice [np.float32(0.9866)]\n",
            "2025-12-23 06:17:17.397998: Epoch time: 22.53 s\n",
            "2025-12-23 06:17:17.398087: Yayy! New best EMA pseudo Dice: 0.9848999977111816\n",
            "2025-12-23 06:17:19.301676: \n",
            "2025-12-23 06:17:19.301859: Epoch 201\n",
            "2025-12-23 06:17:19.301999: Current learning rate: 0.00817\n",
            "2025-12-23 06:17:41.817425: train_loss -0.9703\n",
            "2025-12-23 06:17:41.817662: val_loss -0.9812\n",
            "2025-12-23 06:17:41.817834: Pseudo dice [np.float32(0.9863)]\n",
            "2025-12-23 06:17:41.817926: Epoch time: 22.52 s\n",
            "2025-12-23 06:17:41.818010: Yayy! New best EMA pseudo Dice: 0.9850000143051147\n",
            "2025-12-23 06:17:43.734131: \n",
            "2025-12-23 06:17:43.734515: Epoch 202\n",
            "2025-12-23 06:17:43.734686: Current learning rate: 0.00816\n",
            "2025-12-23 06:18:06.204082: train_loss -0.9696\n",
            "2025-12-23 06:18:06.204470: val_loss -0.9785\n",
            "2025-12-23 06:18:06.204622: Pseudo dice [np.float32(0.983)]\n",
            "2025-12-23 06:18:06.204805: Epoch time: 22.47 s\n",
            "2025-12-23 06:18:08.064352: \n",
            "2025-12-23 06:18:08.064675: Epoch 203\n",
            "2025-12-23 06:18:08.064834: Current learning rate: 0.00815\n",
            "2025-12-23 06:18:30.592736: train_loss -0.9689\n",
            "2025-12-23 06:18:30.592948: val_loss -0.9744\n",
            "2025-12-23 06:18:30.593037: Pseudo dice [np.float32(0.9792)]\n",
            "2025-12-23 06:18:30.593124: Epoch time: 22.53 s\n",
            "2025-12-23 06:18:31.926040: \n",
            "2025-12-23 06:18:31.926452: Epoch 204\n",
            "2025-12-23 06:18:31.926588: Current learning rate: 0.00814\n",
            "2025-12-23 06:18:54.481035: train_loss -0.9665\n",
            "2025-12-23 06:18:54.481400: val_loss -0.9775\n",
            "2025-12-23 06:18:54.481649: Pseudo dice [np.float32(0.9845)]\n",
            "2025-12-23 06:18:54.481850: Epoch time: 22.56 s\n",
            "2025-12-23 06:18:55.884668: \n",
            "2025-12-23 06:18:55.884964: Epoch 205\n",
            "2025-12-23 06:18:55.885096: Current learning rate: 0.00813\n",
            "2025-12-23 06:19:18.401285: train_loss -0.9683\n",
            "2025-12-23 06:19:18.401520: val_loss -0.9793\n",
            "2025-12-23 06:19:18.401609: Pseudo dice [np.float32(0.9849)]\n",
            "2025-12-23 06:19:18.401696: Epoch time: 22.52 s\n",
            "2025-12-23 06:19:19.726040: \n",
            "2025-12-23 06:19:19.726266: Epoch 206\n",
            "2025-12-23 06:19:19.726445: Current learning rate: 0.00813\n",
            "2025-12-23 06:19:42.230393: train_loss -0.9692\n",
            "2025-12-23 06:19:42.230605: val_loss -0.9807\n",
            "2025-12-23 06:19:42.230694: Pseudo dice [np.float32(0.9849)]\n",
            "2025-12-23 06:19:42.230785: Epoch time: 22.51 s\n",
            "2025-12-23 06:19:43.544518: \n",
            "2025-12-23 06:19:43.544720: Epoch 207\n",
            "2025-12-23 06:19:43.544853: Current learning rate: 0.00812\n",
            "2025-12-23 06:20:06.061580: train_loss -0.968\n",
            "2025-12-23 06:20:06.061852: val_loss -0.9795\n",
            "2025-12-23 06:20:06.061956: Pseudo dice [np.float32(0.9853)]\n",
            "2025-12-23 06:20:06.062044: Epoch time: 22.52 s\n",
            "2025-12-23 06:20:07.404757: \n",
            "2025-12-23 06:20:07.404998: Epoch 208\n",
            "2025-12-23 06:20:07.405129: Current learning rate: 0.00811\n",
            "2025-12-23 06:20:29.918221: train_loss -0.9645\n",
            "2025-12-23 06:20:29.918537: val_loss -0.9784\n",
            "2025-12-23 06:20:29.918639: Pseudo dice [np.float32(0.9836)]\n",
            "2025-12-23 06:20:29.918730: Epoch time: 22.51 s\n",
            "2025-12-23 06:20:31.250968: \n",
            "2025-12-23 06:20:31.251306: Epoch 209\n",
            "2025-12-23 06:20:31.251452: Current learning rate: 0.0081\n",
            "2025-12-23 06:20:53.808856: train_loss -0.9669\n",
            "2025-12-23 06:20:53.809233: val_loss -0.9747\n",
            "2025-12-23 06:20:53.809408: Pseudo dice [np.float32(0.9828)]\n",
            "2025-12-23 06:20:53.809552: Epoch time: 22.56 s\n",
            "2025-12-23 06:20:55.135705: \n",
            "2025-12-23 06:20:55.136012: Epoch 210\n",
            "2025-12-23 06:20:55.136199: Current learning rate: 0.00809\n",
            "2025-12-23 06:21:17.630676: train_loss -0.9692\n",
            "2025-12-23 06:21:17.630945: val_loss -0.9813\n",
            "2025-12-23 06:21:17.631091: Pseudo dice [np.float32(0.986)]\n",
            "2025-12-23 06:21:17.631185: Epoch time: 22.5 s\n",
            "2025-12-23 06:21:18.950588: \n",
            "2025-12-23 06:21:18.950906: Epoch 211\n",
            "2025-12-23 06:21:18.951050: Current learning rate: 0.00808\n",
            "2025-12-23 06:21:41.529629: train_loss -0.966\n",
            "2025-12-23 06:21:41.529911: val_loss -0.977\n",
            "2025-12-23 06:21:41.530010: Pseudo dice [np.float32(0.9832)]\n",
            "2025-12-23 06:21:41.530123: Epoch time: 22.58 s\n",
            "2025-12-23 06:21:42.857954: \n",
            "2025-12-23 06:21:42.858303: Epoch 212\n",
            "2025-12-23 06:21:42.858465: Current learning rate: 0.00807\n",
            "2025-12-23 06:22:05.355416: train_loss -0.9646\n",
            "2025-12-23 06:22:05.355644: val_loss -0.9784\n",
            "2025-12-23 06:22:05.355787: Pseudo dice [np.float32(0.9836)]\n",
            "2025-12-23 06:22:05.355894: Epoch time: 22.5 s\n",
            "2025-12-23 06:22:06.686506: \n",
            "2025-12-23 06:22:06.686779: Epoch 213\n",
            "2025-12-23 06:22:06.686922: Current learning rate: 0.00806\n",
            "2025-12-23 06:22:29.231799: train_loss -0.9649\n",
            "2025-12-23 06:22:29.232040: val_loss -0.9781\n",
            "2025-12-23 06:22:29.232127: Pseudo dice [np.float32(0.984)]\n",
            "2025-12-23 06:22:29.232238: Epoch time: 22.55 s\n",
            "2025-12-23 06:22:30.558702: \n",
            "2025-12-23 06:22:30.559016: Epoch 214\n",
            "2025-12-23 06:22:30.559156: Current learning rate: 0.00805\n",
            "2025-12-23 06:22:53.049909: train_loss -0.966\n",
            "2025-12-23 06:22:53.050113: val_loss -0.9785\n",
            "2025-12-23 06:22:53.050200: Pseudo dice [np.float32(0.9841)]\n",
            "2025-12-23 06:22:53.050306: Epoch time: 22.49 s\n",
            "2025-12-23 06:22:54.396003: \n",
            "2025-12-23 06:22:54.396269: Epoch 215\n",
            "2025-12-23 06:22:54.396405: Current learning rate: 0.00804\n",
            "2025-12-23 06:23:16.907684: train_loss -0.966\n",
            "2025-12-23 06:23:16.907929: val_loss -0.9778\n",
            "2025-12-23 06:23:16.908017: Pseudo dice [np.float32(0.9826)]\n",
            "2025-12-23 06:23:16.908108: Epoch time: 22.51 s\n",
            "2025-12-23 06:23:18.230739: \n",
            "2025-12-23 06:23:18.230928: Epoch 216\n",
            "2025-12-23 06:23:18.231077: Current learning rate: 0.00803\n",
            "2025-12-23 06:23:40.711409: train_loss -0.9682\n",
            "2025-12-23 06:23:40.711647: val_loss -0.9764\n",
            "2025-12-23 06:23:40.711741: Pseudo dice [np.float32(0.9816)]\n",
            "2025-12-23 06:23:40.711838: Epoch time: 22.48 s\n",
            "2025-12-23 06:23:42.490640: \n",
            "2025-12-23 06:23:42.491027: Epoch 217\n",
            "2025-12-23 06:23:42.491167: Current learning rate: 0.00802\n",
            "2025-12-23 06:24:05.070556: train_loss -0.9664\n",
            "2025-12-23 06:24:05.070798: val_loss -0.9741\n",
            "2025-12-23 06:24:05.070905: Pseudo dice [np.float32(0.9793)]\n",
            "2025-12-23 06:24:05.070999: Epoch time: 22.58 s\n",
            "2025-12-23 06:24:06.428996: \n",
            "2025-12-23 06:24:06.429365: Epoch 218\n",
            "2025-12-23 06:24:06.429538: Current learning rate: 0.00801\n",
            "2025-12-23 06:24:28.950562: train_loss -0.9664\n",
            "2025-12-23 06:24:28.951128: val_loss -0.9809\n",
            "2025-12-23 06:24:28.951262: Pseudo dice [np.float32(0.9859)]\n",
            "2025-12-23 06:24:28.951362: Epoch time: 22.52 s\n",
            "2025-12-23 06:24:30.294552: \n",
            "2025-12-23 06:24:30.294884: Epoch 219\n",
            "2025-12-23 06:24:30.295020: Current learning rate: 0.00801\n",
            "2025-12-23 06:24:52.848060: train_loss -0.9689\n",
            "2025-12-23 06:24:52.848442: val_loss -0.9796\n",
            "2025-12-23 06:24:52.848635: Pseudo dice [np.float32(0.9852)]\n",
            "2025-12-23 06:24:52.848768: Epoch time: 22.55 s\n",
            "2025-12-23 06:24:54.215336: \n",
            "2025-12-23 06:24:54.215609: Epoch 220\n",
            "2025-12-23 06:24:54.215743: Current learning rate: 0.008\n",
            "2025-12-23 06:25:16.753595: train_loss -0.9693\n",
            "2025-12-23 06:25:16.753831: val_loss -0.98\n",
            "2025-12-23 06:25:16.753922: Pseudo dice [np.float32(0.9848)]\n",
            "2025-12-23 06:25:16.754009: Epoch time: 22.54 s\n",
            "2025-12-23 06:25:18.136752: \n",
            "2025-12-23 06:25:18.137089: Epoch 221\n",
            "2025-12-23 06:25:18.137254: Current learning rate: 0.00799\n",
            "2025-12-23 06:25:40.649122: train_loss -0.9699\n",
            "2025-12-23 06:25:40.649337: val_loss -0.9805\n",
            "2025-12-23 06:25:40.649462: Pseudo dice [np.float32(0.985)]\n",
            "2025-12-23 06:25:40.649571: Epoch time: 22.51 s\n",
            "2025-12-23 06:25:42.026433: \n",
            "2025-12-23 06:25:42.026699: Epoch 222\n",
            "2025-12-23 06:25:42.026828: Current learning rate: 0.00798\n",
            "2025-12-23 06:26:04.504463: train_loss -0.9688\n",
            "2025-12-23 06:26:04.504689: val_loss -0.9808\n",
            "2025-12-23 06:26:04.504780: Pseudo dice [np.float32(0.9861)]\n",
            "2025-12-23 06:26:04.504882: Epoch time: 22.48 s\n",
            "2025-12-23 06:26:05.841812: \n",
            "2025-12-23 06:26:05.842147: Epoch 223\n",
            "2025-12-23 06:26:05.842400: Current learning rate: 0.00797\n",
            "2025-12-23 06:26:28.341069: train_loss -0.9695\n",
            "2025-12-23 06:26:28.341285: val_loss -0.9808\n",
            "2025-12-23 06:26:28.341449: Pseudo dice [np.float32(0.9856)]\n",
            "2025-12-23 06:26:28.341550: Epoch time: 22.5 s\n",
            "2025-12-23 06:26:29.698344: \n",
            "2025-12-23 06:26:29.698657: Epoch 224\n",
            "2025-12-23 06:26:29.698816: Current learning rate: 0.00796\n",
            "2025-12-23 06:26:52.208249: train_loss -0.9685\n",
            "2025-12-23 06:26:52.208460: val_loss -0.9816\n",
            "2025-12-23 06:26:52.208550: Pseudo dice [np.float32(0.9864)]\n",
            "2025-12-23 06:26:52.208638: Epoch time: 22.51 s\n",
            "2025-12-23 06:26:53.577988: \n",
            "2025-12-23 06:26:53.578341: Epoch 225\n",
            "2025-12-23 06:26:53.578496: Current learning rate: 0.00795\n",
            "2025-12-23 06:27:16.088247: train_loss -0.9676\n",
            "2025-12-23 06:27:16.088804: val_loss -0.9767\n",
            "2025-12-23 06:27:16.088986: Pseudo dice [np.float32(0.9803)]\n",
            "2025-12-23 06:27:16.089167: Epoch time: 22.51 s\n",
            "2025-12-23 06:27:17.423906: \n",
            "2025-12-23 06:27:17.424225: Epoch 226\n",
            "2025-12-23 06:27:17.424380: Current learning rate: 0.00794\n",
            "2025-12-23 06:27:39.873162: train_loss -0.9661\n",
            "2025-12-23 06:27:39.873420: val_loss -0.9813\n",
            "2025-12-23 06:27:39.873528: Pseudo dice [np.float32(0.9861)]\n",
            "2025-12-23 06:27:39.873620: Epoch time: 22.45 s\n",
            "2025-12-23 06:27:41.210314: \n",
            "2025-12-23 06:27:41.210516: Epoch 227\n",
            "2025-12-23 06:27:41.210646: Current learning rate: 0.00793\n",
            "2025-12-23 06:28:03.691695: train_loss -0.9663\n",
            "2025-12-23 06:28:03.691900: val_loss -0.9802\n",
            "2025-12-23 06:28:03.691988: Pseudo dice [np.float32(0.9854)]\n",
            "2025-12-23 06:28:03.692077: Epoch time: 22.48 s\n",
            "2025-12-23 06:28:05.007758: \n",
            "2025-12-23 06:28:05.008115: Epoch 228\n",
            "2025-12-23 06:28:05.008262: Current learning rate: 0.00792\n",
            "2025-12-23 06:28:27.508003: train_loss -0.9667\n",
            "2025-12-23 06:28:27.508296: val_loss -0.9736\n",
            "2025-12-23 06:28:27.508403: Pseudo dice [np.float32(0.9807)]\n",
            "2025-12-23 06:28:27.508495: Epoch time: 22.5 s\n",
            "2025-12-23 06:28:28.843966: \n",
            "2025-12-23 06:28:28.844198: Epoch 229\n",
            "2025-12-23 06:28:28.844382: Current learning rate: 0.00791\n",
            "2025-12-23 06:28:51.363019: train_loss -0.965\n",
            "2025-12-23 06:28:51.363240: val_loss -0.9794\n",
            "2025-12-23 06:28:51.363352: Pseudo dice [np.float32(0.9845)]\n",
            "2025-12-23 06:28:51.363464: Epoch time: 22.52 s\n",
            "2025-12-23 06:28:52.679285: \n",
            "2025-12-23 06:28:52.679564: Epoch 230\n",
            "2025-12-23 06:28:52.679708: Current learning rate: 0.0079\n",
            "2025-12-23 06:29:15.126486: train_loss -0.9683\n",
            "2025-12-23 06:29:15.126900: val_loss -0.9778\n",
            "2025-12-23 06:29:15.127086: Pseudo dice [np.float32(0.9837)]\n",
            "2025-12-23 06:29:15.127331: Epoch time: 22.45 s\n",
            "2025-12-23 06:29:16.917685: \n",
            "2025-12-23 06:29:16.917982: Epoch 231\n",
            "2025-12-23 06:29:16.918129: Current learning rate: 0.00789\n",
            "2025-12-23 06:29:39.516611: train_loss -0.9668\n",
            "2025-12-23 06:29:39.516960: val_loss -0.9779\n",
            "2025-12-23 06:29:39.517104: Pseudo dice [np.float32(0.9834)]\n",
            "2025-12-23 06:29:39.517300: Epoch time: 22.6 s\n",
            "2025-12-23 06:29:40.819379: \n",
            "2025-12-23 06:29:40.819791: Epoch 232\n",
            "2025-12-23 06:29:40.819949: Current learning rate: 0.00789\n",
            "2025-12-23 06:30:03.365543: train_loss -0.9618\n",
            "2025-12-23 06:30:03.365753: val_loss -0.9763\n",
            "2025-12-23 06:30:03.365868: Pseudo dice [np.float32(0.9831)]\n",
            "2025-12-23 06:30:03.366008: Epoch time: 22.55 s\n",
            "2025-12-23 06:30:04.678809: \n",
            "2025-12-23 06:30:04.679210: Epoch 233\n",
            "2025-12-23 06:30:04.679381: Current learning rate: 0.00788\n",
            "2025-12-23 06:30:27.183465: train_loss -0.9604\n",
            "2025-12-23 06:30:27.183667: val_loss -0.9753\n",
            "2025-12-23 06:30:27.183757: Pseudo dice [np.float32(0.9828)]\n",
            "2025-12-23 06:30:27.183848: Epoch time: 22.51 s\n",
            "2025-12-23 06:30:28.513751: \n",
            "2025-12-23 06:30:28.514096: Epoch 234\n",
            "2025-12-23 06:30:28.514270: Current learning rate: 0.00787\n",
            "2025-12-23 06:30:51.081284: train_loss -0.9593\n",
            "2025-12-23 06:30:51.081481: val_loss -0.9715\n",
            "2025-12-23 06:30:51.081642: Pseudo dice [np.float32(0.9784)]\n",
            "2025-12-23 06:30:51.081804: Epoch time: 22.57 s\n",
            "2025-12-23 06:30:52.406090: \n",
            "2025-12-23 06:30:52.406469: Epoch 235\n",
            "2025-12-23 06:30:52.406616: Current learning rate: 0.00786\n",
            "2025-12-23 06:31:14.987089: train_loss -0.9604\n",
            "2025-12-23 06:31:14.987329: val_loss -0.9736\n",
            "2025-12-23 06:31:14.987428: Pseudo dice [np.float32(0.9803)]\n",
            "2025-12-23 06:31:14.987519: Epoch time: 22.58 s\n",
            "2025-12-23 06:31:16.320991: \n",
            "2025-12-23 06:31:16.321312: Epoch 236\n",
            "2025-12-23 06:31:16.321463: Current learning rate: 0.00785\n",
            "2025-12-23 06:31:38.849415: train_loss -0.9597\n",
            "2025-12-23 06:31:38.849658: val_loss -0.976\n",
            "2025-12-23 06:31:38.849776: Pseudo dice [np.float32(0.9804)]\n",
            "2025-12-23 06:31:38.849874: Epoch time: 22.53 s\n",
            "2025-12-23 06:31:40.186013: \n",
            "2025-12-23 06:31:40.186321: Epoch 237\n",
            "2025-12-23 06:31:40.186463: Current learning rate: 0.00784\n",
            "2025-12-23 06:32:02.743009: train_loss -0.9602\n",
            "2025-12-23 06:32:02.743255: val_loss -0.9763\n",
            "2025-12-23 06:32:02.743347: Pseudo dice [np.float32(0.9821)]\n",
            "2025-12-23 06:32:02.743450: Epoch time: 22.56 s\n",
            "2025-12-23 06:32:04.068270: \n",
            "2025-12-23 06:32:04.068456: Epoch 238\n",
            "2025-12-23 06:32:04.068578: Current learning rate: 0.00783\n",
            "2025-12-23 06:32:26.595354: train_loss -0.9584\n",
            "2025-12-23 06:32:26.595645: val_loss -0.9741\n",
            "2025-12-23 06:32:26.595771: Pseudo dice [np.float32(0.9813)]\n",
            "2025-12-23 06:32:26.595896: Epoch time: 22.53 s\n",
            "2025-12-23 06:32:27.965110: \n",
            "2025-12-23 06:32:27.965317: Epoch 239\n",
            "2025-12-23 06:32:27.965497: Current learning rate: 0.00782\n",
            "2025-12-23 06:32:50.425275: train_loss -0.9585\n",
            "2025-12-23 06:32:50.425533: val_loss -0.975\n",
            "2025-12-23 06:32:50.425632: Pseudo dice [np.float32(0.9832)]\n",
            "2025-12-23 06:32:50.425721: Epoch time: 22.46 s\n",
            "2025-12-23 06:32:51.747491: \n",
            "2025-12-23 06:32:51.747707: Epoch 240\n",
            "2025-12-23 06:32:51.747855: Current learning rate: 0.00781\n",
            "2025-12-23 06:33:14.303088: train_loss -0.962\n",
            "2025-12-23 06:33:14.303372: val_loss -0.9732\n",
            "2025-12-23 06:33:14.303489: Pseudo dice [np.float32(0.9804)]\n",
            "2025-12-23 06:33:14.303584: Epoch time: 22.56 s\n",
            "2025-12-23 06:33:15.623804: \n",
            "2025-12-23 06:33:15.624147: Epoch 241\n",
            "2025-12-23 06:33:15.624293: Current learning rate: 0.0078\n",
            "2025-12-23 06:33:38.170089: train_loss -0.9563\n",
            "2025-12-23 06:33:38.170323: val_loss -0.9707\n",
            "2025-12-23 06:33:38.170538: Pseudo dice [np.float32(0.9772)]\n",
            "2025-12-23 06:33:38.170645: Epoch time: 22.55 s\n",
            "2025-12-23 06:33:39.522131: \n",
            "2025-12-23 06:33:39.522371: Epoch 242\n",
            "2025-12-23 06:33:39.522598: Current learning rate: 0.00779\n",
            "2025-12-23 06:34:02.063830: train_loss -0.9628\n",
            "2025-12-23 06:34:02.064257: val_loss -0.9771\n",
            "2025-12-23 06:34:02.064470: Pseudo dice [np.float32(0.9834)]\n",
            "2025-12-23 06:34:02.064669: Epoch time: 22.54 s\n",
            "2025-12-23 06:34:03.423309: \n",
            "2025-12-23 06:34:03.423606: Epoch 243\n",
            "2025-12-23 06:34:03.423782: Current learning rate: 0.00778\n",
            "2025-12-23 06:34:25.934845: train_loss -0.9647\n",
            "2025-12-23 06:34:25.935045: val_loss -0.9774\n",
            "2025-12-23 06:34:25.935131: Pseudo dice [np.float32(0.9815)]\n",
            "2025-12-23 06:34:25.935238: Epoch time: 22.51 s\n",
            "2025-12-23 06:34:27.255737: \n",
            "2025-12-23 06:34:27.255910: Epoch 244\n",
            "2025-12-23 06:34:27.256039: Current learning rate: 0.00777\n",
            "2025-12-23 06:34:49.777847: train_loss -0.961\n",
            "2025-12-23 06:34:49.778052: val_loss -0.9763\n",
            "2025-12-23 06:34:49.778161: Pseudo dice [np.float32(0.9819)]\n",
            "2025-12-23 06:34:49.778296: Epoch time: 22.52 s\n",
            "2025-12-23 06:34:51.140407: \n",
            "2025-12-23 06:34:51.140713: Epoch 245\n",
            "2025-12-23 06:34:51.140850: Current learning rate: 0.00777\n",
            "2025-12-23 06:35:13.635854: train_loss -0.9631\n",
            "2025-12-23 06:35:13.636093: val_loss -0.977\n",
            "2025-12-23 06:35:13.636256: Pseudo dice [np.float32(0.9837)]\n",
            "2025-12-23 06:35:13.636359: Epoch time: 22.5 s\n",
            "2025-12-23 06:35:15.418702: \n",
            "2025-12-23 06:35:15.419146: Epoch 246\n",
            "2025-12-23 06:35:15.419310: Current learning rate: 0.00776\n",
            "2025-12-23 06:35:38.031936: train_loss -0.9631\n",
            "2025-12-23 06:35:38.032146: val_loss -0.9771\n",
            "2025-12-23 06:35:38.032264: Pseudo dice [np.float32(0.9824)]\n",
            "2025-12-23 06:35:38.032449: Epoch time: 22.61 s\n",
            "2025-12-23 06:35:39.348101: \n",
            "2025-12-23 06:35:39.348414: Epoch 247\n",
            "2025-12-23 06:35:39.348562: Current learning rate: 0.00775\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n",
            "    sys.exit(run_training_entry())\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/run/run_training.py\", line 266, in run_training_entry\n",
            "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/run/run_training.py\", line 207, in run_training\n",
            "    nnunet_trainer.run_training()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1371, in run_training\n",
            "    train_outputs.append(self.train_step(next(self.dataloader_train)))\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 997, in train_step\n",
            "    self.grad_scaler.step(self.optimizer)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 462, in step\n",
            "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 356, in _maybe_opt_step\n",
            "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 356, in <genexpr>\n",
            "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
            "               ^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah /content/nnUNet/nnUNet_results/Dataset501_KSSD/nnUNetTrainer__nnUNetPlans__2d/fold_1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBlNQEFPDZg-",
        "outputId": "93b3a6fe-9bb5-48be-9662-6cf2b80e7927"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 512M\n",
            "drwxr-xr-x 2 root root 4.0K Dec 23 05:16 .\n",
            "drwxr-xr-x 4 root root 4.0K Dec 23 04:55 ..\n",
            "-rw-r--r-- 1 root root 256M Dec 23 06:17 checkpoint_best.pth\n",
            "-rw-r--r-- 1 root root 256M Dec 23 06:16 checkpoint_latest.pth\n",
            "-rw-r--r-- 1 root root 9.1K Dec 23 04:55 debug.json\n",
            "-rw-r--r-- 1 root root 421K Dec 23 06:35 progress.png\n",
            "-rw-r--r-- 1 root root  92K Dec 23 06:35 training_log_2025_12_23_04_55_11.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_predict \\\n",
        "  -i /content/nnUNet/nnUNet_raw/Dataset501_KSSD/imagesTr \\\n",
        "  -o /content/preds_fold1_best_on_train \\\n",
        "  -d 501 -c 2d -f 1 \\\n",
        "  -chk checkpoint_best.pth\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3boTAv_9Hs-R",
        "outputId": "35735130-a0bb-49d3-facf-6125fa6aa20b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0004\n",
            "\n",
            "Predicting case_0005:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0005\n",
            "\n",
            "Predicting case_0006:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.76it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0006\n",
            "\n",
            "Predicting case_0007:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.70it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0007\n",
            "\n",
            "Predicting case_0008:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.98it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0008\n",
            "\n",
            "Predicting case_0009:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.26it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0009\n",
            "\n",
            "Predicting case_0010:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.37it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0010\n",
            "\n",
            "Predicting case_0011:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 26.92it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0011\n",
            "\n",
            "Predicting case_0012:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0012\n",
            "\n",
            "Predicting case_0013:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.87it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0013\n",
            "\n",
            "Predicting case_0014:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.62it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0014\n",
            "\n",
            "Predicting case_0015:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.64it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0015\n",
            "\n",
            "Predicting case_0016:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.54it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0016\n",
            "\n",
            "Predicting case_0017:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0017\n",
            "\n",
            "Predicting case_0018:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.38it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0018\n",
            "\n",
            "Predicting case_0019:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.45it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0019\n",
            "\n",
            "Predicting case_0020:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.07it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0020\n",
            "\n",
            "Predicting case_0021:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.42it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0021\n",
            "\n",
            "Predicting case_0022:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.92it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0022\n",
            "\n",
            "Predicting case_0023:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.42it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0023\n",
            "\n",
            "Predicting case_0024:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.58it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0024\n",
            "\n",
            "Predicting case_0025:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.89it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0025\n",
            "\n",
            "Predicting case_0026:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.84it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0026\n",
            "\n",
            "Predicting case_0027:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0027\n",
            "\n",
            "Predicting case_0028:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0028\n",
            "\n",
            "Predicting case_0029:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.92it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0029\n",
            "\n",
            "Predicting case_0030:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.32it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0030\n",
            "\n",
            "Predicting case_0031:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.18it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0031\n",
            "\n",
            "Predicting case_0032:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.00it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0032\n",
            "\n",
            "Predicting case_0033:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.92it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0033\n",
            "\n",
            "Predicting case_0034:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.05it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0034\n",
            "\n",
            "Predicting case_0035:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.63it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0035\n",
            "\n",
            "Predicting case_0036:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.11it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0036\n",
            "\n",
            "Predicting case_0037:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.55it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0037\n",
            "\n",
            "Predicting case_0038:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 27.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0038\n",
            "\n",
            "Predicting case_0039:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.04it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0039\n",
            "\n",
            "Predicting case_0040:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.75it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0040\n",
            "\n",
            "Predicting case_0041:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0041\n",
            "\n",
            "Predicting case_0042:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.60it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0042\n",
            "\n",
            "Predicting case_0043:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.02it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0043\n",
            "\n",
            "Predicting case_0044:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.76it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0044\n",
            "\n",
            "Predicting case_0045:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0045\n",
            "\n",
            "Predicting case_0046:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.39it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0046\n",
            "\n",
            "Predicting case_0047:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.58it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0047\n",
            "\n",
            "Predicting case_0048:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.92it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0048\n",
            "\n",
            "Predicting case_0049:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.31it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0049\n",
            "\n",
            "Predicting case_0050:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 26.44it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0050\n",
            "\n",
            "Predicting case_0051:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0051\n",
            "\n",
            "Predicting case_0052:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.04it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0052\n",
            "\n",
            "Predicting case_0053:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.27it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0053\n",
            "\n",
            "Predicting case_0054:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.59it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0054\n",
            "\n",
            "Predicting case_0055:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.82it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0055\n",
            "\n",
            "Predicting case_0056:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.86it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0056\n",
            "\n",
            "Predicting case_0057:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.76it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0057\n",
            "\n",
            "Predicting case_0058:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.89it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0058\n",
            "\n",
            "Predicting case_0059:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.55it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0059\n",
            "\n",
            "Predicting case_0060:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.44it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0060\n",
            "\n",
            "Predicting case_0061:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.86it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0061\n",
            "\n",
            "Predicting case_0062:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.18it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0062\n",
            "\n",
            "Predicting case_0063:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.79it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0063\n",
            "\n",
            "Predicting case_0064:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.84it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0064\n",
            "\n",
            "Predicting case_0065:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0065\n",
            "\n",
            "Predicting case_0066:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.88it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0066\n",
            "\n",
            "Predicting case_0067:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.36it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0067\n",
            "\n",
            "Predicting case_0068:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.37it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0068\n",
            "\n",
            "Predicting case_0069:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.87it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0069\n",
            "\n",
            "Predicting case_0070:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 24.55it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0070\n",
            "\n",
            "Predicting case_0071:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.82it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0071\n",
            "\n",
            "Predicting case_0072:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.60it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0072\n",
            "\n",
            "Predicting case_0073:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0073\n",
            "\n",
            "Predicting case_0074:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.88it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0074\n",
            "\n",
            "Predicting case_0075:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.75it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0075\n",
            "\n",
            "Predicting case_0076:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0076\n",
            "\n",
            "Predicting case_0077:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0077\n",
            "\n",
            "Predicting case_0078:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.20it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0078\n",
            "\n",
            "Predicting case_0079:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.76it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0079\n",
            "\n",
            "Predicting case_0080:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.39it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0080\n",
            "\n",
            "Predicting case_0081:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.00it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0081\n",
            "\n",
            "Predicting case_0082:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.95it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0082\n",
            "\n",
            "Predicting case_0083:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.49it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0083\n",
            "\n",
            "Predicting case_0084:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.36it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0084\n",
            "\n",
            "Predicting case_0085:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.98it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0085\n",
            "\n",
            "Predicting case_0086:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.72it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0086\n",
            "\n",
            "Predicting case_0087:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.63it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0087\n",
            "\n",
            "Predicting case_0088:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.54it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0088\n",
            "\n",
            "Predicting case_0089:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.96it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0089\n",
            "\n",
            "Predicting case_0090:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.57it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0090\n",
            "\n",
            "Predicting case_0091:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0091\n",
            "\n",
            "Predicting case_0092:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.74it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0092\n",
            "\n",
            "Predicting case_0093:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.52it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0093\n",
            "\n",
            "Predicting case_0094:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.51it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0094\n",
            "\n",
            "Predicting case_0095:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0095\n",
            "\n",
            "Predicting case_0096:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.99it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0096\n",
            "\n",
            "Predicting case_0097:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0097\n",
            "\n",
            "Predicting case_0098:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.81it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0098\n",
            "\n",
            "Predicting case_0099:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.83it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0099\n",
            "\n",
            "Predicting case_0100:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.27it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0100\n",
            "\n",
            "Predicting case_0101:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 27.50it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0101\n",
            "\n",
            "Predicting case_0102:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.93it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0102\n",
            "\n",
            "Predicting case_0103:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.60it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0103\n",
            "\n",
            "Predicting case_0104:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.82it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0104\n",
            "\n",
            "Predicting case_0105:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.70it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0105\n",
            "\n",
            "Predicting case_0106:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.03it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0106\n",
            "\n",
            "Predicting case_0107:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0107\n",
            "\n",
            "Predicting case_0108:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.31it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0108\n",
            "\n",
            "Predicting case_0109:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.46it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0109\n",
            "\n",
            "Predicting case_0110:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0110\n",
            "\n",
            "Predicting case_0111:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.40it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0111\n",
            "\n",
            "Predicting case_0112:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.19it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0112\n",
            "\n",
            "Predicting case_0113:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.52it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0113\n",
            "\n",
            "Predicting case_0114:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.59it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0114\n",
            "\n",
            "Predicting case_0115:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0115\n",
            "\n",
            "Predicting case_0116:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.51it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0116\n",
            "\n",
            "Predicting case_0117:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.51it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0117\n",
            "\n",
            "Predicting case_0118:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.59it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0118\n",
            "\n",
            "Predicting case_0119:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.73it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0119\n",
            "\n",
            "Predicting case_0120:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.69it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0120\n",
            "\n",
            "Predicting case_0121:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.50it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0121\n",
            "\n",
            "Predicting case_0122:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.24it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0122\n",
            "\n",
            "Predicting case_0123:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.92it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0123\n",
            "\n",
            "Predicting case_0124:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.02it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0124\n",
            "\n",
            "Predicting case_0125:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.98it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0125\n",
            "\n",
            "Predicting case_0126:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.18it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0126\n",
            "\n",
            "Predicting case_0127:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.61it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0127\n",
            "\n",
            "Predicting case_0128:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.06it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0128\n",
            "\n",
            "Predicting case_0129:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.86it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0129\n",
            "\n",
            "Predicting case_0130:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.69it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0130\n",
            "\n",
            "Predicting case_0131:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.84it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0131\n",
            "\n",
            "Predicting case_0132:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.51it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0132\n",
            "\n",
            "Predicting case_0133:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.81it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0133\n",
            "\n",
            "Predicting case_0134:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.52it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0134\n",
            "\n",
            "Predicting case_0135:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0135\n",
            "\n",
            "Predicting case_0136:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.42it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0136\n",
            "\n",
            "Predicting case_0137:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.72it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0137\n",
            "\n",
            "Predicting case_0138:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.70it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0138\n",
            "\n",
            "Predicting case_0139:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.89it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0139\n",
            "\n",
            "Predicting case_0140:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.43it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0140\n",
            "\n",
            "Predicting case_0141:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.06it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0141\n",
            "\n",
            "Predicting case_0142:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0142\n",
            "\n",
            "Predicting case_0143:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.02it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0143\n",
            "\n",
            "Predicting case_0144:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.08it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0144\n",
            "\n",
            "Predicting case_0145:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.12it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0145\n",
            "\n",
            "Predicting case_0146:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0146\n",
            "\n",
            "Predicting case_0147:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0147\n",
            "\n",
            "Predicting case_0148:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.13it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0148\n",
            "\n",
            "Predicting case_0149:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.59it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0149\n",
            "\n",
            "Predicting case_0150:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.96it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0150\n",
            "\n",
            "Predicting case_0151:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.06it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0151\n",
            "\n",
            "Predicting case_0152:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.51it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0152\n",
            "\n",
            "Predicting case_0153:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.82it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0153\n",
            "\n",
            "Predicting case_0154:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.24it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0154\n",
            "\n",
            "Predicting case_0155:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.35it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0155\n",
            "\n",
            "Predicting case_0156:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0156\n",
            "\n",
            "Predicting case_0157:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.48it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0157\n",
            "\n",
            "Predicting case_0158:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.72it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0158\n",
            "\n",
            "Predicting case_0159:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.13it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0159\n",
            "\n",
            "Predicting case_0160:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.74it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0160\n",
            "\n",
            "Predicting case_0161:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.31it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0161\n",
            "\n",
            "Predicting case_0162:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.65it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0162\n",
            "\n",
            "Predicting case_0163:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.95it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0163\n",
            "\n",
            "Predicting case_0164:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.60it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0164\n",
            "\n",
            "Predicting case_0165:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.88it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0165\n",
            "\n",
            "Predicting case_0166:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.11it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0166\n",
            "\n",
            "Predicting case_0167:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.40it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0167\n",
            "\n",
            "Predicting case_0168:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.93it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0168\n",
            "\n",
            "Predicting case_0169:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.92it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0169\n",
            "\n",
            "Predicting case_0170:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.65it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0170\n",
            "\n",
            "Predicting case_0171:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0171\n",
            "\n",
            "Predicting case_0172:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0172\n",
            "\n",
            "Predicting case_0173:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0173\n",
            "\n",
            "Predicting case_0174:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0174\n",
            "\n",
            "Predicting case_0175:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.72it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0175\n",
            "\n",
            "Predicting case_0176:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.62it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0176\n",
            "\n",
            "Predicting case_0177:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0177\n",
            "\n",
            "Predicting case_0178:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.87it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0178\n",
            "\n",
            "Predicting case_0179:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.32it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0179\n",
            "\n",
            "Predicting case_0180:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0180\n",
            "\n",
            "Predicting case_0181:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.29it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0181\n",
            "\n",
            "Predicting case_0182:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.02it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0182\n",
            "\n",
            "Predicting case_0183:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.09it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0183\n",
            "\n",
            "Predicting case_0184:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0184\n",
            "\n",
            "Predicting case_0185:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.94it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0185\n",
            "\n",
            "Predicting case_0186:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0186\n",
            "\n",
            "Predicting case_0187:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.19it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0187\n",
            "\n",
            "Predicting case_0188:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0188\n",
            "\n",
            "Predicting case_0189:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.89it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0189\n",
            "\n",
            "Predicting case_0190:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.49it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0190\n",
            "\n",
            "Predicting case_0191:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.42it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0191\n",
            "\n",
            "Predicting case_0192:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0192\n",
            "\n",
            "Predicting case_0193:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0193\n",
            "\n",
            "Predicting case_0194:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.73it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0194\n",
            "\n",
            "Predicting case_0195:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.39it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0195\n",
            "\n",
            "Predicting case_0196:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.87it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0196\n",
            "\n",
            "Predicting case_0197:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.52it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0197\n",
            "\n",
            "Predicting case_0198:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0198\n",
            "\n",
            "Predicting case_0199:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.51it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0199\n",
            "\n",
            "Predicting case_0200:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.81it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0200\n",
            "\n",
            "Predicting case_0201:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.23it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0201\n",
            "\n",
            "Predicting case_0202:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.25it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0202\n",
            "\n",
            "Predicting case_0203:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.18it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0203\n",
            "\n",
            "Predicting case_0204:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.20it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0204\n",
            "\n",
            "Predicting case_0205:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.20it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0205\n",
            "\n",
            "Predicting case_0206:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.58it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0206\n",
            "\n",
            "Predicting case_0207:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.31it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0207\n",
            "\n",
            "Predicting case_0208:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.38it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0208\n",
            "\n",
            "Predicting case_0209:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.94it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0209\n",
            "\n",
            "Predicting case_0210:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.05it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0210\n",
            "\n",
            "Predicting case_0211:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0211\n",
            "\n",
            "Predicting case_0212:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.92it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0212\n",
            "\n",
            "Predicting case_0213:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0213\n",
            "\n",
            "Predicting case_0214:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.08it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0214\n",
            "\n",
            "Predicting case_0215:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.13it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0215\n",
            "\n",
            "Predicting case_0216:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.32it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0216\n",
            "\n",
            "Predicting case_0217:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.76it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0217\n",
            "\n",
            "Predicting case_0218:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.08it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0218\n",
            "\n",
            "Predicting case_0219:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.88it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0219\n",
            "\n",
            "Predicting case_0220:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.24it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0220\n",
            "\n",
            "Predicting case_0221:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.99it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0221\n",
            "\n",
            "Predicting case_0222:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.48it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0222\n",
            "\n",
            "Predicting case_0223:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0223\n",
            "\n",
            "Predicting case_0224:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0224\n",
            "\n",
            "Predicting case_0225:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.46it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0225\n",
            "\n",
            "Predicting case_0226:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.37it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0226\n",
            "\n",
            "Predicting case_0227:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.19it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0227\n",
            "\n",
            "Predicting case_0228:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.05it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0228\n",
            "\n",
            "Predicting case_0229:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.61it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0229\n",
            "\n",
            "Predicting case_0230:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.37it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0230\n",
            "\n",
            "Predicting case_0231:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.72it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0231\n",
            "\n",
            "Predicting case_0232:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.36it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0232\n",
            "\n",
            "Predicting case_0233:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.70it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0233\n",
            "\n",
            "Predicting case_0234:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.11it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0234\n",
            "\n",
            "Predicting case_0235:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0235\n",
            "\n",
            "Predicting case_0236:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.06it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0236\n",
            "\n",
            "Predicting case_0237:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0237\n",
            "\n",
            "Predicting case_0238:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.16it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0238\n",
            "\n",
            "Predicting case_0239:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.29it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0239\n",
            "\n",
            "Predicting case_0240:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.75it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0240\n",
            "\n",
            "Predicting case_0241:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.32it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0241\n",
            "\n",
            "Predicting case_0242:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0242\n",
            "\n",
            "Predicting case_0243:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 33.72it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0243\n",
            "\n",
            "Predicting case_0244:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.35it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0244\n",
            "\n",
            "Predicting case_0245:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 33.93it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0245\n",
            "\n",
            "Predicting case_0246:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.43it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0246\n",
            "\n",
            "Predicting case_0247:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.19it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0247\n",
            "\n",
            "Predicting case_0248:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.56it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0248\n",
            "\n",
            "Predicting case_0249:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.23it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0249\n",
            "\n",
            "Predicting case_0250:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.72it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0250\n",
            "\n",
            "Predicting case_0251:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0251\n",
            "\n",
            "Predicting case_0252:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.42it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0252\n",
            "\n",
            "Predicting case_0253:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.09it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0253\n",
            "\n",
            "Predicting case_0254:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.77it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0254\n",
            "\n",
            "Predicting case_0255:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.85it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0255\n",
            "\n",
            "Predicting case_0256:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0256\n",
            "\n",
            "Predicting case_0257:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.15it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0257\n",
            "\n",
            "Predicting case_0258:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0258\n",
            "\n",
            "Predicting case_0259:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0259\n",
            "\n",
            "Predicting case_0260:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0260\n",
            "\n",
            "Predicting case_0261:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0261\n",
            "\n",
            "Predicting case_0262:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.87it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0262\n",
            "\n",
            "Predicting case_0263:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.21it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0263\n",
            "\n",
            "Predicting case_0264:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.44it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0264\n",
            "\n",
            "Predicting case_0265:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.07it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0265\n",
            "\n",
            "Predicting case_0266:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.45it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0266\n",
            "\n",
            "Predicting case_0267:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.61it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0267\n",
            "\n",
            "Predicting case_0268:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.35it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0268\n",
            "\n",
            "Predicting case_0269:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.09it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0269\n",
            "\n",
            "Predicting case_0270:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.00it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0270\n",
            "\n",
            "Predicting case_0271:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.73it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0271\n",
            "\n",
            "Predicting case_0272:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0272\n",
            "\n",
            "Predicting case_0273:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.04it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0273\n",
            "\n",
            "Predicting case_0274:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.52it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0274\n",
            "\n",
            "Predicting case_0275:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.23it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0275\n",
            "\n",
            "Predicting case_0276:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.15it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0276\n",
            "\n",
            "Predicting case_0277:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.82it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0277\n",
            "\n",
            "Predicting case_0278:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0278\n",
            "\n",
            "Predicting case_0279:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 36.39it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0279\n",
            "\n",
            "Predicting case_0280:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 36.36it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0280\n",
            "\n",
            "Predicting case_0281:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 36.25it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0281\n",
            "\n",
            "Predicting case_0282:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 36.41it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0282\n",
            "\n",
            "Predicting case_0283:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 35.04it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0283\n",
            "\n",
            "Predicting case_0284:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 34.41it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0284\n",
            "\n",
            "Predicting case_0285:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 33.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0285\n",
            "\n",
            "Predicting case_0286:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 36.03it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0286\n",
            "\n",
            "Predicting case_0287:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.63it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0287\n",
            "\n",
            "Predicting case_0288:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 33.45it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0288\n",
            "\n",
            "Predicting case_0289:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 28.57it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0289\n",
            "\n",
            "Predicting case_0290:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00, 31.53it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0290\n",
            "\n",
            "Predicting case_0291:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0291\n",
            "\n",
            "Predicting case_0292:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.12it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0292\n",
            "\n",
            "Predicting case_0293:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.02it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0293\n",
            "\n",
            "Predicting case_0294:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0294\n",
            "\n",
            "Predicting case_0295:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.09it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0295\n",
            "\n",
            "Predicting case_0296:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0296\n",
            "\n",
            "Predicting case_0297:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.76it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0297\n",
            "\n",
            "Predicting case_0298:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.61it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0298\n",
            "\n",
            "Predicting case_0299:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.60it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0299\n",
            "\n",
            "Predicting case_0300:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.05it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0300\n",
            "\n",
            "Predicting case_0301:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.13it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0301\n",
            "\n",
            "Predicting case_0302:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.43it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0302\n",
            "\n",
            "Predicting case_0303:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.95it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0303\n",
            "\n",
            "Predicting case_0304:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.60it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0304\n",
            "\n",
            "Predicting case_0305:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.77it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0305\n",
            "\n",
            "Predicting case_0306:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0306\n",
            "\n",
            "Predicting case_0307:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.93it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0307\n",
            "\n",
            "Predicting case_0308:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0308\n",
            "\n",
            "Predicting case_0309:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.81it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0309\n",
            "\n",
            "Predicting case_0310:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.30it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0310\n",
            "\n",
            "Predicting case_0311:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.33it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0311\n",
            "\n",
            "Predicting case_0312:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.25it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0312\n",
            "\n",
            "Predicting case_0313:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0313\n",
            "\n",
            "Predicting case_0314:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.88it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0314\n",
            "\n",
            "Predicting case_0315:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.07it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0315\n",
            "\n",
            "Predicting case_0316:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.23it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0316\n",
            "\n",
            "Predicting case_0317:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.11it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0317\n",
            "\n",
            "Predicting case_0318:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.58it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0318\n",
            "\n",
            "Predicting case_0319:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.63it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0319\n",
            "\n",
            "Predicting case_0320:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.02it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0320\n",
            "\n",
            "Predicting case_0321:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.54it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0321\n",
            "\n",
            "Predicting case_0322:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.69it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0322\n",
            "\n",
            "Predicting case_0323:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.93it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0323\n",
            "\n",
            "Predicting case_0324:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.43it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0324\n",
            "\n",
            "Predicting case_0325:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.32it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0325\n",
            "\n",
            "Predicting case_0326:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.31it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0326\n",
            "\n",
            "Predicting case_0327:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.70it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0327\n",
            "\n",
            "Predicting case_0328:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.43it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0328\n",
            "\n",
            "Predicting case_0329:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.32it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0329\n",
            "\n",
            "Predicting case_0330:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.65it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0330\n",
            "\n",
            "Predicting case_0331:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.65it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0331\n",
            "\n",
            "Predicting case_0332:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.12it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0332\n",
            "\n",
            "Predicting case_0333:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.62it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0333\n",
            "\n",
            "Predicting case_0334:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.79it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0334\n",
            "\n",
            "Predicting case_0335:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.62it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0335\n",
            "\n",
            "Predicting case_0336:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0336\n",
            "\n",
            "Predicting case_0337:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.25it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0337\n",
            "\n",
            "Predicting case_0338:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 26.51it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0338\n",
            "\n",
            "Predicting case_0339:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.19it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0339\n",
            "\n",
            "Predicting case_0340:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.99it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0340\n",
            "\n",
            "Predicting case_0341:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.42it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0341\n",
            "\n",
            "Predicting case_0342:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0342\n",
            "\n",
            "Predicting case_0343:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.21it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0343\n",
            "\n",
            "Predicting case_0344:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0344\n",
            "\n",
            "Predicting case_0345:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.70it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0345\n",
            "\n",
            "Predicting case_0346:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.44it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0346\n",
            "\n",
            "Predicting case_0347:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.59it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0347\n",
            "\n",
            "Predicting case_0348:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.85it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0348\n",
            "\n",
            "Predicting case_0349:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.79it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0349\n",
            "\n",
            "Predicting case_0350:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0350\n",
            "\n",
            "Predicting case_0351:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0351\n",
            "\n",
            "Predicting case_0352:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.06it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0352\n",
            "\n",
            "Predicting case_0353:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.23it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0353\n",
            "\n",
            "Predicting case_0354:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.93it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0354\n",
            "\n",
            "Predicting case_0355:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.86it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0355\n",
            "\n",
            "Predicting case_0356:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.18it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0356\n",
            "\n",
            "Predicting case_0357:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.83it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0357\n",
            "\n",
            "Predicting case_0358:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0358\n",
            "\n",
            "Predicting case_0359:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.12it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0359\n",
            "\n",
            "Predicting case_0360:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.72it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0360\n",
            "\n",
            "Predicting case_0361:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.02it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0361\n",
            "\n",
            "Predicting case_0362:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.64it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0362\n",
            "\n",
            "Predicting case_0363:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.64it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0363\n",
            "\n",
            "Predicting case_0364:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.19it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0364\n",
            "\n",
            "Predicting case_0365:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.35it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0365\n",
            "\n",
            "Predicting case_0366:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.38it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0366\n",
            "\n",
            "Predicting case_0367:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.11it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0367\n",
            "\n",
            "Predicting case_0368:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.17it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0368\n",
            "\n",
            "Predicting case_0369:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.99it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0369\n",
            "\n",
            "Predicting case_0370:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.88it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0370\n",
            "\n",
            "Predicting case_0371:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.62it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0371\n",
            "\n",
            "Predicting case_0372:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.07it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0372\n",
            "\n",
            "Predicting case_0373:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.70it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0373\n",
            "\n",
            "Predicting case_0374:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.17it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0374\n",
            "\n",
            "Predicting case_0375:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.00it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0375\n",
            "\n",
            "Predicting case_0376:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0376\n",
            "\n",
            "Predicting case_0377:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.31it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0377\n",
            "\n",
            "Predicting case_0378:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0378\n",
            "\n",
            "Predicting case_0379:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.71it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0379\n",
            "\n",
            "Predicting case_0380:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0380\n",
            "\n",
            "Predicting case_0381:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0381\n",
            "\n",
            "Predicting case_0382:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0382\n",
            "\n",
            "Predicting case_0383:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.18it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0383\n",
            "\n",
            "Predicting case_0384:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.52it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0384\n",
            "\n",
            "Predicting case_0385:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.52it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0385\n",
            "\n",
            "Predicting case_0386:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0386\n",
            "\n",
            "Predicting case_0387:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.07it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0387\n",
            "\n",
            "Predicting case_0388:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.57it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0388\n",
            "\n",
            "Predicting case_0389:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.49it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0389\n",
            "\n",
            "Predicting case_0390:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.49it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0390\n",
            "\n",
            "Predicting case_0391:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.19it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0391\n",
            "\n",
            "Predicting case_0392:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.63it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0392\n",
            "\n",
            "Predicting case_0393:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.63it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0393\n",
            "\n",
            "Predicting case_0394:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.72it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0394\n",
            "\n",
            "Predicting case_0395:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.13it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0395\n",
            "\n",
            "Predicting case_0396:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.09it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0396\n",
            "\n",
            "Predicting case_0397:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.55it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0397\n",
            "\n",
            "Predicting case_0398:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.45it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0398\n",
            "\n",
            "Predicting case_0399:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.23it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0399\n",
            "\n",
            "Predicting case_0400:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.58it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0400\n",
            "\n",
            "Predicting case_0401:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.75it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0401\n",
            "\n",
            "Predicting case_0402:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0402\n",
            "\n",
            "Predicting case_0403:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 27.55it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0403\n",
            "\n",
            "Predicting case_0404:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0404\n",
            "\n",
            "Predicting case_0405:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 27.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0405\n",
            "\n",
            "Predicting case_0406:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0406\n",
            "\n",
            "Predicting case_0407:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 27.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0407\n",
            "\n",
            "Predicting case_0408:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.69it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0408\n",
            "\n",
            "Predicting case_0409:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.70it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0409\n",
            "\n",
            "Predicting case_0410:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.56it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0410\n",
            "\n",
            "Predicting case_0411:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.71it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0411\n",
            "\n",
            "Predicting case_0412:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0412\n",
            "\n",
            "Predicting case_0413:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0413\n",
            "\n",
            "Predicting case_0414:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.29it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0414\n",
            "\n",
            "Predicting case_0415:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.69it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0415\n",
            "\n",
            "Predicting case_0416:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.55it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0416\n",
            "\n",
            "Predicting case_0417:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.40it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0417\n",
            "\n",
            "Predicting case_0418:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0418\n",
            "\n",
            "Predicting case_0419:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0419\n",
            "\n",
            "Predicting case_0420:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.18it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0420\n",
            "\n",
            "Predicting case_0421:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.17it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0421\n",
            "\n",
            "Predicting case_0422:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.32it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0422\n",
            "\n",
            "Predicting case_0423:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.05it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0423\n",
            "\n",
            "Predicting case_0424:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.98it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0424\n",
            "\n",
            "Predicting case_0425:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0425\n",
            "\n",
            "Predicting case_0426:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.54it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0426\n",
            "\n",
            "Predicting case_0427:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.45it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0427\n",
            "\n",
            "Predicting case_0428:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.56it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0428\n",
            "\n",
            "Predicting case_0429:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0429\n",
            "\n",
            "Predicting case_0430:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.00it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0430\n",
            "\n",
            "Predicting case_0431:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0431\n",
            "\n",
            "Predicting case_0432:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.98it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0432\n",
            "\n",
            "Predicting case_0433:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.07it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0433\n",
            "\n",
            "Predicting case_0434:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.96it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0434\n",
            "\n",
            "Predicting case_0435:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.59it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0435\n",
            "\n",
            "Predicting case_0436:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.84it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0436\n",
            "\n",
            "Predicting case_0437:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.06it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0437\n",
            "\n",
            "Predicting case_0438:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.84it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0438\n",
            "\n",
            "Predicting case_0439:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.00it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0439\n",
            "\n",
            "Predicting case_0440:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.25it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0440\n",
            "\n",
            "Predicting case_0441:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.24it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0441\n",
            "\n",
            "Predicting case_0442:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.36it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0442\n",
            "\n",
            "Predicting case_0443:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.13it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0443\n",
            "\n",
            "Predicting case_0444:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.02it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0444\n",
            "\n",
            "Predicting case_0445:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.62it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0445\n",
            "\n",
            "Predicting case_0446:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.49it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0446\n",
            "\n",
            "Predicting case_0447:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.40it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0447\n",
            "\n",
            "Predicting case_0448:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.17it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0448\n",
            "\n",
            "Predicting case_0449:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.12it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0449\n",
            "\n",
            "Predicting case_0450:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.83it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0450\n",
            "\n",
            "Predicting case_0451:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.44it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0451\n",
            "\n",
            "Predicting case_0452:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.41it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0452\n",
            "\n",
            "Predicting case_0453:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0453\n",
            "\n",
            "Predicting case_0454:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.61it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0454\n",
            "\n",
            "Predicting case_0455:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.52it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0455\n",
            "\n",
            "Predicting case_0456:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0456\n",
            "\n",
            "Predicting case_0457:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.60it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0457\n",
            "\n",
            "Predicting case_0458:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.37it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0458\n",
            "\n",
            "Predicting case_0459:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.43it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0459\n",
            "\n",
            "Predicting case_0460:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.24it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0460\n",
            "\n",
            "Predicting case_0461:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.95it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0461\n",
            "\n",
            "Predicting case_0462:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.98it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0462\n",
            "\n",
            "Predicting case_0463:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.59it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0463\n",
            "\n",
            "Predicting case_0464:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.43it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0464\n",
            "\n",
            "Predicting case_0465:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.38it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0465\n",
            "\n",
            "Predicting case_0466:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0466\n",
            "\n",
            "Predicting case_0467:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.84it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0467\n",
            "\n",
            "Predicting case_0468:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.75it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0468\n",
            "\n",
            "Predicting case_0469:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.61it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0469\n",
            "\n",
            "Predicting case_0470:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.95it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0470\n",
            "\n",
            "Predicting case_0471:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.61it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0471\n",
            "\n",
            "Predicting case_0472:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.07it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0472\n",
            "\n",
            "Predicting case_0473:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0473\n",
            "\n",
            "Predicting case_0474:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0474\n",
            "\n",
            "Predicting case_0475:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.92it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0475\n",
            "\n",
            "Predicting case_0476:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.19it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0476\n",
            "\n",
            "Predicting case_0477:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0477\n",
            "\n",
            "Predicting case_0478:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.96it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0478\n",
            "\n",
            "Predicting case_0479:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.83it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0479\n",
            "\n",
            "Predicting case_0480:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.69it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0480\n",
            "\n",
            "Predicting case_0481:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.86it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0481\n",
            "\n",
            "Predicting case_0482:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.83it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0482\n",
            "\n",
            "Predicting case_0483:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.11it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0483\n",
            "\n",
            "Predicting case_0484:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.75it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0484\n",
            "\n",
            "Predicting case_0485:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0485\n",
            "\n",
            "Predicting case_0486:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.25it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0486\n",
            "\n",
            "Predicting case_0487:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.98it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0487\n",
            "\n",
            "Predicting case_0488:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.37it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0488\n",
            "\n",
            "Predicting case_0489:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0489\n",
            "\n",
            "Predicting case_0490:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.28it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0490\n",
            "\n",
            "Predicting case_0491:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0491\n",
            "\n",
            "Predicting case_0492:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.13it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0492\n",
            "\n",
            "Predicting case_0493:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.06it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0493\n",
            "\n",
            "Predicting case_0494:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.56it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0494\n",
            "\n",
            "Predicting case_0495:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.25it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0495\n",
            "\n",
            "Predicting case_0496:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.18it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0496\n",
            "\n",
            "Predicting case_0497:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.45it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0497\n",
            "\n",
            "Predicting case_0498:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.19it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0498\n",
            "\n",
            "Predicting case_0499:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.62it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0499\n",
            "\n",
            "Predicting case_0500:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.58it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0500\n",
            "\n",
            "Predicting case_0501:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.00it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0501\n",
            "\n",
            "Predicting case_0502:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0502\n",
            "\n",
            "Predicting case_0503:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.45it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0503\n",
            "\n",
            "Predicting case_0504:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0504\n",
            "\n",
            "Predicting case_0505:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.39it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0505\n",
            "\n",
            "Predicting case_0506:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.43it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0506\n",
            "\n",
            "Predicting case_0507:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0507\n",
            "\n",
            "Predicting case_0508:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.79it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0508\n",
            "\n",
            "Predicting case_0509:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0509\n",
            "\n",
            "Predicting case_0510:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0510\n",
            "\n",
            "Predicting case_0511:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.81it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0511\n",
            "\n",
            "Predicting case_0512:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.63it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0512\n",
            "\n",
            "Predicting case_0513:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.36it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0513\n",
            "\n",
            "Predicting case_0514:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.83it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0514\n",
            "\n",
            "Predicting case_0515:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0515\n",
            "\n",
            "Predicting case_0516:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.11it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0516\n",
            "\n",
            "Predicting case_0517:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.31it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0517\n",
            "\n",
            "Predicting case_0518:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0518\n",
            "\n",
            "Predicting case_0519:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.60it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0519\n",
            "\n",
            "Predicting case_0520:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.32it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0520\n",
            "\n",
            "Predicting case_0521:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.38it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0521\n",
            "\n",
            "Predicting case_0522:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.99it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0522\n",
            "\n",
            "Predicting case_0523:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.62it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0523\n",
            "\n",
            "Predicting case_0524:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0524\n",
            "\n",
            "Predicting case_0525:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.96it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0525\n",
            "\n",
            "Predicting case_0526:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.46it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0526\n",
            "\n",
            "Predicting case_0527:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.57it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0527\n",
            "\n",
            "Predicting case_0528:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.12it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0528\n",
            "\n",
            "Predicting case_0529:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.93it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0529\n",
            "\n",
            "Predicting case_0530:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.64it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0530\n",
            "\n",
            "Predicting case_0531:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.31it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0531\n",
            "\n",
            "Predicting case_0532:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.39it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0532\n",
            "\n",
            "Predicting case_0533:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.88it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0533\n",
            "\n",
            "Predicting case_0534:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.28it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0534\n",
            "\n",
            "Predicting case_0535:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.40it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0535\n",
            "\n",
            "Predicting case_0536:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.44it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0536\n",
            "\n",
            "Predicting case_0537:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.65it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0537\n",
            "\n",
            "Predicting case_0538:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.35it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0538\n",
            "\n",
            "Predicting case_0539:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.42it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0539\n",
            "\n",
            "Predicting case_0540:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.42it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0540\n",
            "\n",
            "Predicting case_0541:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.95it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0541\n",
            "\n",
            "Predicting case_0542:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0542\n",
            "\n",
            "Predicting case_0543:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0543\n",
            "\n",
            "Predicting case_0544:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.71it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0544\n",
            "\n",
            "Predicting case_0545:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.04it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0545\n",
            "\n",
            "Predicting case_0546:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.99it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0546\n",
            "\n",
            "Predicting case_0547:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.61it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0547\n",
            "\n",
            "Predicting case_0548:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.86it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0548\n",
            "\n",
            "Predicting case_0549:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.48it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0549\n",
            "\n",
            "Predicting case_0550:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.58it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0550\n",
            "\n",
            "Predicting case_0551:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.54it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0551\n",
            "\n",
            "Predicting case_0552:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.20it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0552\n",
            "\n",
            "Predicting case_0553:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.27it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0553\n",
            "\n",
            "Predicting case_0554:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.33it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0554\n",
            "\n",
            "Predicting case_0555:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.92it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0555\n",
            "\n",
            "Predicting case_0556:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0556\n",
            "\n",
            "Predicting case_0557:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.28it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0557\n",
            "\n",
            "Predicting case_0558:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.52it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0558\n",
            "\n",
            "Predicting case_0559:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0559\n",
            "\n",
            "Predicting case_0560:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.25it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0560\n",
            "\n",
            "Predicting case_0561:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.65it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0561\n",
            "\n",
            "Predicting case_0562:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.62it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0562\n",
            "\n",
            "Predicting case_0563:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.37it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0563\n",
            "\n",
            "Predicting case_0564:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.69it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0564\n",
            "\n",
            "Predicting case_0565:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.85it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0565\n",
            "\n",
            "Predicting case_0566:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.36it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0566\n",
            "\n",
            "Predicting case_0567:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.58it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0567\n",
            "\n",
            "Predicting case_0568:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.46it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0568\n",
            "\n",
            "Predicting case_0569:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.73it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0569\n",
            "\n",
            "Predicting case_0570:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0570\n",
            "\n",
            "Predicting case_0571:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.13it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0571\n",
            "\n",
            "Predicting case_0572:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.30it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0572\n",
            "\n",
            "Predicting case_0573:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.18it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0573\n",
            "\n",
            "Predicting case_0574:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.28it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0574\n",
            "\n",
            "Predicting case_0575:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.29it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0575\n",
            "\n",
            "Predicting case_0576:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.12it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0576\n",
            "\n",
            "Predicting case_0577:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.71it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0577\n",
            "\n",
            "Predicting case_0578:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.51it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0578\n",
            "\n",
            "Predicting case_0579:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.89it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0579\n",
            "\n",
            "Predicting case_0580:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.13it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0580\n",
            "\n",
            "Predicting case_0581:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.16it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0581\n",
            "\n",
            "Predicting case_0582:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.11it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0582\n",
            "\n",
            "Predicting case_0583:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.63it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0583\n",
            "\n",
            "Predicting case_0584:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0584\n",
            "\n",
            "Predicting case_0585:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.09it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0585\n",
            "\n",
            "Predicting case_0586:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.25it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0586\n",
            "\n",
            "Predicting case_0587:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.63it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0587\n",
            "\n",
            "Predicting case_0588:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.06it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0588\n",
            "\n",
            "Predicting case_0589:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.30it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0589\n",
            "\n",
            "Predicting case_0590:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.42it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0590\n",
            "\n",
            "Predicting case_0591:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 26.11it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0591\n",
            "\n",
            "Predicting case_0592:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.77it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0592\n",
            "\n",
            "Predicting case_0593:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00,  3.24it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0593\n",
            "\n",
            "Predicting case_0594:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.09it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0594\n",
            "\n",
            "Predicting case_0595:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0595\n",
            "\n",
            "Predicting case_0596:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0596\n",
            "\n",
            "Predicting case_0597:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.93it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0597\n",
            "\n",
            "Predicting case_0598:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.17it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0598\n",
            "\n",
            "Predicting case_0599:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.06it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0599\n",
            "\n",
            "Predicting case_0600:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.03it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0600\n",
            "\n",
            "Predicting case_0601:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.08it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0601\n",
            "\n",
            "Predicting case_0602:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0602\n",
            "\n",
            "Predicting case_0603:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0603\n",
            "\n",
            "Predicting case_0604:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.36it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0604\n",
            "\n",
            "Predicting case_0605:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.00it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0605\n",
            "\n",
            "Predicting case_0606:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.70it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0606\n",
            "\n",
            "Predicting case_0607:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.29it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0607\n",
            "\n",
            "Predicting case_0608:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.79it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0608\n",
            "\n",
            "Predicting case_0609:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.13it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0609\n",
            "\n",
            "Predicting case_0610:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.11it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0610\n",
            "\n",
            "Predicting case_0611:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.84it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0611\n",
            "\n",
            "Predicting case_0612:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.05it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0612\n",
            "\n",
            "Predicting case_0613:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0613\n",
            "\n",
            "Predicting case_0614:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.03it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0614\n",
            "\n",
            "Predicting case_0615:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.17it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0615\n",
            "\n",
            "Predicting case_0616:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.13it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0616\n",
            "\n",
            "Predicting case_0617:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.74it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0617\n",
            "\n",
            "Predicting case_0618:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.42it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0618\n",
            "\n",
            "Predicting case_0619:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.88it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0619\n",
            "\n",
            "Predicting case_0620:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.72it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0620\n",
            "\n",
            "Predicting case_0621:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.71it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0621\n",
            "\n",
            "Predicting case_0622:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.82it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0622\n",
            "\n",
            "Predicting case_0623:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0623\n",
            "\n",
            "Predicting case_0624:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.46it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0624\n",
            "\n",
            "Predicting case_0625:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.46it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0625\n",
            "\n",
            "Predicting case_0626:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 25.43it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0626\n",
            "\n",
            "Predicting case_0627:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0627\n",
            "\n",
            "Predicting case_0628:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.73it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0628\n",
            "\n",
            "Predicting case_0629:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.09it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0629\n",
            "\n",
            "Predicting case_0630:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.54it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0630\n",
            "\n",
            "Predicting case_0631:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.74it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0631\n",
            "\n",
            "Predicting case_0632:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.64it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0632\n",
            "\n",
            "Predicting case_0633:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.26it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0633\n",
            "\n",
            "Predicting case_0634:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.71it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0634\n",
            "\n",
            "Predicting case_0635:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.48it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0635\n",
            "\n",
            "Predicting case_0636:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.61it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0636\n",
            "\n",
            "Predicting case_0637:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0637\n",
            "\n",
            "Predicting case_0638:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.58it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0638\n",
            "\n",
            "Predicting case_0639:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.40it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0639\n",
            "\n",
            "Predicting case_0640:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.57it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0640\n",
            "\n",
            "Predicting case_0641:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.00it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0641\n",
            "\n",
            "Predicting case_0642:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.84it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0642\n",
            "\n",
            "Predicting case_0643:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.59it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0643\n",
            "\n",
            "Predicting case_0644:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.49it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0644\n",
            "\n",
            "Predicting case_0645:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.75it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0645\n",
            "\n",
            "Predicting case_0646:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0646\n",
            "\n",
            "Predicting case_0647:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.63it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0647\n",
            "\n",
            "Predicting case_0648:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.36it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0648\n",
            "\n",
            "Predicting case_0649:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.40it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0649\n",
            "\n",
            "Predicting case_0650:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.28it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0650\n",
            "\n",
            "Predicting case_0651:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.99it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0651\n",
            "\n",
            "Predicting case_0652:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.45it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0652\n",
            "\n",
            "Predicting case_0653:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0653\n",
            "\n",
            "Predicting case_0654:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.69it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0654\n",
            "\n",
            "Predicting case_0655:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0655\n",
            "\n",
            "Predicting case_0656:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.38it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0656\n",
            "\n",
            "Predicting case_0657:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0657\n",
            "\n",
            "Predicting case_0658:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.72it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0658\n",
            "\n",
            "Predicting case_0659:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0659\n",
            "\n",
            "Predicting case_0660:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0660\n",
            "\n",
            "Predicting case_0661:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0661\n",
            "\n",
            "Predicting case_0662:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.37it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0662\n",
            "\n",
            "Predicting case_0663:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.57it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0663\n",
            "\n",
            "Predicting case_0664:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.20it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0664\n",
            "\n",
            "Predicting case_0665:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0665\n",
            "\n",
            "Predicting case_0666:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.36it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0666\n",
            "\n",
            "Predicting case_0667:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0667\n",
            "\n",
            "Predicting case_0668:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.20it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0668\n",
            "\n",
            "Predicting case_0669:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.72it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0669\n",
            "\n",
            "Predicting case_0670:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0670\n",
            "\n",
            "Predicting case_0671:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.69it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0671\n",
            "\n",
            "Predicting case_0672:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.35it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0672\n",
            "\n",
            "Predicting case_0673:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.76it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0673\n",
            "\n",
            "Predicting case_0674:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.76it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0674\n",
            "\n",
            "Predicting case_0675:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.08it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0675\n",
            "\n",
            "Predicting case_0676:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.25it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0676\n",
            "\n",
            "Predicting case_0677:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.51it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0677\n",
            "\n",
            "Predicting case_0678:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.09it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0678\n",
            "\n",
            "Predicting case_0679:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.33it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0679\n",
            "\n",
            "Predicting case_0680:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.53it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0680\n",
            "\n",
            "Predicting case_0681:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.07it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0681\n",
            "\n",
            "Predicting case_0682:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.07it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0682\n",
            "\n",
            "Predicting case_0683:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.29it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0683\n",
            "\n",
            "Predicting case_0684:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0684\n",
            "\n",
            "Predicting case_0685:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.49it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0685\n",
            "\n",
            "Predicting case_0686:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.85it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0686\n",
            "\n",
            "Predicting case_0687:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.76it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0687\n",
            "\n",
            "Predicting case_0688:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.82it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0688\n",
            "\n",
            "Predicting case_0689:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0689\n",
            "\n",
            "Predicting case_0690:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.50it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0690\n",
            "\n",
            "Predicting case_0691:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.54it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0691\n",
            "\n",
            "Predicting case_0692:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.59it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0692\n",
            "\n",
            "Predicting case_0693:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.96it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0693\n",
            "\n",
            "Predicting case_0694:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.79it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0694\n",
            "\n",
            "Predicting case_0695:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.26it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0695\n",
            "\n",
            "Predicting case_0696:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.44it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0696\n",
            "\n",
            "Predicting case_0697:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.03it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0697\n",
            "\n",
            "Predicting case_0698:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.55it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0698\n",
            "\n",
            "Predicting case_0699:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0699\n",
            "\n",
            "Predicting case_0700:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.56it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0700\n",
            "\n",
            "Predicting case_0701:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0701\n",
            "\n",
            "Predicting case_0702:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.94it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0702\n",
            "\n",
            "Predicting case_0703:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.18it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0703\n",
            "\n",
            "Predicting case_0704:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 26.48it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0704\n",
            "\n",
            "Predicting case_0705:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0705\n",
            "\n",
            "Predicting case_0706:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.11it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0706\n",
            "\n",
            "Predicting case_0707:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.26it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0707\n",
            "\n",
            "Predicting case_0708:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.59it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0708\n",
            "\n",
            "Predicting case_0709:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.04it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0709\n",
            "\n",
            "Predicting case_0710:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.53it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0710\n",
            "\n",
            "Predicting case_0711:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.33it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0711\n",
            "\n",
            "Predicting case_0712:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.20it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0712\n",
            "\n",
            "Predicting case_0713:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.95it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0713\n",
            "\n",
            "Predicting case_0714:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.35it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0714\n",
            "\n",
            "Predicting case_0715:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.16it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0715\n",
            "\n",
            "Predicting case_0716:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.24it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0716\n",
            "\n",
            "Predicting case_0717:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.89it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0717\n",
            "\n",
            "Predicting case_0718:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.87it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0718\n",
            "\n",
            "Predicting case_0719:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.42it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0719\n",
            "\n",
            "Predicting case_0720:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.24it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0720\n",
            "\n",
            "Predicting case_0721:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.03it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0721\n",
            "\n",
            "Predicting case_0722:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0722\n",
            "\n",
            "Predicting case_0723:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0723\n",
            "\n",
            "Predicting case_0724:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.93it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0724\n",
            "\n",
            "Predicting case_0725:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.06it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0725\n",
            "\n",
            "Predicting case_0726:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.85it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0726\n",
            "\n",
            "Predicting case_0727:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.55it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0727\n",
            "\n",
            "Predicting case_0728:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.46it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0728\n",
            "\n",
            "Predicting case_0729:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.00it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0729\n",
            "\n",
            "Predicting case_0730:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.45it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0730\n",
            "\n",
            "Predicting case_0731:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0731\n",
            "\n",
            "Predicting case_0732:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.04it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0732\n",
            "\n",
            "Predicting case_0733:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0733\n",
            "\n",
            "Predicting case_0734:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.27it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0734\n",
            "\n",
            "Predicting case_0735:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0735\n",
            "\n",
            "Predicting case_0736:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.88it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0736\n",
            "\n",
            "Predicting case_0737:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.87it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0737\n",
            "\n",
            "Predicting case_0738:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.24it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0738\n",
            "\n",
            "Predicting case_0739:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0739\n",
            "\n",
            "Predicting case_0740:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0740\n",
            "\n",
            "Predicting case_0741:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.91it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0741\n",
            "\n",
            "Predicting case_0742:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.31it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0742\n",
            "\n",
            "Predicting case_0743:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.83it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0743\n",
            "\n",
            "Predicting case_0744:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.05it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0744\n",
            "\n",
            "Predicting case_0745:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.48it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0745\n",
            "\n",
            "Predicting case_0746:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0746\n",
            "\n",
            "Predicting case_0747:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.85it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0747\n",
            "\n",
            "Predicting case_0748:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.26it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0748\n",
            "\n",
            "Predicting case_0749:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.46it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0749\n",
            "\n",
            "Predicting case_0750:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.28it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0750\n",
            "\n",
            "Predicting case_0751:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.73it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0751\n",
            "\n",
            "Predicting case_0752:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.09it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0752\n",
            "\n",
            "Predicting case_0753:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.03it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0753\n",
            "\n",
            "Predicting case_0754:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0754\n",
            "\n",
            "Predicting case_0755:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.81it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0755\n",
            "\n",
            "Predicting case_0756:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.03it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0756\n",
            "\n",
            "Predicting case_0757:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.43it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0757\n",
            "\n",
            "Predicting case_0758:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.04it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0758\n",
            "\n",
            "Predicting case_0759:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.11it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0759\n",
            "\n",
            "Predicting case_0760:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.42it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0760\n",
            "\n",
            "Predicting case_0761:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.21it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0761\n",
            "\n",
            "Predicting case_0762:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.39it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0762\n",
            "\n",
            "Predicting case_0763:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.36it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0763\n",
            "\n",
            "Predicting case_0764:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.24it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0764\n",
            "\n",
            "Predicting case_0765:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.27it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0765\n",
            "\n",
            "Predicting case_0766:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.53it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0766\n",
            "\n",
            "Predicting case_0767:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.27it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0767\n",
            "\n",
            "Predicting case_0768:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.96it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0768\n",
            "\n",
            "Predicting case_0769:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.27it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0769\n",
            "\n",
            "Predicting case_0770:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0770\n",
            "\n",
            "Predicting case_0771:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.93it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0771\n",
            "\n",
            "Predicting case_0772:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.80it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0772\n",
            "\n",
            "Predicting case_0773:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.23it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0773\n",
            "\n",
            "Predicting case_0774:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.54it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0774\n",
            "\n",
            "Predicting case_0775:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.30it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0775\n",
            "\n",
            "Predicting case_0776:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0776\n",
            "\n",
            "Predicting case_0777:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 27.54it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0777\n",
            "\n",
            "Predicting case_0778:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.49it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0778\n",
            "\n",
            "Predicting case_0779:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.53it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0779\n",
            "\n",
            "Predicting case_0780:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0780\n",
            "\n",
            "Predicting case_0781:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.78it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0781\n",
            "\n",
            "Predicting case_0782:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.84it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0782\n",
            "\n",
            "Predicting case_0783:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.96it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0783\n",
            "\n",
            "Predicting case_0784:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.24it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0784\n",
            "\n",
            "Predicting case_0785:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.04it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0785\n",
            "\n",
            "Predicting case_0786:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.21it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0786\n",
            "\n",
            "Predicting case_0787:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.24it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0787\n",
            "\n",
            "Predicting case_0788:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.89it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0788\n",
            "\n",
            "Predicting case_0789:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.90it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0789\n",
            "\n",
            "Predicting case_0790:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.46it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0790\n",
            "\n",
            "Predicting case_0791:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.33it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0791\n",
            "\n",
            "Predicting case_0792:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.04it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0792\n",
            "\n",
            "Predicting case_0793:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.88it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0793\n",
            "\n",
            "Predicting case_0794:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.52it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0794\n",
            "\n",
            "Predicting case_0795:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.58it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0795\n",
            "\n",
            "Predicting case_0796:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.71it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0796\n",
            "\n",
            "Predicting case_0797:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.74it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0797\n",
            "\n",
            "Predicting case_0798:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.38it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0798\n",
            "\n",
            "Predicting case_0799:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.45it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0799\n",
            "\n",
            "Predicting case_0800:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0800\n",
            "\n",
            "Predicting case_0801:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.61it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0801\n",
            "\n",
            "Predicting case_0802:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.62it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0802\n",
            "\n",
            "Predicting case_0803:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.83it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0803\n",
            "\n",
            "Predicting case_0804:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.32it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0804\n",
            "\n",
            "Predicting case_0805:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.53it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0805\n",
            "\n",
            "Predicting case_0806:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.30it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0806\n",
            "\n",
            "Predicting case_0807:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0807\n",
            "\n",
            "Predicting case_0808:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0808\n",
            "\n",
            "Predicting case_0809:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.76it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0809\n",
            "\n",
            "Predicting case_0810:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.92it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0810\n",
            "\n",
            "Predicting case_0811:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.20it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0811\n",
            "\n",
            "Predicting case_0812:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0812\n",
            "\n",
            "Predicting case_0813:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.60it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0813\n",
            "\n",
            "Predicting case_0814:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.73it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0814\n",
            "\n",
            "Predicting case_0815:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.61it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0815\n",
            "\n",
            "Predicting case_0816:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.05it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0816\n",
            "\n",
            "Predicting case_0817:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.98it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0817\n",
            "\n",
            "Predicting case_0818:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.58it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0818\n",
            "\n",
            "Predicting case_0819:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.62it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0819\n",
            "\n",
            "Predicting case_0820:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.79it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0820\n",
            "\n",
            "Predicting case_0821:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.82it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0821\n",
            "\n",
            "Predicting case_0822:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.18it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0822\n",
            "\n",
            "Predicting case_0823:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.15it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0823\n",
            "\n",
            "Predicting case_0824:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.39it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0824\n",
            "\n",
            "Predicting case_0825:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.45it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0825\n",
            "\n",
            "Predicting case_0826:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0826\n",
            "\n",
            "Predicting case_0827:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.05it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0827\n",
            "\n",
            "Predicting case_0828:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.83it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0828\n",
            "\n",
            "Predicting case_0829:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.77it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0829\n",
            "\n",
            "Predicting case_0830:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.22it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0830\n",
            "\n",
            "Predicting case_0831:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.03it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0831\n",
            "\n",
            "Predicting case_0832:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.36it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0832\n",
            "\n",
            "Predicting case_0833:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.27it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0833\n",
            "\n",
            "Predicting case_0834:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.01it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0834\n",
            "\n",
            "Predicting case_0835:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.34it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0835\n",
            "\n",
            "Predicting case_0836:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.59it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0836\n",
            "\n",
            "Predicting case_0837:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.19it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_evaluate_simple \\\n",
        "  /content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTr \\\n",
        "  /content/preds_fold1_best_on_train \\\n",
        "  -l 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGkykhaDHvyF",
        "outputId": "48e4616a-1dc7-4650-c118-8d4d9bf4717b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multiprocessing.pool.RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "                    ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/pool.py\", line 51, in starmapstar\n",
            "    return list(itertools.starmap(args[0], args[1]))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/evaluation/evaluate_predictions.py\", line 92, in compute_metrics\n",
            "    seg_ref, seg_ref_dict = image_reader_writer.read_seg(reference_file)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/imageio/simpleitk_reader_writer.py\", line 115, in read_seg\n",
            "    return self.read_images((seg_fname, ))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/imageio/simpleitk_reader_writer.py\", line 38, in read_images\n",
            "    itk_image = sitk.ReadImage(f)\n",
            "                ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/SimpleITK/extra.py\", line 384, in ReadImage\n",
            "    return reader.Execute()\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/SimpleITK/SimpleITK.py\", line 8534, in Execute\n",
            "    return _SimpleITK.ImageFileReader_Execute(self)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Exception thrown in SimpleITK ImageFileReader_Execute: /work/src/Code/IO/src/sitkImageReaderBase.cxx:91:\n",
            "sitk::ERROR: The file \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTr/case_0000.nii.gz\" does not exist.\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/nnUNetv2_evaluate_simple\", line 8, in <module>\n",
            "    sys.exit(evaluate_simple_entry_point())\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/evaluation/evaluate_predictions.py\", line 249, in evaluate_simple_entry_point\n",
            "    compute_metrics_on_folder_simple(args.gt_folder, args.pred_folder, args.l, args.o, args.np, args.il, chill=args.chill)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/evaluation/evaluate_predictions.py\", line 211, in compute_metrics_on_folder_simple\n",
            "    compute_metrics_on_folder(folder_ref, folder_pred, output_file, rw, file_ending,\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/evaluation/evaluate_predictions.py\", line 143, in compute_metrics_on_folder\n",
            "    results = pool.starmap(\n",
            "              ^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/pool.py\", line 375, in starmap\n",
            "    return self._map_async(func, iterable, starmapstar, chunksize).get()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/pool.py\", line 774, in get\n",
            "    raise self._value\n",
            "RuntimeError: Exception thrown in SimpleITK ImageFileReader_Execute: /work/src/Code/IO/src/sitkImageReaderBase.cxx:91:\n",
            "sitk::ERROR: The file \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTr/case_0000.nii.gz\" does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6db99575"
      },
      "source": [
        "## Re-plan + Preprocess with New Test Data\n",
        "\n",
        "**Why**: After moving 20 cases from the training set (`imagesTr`/`labelsTr`) to a dedicated test set (`imagesTs`/`labelsTs`), nnU-Net's internal dataset configuration (`splits_final.json`, etc.) still reflects the original dataset structure. To ensure that nnU-Net correctly recognizes the new training set size and the existence of the test set, we need to re-run the planning and preprocessing step. This will update the dataset's metadata within nnU-Net.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d1467ca0",
        "outputId": "378bb696-a77a-4e3f-93d3-e37244efb5a1"
      },
      "source": [
        "!nnUNetv2_plan_and_preprocess -d 501 --verify_dataset_integrity"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fingerprint extraction...\n",
            "Dataset501_KSSD\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "\n",
            "####################\n",
            "verify_dataset_integrity Done. \n",
            "If you didn't see any error messages then your dataset is most likely OK!\n",
            "####################\n",
            "\n",
            "Experiment planning...\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "2D U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 14, 'patch_size': (np.int64(512), np.int64(448)), 'median_image_size_in_voxels': array([512., 416.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
            "\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "Plans were saved to /content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/nnUNetPlans.json\n",
            "Preprocessing...\n",
            "Preprocessing dataset Dataset501_KSSD\n",
            "Configuration: 2d...\n",
            "100% 818/818 [00:33<00:00, 24.36it/s]\n",
            "Configuration: 3d_fullres...\n",
            "INFO: Configuration 3d_fullres not found in plans file nnUNetPlans.json of dataset Dataset501_KSSD. Skipping.\n",
            "Configuration: 3d_lowres...\n",
            "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset501_KSSD. Skipping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f96f14f2"
      },
      "source": [
        "## Predict on Test Data\n",
        "\n",
        "**Why**: With the dataset re-planned to include the new test set, we can now use the trained model (from `fold_1` or any other fold) to generate predictions specifically for the `imagesTs` directory. This is essential for evaluating the model's performance on unseen data. We'll output these predictions to a new directory `/content/preds_test`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "30e0d0b9",
        "outputId": "94bae80d-48cd-4c89-92a6-8eabfe61e216"
      },
      "source": [
        "!mkdir -p /content/preds_test\n",
        "\n",
        "!nnUNetv2_predict -d 501 -c 2d -f 1 \\\n",
        "  -tr nnUNetTrainer -p nnUNetPlans \\\n",
        "  -i /content/nnUNet/nnUNet_raw/Dataset501_KSSD/imagesTs \\\n",
        "  -o /content/preds_test \\\n",
        "  -chk checkpoint_best.pth"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "There are 20 cases in the source folder\n",
            "I am processing 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
            "There are 20 cases that I would like to predict\n",
            "\n",
            "Predicting case_0000:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00,  1.33it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0000\n",
            "\n",
            "Predicting case_0001:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.74it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0001\n",
            "\n",
            "Predicting case_0002:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 29.45it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0002\n",
            "\n",
            "Predicting case_0003:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.57it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0003\n",
            "\n",
            "Predicting case_0004:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 28.65it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0004\n",
            "\n",
            "Predicting case_0005:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.51it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0005\n",
            "\n",
            "Predicting case_0006:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.35it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0006\n",
            "\n",
            "Predicting case_0007:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 27.55it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0007\n",
            "\n",
            "Predicting case_0008:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.83it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0008\n",
            "\n",
            "Predicting case_0009:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.64it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0009\n",
            "\n",
            "Predicting case_0010:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.98it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0010\n",
            "\n",
            "Predicting case_0011:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.87it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0011\n",
            "\n",
            "Predicting case_0012:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 33.16it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0012\n",
            "\n",
            "Predicting case_0013:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.05it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0013\n",
            "\n",
            "Predicting case_0014:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.77it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0014\n",
            "\n",
            "Predicting case_0015:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 32.00it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0015\n",
            "\n",
            "Predicting case_0016:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.74it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0016\n",
            "\n",
            "Predicting case_0017:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.82it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0017\n",
            "\n",
            "Predicting case_0018:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 31.86it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0018\n",
            "\n",
            "Predicting case_0019:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00, 30.88it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with case_0019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0f8a07ef",
        "outputId": "f01f4e1b-8a48-49df-f7ce-8fa479b98751"
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "summary_file_path = \"/content/preds_test/summary.json\"\n",
        "\n",
        "if os.path.exists(summary_file_path):\n",
        "    with open(summary_file_path, \"r\") as f:\n",
        "        evaluation_summary = json.load(f)\n",
        "\n",
        "    print(\"Evaluation Summary (Fold 1, on test data):\")\n",
        "    # Pretty print the first part of the JSON to avoid overwhelming output\n",
        "    print(json.dumps(evaluation_summary, indent=2))\n",
        "\n",
        "    # Extract and print the mean Dice score if available\n",
        "    if \"mean\" in evaluation_summary and \"1\" in evaluation_summary[\"mean\"] and \"Dice\" in evaluation_summary[\"mean\"][\"1\"]:\n",
        "        mean_dice = evaluation_summary[\"mean\"][\"1\"][\"Dice\"]\n",
        "        print(f\"\\nMean Dice Score for Label 1 (stone): {mean_dice:.4f}\")\n",
        "    else:\n",
        "        print(\"\\nCould not find mean Dice score for label 1 in summary.\")\n",
        "else:\n",
        "    print(f\"Error: Summary file not found at {summary_file_path}\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Summary (Fold 1, on test data):\n",
            "{\n",
            "  \"foreground_mean\": {\n",
            "    \"Dice\": 0.9759272671343489,\n",
            "    \"FN\": 2.9,\n",
            "    \"FP\": 0.8,\n",
            "    \"IoU\": 0.953861654486729,\n",
            "    \"TN\": 262047.95,\n",
            "    \"TP\": 92.35,\n",
            "    \"n_pred\": 93.15,\n",
            "    \"n_ref\": 95.25\n",
            "  },\n",
            "  \"mean\": {\n",
            "    \"1\": {\n",
            "      \"Dice\": 0.9759272671343489,\n",
            "      \"FN\": 2.9,\n",
            "      \"FP\": 0.8,\n",
            "      \"IoU\": 0.953861654486729,\n",
            "      \"TN\": 262047.95,\n",
            "      \"TP\": 92.35,\n",
            "      \"n_pred\": 93.15,\n",
            "      \"n_ref\": 95.25\n",
            "    }\n",
            "  },\n",
            "  \"metric_per_case\": [\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9950738916256158,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9901960784313726,\n",
            "          \"TN\": 262042,\n",
            "          \"TP\": 101,\n",
            "          \"n_pred\": 102,\n",
            "          \"n_ref\": 101\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0000.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0000.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9962825278810409,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9925925925925926,\n",
            "          \"TN\": 262009,\n",
            "          \"TP\": 134,\n",
            "          \"n_pred\": 135,\n",
            "          \"n_ref\": 134\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0001.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0001.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262097,\n",
            "          \"TP\": 47,\n",
            "          \"n_pred\": 47,\n",
            "          \"n_ref\": 47\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0002.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0002.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.958904109589041,\n",
            "          \"FN\": 2,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9210526315789473,\n",
            "          \"TN\": 262106,\n",
            "          \"TP\": 35,\n",
            "          \"n_pred\": 36,\n",
            "          \"n_ref\": 37\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0003.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0003.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262120,\n",
            "          \"TP\": 24,\n",
            "          \"n_pred\": 24,\n",
            "          \"n_ref\": 24\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0004.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0004.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9333333333333333,\n",
            "          \"FN\": 1,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.875,\n",
            "          \"TN\": 262136,\n",
            "          \"TP\": 7,\n",
            "          \"n_pred\": 7,\n",
            "          \"n_ref\": 8\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0005.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0005.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9333333333333333,\n",
            "          \"FN\": 1,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.875,\n",
            "          \"TN\": 262136,\n",
            "          \"TP\": 7,\n",
            "          \"n_pred\": 7,\n",
            "          \"n_ref\": 8\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0006.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0006.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262130,\n",
            "          \"TP\": 14,\n",
            "          \"n_pred\": 14,\n",
            "          \"n_ref\": 14\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0007.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0007.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262129,\n",
            "          \"TP\": 15,\n",
            "          \"n_pred\": 15,\n",
            "          \"n_ref\": 15\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0008.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0008.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9333333333333333,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.875,\n",
            "          \"TN\": 262136,\n",
            "          \"TP\": 7,\n",
            "          \"n_pred\": 8,\n",
            "          \"n_ref\": 7\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0009.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0009.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9585798816568047,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9204545454545454,\n",
            "          \"TN\": 262056,\n",
            "          \"TP\": 81,\n",
            "          \"n_pred\": 82,\n",
            "          \"n_ref\": 87\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0010.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0010.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9724770642201835,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.9464285714285714,\n",
            "          \"TN\": 262032,\n",
            "          \"TP\": 106,\n",
            "          \"n_pred\": 106,\n",
            "          \"n_ref\": 112\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0011.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0011.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9857142857142858,\n",
            "          \"FN\": 2,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.971830985915493,\n",
            "          \"TN\": 262002,\n",
            "          \"TP\": 138,\n",
            "          \"n_pred\": 140,\n",
            "          \"n_ref\": 140\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0012.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0012.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9822064056939501,\n",
            "          \"FN\": 3,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.965034965034965,\n",
            "          \"TN\": 262001,\n",
            "          \"TP\": 138,\n",
            "          \"n_pred\": 140,\n",
            "          \"n_ref\": 141\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0013.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0013.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9708029197080292,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.9432624113475178,\n",
            "          \"TN\": 262003,\n",
            "          \"TP\": 133,\n",
            "          \"n_pred\": 135,\n",
            "          \"n_ref\": 139\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0014.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0014.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9894736842105263,\n",
            "          \"FN\": 3,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.9791666666666666,\n",
            "          \"TN\": 262000,\n",
            "          \"TP\": 141,\n",
            "          \"n_pred\": 141,\n",
            "          \"n_ref\": 144\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0015.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0015.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9710610932475884,\n",
            "          \"FN\": 7,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.94375,\n",
            "          \"TN\": 261984,\n",
            "          \"TP\": 151,\n",
            "          \"n_pred\": 153,\n",
            "          \"n_ref\": 158\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0016.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0016.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.98005698005698,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9608938547486033,\n",
            "          \"TN\": 261965,\n",
            "          \"TP\": 172,\n",
            "          \"n_pred\": 173,\n",
            "          \"n_ref\": 178\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0017.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0017.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9773299748110831,\n",
            "          \"FN\": 9,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.9556650246305419,\n",
            "          \"TN\": 261941,\n",
            "          \"TP\": 194,\n",
            "          \"n_pred\": 194,\n",
            "          \"n_ref\": 203\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0018.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0018.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9805825242718447,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.9619047619047619,\n",
            "          \"TN\": 261934,\n",
            "          \"TP\": 202,\n",
            "          \"n_pred\": 204,\n",
            "          \"n_ref\": 208\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0019.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0019.nii.gz\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "Mean Dice Score for Label 1 (stone): 0.9759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "new_cell_1",
        "outputId": "67f410a1-c0bb-4d55-cc5a-acdee60a47be"
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "summary_file_path = \"/content/preds_test/summary.json\"\n",
        "\n",
        "if os.path.exists(summary_file_path):\n",
        "    with open(summary_file_path, \"r\") as f:\n",
        "        evaluation_summary = json.load(f)\n",
        "\n",
        "    print(\"Evaluation Summary (Fold 1, on test data):\")\n",
        "    # Pretty print the first part of the JSON to avoid overwhelming output\n",
        "    print(json.dumps(evaluation_summary, indent=2))\n",
        "\n",
        "    # Extract and print the mean Dice score if available\n",
        "    if \"mean\" in evaluation_summary and \"1\" in evaluation_summary[\"mean\"] and \"Dice\" in evaluation_summary[\"mean\"][\"1\"]:\n",
        "        mean_dice = evaluation_summary[\"mean\"][\"1\"][\"Dice\"]\n",
        "        print(f\"\\nMean Dice Score for Label 1 (stone): {mean_dice:.4f}\")\n",
        "    else:\n",
        "        print(\"\\nCould not find mean Dice score for label 1 in summary.\")\n",
        "else:\n",
        "    print(f\"Error: Summary file not found at {summary_file_path}\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Summary (Fold 1, on test data):\n",
            "{\n",
            "  \"foreground_mean\": {\n",
            "    \"Dice\": 0.9759272671343489,\n",
            "    \"FN\": 2.9,\n",
            "    \"FP\": 0.8,\n",
            "    \"IoU\": 0.953861654486729,\n",
            "    \"TN\": 262047.95,\n",
            "    \"TP\": 92.35,\n",
            "    \"n_pred\": 93.15,\n",
            "    \"n_ref\": 95.25\n",
            "  },\n",
            "  \"mean\": {\n",
            "    \"1\": {\n",
            "      \"Dice\": 0.9759272671343489,\n",
            "      \"FN\": 2.9,\n",
            "      \"FP\": 0.8,\n",
            "      \"IoU\": 0.953861654486729,\n",
            "      \"TN\": 262047.95,\n",
            "      \"TP\": 92.35,\n",
            "      \"n_pred\": 93.15,\n",
            "      \"n_ref\": 95.25\n",
            "    }\n",
            "  },\n",
            "  \"metric_per_case\": [\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9950738916256158,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9901960784313726,\n",
            "          \"TN\": 262042,\n",
            "          \"TP\": 101,\n",
            "          \"n_pred\": 102,\n",
            "          \"n_ref\": 101\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0000.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0000.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9962825278810409,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9925925925925926,\n",
            "          \"TN\": 262009,\n",
            "          \"TP\": 134,\n",
            "          \"n_pred\": 135,\n",
            "          \"n_ref\": 134\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0001.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0001.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262097,\n",
            "          \"TP\": 47,\n",
            "          \"n_pred\": 47,\n",
            "          \"n_ref\": 47\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0002.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0002.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.958904109589041,\n",
            "          \"FN\": 2,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9210526315789473,\n",
            "          \"TN\": 262106,\n",
            "          \"TP\": 35,\n",
            "          \"n_pred\": 36,\n",
            "          \"n_ref\": 37\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0003.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0003.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262120,\n",
            "          \"TP\": 24,\n",
            "          \"n_pred\": 24,\n",
            "          \"n_ref\": 24\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0004.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0004.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9333333333333333,\n",
            "          \"FN\": 1,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.875,\n",
            "          \"TN\": 262136,\n",
            "          \"TP\": 7,\n",
            "          \"n_pred\": 7,\n",
            "          \"n_ref\": 8\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0005.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0005.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9333333333333333,\n",
            "          \"FN\": 1,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.875,\n",
            "          \"TN\": 262136,\n",
            "          \"TP\": 7,\n",
            "          \"n_pred\": 7,\n",
            "          \"n_ref\": 8\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0006.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0006.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262130,\n",
            "          \"TP\": 14,\n",
            "          \"n_pred\": 14,\n",
            "          \"n_ref\": 14\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0007.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0007.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262129,\n",
            "          \"TP\": 15,\n",
            "          \"n_pred\": 15,\n",
            "          \"n_ref\": 15\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0008.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0008.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9333333333333333,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.875,\n",
            "          \"TN\": 262136,\n",
            "          \"TP\": 7,\n",
            "          \"n_pred\": 8,\n",
            "          \"n_ref\": 7\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0009.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0009.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9585798816568047,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9204545454545454,\n",
            "          \"TN\": 262056,\n",
            "          \"TP\": 81,\n",
            "          \"n_pred\": 82,\n",
            "          \"n_ref\": 87\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0010.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0010.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9724770642201835,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.9464285714285714,\n",
            "          \"TN\": 262032,\n",
            "          \"TP\": 106,\n",
            "          \"n_pred\": 106,\n",
            "          \"n_ref\": 112\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0011.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0011.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9857142857142858,\n",
            "          \"FN\": 2,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.971830985915493,\n",
            "          \"TN\": 262002,\n",
            "          \"TP\": 138,\n",
            "          \"n_pred\": 140,\n",
            "          \"n_ref\": 140\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0012.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0012.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9822064056939501,\n",
            "          \"FN\": 3,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.965034965034965,\n",
            "          \"TN\": 262001,\n",
            "          \"TP\": 138,\n",
            "          \"n_pred\": 140,\n",
            "          \"n_ref\": 141\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0013.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0013.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9708029197080292,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.9432624113475178,\n",
            "          \"TN\": 262003,\n",
            "          \"TP\": 133,\n",
            "          \"n_pred\": 135,\n",
            "          \"n_ref\": 139\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0014.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0014.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9894736842105263,\n",
            "          \"FN\": 3,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.9791666666666666,\n",
            "          \"TN\": 262000,\n",
            "          \"TP\": 141,\n",
            "          \"n_pred\": 141,\n",
            "          \"n_ref\": 144\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0015.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0015.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9710610932475884,\n",
            "          \"FN\": 7,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.94375,\n",
            "          \"TN\": 261984,\n",
            "          \"TP\": 151,\n",
            "          \"n_pred\": 153,\n",
            "          \"n_ref\": 158\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0016.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0016.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.98005698005698,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9608938547486033,\n",
            "          \"TN\": 261965,\n",
            "          \"TP\": 172,\n",
            "          \"n_pred\": 173,\n",
            "          \"n_ref\": 178\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0017.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0017.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9773299748110831,\n",
            "          \"FN\": 9,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.9556650246305419,\n",
            "          \"TN\": 261941,\n",
            "          \"TP\": 194,\n",
            "          \"n_pred\": 194,\n",
            "          \"n_ref\": 203\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0018.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0018.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9805825242718447,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.9619047619047619,\n",
            "          \"TN\": 261934,\n",
            "          \"TP\": 202,\n",
            "          \"n_pred\": 204,\n",
            "          \"n_ref\": 208\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0019.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0019.nii.gz\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "Mean Dice Score for Label 1 (stone): 0.9759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e046efba",
        "outputId": "ff31a628-4fa6-4022-81d1-2b7c5d553b14"
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "summary_file_path = \"/content/preds_test/summary.json\"\n",
        "\n",
        "if os.path.exists(summary_file_path):\n",
        "    with open(summary_file_path, \"r\") as f:\n",
        "        evaluation_summary = json.load(f)\n",
        "\n",
        "    print(\"Evaluation Summary (Fold 1, on test data):\")\n",
        "    # Pretty print the first part of the JSON to avoid overwhelming output\n",
        "    print(json.dumps(evaluation_summary, indent=2))\n",
        "\n",
        "    # Extract and print the mean Dice score if available\n",
        "    if \"mean\" in evaluation_summary and \"1\" in evaluation_summary[\"mean\"] and \"Dice\" in evaluation_summary[\"mean\"][\"1\"]:\n",
        "        mean_dice = evaluation_summary[\"mean\"][\"1\"][\"Dice\"]\n",
        "        print(f\"\\nMean Dice Score for Label 1 (stone): {mean_dice:.4f}\")\n",
        "    else:\n",
        "        print(\"\\nCould not find mean Dice score for label 1 in summary.\")\n",
        "else:\n",
        "    print(f\"Error: Summary file not found at {summary_file_path}\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Summary (Fold 1, on test data):\n",
            "{\n",
            "  \"foreground_mean\": {\n",
            "    \"Dice\": 0.9759272671343489,\n",
            "    \"FN\": 2.9,\n",
            "    \"FP\": 0.8,\n",
            "    \"IoU\": 0.953861654486729,\n",
            "    \"TN\": 262047.95,\n",
            "    \"TP\": 92.35,\n",
            "    \"n_pred\": 93.15,\n",
            "    \"n_ref\": 95.25\n",
            "  },\n",
            "  \"mean\": {\n",
            "    \"1\": {\n",
            "      \"Dice\": 0.9759272671343489,\n",
            "      \"FN\": 2.9,\n",
            "      \"FP\": 0.8,\n",
            "      \"IoU\": 0.953861654486729,\n",
            "      \"TN\": 262047.95,\n",
            "      \"TP\": 92.35,\n",
            "      \"n_pred\": 93.15,\n",
            "      \"n_ref\": 95.25\n",
            "    }\n",
            "  },\n",
            "  \"metric_per_case\": [\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9950738916256158,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9901960784313726,\n",
            "          \"TN\": 262042,\n",
            "          \"TP\": 101,\n",
            "          \"n_pred\": 102,\n",
            "          \"n_ref\": 101\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0000.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0000.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9962825278810409,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9925925925925926,\n",
            "          \"TN\": 262009,\n",
            "          \"TP\": 134,\n",
            "          \"n_pred\": 135,\n",
            "          \"n_ref\": 134\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0001.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0001.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262097,\n",
            "          \"TP\": 47,\n",
            "          \"n_pred\": 47,\n",
            "          \"n_ref\": 47\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0002.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0002.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.958904109589041,\n",
            "          \"FN\": 2,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9210526315789473,\n",
            "          \"TN\": 262106,\n",
            "          \"TP\": 35,\n",
            "          \"n_pred\": 36,\n",
            "          \"n_ref\": 37\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0003.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0003.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262120,\n",
            "          \"TP\": 24,\n",
            "          \"n_pred\": 24,\n",
            "          \"n_ref\": 24\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0004.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0004.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9333333333333333,\n",
            "          \"FN\": 1,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.875,\n",
            "          \"TN\": 262136,\n",
            "          \"TP\": 7,\n",
            "          \"n_pred\": 7,\n",
            "          \"n_ref\": 8\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0005.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0005.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9333333333333333,\n",
            "          \"FN\": 1,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.875,\n",
            "          \"TN\": 262136,\n",
            "          \"TP\": 7,\n",
            "          \"n_pred\": 7,\n",
            "          \"n_ref\": 8\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0006.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0006.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262130,\n",
            "          \"TP\": 14,\n",
            "          \"n_pred\": 14,\n",
            "          \"n_ref\": 14\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0007.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0007.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 1.0,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 1.0,\n",
            "          \"TN\": 262129,\n",
            "          \"TP\": 15,\n",
            "          \"n_pred\": 15,\n",
            "          \"n_ref\": 15\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0008.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0008.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9333333333333333,\n",
            "          \"FN\": 0,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.875,\n",
            "          \"TN\": 262136,\n",
            "          \"TP\": 7,\n",
            "          \"n_pred\": 8,\n",
            "          \"n_ref\": 7\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0009.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0009.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9585798816568047,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9204545454545454,\n",
            "          \"TN\": 262056,\n",
            "          \"TP\": 81,\n",
            "          \"n_pred\": 82,\n",
            "          \"n_ref\": 87\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0010.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0010.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9724770642201835,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.9464285714285714,\n",
            "          \"TN\": 262032,\n",
            "          \"TP\": 106,\n",
            "          \"n_pred\": 106,\n",
            "          \"n_ref\": 112\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0011.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0011.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9857142857142858,\n",
            "          \"FN\": 2,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.971830985915493,\n",
            "          \"TN\": 262002,\n",
            "          \"TP\": 138,\n",
            "          \"n_pred\": 140,\n",
            "          \"n_ref\": 140\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0012.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0012.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9822064056939501,\n",
            "          \"FN\": 3,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.965034965034965,\n",
            "          \"TN\": 262001,\n",
            "          \"TP\": 138,\n",
            "          \"n_pred\": 140,\n",
            "          \"n_ref\": 141\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0013.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0013.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9708029197080292,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.9432624113475178,\n",
            "          \"TN\": 262003,\n",
            "          \"TP\": 133,\n",
            "          \"n_pred\": 135,\n",
            "          \"n_ref\": 139\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0014.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0014.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9894736842105263,\n",
            "          \"FN\": 3,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.9791666666666666,\n",
            "          \"TN\": 262000,\n",
            "          \"TP\": 141,\n",
            "          \"n_pred\": 141,\n",
            "          \"n_ref\": 144\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0015.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0015.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9710610932475884,\n",
            "          \"FN\": 7,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.94375,\n",
            "          \"TN\": 261984,\n",
            "          \"TP\": 151,\n",
            "          \"n_pred\": 153,\n",
            "          \"n_ref\": 158\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0016.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0016.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.98005698005698,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 1,\n",
            "          \"IoU\": 0.9608938547486033,\n",
            "          \"TN\": 261965,\n",
            "          \"TP\": 172,\n",
            "          \"n_pred\": 173,\n",
            "          \"n_ref\": 178\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0017.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0017.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9773299748110831,\n",
            "          \"FN\": 9,\n",
            "          \"FP\": 0,\n",
            "          \"IoU\": 0.9556650246305419,\n",
            "          \"TN\": 261941,\n",
            "          \"TP\": 194,\n",
            "          \"n_pred\": 194,\n",
            "          \"n_ref\": 203\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0018.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0018.nii.gz\"\n",
            "    },\n",
            "    {\n",
            "      \"metrics\": {\n",
            "        \"1\": {\n",
            "          \"Dice\": 0.9805825242718447,\n",
            "          \"FN\": 6,\n",
            "          \"FP\": 2,\n",
            "          \"IoU\": 0.9619047619047619,\n",
            "          \"TN\": 261934,\n",
            "          \"TP\": 202,\n",
            "          \"n_pred\": 204,\n",
            "          \"n_ref\": 208\n",
            "        }\n",
            "      },\n",
            "      \"prediction_file\": \"/content/preds_test/case_0019.nii.gz\",\n",
            "      \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0019.nii.gz\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "Mean Dice Score for Label 1 (stone): 0.9759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79db2bb5"
      },
      "source": [
        "## Evaluate Test Predictions\n",
        "\n",
        "**Why**: Finally, we will evaluate the predictions made on the test set (`preds_test`) against the true labels in `labelsTs`. This will give us a quantitative measure of the model's performance on the data it has not seen during training, providing a more realistic assessment of its generalization capabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba9244de"
      },
      "source": [
        "!nnUNetv2_evaluate_simple \\\n",
        "  /content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs \\\n",
        "  /content/preds_test \\\n",
        "  -l 1"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "757bbfe8",
        "outputId": "0d3e091d-0bf3-4763-b4d7-00eb784c952d"
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "summary_file_path = \"/content/preds_test/summary.json\"\n",
        "\n",
        "if os.path.exists(summary_file_path):\n",
        "    with open(summary_file_path, \"r\") as f:\n",
        "        evaluation_summary = json.load(f)\n",
        "\n",
        "    if \"metric_per_case\" in evaluation_summary:\n",
        "        print(\"Metrics Per Case (Fold 1, on test data):\")\n",
        "        print(json.dumps(evaluation_summary[\"metric_per_case\"], indent=2))\n",
        "    else:\n",
        "        print(\"Could not find 'metric_per_case' in the summary.\")\n",
        "else:\n",
        "    print(f\"Error: Summary file not found at {summary_file_path}\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Per Case (Fold 1, on test data):\n",
            "[\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9950738916256158,\n",
            "        \"FN\": 0,\n",
            "        \"FP\": 1,\n",
            "        \"IoU\": 0.9901960784313726,\n",
            "        \"TN\": 262042,\n",
            "        \"TP\": 101,\n",
            "        \"n_pred\": 102,\n",
            "        \"n_ref\": 101\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0000.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0000.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9962825278810409,\n",
            "        \"FN\": 0,\n",
            "        \"FP\": 1,\n",
            "        \"IoU\": 0.9925925925925926,\n",
            "        \"TN\": 262009,\n",
            "        \"TP\": 134,\n",
            "        \"n_pred\": 135,\n",
            "        \"n_ref\": 134\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0001.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0001.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 1.0,\n",
            "        \"FN\": 0,\n",
            "        \"FP\": 0,\n",
            "        \"IoU\": 1.0,\n",
            "        \"TN\": 262097,\n",
            "        \"TP\": 47,\n",
            "        \"n_pred\": 47,\n",
            "        \"n_ref\": 47\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0002.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0002.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.958904109589041,\n",
            "        \"FN\": 2,\n",
            "        \"FP\": 1,\n",
            "        \"IoU\": 0.9210526315789473,\n",
            "        \"TN\": 262106,\n",
            "        \"TP\": 35,\n",
            "        \"n_pred\": 36,\n",
            "        \"n_ref\": 37\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0003.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0003.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 1.0,\n",
            "        \"FN\": 0,\n",
            "        \"FP\": 0,\n",
            "        \"IoU\": 1.0,\n",
            "        \"TN\": 262120,\n",
            "        \"TP\": 24,\n",
            "        \"n_pred\": 24,\n",
            "        \"n_ref\": 24\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0004.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0004.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9333333333333333,\n",
            "        \"FN\": 1,\n",
            "        \"FP\": 0,\n",
            "        \"IoU\": 0.875,\n",
            "        \"TN\": 262136,\n",
            "        \"TP\": 7,\n",
            "        \"n_pred\": 7,\n",
            "        \"n_ref\": 8\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0005.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0005.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9333333333333333,\n",
            "        \"FN\": 1,\n",
            "        \"FP\": 0,\n",
            "        \"IoU\": 0.875,\n",
            "        \"TN\": 262136,\n",
            "        \"TP\": 7,\n",
            "        \"n_pred\": 7,\n",
            "        \"n_ref\": 8\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0006.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0006.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 1.0,\n",
            "        \"FN\": 0,\n",
            "        \"FP\": 0,\n",
            "        \"IoU\": 1.0,\n",
            "        \"TN\": 262130,\n",
            "        \"TP\": 14,\n",
            "        \"n_pred\": 14,\n",
            "        \"n_ref\": 14\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0007.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0007.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 1.0,\n",
            "        \"FN\": 0,\n",
            "        \"FP\": 0,\n",
            "        \"IoU\": 1.0,\n",
            "        \"TN\": 262129,\n",
            "        \"TP\": 15,\n",
            "        \"n_pred\": 15,\n",
            "        \"n_ref\": 15\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0008.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0008.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9333333333333333,\n",
            "        \"FN\": 0,\n",
            "        \"FP\": 1,\n",
            "        \"IoU\": 0.875,\n",
            "        \"TN\": 262136,\n",
            "        \"TP\": 7,\n",
            "        \"n_pred\": 8,\n",
            "        \"n_ref\": 7\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0009.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0009.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9585798816568047,\n",
            "        \"FN\": 6,\n",
            "        \"FP\": 1,\n",
            "        \"IoU\": 0.9204545454545454,\n",
            "        \"TN\": 262056,\n",
            "        \"TP\": 81,\n",
            "        \"n_pred\": 82,\n",
            "        \"n_ref\": 87\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0010.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0010.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9724770642201835,\n",
            "        \"FN\": 6,\n",
            "        \"FP\": 0,\n",
            "        \"IoU\": 0.9464285714285714,\n",
            "        \"TN\": 262032,\n",
            "        \"TP\": 106,\n",
            "        \"n_pred\": 106,\n",
            "        \"n_ref\": 112\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0011.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0011.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9857142857142858,\n",
            "        \"FN\": 2,\n",
            "        \"FP\": 2,\n",
            "        \"IoU\": 0.971830985915493,\n",
            "        \"TN\": 262002,\n",
            "        \"TP\": 138,\n",
            "        \"n_pred\": 140,\n",
            "        \"n_ref\": 140\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0012.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0012.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9822064056939501,\n",
            "        \"FN\": 3,\n",
            "        \"FP\": 2,\n",
            "        \"IoU\": 0.965034965034965,\n",
            "        \"TN\": 262001,\n",
            "        \"TP\": 138,\n",
            "        \"n_pred\": 140,\n",
            "        \"n_ref\": 141\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0013.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0013.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9708029197080292,\n",
            "        \"FN\": 6,\n",
            "        \"FP\": 2,\n",
            "        \"IoU\": 0.9432624113475178,\n",
            "        \"TN\": 262003,\n",
            "        \"TP\": 133,\n",
            "        \"n_pred\": 135,\n",
            "        \"n_ref\": 139\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0014.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0014.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9894736842105263,\n",
            "        \"FN\": 3,\n",
            "        \"FP\": 0,\n",
            "        \"IoU\": 0.9791666666666666,\n",
            "        \"TN\": 262000,\n",
            "        \"TP\": 141,\n",
            "        \"n_pred\": 141,\n",
            "        \"n_ref\": 144\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0015.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0015.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9710610932475884,\n",
            "        \"FN\": 7,\n",
            "        \"FP\": 2,\n",
            "        \"IoU\": 0.94375,\n",
            "        \"TN\": 261984,\n",
            "        \"TP\": 151,\n",
            "        \"n_pred\": 153,\n",
            "        \"n_ref\": 158\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0016.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0016.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.98005698005698,\n",
            "        \"FN\": 6,\n",
            "        \"FP\": 1,\n",
            "        \"IoU\": 0.9608938547486033,\n",
            "        \"TN\": 261965,\n",
            "        \"TP\": 172,\n",
            "        \"n_pred\": 173,\n",
            "        \"n_ref\": 178\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0017.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0017.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9773299748110831,\n",
            "        \"FN\": 9,\n",
            "        \"FP\": 0,\n",
            "        \"IoU\": 0.9556650246305419,\n",
            "        \"TN\": 261941,\n",
            "        \"TP\": 194,\n",
            "        \"n_pred\": 194,\n",
            "        \"n_ref\": 203\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0018.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0018.nii.gz\"\n",
            "  },\n",
            "  {\n",
            "    \"metrics\": {\n",
            "      \"1\": {\n",
            "        \"Dice\": 0.9805825242718447,\n",
            "        \"FN\": 6,\n",
            "        \"FP\": 2,\n",
            "        \"IoU\": 0.9619047619047619,\n",
            "        \"TN\": 261934,\n",
            "        \"TP\": 202,\n",
            "        \"n_pred\": 204,\n",
            "        \"n_ref\": 208\n",
            "      }\n",
            "    },\n",
            "    \"prediction_file\": \"/content/preds_test/case_0019.nii.gz\",\n",
            "    \"reference_file\": \"/content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs/case_0019.nii.gz\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/nnUNet/nnUNet_raw/Dataset501_KSSD/imagesTs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBMWKTuSImLL",
        "outputId": "e1ae6ab7-7463-4550-8a55-e979de640b70"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /content/nnUNet/nnUNet_raw/Dataset501_KSSD/imagesTs: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LJsk8pZ8I3U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ad40f8d"
      },
      "source": [
        "# Task\n",
        "Create `imagesTs` and `labelsTs` subdirectories within the nnU-Net raw data folder at `/content/nnUNet/nnUNet_raw/Dataset501_KSSD`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84d79b79"
      },
      "source": [
        "## Create Test Directories\n",
        "\n",
        "### Subtask:\n",
        "Create the `imagesTs` and `labelsTs` subdirectories within the nnU-Net raw data folder, which will house the test images and their corresponding labels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f498d3a3"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires creating `imagesTs` and `labelsTs` subdirectories within the `nn_folder` for nnU-Net. I will use `os.makedirs` to create these directories and set `exist_ok=True` to prevent errors if they already exist.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "959faa1a",
        "outputId": "d24a5a16-4c5c-484a-e126-c1330f318383"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create imagesTs subdirectory\n",
        "imagesTs = f\"{nn_folder}/imagesTs\"\n",
        "os.makedirs(imagesTs, exist_ok=True)\n",
        "\n",
        "# Create labelsTs subdirectory\n",
        "labelsTs = f\"{nn_folder}/labelsTs\"\n",
        "os.makedirs(labelsTs, exist_ok=True)\n",
        "\n",
        "print(f\"Created imagesTs directory: {imagesTs}\")\n",
        "print(f\"Created labelsTs directory: {labelsTs}\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created imagesTs directory: /content/nnUNet/nnUNet_raw/Dataset501_KSSD/imagesTs\n",
            "Created labelsTs directory: /content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "009320bb"
      },
      "source": [
        "## Move Data to Test Set\n",
        "\n",
        "### Subtask:\n",
        "Select a subset of 20 cases from the existing `imagesTr` and `labelsTr` directories and move them to the newly created `imagesTs` and `labelsTs` directories. This simulates a test dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fbace7c"
      },
      "source": [
        "**Reasoning**:\n",
        "To select a subset of 20 cases and move them from the training directories to the test directories, I need to list the files in `imagesTr` and `labelsTr`, select the first 20 pairs, and then use `shutil.move` to transfer them to `imagesTs` and `labelsTs`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b72f8a3",
        "outputId": "a24269f6-0825-49c4-9d7d-359c513515da"
      },
      "source": [
        "import glob\n",
        "import shutil\n",
        "\n",
        "# Get all image and label files from training directories\n",
        "all_img_tr_files = sorted(glob.glob(os.path.join(imagesTr, \"*.nii.gz\")))\n",
        "all_lbl_tr_files = sorted(glob.glob(os.path.join(labelsTr, \"*.nii.gz\")))\n",
        "\n",
        "# Ensure there are enough files to move\n",
        "num_files_to_move = min(20, len(all_img_tr_files), len(all_lbl_tr_files))\n",
        "\n",
        "# Select the first 20 cases for the test set\n",
        "selected_img_files = all_img_tr_files[:num_files_to_move]\n",
        "selected_lbl_files = all_lbl_tr_files[:num_files_to_move]\n",
        "\n",
        "# Move the selected files\n",
        "for img_src, lbl_src in zip(selected_img_files, selected_lbl_files):\n",
        "    # Extract filename (e.g., case_0000_0000.nii.gz)\n",
        "    img_filename = os.path.basename(img_src)\n",
        "    lbl_filename = os.path.basename(lbl_src)\n",
        "\n",
        "    # Construct destination paths\n",
        "    img_dst = os.path.join(imagesTs, img_filename)\n",
        "    lbl_dst = os.path.join(labelsTs, lbl_filename)\n",
        "\n",
        "    # Move files\n",
        "    shutil.move(img_src, img_dst)\n",
        "    shutil.move(lbl_src, lbl_dst)\n",
        "\n",
        "print(f\"Moved {num_files_to_move} cases to test set.\")\n",
        "\n",
        "# Update the numTraining in dataset.json\n",
        "# It's important to update the dataset.json to reflect the actual number of training samples\n",
        "# before planning and preprocessing again or training other folds.\n",
        "import json\n",
        "\n",
        "dataset_json_path = f\"{nn_folder}/dataset.json\"\n",
        "with open(dataset_json_path, \"r\") as f:\n",
        "    dataset_json = json.load(f)\n",
        "\n",
        "dataset_json[\"numTraining\"] = len(glob.glob(os.path.join(imagesTr, \"*.nii.gz\")))\n",
        "\n",
        "with open(dataset_json_path, \"w\") as f:\n",
        "    json.dump(dataset_json, f, indent=2)\n",
        "\n",
        "print(f\"Updated numTraining in dataset.json to: {dataset_json['numTraining']}\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved 20 cases to test set.\n",
            "Updated numTraining in dataset.json to: 818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "393c2f1b"
      },
      "source": [
        "## Verify Test Data\n",
        "\n",
        "### Subtask:\n",
        "List the contents of the `imagesTs` and `labelsTs` directories to confirm that the files have been successfully moved and the test set is ready.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2032d64c"
      },
      "source": [
        "**Reasoning**:\n",
        "To confirm that the image files have been successfully moved to the `imagesTs` directory, I will list its contents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0e4e4c5",
        "outputId": "0871a25f-5773-44eb-b79a-3c2e9f729f0d"
      },
      "source": [
        "print(f\"Contents of {imagesTs}:\")\n",
        "!ls {imagesTs}"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/nnUNet/nnUNet_raw/Dataset501_KSSD/imagesTs:\n",
            "case_0000_0000.nii.gz  case_0007_0000.nii.gz  case_0014_0000.nii.gz\n",
            "case_0001_0000.nii.gz  case_0008_0000.nii.gz  case_0015_0000.nii.gz\n",
            "case_0002_0000.nii.gz  case_0009_0000.nii.gz  case_0016_0000.nii.gz\n",
            "case_0003_0000.nii.gz  case_0010_0000.nii.gz  case_0017_0000.nii.gz\n",
            "case_0004_0000.nii.gz  case_0011_0000.nii.gz  case_0018_0000.nii.gz\n",
            "case_0005_0000.nii.gz  case_0012_0000.nii.gz  case_0019_0000.nii.gz\n",
            "case_0006_0000.nii.gz  case_0013_0000.nii.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11b94eec"
      },
      "source": [
        "**Reasoning**:\n",
        "To confirm that the label files have been successfully moved to the `labelsTs` directory, I will list its contents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "256fe7d1",
        "outputId": "103013a0-b058-4773-9fd8-944ce1a43cdc"
      },
      "source": [
        "print(f\"Contents of {labelsTs}:\")\n",
        "!ls {labelsTs}"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTs:\n",
            "case_0000.nii.gz  case_0005.nii.gz  case_0010.nii.gz  case_0015.nii.gz\n",
            "case_0001.nii.gz  case_0006.nii.gz  case_0011.nii.gz  case_0016.nii.gz\n",
            "case_0002.nii.gz  case_0007.nii.gz  case_0012.nii.gz  case_0017.nii.gz\n",
            "case_0003.nii.gz  case_0008.nii.gz  case_0013.nii.gz  case_0018.nii.gz\n",
            "case_0004.nii.gz  case_0009.nii.gz  case_0014.nii.gz  case_0019.nii.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6750821"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Confirm the test dataset is set up and ready for prediction and evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8b3949d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The test dataset for nnU-Net has been successfully set up and is ready for prediction and evaluation.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Two new subdirectories, `imagesTs` and `labelsTs`, were created within `/content/nnUNet/nnUNet_raw/Dataset501_KSSD` to house the test images and labels, respectively.\n",
        "*   A total of 20 cases (20 image files and 20 corresponding label files) were moved from the training directories (`imagesTr` and `labelsTr`) to the newly created test directories (`imagesTs` and `labelsTs`).\n",
        "*   The `numTraining` field in the `dataset.json` file, located at `/content/nnUNet/nnUNet_raw/Dataset501_KSSD/dataset.json`, was updated to `818`, reflecting the removal of 20 cases from the training set.\n",
        "*   Verification of the `imagesTs` and `labelsTs` directories confirmed that they each contain 20 `.nii.gz` files, specifically `case_0000_0000.nii.gz` to `case_0019_0000.nii.gz` for images and `case_0000.nii.gz` to `case_0019.nii.gz` for labels.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The dataset is now correctly partitioned, allowing for independent testing of trained models. The updated `dataset.json` ensures nnU-Net will correctly recognize the new training set size.\n",
        "*   The next logical step is to proceed with nnU-Net's planning, preprocessing, and model training phases, which will now utilize the adjusted training set and can be evaluated on the newly established test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1 /content/nnUNet/nnUNet_raw/Dataset501_KSSD/labelsTr | head -n 20\n",
        "!ls -1 /content/preds_fold1_best_on_train | head -n 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wCGOcGs0LdMA",
        "outputId": "39770051-af4f-4230-a18d-b91b7eb7160e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "case_0020.nii.gz\n",
            "case_0021.nii.gz\n",
            "case_0022.nii.gz\n",
            "case_0023.nii.gz\n",
            "case_0024.nii.gz\n",
            "case_0025.nii.gz\n",
            "case_0026.nii.gz\n",
            "case_0027.nii.gz\n",
            "case_0028.nii.gz\n",
            "case_0029.nii.gz\n",
            "case_0030.nii.gz\n",
            "case_0031.nii.gz\n",
            "case_0032.nii.gz\n",
            "case_0033.nii.gz\n",
            "case_0034.nii.gz\n",
            "case_0035.nii.gz\n",
            "case_0036.nii.gz\n",
            "case_0037.nii.gz\n",
            "case_0038.nii.gz\n",
            "case_0039.nii.gz\n",
            "case_0000.nii.gz\n",
            "case_0001.nii.gz\n",
            "case_0002.nii.gz\n",
            "case_0003.nii.gz\n",
            "case_0004.nii.gz\n",
            "case_0005.nii.gz\n",
            "case_0006.nii.gz\n",
            "case_0007.nii.gz\n",
            "case_0008.nii.gz\n",
            "case_0009.nii.gz\n",
            "case_0010.nii.gz\n",
            "case_0011.nii.gz\n",
            "case_0012.nii.gz\n",
            "case_0013.nii.gz\n",
            "case_0014.nii.gz\n",
            "case_0015.nii.gz\n",
            "case_0016.nii.gz\n",
            "case_0017.nii.gz\n",
            "case_0018.nii.gz\n",
            "case_0019.nii.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start training Fold 2"
      ],
      "metadata": {
        "id": "5hyjkbhsQBrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train 501 2d 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SmXuaIKL3Cb",
        "outputId": "cb7c215d-fcbc-4a38-dbb4-4d378b046568"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2025-12-23 08:08:25.074260: Using torch.compile...\n",
            "2025-12-23 08:08:26.646938: do_dummy_2d_data_aug: False\n",
            "2025-12-23 08:08:26.649082: Using splits from existing split file: /content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/splits_final.json\n",
            "2025-12-23 08:08:26.649651: The split file contains 5 splits.\n",
            "2025-12-23 08:08:26.649724: Desired fold for training: 2\n",
            "2025-12-23 08:08:26.649768: This split has 670 training and 168 validation cases.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n",
            "    sys.exit(run_training_entry())\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/run/run_training.py\", line 266, in run_training_entry\n",
            "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/run/run_training.py\", line 207, in run_training\n",
            "    nnunet_trainer.run_training()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1363, in run_training\n",
            "    self.on_train_start()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 900, in on_train_start\n",
            "    self.dataloader_train, self.dataloader_val = self.get_dataloaders()\n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 660, in get_dataloaders\n",
            "    dl_tr = nnUNetDataLoader(dataset_tr, self.batch_size,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/training/dataloading/data_loader.py\", line 61, in __init__\n",
            "    self.data_shape, self.seg_shape = self.determine_shapes()\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/training/dataloading/data_loader.py\", line 81, in determine_shapes\n",
            "    data, seg, seg_prev, properties = self._data.load_case(self._data.identifiers[0])\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/training/dataloading/nnunet_dataset.py\", line 139, in load_case\n",
            "    data = blosc2.open(urlpath=data_b2nd_file, mode='r', dparams=dparams, **mmap_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/blosc2/schunk.py\", line 1581, in open\n",
            "    raise FileNotFoundError(f\"No such file or directory: {urlpath}\")\n",
            "FileNotFoundError: No such file or directory: /content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/nnUNetPlans_2d/case_0000.b2nd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abce2585"
      },
      "source": [
        "### Delete old `splits_final.json`\n",
        "\n",
        "**Why**: Deleting the existing `splits_final.json` file forces nnU-Net to re-generate the dataset splits when `nnUNetv2_plan_and_preprocess` is run. This ensures that the splits correctly reflect the current contents of `imagesTr` and exclude the cases that were moved to `imagesTs`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7762620",
        "outputId": "55d70f14-9da4-4a7f-88ee-94fa7e4d083f"
      },
      "source": [
        "import os\n",
        "\n",
        "splits_file = \"/content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/splits_final.json\"\n",
        "if os.path.exists(splits_file):\n",
        "    os.remove(splits_file)\n",
        "    print(f\"Removed: {splits_file}\")\n",
        "else:\n",
        "    print(f\"{splits_file} not found, no need to remove.\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed: /content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/splits_final.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f16882f4"
      },
      "source": [
        "### Re-plan and Preprocess\n",
        "\n",
        "**Why**: After deleting the old splits file, we need to re-run `nnUNetv2_plan_and_preprocess`. This will create new, correct data splits and preprocess the training data (excluding the test set), which is essential for `nnUNetv2_train` to function properly with the updated dataset structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d33b81d3",
        "outputId": "201cde3f-e75f-4932-c285-2b84adcd557a"
      },
      "source": [
        "!nnUNetv2_plan_and_preprocess -d 501 --verify_dataset_integrity"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fingerprint extraction...\n",
            "Dataset501_KSSD\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "\n",
            "####################\n",
            "verify_dataset_integrity Done. \n",
            "If you didn't see any error messages then your dataset is most likely OK!\n",
            "####################\n",
            "\n",
            "Experiment planning...\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "2D U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 14, 'patch_size': (np.int64(512), np.int64(448)), 'median_image_size_in_voxels': array([512., 416.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
            "\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "Plans were saved to /content/nnUNet/nnUNet_preprocessed/Dataset501_KSSD/nnUNetPlans.json\n",
            "Preprocessing...\n",
            "Preprocessing dataset Dataset501_KSSD\n",
            "Configuration: 2d...\n",
            "100% 818/818 [00:33<00:00, 24.09it/s]\n",
            "Configuration: 3d_fullres...\n",
            "INFO: Configuration 3d_fullres not found in plans file nnUNetPlans.json of dataset Dataset501_KSSD. Skipping.\n",
            "Configuration: 3d_lowres...\n",
            "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset501_KSSD. Skipping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b839585e"
      },
      "source": [
        "### Re-run Training for Fold 2\n",
        "\n",
        "**Why**: With the dataset splits and preprocessed data now correctly updated, we can attempt to train Fold 2 again. It should no longer encounter `FileNotFoundError` for cases moved to the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecd07576",
        "outputId": "c01415be-4330-4061-cf70-cf98b2b12d7f"
      },
      "source": [
        "!nnUNetv2_train 501 2d 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2025-12-23 08:11:00.034545: Using torch.compile...\n",
            "2025-12-23 08:11:01.572028: do_dummy_2d_data_aug: False\n",
            "2025-12-23 08:11:01.574136: Creating new 5-fold cross-validation split...\n",
            "2025-12-23 08:11:01.579701: Desired fold for training: 2\n",
            "2025-12-23 08:11:01.579782: This split has 654 training and 164 validation cases.\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "using pin_memory on device 0\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "using pin_memory on device 0\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 2d\n",
            " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 14, 'patch_size': [512, 448], 'median_image_size_in_voxels': [512.0, 416.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset501_KSSD', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 512, 416], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 237.29641723632812, 'median': 255.0, 'min': 95.0, 'percentile_00_5': 162.0, 'percentile_99_5': 255.0, 'std': 27.940317153930664}}} \n",
            "\n",
            "2025-12-23 08:11:04.283937: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2025-12-23 08:11:04.312456: \n",
            "2025-12-23 08:11:04.312923: Epoch 0\n",
            "2025-12-23 08:11:04.313335: Current learning rate: 0.01\n",
            "2025-12-23 08:12:42.442318: train_loss 0.0196\n",
            "2025-12-23 08:12:42.442569: val_loss -0.0973\n",
            "2025-12-23 08:12:42.442721: Pseudo dice [np.float32(0.0902)]\n",
            "2025-12-23 08:12:42.442832: Epoch time: 98.14 s\n",
            "2025-12-23 08:12:42.442908: Yayy! New best EMA pseudo Dice: 0.09019999951124191\n",
            "2025-12-23 08:12:43.844478: \n",
            "2025-12-23 08:12:43.844809: Epoch 1\n",
            "2025-12-23 08:12:43.844967: Current learning rate: 0.00999\n",
            "2025-12-23 08:13:06.297262: train_loss -0.5574\n",
            "2025-12-23 08:13:06.297502: val_loss -0.8539\n",
            "2025-12-23 08:13:06.297722: Pseudo dice [np.float32(0.9148)]\n",
            "2025-12-23 08:13:06.297842: Epoch time: 22.45 s\n",
            "2025-12-23 08:13:06.297920: Yayy! New best EMA pseudo Dice: 0.17270000278949738\n",
            "2025-12-23 08:13:08.379506: \n",
            "2025-12-23 08:13:08.379816: Epoch 2\n",
            "2025-12-23 08:13:08.379951: Current learning rate: 0.00998\n",
            "2025-12-23 08:13:30.810441: train_loss -0.821\n",
            "2025-12-23 08:13:30.810834: val_loss -0.8705\n",
            "2025-12-23 08:13:30.810948: Pseudo dice [np.float32(0.924)]\n",
            "2025-12-23 08:13:30.811055: Epoch time: 22.43 s\n",
            "2025-12-23 08:13:30.811127: Yayy! New best EMA pseudo Dice: 0.24779999256134033\n",
            "2025-12-23 08:13:32.667635: \n",
            "2025-12-23 08:13:32.667984: Epoch 3\n",
            "2025-12-23 08:13:32.668119: Current learning rate: 0.00997\n",
            "2025-12-23 08:13:55.149153: train_loss -0.8688\n",
            "2025-12-23 08:13:55.149489: val_loss -0.9181\n",
            "2025-12-23 08:13:55.149614: Pseudo dice [np.float32(0.9497)]\n",
            "2025-12-23 08:13:55.149707: Epoch time: 22.48 s\n",
            "2025-12-23 08:13:55.149793: Yayy! New best EMA pseudo Dice: 0.3179999887943268\n",
            "2025-12-23 08:13:57.250624: \n",
            "2025-12-23 08:13:57.250961: Epoch 4\n",
            "2025-12-23 08:13:57.251096: Current learning rate: 0.00996\n",
            "2025-12-23 08:14:19.695323: train_loss -0.8932\n",
            "2025-12-23 08:14:19.695542: val_loss -0.9231\n",
            "2025-12-23 08:14:19.695668: Pseudo dice [np.float32(0.9516)]\n",
            "2025-12-23 08:14:19.695858: Epoch time: 22.45 s\n",
            "2025-12-23 08:14:19.695975: Yayy! New best EMA pseudo Dice: 0.3813999891281128\n",
            "2025-12-23 08:14:21.553135: \n",
            "2025-12-23 08:14:21.553477: Epoch 5\n",
            "2025-12-23 08:14:21.553630: Current learning rate: 0.00995\n",
            "2025-12-23 08:14:43.995654: train_loss -0.9151\n",
            "2025-12-23 08:14:43.995882: val_loss -0.933\n",
            "2025-12-23 08:14:43.996046: Pseudo dice [np.float32(0.9536)]\n",
            "2025-12-23 08:14:43.996257: Epoch time: 22.44 s\n",
            "2025-12-23 08:14:43.996357: Yayy! New best EMA pseudo Dice: 0.43860000371932983\n",
            "2025-12-23 08:14:45.911689: \n",
            "2025-12-23 08:14:45.911927: Epoch 6\n",
            "2025-12-23 08:14:45.912109: Current learning rate: 0.00995\n",
            "2025-12-23 08:15:08.379893: train_loss -0.9234\n",
            "2025-12-23 08:15:08.380111: val_loss -0.9323\n",
            "2025-12-23 08:15:08.380250: Pseudo dice [np.float32(0.9514)]\n",
            "2025-12-23 08:15:08.380379: Epoch time: 22.47 s\n",
            "2025-12-23 08:15:08.380492: Yayy! New best EMA pseudo Dice: 0.48989999294281006\n",
            "2025-12-23 08:15:10.251639: \n",
            "2025-12-23 08:15:10.251817: Epoch 7\n",
            "2025-12-23 08:15:10.251940: Current learning rate: 0.00994\n",
            "2025-12-23 08:15:32.695051: train_loss -0.9288\n",
            "2025-12-23 08:15:32.695279: val_loss -0.9375\n",
            "2025-12-23 08:15:32.695387: Pseudo dice [np.float32(0.9541)]\n",
            "2025-12-23 08:15:32.695491: Epoch time: 22.44 s\n",
            "2025-12-23 08:15:32.695605: Yayy! New best EMA pseudo Dice: 0.536300003528595\n",
            "2025-12-23 08:15:34.581974: \n",
            "2025-12-23 08:15:34.582345: Epoch 8\n",
            "2025-12-23 08:15:34.582503: Current learning rate: 0.00993\n",
            "2025-12-23 08:15:57.032300: train_loss -0.9205\n",
            "2025-12-23 08:15:57.032555: val_loss -0.9444\n",
            "2025-12-23 08:15:57.032646: Pseudo dice [np.float32(0.9558)]\n",
            "2025-12-23 08:15:57.032741: Epoch time: 22.45 s\n",
            "2025-12-23 08:15:57.032818: Yayy! New best EMA pseudo Dice: 0.5781999826431274\n",
            "2025-12-23 08:15:58.990165: \n",
            "2025-12-23 08:15:58.990477: Epoch 9\n",
            "2025-12-23 08:15:58.990610: Current learning rate: 0.00992\n",
            "2025-12-23 08:16:21.509740: train_loss -0.9239\n",
            "2025-12-23 08:16:21.510073: val_loss -0.9448\n",
            "2025-12-23 08:16:21.510242: Pseudo dice [np.float32(0.9598)]\n",
            "2025-12-23 08:16:21.510445: Epoch time: 22.52 s\n",
            "2025-12-23 08:16:21.510564: Yayy! New best EMA pseudo Dice: 0.6164000034332275\n",
            "2025-12-23 08:16:23.420620: \n",
            "2025-12-23 08:16:23.420877: Epoch 10\n",
            "2025-12-23 08:16:23.421011: Current learning rate: 0.00991\n",
            "2025-12-23 08:16:45.908190: train_loss -0.932\n",
            "2025-12-23 08:16:45.908422: val_loss -0.9465\n",
            "2025-12-23 08:16:45.908572: Pseudo dice [np.float32(0.9556)]\n",
            "2025-12-23 08:16:45.908686: Epoch time: 22.49 s\n",
            "2025-12-23 08:16:45.908774: Yayy! New best EMA pseudo Dice: 0.6503000259399414\n",
            "2025-12-23 08:16:47.672394: \n",
            "2025-12-23 08:16:47.672688: Epoch 11\n",
            "2025-12-23 08:16:47.672826: Current learning rate: 0.0099\n",
            "2025-12-23 08:17:10.109266: train_loss -0.9329\n",
            "2025-12-23 08:17:10.109567: val_loss -0.9503\n",
            "2025-12-23 08:17:10.109671: Pseudo dice [np.float32(0.9601)]\n",
            "2025-12-23 08:17:10.109777: Epoch time: 22.44 s\n",
            "2025-12-23 08:17:10.109869: Yayy! New best EMA pseudo Dice: 0.6812999844551086\n",
            "2025-12-23 08:17:11.916412: \n",
            "2025-12-23 08:17:11.916742: Epoch 12\n",
            "2025-12-23 08:17:11.916880: Current learning rate: 0.00989\n",
            "2025-12-23 08:17:34.359140: train_loss -0.9371\n",
            "2025-12-23 08:17:34.359359: val_loss -0.9566\n",
            "2025-12-23 08:17:34.359478: Pseudo dice [np.float32(0.9665)]\n",
            "2025-12-23 08:17:34.359632: Epoch time: 22.44 s\n",
            "2025-12-23 08:17:34.359714: Yayy! New best EMA pseudo Dice: 0.7098000049591064\n",
            "2025-12-23 08:17:36.208814: \n",
            "2025-12-23 08:17:36.209078: Epoch 13\n",
            "2025-12-23 08:17:36.209211: Current learning rate: 0.00988\n",
            "2025-12-23 08:17:58.686959: train_loss -0.9412\n",
            "2025-12-23 08:17:58.687393: val_loss -0.9469\n",
            "2025-12-23 08:17:58.687509: Pseudo dice [np.float32(0.9579)]\n",
            "2025-12-23 08:17:58.687611: Epoch time: 22.48 s\n",
            "2025-12-23 08:17:58.687683: Yayy! New best EMA pseudo Dice: 0.7346000075340271\n",
            "2025-12-23 08:18:00.520083: \n",
            "2025-12-23 08:18:00.520395: Epoch 14\n",
            "2025-12-23 08:18:00.520551: Current learning rate: 0.00987\n",
            "2025-12-23 08:18:22.991639: train_loss -0.9359\n",
            "2025-12-23 08:18:22.991909: val_loss -0.9578\n",
            "2025-12-23 08:18:22.992021: Pseudo dice [np.float32(0.9677)]\n",
            "2025-12-23 08:18:22.992116: Epoch time: 22.47 s\n",
            "2025-12-23 08:18:22.992193: Yayy! New best EMA pseudo Dice: 0.7578999996185303\n",
            "2025-12-23 08:18:24.862061: \n",
            "2025-12-23 08:18:24.862323: Epoch 15\n",
            "2025-12-23 08:18:24.862501: Current learning rate: 0.00986\n",
            "2025-12-23 08:18:47.254049: train_loss -0.9443\n",
            "2025-12-23 08:18:47.254514: val_loss -0.9591\n",
            "2025-12-23 08:18:47.254668: Pseudo dice [np.float32(0.9657)]\n",
            "2025-12-23 08:18:47.254765: Epoch time: 22.39 s\n",
            "2025-12-23 08:18:47.254839: Yayy! New best EMA pseudo Dice: 0.7786999940872192\n",
            "2025-12-23 08:18:49.659257: \n",
            "2025-12-23 08:18:49.659612: Epoch 16\n",
            "2025-12-23 08:18:49.659767: Current learning rate: 0.00986\n",
            "2025-12-23 08:19:12.186291: train_loss -0.9391\n",
            "2025-12-23 08:19:12.186597: val_loss -0.9584\n",
            "2025-12-23 08:19:12.186718: Pseudo dice [np.float32(0.9673)]\n",
            "2025-12-23 08:19:12.186847: Epoch time: 22.53 s\n",
            "2025-12-23 08:19:12.186947: Yayy! New best EMA pseudo Dice: 0.7975999712944031\n",
            "2025-12-23 08:19:14.071984: \n",
            "2025-12-23 08:19:14.072331: Epoch 17\n",
            "2025-12-23 08:19:14.072477: Current learning rate: 0.00985\n",
            "2025-12-23 08:19:36.564477: train_loss -0.9444\n",
            "2025-12-23 08:19:36.564726: val_loss -0.9583\n",
            "2025-12-23 08:19:36.564867: Pseudo dice [np.float32(0.9666)]\n",
            "2025-12-23 08:19:36.564964: Epoch time: 22.49 s\n",
            "2025-12-23 08:19:36.565043: Yayy! New best EMA pseudo Dice: 0.8144999742507935\n",
            "2025-12-23 08:19:38.438802: \n",
            "2025-12-23 08:19:38.439131: Epoch 18\n",
            "2025-12-23 08:19:38.439309: Current learning rate: 0.00984\n",
            "2025-12-23 08:20:00.910105: train_loss -0.9512\n",
            "2025-12-23 08:20:00.910390: val_loss -0.9605\n",
            "2025-12-23 08:20:00.910589: Pseudo dice [np.float32(0.9679)]\n",
            "2025-12-23 08:20:00.910739: Epoch time: 22.47 s\n",
            "2025-12-23 08:20:00.910826: Yayy! New best EMA pseudo Dice: 0.829800009727478\n",
            "2025-12-23 08:20:02.763840: \n",
            "2025-12-23 08:20:02.764113: Epoch 19\n",
            "2025-12-23 08:20:02.764261: Current learning rate: 0.00983\n",
            "2025-12-23 08:20:25.201531: train_loss -0.9512\n",
            "2025-12-23 08:20:25.201768: val_loss -0.9693\n",
            "2025-12-23 08:20:25.201857: Pseudo dice [np.float32(0.975)]\n",
            "2025-12-23 08:20:25.201947: Epoch time: 22.44 s\n",
            "2025-12-23 08:20:25.202020: Yayy! New best EMA pseudo Dice: 0.8442999720573425\n",
            "2025-12-23 08:20:27.142071: \n",
            "2025-12-23 08:20:27.142390: Epoch 20\n",
            "2025-12-23 08:20:27.142529: Current learning rate: 0.00982\n",
            "2025-12-23 08:20:49.633508: train_loss -0.9556\n",
            "2025-12-23 08:20:49.633729: val_loss -0.9695\n",
            "2025-12-23 08:20:49.633814: Pseudo dice [np.float32(0.976)]\n",
            "2025-12-23 08:20:49.633905: Epoch time: 22.49 s\n",
            "2025-12-23 08:20:49.633980: Yayy! New best EMA pseudo Dice: 0.8575000166893005\n",
            "2025-12-23 08:20:51.456944: \n",
            "2025-12-23 08:20:51.457269: Epoch 21\n",
            "2025-12-23 08:20:51.457404: Current learning rate: 0.00981\n",
            "2025-12-23 08:21:13.970774: train_loss -0.9556\n",
            "2025-12-23 08:21:13.971052: val_loss -0.9667\n",
            "2025-12-23 08:21:13.971150: Pseudo dice [np.float32(0.9745)]\n",
            "2025-12-23 08:21:13.971266: Epoch time: 22.52 s\n",
            "2025-12-23 08:21:13.971379: Yayy! New best EMA pseudo Dice: 0.8691999912261963\n",
            "2025-12-23 08:21:15.827988: \n",
            "2025-12-23 08:21:15.828386: Epoch 22\n",
            "2025-12-23 08:21:15.828525: Current learning rate: 0.0098\n",
            "2025-12-23 08:21:38.250423: train_loss -0.9565\n",
            "2025-12-23 08:21:38.250680: val_loss -0.9672\n",
            "2025-12-23 08:21:38.250767: Pseudo dice [np.float32(0.9741)]\n",
            "2025-12-23 08:21:38.250855: Epoch time: 22.42 s\n",
            "2025-12-23 08:21:38.250926: Yayy! New best EMA pseudo Dice: 0.8797000050544739\n",
            "2025-12-23 08:21:40.069710: \n",
            "2025-12-23 08:21:40.070053: Epoch 23\n",
            "2025-12-23 08:21:40.070199: Current learning rate: 0.00979\n",
            "2025-12-23 08:22:02.527363: train_loss -0.9578\n",
            "2025-12-23 08:22:02.527572: val_loss -0.9679\n",
            "2025-12-23 08:22:02.527660: Pseudo dice [np.float32(0.9731)]\n",
            "2025-12-23 08:22:02.527752: Epoch time: 22.46 s\n",
            "2025-12-23 08:22:02.527910: Yayy! New best EMA pseudo Dice: 0.8889999985694885\n",
            "2025-12-23 08:22:04.354742: \n",
            "2025-12-23 08:22:04.354978: Epoch 24\n",
            "2025-12-23 08:22:04.355130: Current learning rate: 0.00978\n",
            "2025-12-23 08:22:26.876307: train_loss -0.9526\n",
            "2025-12-23 08:22:26.876505: val_loss -0.9664\n",
            "2025-12-23 08:22:26.876597: Pseudo dice [np.float32(0.9686)]\n",
            "2025-12-23 08:22:26.876688: Epoch time: 22.52 s\n",
            "2025-12-23 08:22:26.876763: Yayy! New best EMA pseudo Dice: 0.8970000147819519\n",
            "2025-12-23 08:22:28.716440: \n",
            "2025-12-23 08:22:28.716684: Epoch 25\n",
            "2025-12-23 08:22:28.716829: Current learning rate: 0.00977\n",
            "2025-12-23 08:22:51.163999: train_loss -0.9578\n",
            "2025-12-23 08:22:51.164194: val_loss -0.9672\n",
            "2025-12-23 08:22:51.164307: Pseudo dice [np.float32(0.9722)]\n",
            "2025-12-23 08:22:51.164414: Epoch time: 22.45 s\n",
            "2025-12-23 08:22:51.164670: Yayy! New best EMA pseudo Dice: 0.9045000076293945\n",
            "2025-12-23 08:22:52.988908: \n",
            "2025-12-23 08:22:52.989289: Epoch 26\n",
            "2025-12-23 08:22:52.989439: Current learning rate: 0.00977\n",
            "2025-12-23 08:23:15.453381: train_loss -0.9564\n",
            "2025-12-23 08:23:15.453642: val_loss -0.9687\n",
            "2025-12-23 08:23:15.453748: Pseudo dice [np.float32(0.974)]\n",
            "2025-12-23 08:23:15.453844: Epoch time: 22.47 s\n",
            "2025-12-23 08:23:15.453921: Yayy! New best EMA pseudo Dice: 0.9114999771118164\n",
            "2025-12-23 08:23:17.274817: \n",
            "2025-12-23 08:23:17.274973: Epoch 27\n",
            "2025-12-23 08:23:17.275132: Current learning rate: 0.00976\n",
            "2025-12-23 08:23:39.717602: train_loss -0.9522\n",
            "2025-12-23 08:23:39.717808: val_loss -0.9693\n",
            "2025-12-23 08:23:39.717937: Pseudo dice [np.float32(0.9758)]\n",
            "2025-12-23 08:23:39.718066: Epoch time: 22.44 s\n",
            "2025-12-23 08:23:39.718149: Yayy! New best EMA pseudo Dice: 0.917900025844574\n",
            "2025-12-23 08:23:41.548900: \n",
            "2025-12-23 08:23:41.549062: Epoch 28\n",
            "2025-12-23 08:23:41.549277: Current learning rate: 0.00975\n",
            "2025-12-23 08:24:04.000080: train_loss -0.9584\n",
            "2025-12-23 08:24:04.000381: val_loss -0.9691\n",
            "2025-12-23 08:24:04.000480: Pseudo dice [np.float32(0.9767)]\n",
            "2025-12-23 08:24:04.000580: Epoch time: 22.45 s\n",
            "2025-12-23 08:24:04.000666: Yayy! New best EMA pseudo Dice: 0.923799991607666\n",
            "2025-12-23 08:24:05.822510: \n",
            "2025-12-23 08:24:05.822745: Epoch 29\n",
            "2025-12-23 08:24:05.822882: Current learning rate: 0.00974\n",
            "2025-12-23 08:24:28.290112: train_loss -0.96\n",
            "2025-12-23 08:24:28.290350: val_loss -0.9725\n",
            "2025-12-23 08:24:28.290441: Pseudo dice [np.float32(0.9787)]\n",
            "2025-12-23 08:24:28.290530: Epoch time: 22.47 s\n",
            "2025-12-23 08:24:28.290607: Yayy! New best EMA pseudo Dice: 0.9293000102043152\n",
            "2025-12-23 08:24:30.575028: \n",
            "2025-12-23 08:24:30.575381: Epoch 30\n",
            "2025-12-23 08:24:30.575527: Current learning rate: 0.00973\n",
            "2025-12-23 08:24:53.062987: train_loss -0.9596\n",
            "2025-12-23 08:24:53.063189: val_loss -0.9648\n",
            "2025-12-23 08:24:53.063325: Pseudo dice [np.float32(0.9727)]\n",
            "2025-12-23 08:24:53.063441: Epoch time: 22.49 s\n",
            "2025-12-23 08:24:53.063531: Yayy! New best EMA pseudo Dice: 0.9336000084877014\n",
            "2025-12-23 08:24:54.918277: \n",
            "2025-12-23 08:24:54.918560: Epoch 31\n",
            "2025-12-23 08:24:54.918755: Current learning rate: 0.00972\n",
            "2025-12-23 08:25:17.401386: train_loss -0.9544\n",
            "2025-12-23 08:25:17.401618: val_loss -0.9699\n",
            "2025-12-23 08:25:17.401720: Pseudo dice [np.float32(0.9772)]\n",
            "2025-12-23 08:25:17.401819: Epoch time: 22.48 s\n",
            "2025-12-23 08:25:17.401898: Yayy! New best EMA pseudo Dice: 0.9380000233650208\n",
            "2025-12-23 08:25:19.293450: \n",
            "2025-12-23 08:25:19.293694: Epoch 32\n",
            "2025-12-23 08:25:19.293907: Current learning rate: 0.00971\n",
            "2025-12-23 08:25:41.772865: train_loss -0.9591\n",
            "2025-12-23 08:25:41.773057: val_loss -0.9705\n",
            "2025-12-23 08:25:41.773143: Pseudo dice [np.float32(0.9781)]\n",
            "2025-12-23 08:25:41.773244: Epoch time: 22.48 s\n",
            "2025-12-23 08:25:41.773324: Yayy! New best EMA pseudo Dice: 0.9419999718666077\n",
            "2025-12-23 08:25:43.629892: \n",
            "2025-12-23 08:25:43.630273: Epoch 33\n",
            "2025-12-23 08:25:43.630419: Current learning rate: 0.0097\n",
            "2025-12-23 08:26:06.068685: train_loss -0.9606\n",
            "2025-12-23 08:26:06.068980: val_loss -0.9743\n",
            "2025-12-23 08:26:06.069165: Pseudo dice [np.float32(0.9798)]\n",
            "2025-12-23 08:26:06.069434: Epoch time: 22.44 s\n",
            "2025-12-23 08:26:06.069629: Yayy! New best EMA pseudo Dice: 0.9458000063896179\n",
            "2025-12-23 08:26:07.906991: \n",
            "2025-12-23 08:26:07.907289: Epoch 34\n",
            "2025-12-23 08:26:07.907439: Current learning rate: 0.00969\n",
            "2025-12-23 08:26:30.361175: train_loss -0.9619\n",
            "2025-12-23 08:26:30.361417: val_loss -0.9739\n",
            "2025-12-23 08:26:30.361522: Pseudo dice [np.float32(0.9802)]\n",
            "2025-12-23 08:26:30.361614: Epoch time: 22.46 s\n",
            "2025-12-23 08:26:30.361688: Yayy! New best EMA pseudo Dice: 0.9491999745368958\n",
            "2025-12-23 08:26:32.220896: \n",
            "2025-12-23 08:26:32.221242: Epoch 35\n",
            "2025-12-23 08:26:32.221401: Current learning rate: 0.00968\n",
            "2025-12-23 08:26:54.688668: train_loss -0.9611\n",
            "2025-12-23 08:26:54.688877: val_loss -0.9723\n",
            "2025-12-23 08:26:54.688965: Pseudo dice [np.float32(0.9777)]\n",
            "2025-12-23 08:26:54.689069: Epoch time: 22.47 s\n",
            "2025-12-23 08:26:54.689146: Yayy! New best EMA pseudo Dice: 0.9520999789237976\n",
            "2025-12-23 08:26:56.575903: \n",
            "2025-12-23 08:26:56.576127: Epoch 36\n",
            "2025-12-23 08:26:56.576300: Current learning rate: 0.00968\n",
            "2025-12-23 08:27:19.048734: train_loss -0.9604\n",
            "2025-12-23 08:27:19.048947: val_loss -0.9678\n",
            "2025-12-23 08:27:19.049036: Pseudo dice [np.float32(0.9721)]\n",
            "2025-12-23 08:27:19.049125: Epoch time: 22.47 s\n",
            "2025-12-23 08:27:19.049303: Yayy! New best EMA pseudo Dice: 0.9541000127792358\n",
            "2025-12-23 08:27:20.906187: \n",
            "2025-12-23 08:27:20.906527: Epoch 37\n",
            "2025-12-23 08:27:20.906657: Current learning rate: 0.00967\n",
            "2025-12-23 08:27:43.342793: train_loss -0.9603\n",
            "2025-12-23 08:27:43.343113: val_loss -0.9711\n",
            "2025-12-23 08:27:43.343283: Pseudo dice [np.float32(0.9756)]\n",
            "2025-12-23 08:27:43.343436: Epoch time: 22.44 s\n",
            "2025-12-23 08:27:43.343554: Yayy! New best EMA pseudo Dice: 0.9562000036239624\n",
            "2025-12-23 08:27:45.240870: \n",
            "2025-12-23 08:27:45.241052: Epoch 38\n",
            "2025-12-23 08:27:45.241180: Current learning rate: 0.00966\n",
            "2025-12-23 08:28:07.697308: train_loss -0.9616\n",
            "2025-12-23 08:28:07.697655: val_loss -0.9741\n",
            "2025-12-23 08:28:07.697765: Pseudo dice [np.float32(0.9815)]\n",
            "2025-12-23 08:28:07.697873: Epoch time: 22.46 s\n",
            "2025-12-23 08:28:07.697956: Yayy! New best EMA pseudo Dice: 0.9588000178337097\n",
            "2025-12-23 08:28:09.601032: \n",
            "2025-12-23 08:28:09.601428: Epoch 39\n",
            "2025-12-23 08:28:09.601570: Current learning rate: 0.00965\n",
            "2025-12-23 08:28:32.051194: train_loss -0.9627\n",
            "2025-12-23 08:28:32.051411: val_loss -0.9731\n",
            "2025-12-23 08:28:32.051497: Pseudo dice [np.float32(0.9789)]\n",
            "2025-12-23 08:28:32.051598: Epoch time: 22.45 s\n",
            "2025-12-23 08:28:32.051673: Yayy! New best EMA pseudo Dice: 0.9607999920845032\n",
            "2025-12-23 08:28:33.959960: \n",
            "2025-12-23 08:28:33.960182: Epoch 40\n",
            "2025-12-23 08:28:33.960439: Current learning rate: 0.00964\n",
            "2025-12-23 08:28:56.418932: train_loss -0.9618\n",
            "2025-12-23 08:28:56.419150: val_loss -0.973\n",
            "2025-12-23 08:28:56.419466: Pseudo dice [np.float32(0.9794)]\n",
            "2025-12-23 08:28:56.419626: Epoch time: 22.46 s\n",
            "2025-12-23 08:28:56.419706: Yayy! New best EMA pseudo Dice: 0.9625999927520752\n",
            "2025-12-23 08:28:58.316238: \n",
            "2025-12-23 08:28:58.316557: Epoch 41\n",
            "2025-12-23 08:28:58.316711: Current learning rate: 0.00963\n",
            "2025-12-23 08:29:20.808192: train_loss -0.96\n",
            "2025-12-23 08:29:20.808459: val_loss -0.9737\n",
            "2025-12-23 08:29:20.808575: Pseudo dice [np.float32(0.9796)]\n",
            "2025-12-23 08:29:20.808675: Epoch time: 22.49 s\n",
            "2025-12-23 08:29:20.808756: Yayy! New best EMA pseudo Dice: 0.9642999768257141\n",
            "2025-12-23 08:29:22.648566: \n",
            "2025-12-23 08:29:22.648936: Epoch 42\n",
            "2025-12-23 08:29:22.649088: Current learning rate: 0.00962\n",
            "2025-12-23 08:29:45.082581: train_loss -0.9621\n",
            "2025-12-23 08:29:45.082807: val_loss -0.9732\n",
            "2025-12-23 08:29:45.082908: Pseudo dice [np.float32(0.9791)]\n",
            "2025-12-23 08:29:45.082998: Epoch time: 22.44 s\n",
            "2025-12-23 08:29:45.083076: Yayy! New best EMA pseudo Dice: 0.9657999873161316\n",
            "2025-12-23 08:29:47.416576: \n",
            "2025-12-23 08:29:47.416969: Epoch 43\n",
            "2025-12-23 08:29:47.417109: Current learning rate: 0.00961\n",
            "2025-12-23 08:30:09.878353: train_loss -0.9616\n",
            "2025-12-23 08:30:09.878557: val_loss -0.9748\n",
            "2025-12-23 08:30:09.878647: Pseudo dice [np.float32(0.9804)]\n",
            "2025-12-23 08:30:09.878738: Epoch time: 22.46 s\n",
            "2025-12-23 08:30:09.878827: Yayy! New best EMA pseudo Dice: 0.9672999978065491\n",
            "2025-12-23 08:30:11.733118: \n",
            "2025-12-23 08:30:11.733315: Epoch 44\n",
            "2025-12-23 08:30:11.733519: Current learning rate: 0.0096\n",
            "2025-12-23 08:30:34.240564: train_loss -0.9626\n",
            "2025-12-23 08:30:34.240847: val_loss -0.9719\n",
            "2025-12-23 08:30:34.240964: Pseudo dice [np.float32(0.9786)]\n",
            "2025-12-23 08:30:34.241083: Epoch time: 22.51 s\n",
            "2025-12-23 08:30:34.241198: Yayy! New best EMA pseudo Dice: 0.9684000015258789\n",
            "2025-12-23 08:30:36.124289: \n",
            "2025-12-23 08:30:36.124513: Epoch 45\n",
            "2025-12-23 08:30:36.124678: Current learning rate: 0.00959\n",
            "2025-12-23 08:30:58.605353: train_loss -0.9615\n",
            "2025-12-23 08:30:58.605563: val_loss -0.9755\n",
            "2025-12-23 08:30:58.605654: Pseudo dice [np.float32(0.9808)]\n",
            "2025-12-23 08:30:58.605743: Epoch time: 22.48 s\n",
            "2025-12-23 08:30:58.605822: Yayy! New best EMA pseudo Dice: 0.9696000218391418\n",
            "2025-12-23 08:31:00.483426: \n",
            "2025-12-23 08:31:00.483752: Epoch 46\n",
            "2025-12-23 08:31:00.483897: Current learning rate: 0.00959\n",
            "2025-12-23 08:31:23.015649: train_loss -0.9611\n",
            "2025-12-23 08:31:23.015949: val_loss -0.9736\n",
            "2025-12-23 08:31:23.016165: Pseudo dice [np.float32(0.9783)]\n",
            "2025-12-23 08:31:23.016369: Epoch time: 22.53 s\n",
            "2025-12-23 08:31:23.016550: Yayy! New best EMA pseudo Dice: 0.9704999923706055\n",
            "2025-12-23 08:31:24.876014: \n",
            "2025-12-23 08:31:24.876212: Epoch 47\n",
            "2025-12-23 08:31:24.876372: Current learning rate: 0.00958\n",
            "2025-12-23 08:31:47.394162: train_loss -0.9601\n",
            "2025-12-23 08:31:47.394625: val_loss -0.972\n",
            "2025-12-23 08:31:47.394726: Pseudo dice [np.float32(0.9774)]\n",
            "2025-12-23 08:31:47.394826: Epoch time: 22.52 s\n",
            "2025-12-23 08:31:47.394898: Yayy! New best EMA pseudo Dice: 0.9711999893188477\n",
            "2025-12-23 08:31:49.258665: \n",
            "2025-12-23 08:31:49.258892: Epoch 48\n",
            "2025-12-23 08:31:49.259068: Current learning rate: 0.00957\n",
            "2025-12-23 08:32:11.691552: train_loss -0.9584\n",
            "2025-12-23 08:32:11.691835: val_loss -0.9728\n",
            "2025-12-23 08:32:11.691936: Pseudo dice [np.float32(0.9791)]\n",
            "2025-12-23 08:32:11.692031: Epoch time: 22.43 s\n",
            "2025-12-23 08:32:11.692107: Yayy! New best EMA pseudo Dice: 0.972000002861023\n",
            "2025-12-23 08:32:13.566595: \n",
            "2025-12-23 08:32:13.566787: Epoch 49\n",
            "2025-12-23 08:32:13.566968: Current learning rate: 0.00956\n",
            "2025-12-23 08:32:36.065723: train_loss -0.9606\n",
            "2025-12-23 08:32:36.066445: val_loss -0.9349\n",
            "2025-12-23 08:32:36.066667: Pseudo dice [np.float32(0.9415)]\n",
            "2025-12-23 08:32:36.066771: Epoch time: 22.5 s\n",
            "2025-12-23 08:32:37.725740: \n",
            "2025-12-23 08:32:37.726074: Epoch 50\n",
            "2025-12-23 08:32:37.726211: Current learning rate: 0.00955\n",
            "2025-12-23 08:33:00.150055: train_loss -0.944\n",
            "2025-12-23 08:33:00.150393: val_loss -0.9681\n",
            "2025-12-23 08:33:00.150654: Pseudo dice [np.float32(0.9756)]\n",
            "2025-12-23 08:33:00.150839: Epoch time: 22.43 s\n",
            "2025-12-23 08:33:01.508924: \n",
            "2025-12-23 08:33:01.509182: Epoch 51\n",
            "2025-12-23 08:33:01.509350: Current learning rate: 0.00954\n",
            "2025-12-23 08:33:23.899310: train_loss -0.9555\n",
            "2025-12-23 08:33:23.899514: val_loss -0.9713\n",
            "2025-12-23 08:33:23.899608: Pseudo dice [np.float32(0.9794)]\n",
            "2025-12-23 08:33:23.899744: Epoch time: 22.39 s\n",
            "2025-12-23 08:33:25.265063: \n",
            "2025-12-23 08:33:25.265402: Epoch 52\n",
            "2025-12-23 08:33:25.265588: Current learning rate: 0.00953\n",
            "2025-12-23 08:33:47.725565: train_loss -0.9583\n",
            "2025-12-23 08:33:47.725786: val_loss -0.9728\n",
            "2025-12-23 08:33:47.726085: Pseudo dice [np.float32(0.9802)]\n",
            "2025-12-23 08:33:47.726255: Epoch time: 22.46 s\n",
            "2025-12-23 08:33:49.088289: \n",
            "2025-12-23 08:33:49.088703: Epoch 53\n",
            "2025-12-23 08:33:49.088851: Current learning rate: 0.00952\n",
            "2025-12-23 08:34:11.510487: train_loss -0.9617\n",
            "2025-12-23 08:34:11.510833: val_loss -0.9738\n",
            "2025-12-23 08:34:11.510930: Pseudo dice [np.float32(0.9808)]\n",
            "2025-12-23 08:34:11.511022: Epoch time: 22.42 s\n",
            "2025-12-23 08:34:11.511108: Yayy! New best EMA pseudo Dice: 0.9725000262260437\n",
            "2025-12-23 08:34:13.370493: \n",
            "2025-12-23 08:34:13.370778: Epoch 54\n",
            "2025-12-23 08:34:13.370975: Current learning rate: 0.00951\n",
            "2025-12-23 08:34:35.823924: train_loss -0.9619\n",
            "2025-12-23 08:34:35.824394: val_loss -0.9724\n",
            "2025-12-23 08:34:35.824566: Pseudo dice [np.float32(0.9788)]\n",
            "2025-12-23 08:34:35.824714: Epoch time: 22.45 s\n",
            "2025-12-23 08:34:35.824852: Yayy! New best EMA pseudo Dice: 0.9731000065803528\n",
            "2025-12-23 08:34:37.730561: \n",
            "2025-12-23 08:34:37.730773: Epoch 55\n",
            "2025-12-23 08:34:37.730905: Current learning rate: 0.0095\n",
            "2025-12-23 08:35:00.234837: train_loss -0.9626\n",
            "2025-12-23 08:35:00.235257: val_loss -0.9759\n",
            "2025-12-23 08:35:00.235464: Pseudo dice [np.float32(0.9811)]\n",
            "2025-12-23 08:35:00.235615: Epoch time: 22.51 s\n",
            "2025-12-23 08:35:00.235745: Yayy! New best EMA pseudo Dice: 0.9739000201225281\n",
            "2025-12-23 08:35:02.565870: \n",
            "2025-12-23 08:35:02.566196: Epoch 56\n",
            "2025-12-23 08:35:02.566348: Current learning rate: 0.00949\n",
            "2025-12-23 08:35:25.111522: train_loss -0.963\n",
            "2025-12-23 08:35:25.111785: val_loss -0.9737\n",
            "2025-12-23 08:35:25.111881: Pseudo dice [np.float32(0.9818)]\n",
            "2025-12-23 08:35:25.111971: Epoch time: 22.55 s\n",
            "2025-12-23 08:35:25.112067: Yayy! New best EMA pseudo Dice: 0.9746999740600586\n",
            "2025-12-23 08:35:27.136781: \n",
            "2025-12-23 08:35:27.137119: Epoch 57\n",
            "2025-12-23 08:35:27.137286: Current learning rate: 0.00949\n",
            "2025-12-23 08:35:49.646182: train_loss -0.9621\n",
            "2025-12-23 08:35:49.646441: val_loss -0.9748\n",
            "2025-12-23 08:35:49.646539: Pseudo dice [np.float32(0.9809)]\n",
            "2025-12-23 08:35:49.646632: Epoch time: 22.51 s\n",
            "2025-12-23 08:35:49.646718: Yayy! New best EMA pseudo Dice: 0.9753000140190125\n",
            "2025-12-23 08:35:51.498731: \n",
            "2025-12-23 08:35:51.498917: Epoch 58\n",
            "2025-12-23 08:35:51.499057: Current learning rate: 0.00948\n",
            "2025-12-23 08:36:14.020069: train_loss -0.9622\n",
            "2025-12-23 08:36:14.020444: val_loss -0.9747\n",
            "2025-12-23 08:36:14.020625: Pseudo dice [np.float32(0.9811)]\n",
            "2025-12-23 08:36:14.020740: Epoch time: 22.52 s\n",
            "2025-12-23 08:36:14.020826: Yayy! New best EMA pseudo Dice: 0.9758999943733215\n",
            "2025-12-23 08:36:15.866305: \n",
            "2025-12-23 08:36:15.866636: Epoch 59\n",
            "2025-12-23 08:36:15.866774: Current learning rate: 0.00947\n",
            "2025-12-23 08:36:38.343303: train_loss -0.9635\n",
            "2025-12-23 08:36:38.343532: val_loss -0.976\n",
            "2025-12-23 08:36:38.343640: Pseudo dice [np.float32(0.9826)]\n",
            "2025-12-23 08:36:38.343734: Epoch time: 22.48 s\n",
            "2025-12-23 08:36:38.343856: Yayy! New best EMA pseudo Dice: 0.9765999913215637\n",
            "2025-12-23 08:36:40.247543: \n",
            "2025-12-23 08:36:40.247881: Epoch 60\n",
            "2025-12-23 08:36:40.248020: Current learning rate: 0.00946\n",
            "2025-12-23 08:37:02.798998: train_loss -0.9626\n",
            "2025-12-23 08:37:02.799273: val_loss -0.9737\n",
            "2025-12-23 08:37:02.799471: Pseudo dice [np.float32(0.9789)]\n",
            "2025-12-23 08:37:02.799747: Epoch time: 22.55 s\n",
            "2025-12-23 08:37:02.799917: Yayy! New best EMA pseudo Dice: 0.9768000245094299\n",
            "2025-12-23 08:37:04.633738: \n",
            "2025-12-23 08:37:04.633933: Epoch 61\n",
            "2025-12-23 08:37:04.634099: Current learning rate: 0.00945\n",
            "2025-12-23 08:37:27.123157: train_loss -0.9647\n",
            "2025-12-23 08:37:27.123613: val_loss -0.9775\n",
            "2025-12-23 08:37:27.123775: Pseudo dice [np.float32(0.9834)]\n",
            "2025-12-23 08:37:27.123914: Epoch time: 22.49 s\n",
            "2025-12-23 08:37:27.124036: Yayy! New best EMA pseudo Dice: 0.9775000214576721\n",
            "2025-12-23 08:37:28.995786: \n",
            "2025-12-23 08:37:28.996180: Epoch 62\n",
            "2025-12-23 08:37:28.996336: Current learning rate: 0.00944\n",
            "2025-12-23 08:37:51.471447: train_loss -0.9616\n",
            "2025-12-23 08:37:51.471678: val_loss -0.9729\n",
            "2025-12-23 08:37:51.471789: Pseudo dice [np.float32(0.9786)]\n",
            "2025-12-23 08:37:51.471883: Epoch time: 22.48 s\n",
            "2025-12-23 08:37:51.471959: Yayy! New best EMA pseudo Dice: 0.9775999784469604\n",
            "2025-12-23 08:37:53.311554: \n",
            "2025-12-23 08:37:53.311890: Epoch 63\n",
            "2025-12-23 08:37:53.312021: Current learning rate: 0.00943\n",
            "2025-12-23 08:38:15.790322: train_loss -0.9612\n",
            "2025-12-23 08:38:15.790596: val_loss -0.9756\n",
            "2025-12-23 08:38:15.790762: Pseudo dice [np.float32(0.9814)]\n",
            "2025-12-23 08:38:15.790914: Epoch time: 22.48 s\n",
            "2025-12-23 08:38:15.791103: Yayy! New best EMA pseudo Dice: 0.9779999852180481\n",
            "2025-12-23 08:38:17.694206: \n",
            "2025-12-23 08:38:17.694497: Epoch 64\n",
            "2025-12-23 08:38:17.694658: Current learning rate: 0.00942\n",
            "2025-12-23 08:38:40.279440: train_loss -0.9641\n",
            "2025-12-23 08:38:40.279653: val_loss -0.9767\n",
            "2025-12-23 08:38:40.279773: Pseudo dice [np.float32(0.9823)]\n",
            "2025-12-23 08:38:40.279895: Epoch time: 22.59 s\n",
            "2025-12-23 08:38:40.280015: Yayy! New best EMA pseudo Dice: 0.9783999919891357\n",
            "2025-12-23 08:38:42.177953: \n",
            "2025-12-23 08:38:42.178273: Epoch 65\n",
            "2025-12-23 08:38:42.178477: Current learning rate: 0.00941\n",
            "2025-12-23 08:39:04.726589: train_loss -0.9641\n",
            "2025-12-23 08:39:04.726851: val_loss -0.9768\n",
            "2025-12-23 08:39:04.726949: Pseudo dice [np.float32(0.9829)]\n",
            "2025-12-23 08:39:04.727040: Epoch time: 22.55 s\n",
            "2025-12-23 08:39:04.727117: Yayy! New best EMA pseudo Dice: 0.9787999987602234\n",
            "2025-12-23 08:39:06.574097: \n",
            "2025-12-23 08:39:06.574286: Epoch 66\n",
            "2025-12-23 08:39:06.574455: Current learning rate: 0.0094\n",
            "2025-12-23 08:39:29.071391: train_loss -0.9649\n",
            "2025-12-23 08:39:29.071690: val_loss -0.9758\n",
            "2025-12-23 08:39:29.071843: Pseudo dice [np.float32(0.9804)]\n",
            "2025-12-23 08:39:29.072007: Epoch time: 22.5 s\n",
            "2025-12-23 08:39:29.072135: Yayy! New best EMA pseudo Dice: 0.9789999723434448\n",
            "2025-12-23 08:39:30.965293: \n",
            "2025-12-23 08:39:30.965477: Epoch 67\n",
            "2025-12-23 08:39:30.965635: Current learning rate: 0.00939\n",
            "2025-12-23 08:39:53.417895: train_loss -0.9646\n",
            "2025-12-23 08:39:53.418136: val_loss -0.9786\n",
            "2025-12-23 08:39:53.418264: Pseudo dice [np.float32(0.9838)]\n",
            "2025-12-23 08:39:53.418436: Epoch time: 22.45 s\n",
            "2025-12-23 08:39:53.418540: Yayy! New best EMA pseudo Dice: 0.9794999957084656\n",
            "2025-12-23 08:39:55.283508: \n",
            "2025-12-23 08:39:55.283740: Epoch 68\n",
            "2025-12-23 08:39:55.283874: Current learning rate: 0.00939\n",
            "2025-12-23 08:40:17.725783: train_loss -0.966\n",
            "2025-12-23 08:40:17.726302: val_loss -0.9792\n",
            "2025-12-23 08:40:17.726454: Pseudo dice [np.float32(0.9838)]\n",
            "2025-12-23 08:40:17.726606: Epoch time: 22.44 s\n",
            "2025-12-23 08:40:17.726746: Yayy! New best EMA pseudo Dice: 0.9799000024795532\n",
            "2025-12-23 08:40:19.627113: \n",
            "2025-12-23 08:40:19.627322: Epoch 69\n",
            "2025-12-23 08:40:19.627495: Current learning rate: 0.00938\n",
            "2025-12-23 08:40:42.131793: train_loss -0.966\n",
            "2025-12-23 08:40:42.132293: val_loss -0.9773\n",
            "2025-12-23 08:40:42.132524: Pseudo dice [np.float32(0.981)]\n",
            "2025-12-23 08:40:42.132762: Epoch time: 22.51 s\n",
            "2025-12-23 08:40:42.132919: Yayy! New best EMA pseudo Dice: 0.9800000190734863\n",
            "2025-12-23 08:40:44.469503: \n",
            "2025-12-23 08:40:44.469688: Epoch 70\n",
            "2025-12-23 08:40:44.469861: Current learning rate: 0.00937\n",
            "2025-12-23 08:41:06.968059: train_loss -0.9659\n",
            "2025-12-23 08:41:06.968296: val_loss -0.9789\n",
            "2025-12-23 08:41:06.968407: Pseudo dice [np.float32(0.9839)]\n",
            "2025-12-23 08:41:06.968503: Epoch time: 22.5 s\n",
            "2025-12-23 08:41:06.968580: Yayy! New best EMA pseudo Dice: 0.980400025844574\n",
            "2025-12-23 08:41:08.869300: \n",
            "2025-12-23 08:41:08.869647: Epoch 71\n",
            "2025-12-23 08:41:08.869794: Current learning rate: 0.00936\n",
            "2025-12-23 08:41:31.373574: train_loss -0.9668\n",
            "2025-12-23 08:41:31.373785: val_loss -0.9783\n",
            "2025-12-23 08:41:31.373878: Pseudo dice [np.float32(0.9827)]\n",
            "2025-12-23 08:41:31.373969: Epoch time: 22.51 s\n",
            "2025-12-23 08:41:31.374044: Yayy! New best EMA pseudo Dice: 0.9805999994277954\n",
            "2025-12-23 08:41:33.230951: \n",
            "2025-12-23 08:41:33.231273: Epoch 72\n",
            "2025-12-23 08:41:33.231406: Current learning rate: 0.00935\n",
            "2025-12-23 08:41:55.707288: train_loss -0.9662\n",
            "2025-12-23 08:41:55.707515: val_loss -0.9792\n",
            "2025-12-23 08:41:55.707724: Pseudo dice [np.float32(0.9846)]\n",
            "2025-12-23 08:41:55.707983: Epoch time: 22.48 s\n",
            "2025-12-23 08:41:55.708236: Yayy! New best EMA pseudo Dice: 0.9810000061988831\n",
            "2025-12-23 08:41:57.561818: \n",
            "2025-12-23 08:41:57.562100: Epoch 73\n",
            "2025-12-23 08:41:57.562272: Current learning rate: 0.00934\n",
            "2025-12-23 08:42:20.074593: train_loss -0.966\n",
            "2025-12-23 08:42:20.074814: val_loss -0.9791\n",
            "2025-12-23 08:42:20.074904: Pseudo dice [np.float32(0.9841)]\n",
            "2025-12-23 08:42:20.074995: Epoch time: 22.51 s\n",
            "2025-12-23 08:42:20.075119: Yayy! New best EMA pseudo Dice: 0.9812999963760376\n",
            "2025-12-23 08:42:21.956563: \n",
            "2025-12-23 08:42:21.956736: Epoch 74\n",
            "2025-12-23 08:42:21.956866: Current learning rate: 0.00933\n",
            "2025-12-23 08:42:44.467160: train_loss -0.9666\n",
            "2025-12-23 08:42:44.467608: val_loss -0.9781\n",
            "2025-12-23 08:42:44.467729: Pseudo dice [np.float32(0.9832)]\n",
            "2025-12-23 08:42:44.467829: Epoch time: 22.51 s\n",
            "2025-12-23 08:42:44.467899: Yayy! New best EMA pseudo Dice: 0.9815000295639038\n",
            "2025-12-23 08:42:46.370512: \n",
            "2025-12-23 08:42:46.370806: Epoch 75\n",
            "2025-12-23 08:42:46.370992: Current learning rate: 0.00932\n",
            "2025-12-23 08:43:08.883079: train_loss -0.9678\n",
            "2025-12-23 08:43:08.883462: val_loss -0.9773\n",
            "2025-12-23 08:43:08.883698: Pseudo dice [np.float32(0.9818)]\n",
            "2025-12-23 08:43:08.883866: Epoch time: 22.51 s\n",
            "2025-12-23 08:43:08.884079: Yayy! New best EMA pseudo Dice: 0.9815999865531921\n",
            "2025-12-23 08:43:10.738545: \n",
            "2025-12-23 08:43:10.738816: Epoch 76\n",
            "2025-12-23 08:43:10.738956: Current learning rate: 0.00931\n",
            "2025-12-23 08:43:33.229756: train_loss -0.9684\n",
            "2025-12-23 08:43:33.229957: val_loss -0.9783\n",
            "2025-12-23 08:43:33.230044: Pseudo dice [np.float32(0.9834)]\n",
            "2025-12-23 08:43:33.230133: Epoch time: 22.49 s\n",
            "2025-12-23 08:43:33.230206: Yayy! New best EMA pseudo Dice: 0.9817000031471252\n",
            "2025-12-23 08:43:35.114292: \n",
            "2025-12-23 08:43:35.114571: Epoch 77\n",
            "2025-12-23 08:43:35.114709: Current learning rate: 0.0093\n",
            "2025-12-23 08:43:57.611475: train_loss -0.9665\n",
            "2025-12-23 08:43:57.611684: val_loss -0.9781\n",
            "2025-12-23 08:43:57.611777: Pseudo dice [np.float32(0.9838)]\n",
            "2025-12-23 08:43:57.611866: Epoch time: 22.5 s\n",
            "2025-12-23 08:43:57.611941: Yayy! New best EMA pseudo Dice: 0.9818999767303467\n",
            "2025-12-23 08:43:59.516521: \n",
            "2025-12-23 08:43:59.516826: Epoch 78\n",
            "2025-12-23 08:43:59.516963: Current learning rate: 0.0093\n",
            "2025-12-23 08:44:21.976180: train_loss -0.9675\n",
            "2025-12-23 08:44:21.976477: val_loss -0.9793\n",
            "2025-12-23 08:44:21.976577: Pseudo dice [np.float32(0.985)]\n",
            "2025-12-23 08:44:21.976675: Epoch time: 22.46 s\n",
            "2025-12-23 08:44:21.976752: Yayy! New best EMA pseudo Dice: 0.982200026512146\n",
            "2025-12-23 08:44:23.884549: \n",
            "2025-12-23 08:44:23.884830: Epoch 79\n",
            "2025-12-23 08:44:23.884963: Current learning rate: 0.00929\n",
            "2025-12-23 08:44:46.408084: train_loss -0.9689\n",
            "2025-12-23 08:44:46.408315: val_loss -0.9778\n",
            "2025-12-23 08:44:46.408442: Pseudo dice [np.float32(0.9827)]\n",
            "2025-12-23 08:44:46.408564: Epoch time: 22.52 s\n",
            "2025-12-23 08:44:46.408766: Yayy! New best EMA pseudo Dice: 0.9822999835014343\n",
            "2025-12-23 08:44:48.308788: \n",
            "2025-12-23 08:44:48.308970: Epoch 80\n",
            "2025-12-23 08:44:48.309101: Current learning rate: 0.00928\n",
            "2025-12-23 08:45:10.817873: train_loss -0.9683\n",
            "2025-12-23 08:45:10.818127: val_loss -0.9781\n",
            "2025-12-23 08:45:10.818241: Pseudo dice [np.float32(0.9838)]\n",
            "2025-12-23 08:45:10.818385: Epoch time: 22.51 s\n",
            "2025-12-23 08:45:10.818487: Yayy! New best EMA pseudo Dice: 0.9824000000953674\n",
            "2025-12-23 08:45:12.721334: \n",
            "2025-12-23 08:45:12.721568: Epoch 81\n",
            "2025-12-23 08:45:12.721724: Current learning rate: 0.00927\n",
            "2025-12-23 08:45:35.241963: train_loss -0.9672\n",
            "2025-12-23 08:45:35.242168: val_loss -0.9777\n",
            "2025-12-23 08:45:35.242292: Pseudo dice [np.float32(0.9834)]\n",
            "2025-12-23 08:45:35.242395: Epoch time: 22.52 s\n",
            "2025-12-23 08:45:35.242482: Yayy! New best EMA pseudo Dice: 0.9825000166893005\n",
            "2025-12-23 08:45:37.582393: \n",
            "2025-12-23 08:45:37.582625: Epoch 82\n",
            "2025-12-23 08:45:37.582769: Current learning rate: 0.00926\n",
            "2025-12-23 08:46:00.085033: train_loss -0.9674\n",
            "2025-12-23 08:46:00.085249: val_loss -0.9792\n",
            "2025-12-23 08:46:00.085369: Pseudo dice [np.float32(0.984)]\n",
            "2025-12-23 08:46:00.085464: Epoch time: 22.5 s\n",
            "2025-12-23 08:46:00.085563: Yayy! New best EMA pseudo Dice: 0.982699990272522\n",
            "2025-12-23 08:46:01.903975: \n",
            "2025-12-23 08:46:01.904374: Epoch 83\n",
            "2025-12-23 08:46:01.904524: Current learning rate: 0.00925\n",
            "2025-12-23 08:46:24.433122: train_loss -0.9674\n",
            "2025-12-23 08:46:24.433369: val_loss -0.9795\n",
            "2025-12-23 08:46:24.433466: Pseudo dice [np.float32(0.985)]\n",
            "2025-12-23 08:46:24.433557: Epoch time: 22.53 s\n",
            "2025-12-23 08:46:24.433635: Yayy! New best EMA pseudo Dice: 0.9829000234603882\n",
            "2025-12-23 08:46:26.236827: \n",
            "2025-12-23 08:46:26.237044: Epoch 84\n",
            "2025-12-23 08:46:26.237250: Current learning rate: 0.00924\n",
            "2025-12-23 08:46:48.729305: train_loss -0.9667\n",
            "2025-12-23 08:46:48.729512: val_loss -0.9774\n",
            "2025-12-23 08:46:48.729686: Pseudo dice [np.float32(0.9826)]\n",
            "2025-12-23 08:46:48.729819: Epoch time: 22.49 s\n",
            "2025-12-23 08:46:50.078330: \n",
            "2025-12-23 08:46:50.078571: Epoch 85\n",
            "2025-12-23 08:46:50.078712: Current learning rate: 0.00923\n",
            "2025-12-23 08:47:12.558532: train_loss -0.9649\n",
            "2025-12-23 08:47:12.558737: val_loss -0.9788\n",
            "2025-12-23 08:47:12.558827: Pseudo dice [np.float32(0.9838)]\n",
            "2025-12-23 08:47:12.558916: Epoch time: 22.48 s\n",
            "2025-12-23 08:47:12.558991: Yayy! New best EMA pseudo Dice: 0.9829999804496765\n",
            "2025-12-23 08:47:14.402963: \n",
            "2025-12-23 08:47:14.403275: Epoch 86\n",
            "2025-12-23 08:47:14.403420: Current learning rate: 0.00922\n",
            "2025-12-23 08:47:36.912693: train_loss -0.9659\n",
            "2025-12-23 08:47:36.912902: val_loss -0.9758\n",
            "2025-12-23 08:47:36.912996: Pseudo dice [np.float32(0.9801)]\n",
            "2025-12-23 08:47:36.913085: Epoch time: 22.51 s\n",
            "2025-12-23 08:47:38.240456: \n",
            "2025-12-23 08:47:38.240758: Epoch 87\n",
            "2025-12-23 08:47:38.240895: Current learning rate: 0.00921\n",
            "2025-12-23 08:48:00.733588: train_loss -0.9669\n",
            "2025-12-23 08:48:00.734118: val_loss -0.9796\n",
            "2025-12-23 08:48:00.734339: Pseudo dice [np.float32(0.9839)]\n",
            "2025-12-23 08:48:00.734569: Epoch time: 22.49 s\n",
            "2025-12-23 08:48:02.081277: \n",
            "2025-12-23 08:48:02.081473: Epoch 88\n",
            "2025-12-23 08:48:02.081601: Current learning rate: 0.0092\n",
            "2025-12-23 08:48:24.520753: train_loss -0.9679\n",
            "2025-12-23 08:48:24.521003: val_loss -0.98\n",
            "2025-12-23 08:48:24.521100: Pseudo dice [np.float32(0.9854)]\n",
            "2025-12-23 08:48:24.521189: Epoch time: 22.44 s\n",
            "2025-12-23 08:48:24.521312: Yayy! New best EMA pseudo Dice: 0.9830999970436096\n",
            "2025-12-23 08:48:26.382519: \n",
            "2025-12-23 08:48:26.382803: Epoch 89\n",
            "2025-12-23 08:48:26.382939: Current learning rate: 0.0092\n",
            "2025-12-23 08:48:48.881952: train_loss -0.9664\n",
            "2025-12-23 08:48:48.882175: val_loss -0.9782\n",
            "2025-12-23 08:48:48.882280: Pseudo dice [np.float32(0.9835)]\n",
            "2025-12-23 08:48:48.882372: Epoch time: 22.5 s\n",
            "2025-12-23 08:48:48.882447: Yayy! New best EMA pseudo Dice: 0.9830999970436096\n",
            "2025-12-23 08:48:50.767492: \n",
            "2025-12-23 08:48:50.767740: Epoch 90\n",
            "2025-12-23 08:48:50.767895: Current learning rate: 0.00919\n",
            "2025-12-23 08:49:13.278265: train_loss -0.9642\n",
            "2025-12-23 08:49:13.278591: val_loss -0.9761\n",
            "2025-12-23 08:49:13.278739: Pseudo dice [np.float32(0.9813)]\n",
            "2025-12-23 08:49:13.278886: Epoch time: 22.51 s\n",
            "2025-12-23 08:49:14.630729: \n",
            "2025-12-23 08:49:14.630902: Epoch 91\n",
            "2025-12-23 08:49:14.631031: Current learning rate: 0.00918\n",
            "2025-12-23 08:49:37.132281: train_loss -0.9595\n",
            "2025-12-23 08:49:37.132494: val_loss -0.9736\n",
            "2025-12-23 08:49:37.132592: Pseudo dice [np.float32(0.9798)]\n",
            "2025-12-23 08:49:37.132686: Epoch time: 22.5 s\n",
            "2025-12-23 08:49:38.484184: \n",
            "2025-12-23 08:49:38.484409: Epoch 92\n",
            "2025-12-23 08:49:38.484566: Current learning rate: 0.00917\n",
            "2025-12-23 08:50:00.953415: train_loss -0.9628\n",
            "2025-12-23 08:50:00.953868: val_loss -0.9753\n",
            "2025-12-23 08:50:00.954030: Pseudo dice [np.float32(0.9806)]\n",
            "2025-12-23 08:50:00.954193: Epoch time: 22.47 s\n",
            "2025-12-23 08:50:02.266034: \n",
            "2025-12-23 08:50:02.266329: Epoch 93\n",
            "2025-12-23 08:50:02.266463: Current learning rate: 0.00916\n",
            "2025-12-23 08:50:24.713304: train_loss -0.9618\n",
            "2025-12-23 08:50:24.713733: val_loss -0.9731\n",
            "2025-12-23 08:50:24.713930: Pseudo dice [np.float32(0.9797)]\n",
            "2025-12-23 08:50:24.714096: Epoch time: 22.45 s\n",
            "2025-12-23 08:50:26.044482: \n",
            "2025-12-23 08:50:26.044722: Epoch 94\n",
            "2025-12-23 08:50:26.044873: Current learning rate: 0.00915\n",
            "2025-12-23 08:50:48.455752: train_loss -0.9621\n",
            "2025-12-23 08:50:48.456084: val_loss -0.9761\n",
            "2025-12-23 08:50:48.456291: Pseudo dice [np.float32(0.9823)]\n",
            "2025-12-23 08:50:48.456405: Epoch time: 22.41 s\n",
            "2025-12-23 08:50:49.776601: \n",
            "2025-12-23 08:50:49.776778: Epoch 95\n",
            "2025-12-23 08:50:49.776989: Current learning rate: 0.00914\n",
            "2025-12-23 08:51:12.197290: train_loss -0.959\n",
            "2025-12-23 08:51:12.197504: val_loss -0.975\n",
            "2025-12-23 08:51:12.197595: Pseudo dice [np.float32(0.9803)]\n",
            "2025-12-23 08:51:12.197688: Epoch time: 22.42 s\n",
            "2025-12-23 08:51:13.483257: \n",
            "2025-12-23 08:51:13.483561: Epoch 96\n",
            "2025-12-23 08:51:13.483694: Current learning rate: 0.00913\n",
            "2025-12-23 08:51:35.901221: train_loss -0.9628\n",
            "2025-12-23 08:51:35.901482: val_loss -0.9752\n",
            "2025-12-23 08:51:35.901767: Pseudo dice [np.float32(0.9813)]\n",
            "2025-12-23 08:51:35.901877: Epoch time: 22.42 s\n",
            "2025-12-23 08:51:37.717063: \n",
            "2025-12-23 08:51:37.717426: Epoch 97\n",
            "2025-12-23 08:51:37.717587: Current learning rate: 0.00912\n",
            "2025-12-23 08:52:00.207894: train_loss -0.9607\n",
            "2025-12-23 08:52:00.208134: val_loss -0.9788\n",
            "2025-12-23 08:52:00.208288: Pseudo dice [np.float32(0.9832)]\n",
            "2025-12-23 08:52:00.208388: Epoch time: 22.49 s\n",
            "2025-12-23 08:52:01.529976: \n",
            "2025-12-23 08:52:01.530177: Epoch 98\n",
            "2025-12-23 08:52:01.530382: Current learning rate: 0.00911\n",
            "2025-12-23 08:52:24.040009: train_loss -0.9652\n",
            "2025-12-23 08:52:24.040210: val_loss -0.9773\n",
            "2025-12-23 08:52:24.040325: Pseudo dice [np.float32(0.9835)]\n",
            "2025-12-23 08:52:24.040417: Epoch time: 22.51 s\n",
            "2025-12-23 08:52:25.365655: \n",
            "2025-12-23 08:52:25.366011: Epoch 99\n",
            "2025-12-23 08:52:25.366143: Current learning rate: 0.0091\n",
            "2025-12-23 08:52:47.881853: train_loss -0.9657\n",
            "2025-12-23 08:52:47.882080: val_loss -0.9762\n",
            "2025-12-23 08:52:47.882168: Pseudo dice [np.float32(0.9829)]\n",
            "2025-12-23 08:52:47.882276: Epoch time: 22.52 s\n",
            "2025-12-23 08:52:49.739367: \n",
            "2025-12-23 08:52:49.739659: Epoch 100\n",
            "2025-12-23 08:52:49.739816: Current learning rate: 0.0091\n",
            "2025-12-23 08:53:12.240623: train_loss -0.9616\n",
            "2025-12-23 08:53:12.240829: val_loss -0.9723\n",
            "2025-12-23 08:53:12.240919: Pseudo dice [np.float32(0.9794)]\n",
            "2025-12-23 08:53:12.241011: Epoch time: 22.5 s\n",
            "2025-12-23 08:53:13.544992: \n",
            "2025-12-23 08:53:13.545166: Epoch 101\n",
            "2025-12-23 08:53:13.545315: Current learning rate: 0.00909\n",
            "2025-12-23 08:53:36.051790: train_loss -0.9566\n",
            "2025-12-23 08:53:36.052047: val_loss -0.9734\n",
            "2025-12-23 08:53:36.052137: Pseudo dice [np.float32(0.9789)]\n",
            "2025-12-23 08:53:36.052284: Epoch time: 22.51 s\n",
            "2025-12-23 08:53:37.382563: \n",
            "2025-12-23 08:53:37.382884: Epoch 102\n",
            "2025-12-23 08:53:37.383034: Current learning rate: 0.00908\n",
            "2025-12-23 08:53:59.855557: train_loss -0.9624\n",
            "2025-12-23 08:53:59.855879: val_loss -0.9763\n",
            "2025-12-23 08:53:59.855977: Pseudo dice [np.float32(0.9828)]\n",
            "2025-12-23 08:53:59.856067: Epoch time: 22.47 s\n",
            "2025-12-23 08:54:01.192520: \n",
            "2025-12-23 08:54:01.192783: Epoch 103\n",
            "2025-12-23 08:54:01.192924: Current learning rate: 0.00907\n",
            "2025-12-23 08:54:23.681430: train_loss -0.9618\n",
            "2025-12-23 08:54:23.681710: val_loss -0.9682\n",
            "2025-12-23 08:54:23.681813: Pseudo dice [np.float32(0.9758)]\n",
            "2025-12-23 08:54:23.681907: Epoch time: 22.49 s\n",
            "2025-12-23 08:54:24.983391: \n",
            "2025-12-23 08:54:24.983574: Epoch 104\n",
            "2025-12-23 08:54:24.983703: Current learning rate: 0.00906\n",
            "2025-12-23 08:54:47.467789: train_loss -0.9439\n",
            "2025-12-23 08:54:47.468078: val_loss -0.9675\n",
            "2025-12-23 08:54:47.468175: Pseudo dice [np.float32(0.9771)]\n",
            "2025-12-23 08:54:47.468306: Epoch time: 22.49 s\n",
            "2025-12-23 08:54:48.807673: \n",
            "2025-12-23 08:54:48.808002: Epoch 105\n",
            "2025-12-23 08:54:48.808134: Current learning rate: 0.00905\n",
            "2025-12-23 08:55:11.289687: train_loss -0.9452\n",
            "2025-12-23 08:55:11.289911: val_loss -0.9633\n",
            "2025-12-23 08:55:11.289998: Pseudo dice [np.float32(0.9685)]\n",
            "2025-12-23 08:55:11.290085: Epoch time: 22.48 s\n",
            "2025-12-23 08:55:12.621556: \n",
            "2025-12-23 08:55:12.621746: Epoch 106\n",
            "2025-12-23 08:55:12.622005: Current learning rate: 0.00904\n",
            "2025-12-23 08:55:35.127482: train_loss -0.9525\n",
            "2025-12-23 08:55:35.127851: val_loss -0.9759\n",
            "2025-12-23 08:55:35.128067: Pseudo dice [np.float32(0.9824)]\n",
            "2025-12-23 08:55:35.128190: Epoch time: 22.51 s\n",
            "2025-12-23 08:55:36.445976: \n",
            "2025-12-23 08:55:36.446260: Epoch 107\n",
            "2025-12-23 08:55:36.446400: Current learning rate: 0.00903\n",
            "2025-12-23 08:55:58.924456: train_loss -0.9627\n",
            "2025-12-23 08:55:58.924661: val_loss -0.9748\n",
            "2025-12-23 08:55:58.924757: Pseudo dice [np.float32(0.9816)]\n",
            "2025-12-23 08:55:58.924850: Epoch time: 22.48 s\n",
            "2025-12-23 08:56:00.271092: \n",
            "2025-12-23 08:56:00.271348: Epoch 108\n",
            "2025-12-23 08:56:00.271492: Current learning rate: 0.00902\n",
            "2025-12-23 08:56:22.761966: train_loss -0.9642\n",
            "2025-12-23 08:56:22.762282: val_loss -0.9769\n",
            "2025-12-23 08:56:22.762394: Pseudo dice [np.float32(0.9834)]\n",
            "2025-12-23 08:56:22.762488: Epoch time: 22.49 s\n",
            "2025-12-23 08:56:24.096040: \n",
            "2025-12-23 08:56:24.096405: Epoch 109\n",
            "2025-12-23 08:56:24.096554: Current learning rate: 0.00901\n",
            "2025-12-23 08:56:46.575512: train_loss -0.9527\n",
            "2025-12-23 08:56:46.575859: val_loss -0.9715\n",
            "2025-12-23 08:56:46.575954: Pseudo dice [np.float32(0.9816)]\n",
            "2025-12-23 08:56:46.576052: Epoch time: 22.48 s\n",
            "2025-12-23 08:56:47.920955: \n",
            "2025-12-23 08:56:47.921132: Epoch 110\n",
            "2025-12-23 08:56:47.921284: Current learning rate: 0.009\n",
            "2025-12-23 08:57:10.389562: train_loss -0.9569\n",
            "2025-12-23 08:57:10.389794: val_loss -0.9729\n",
            "2025-12-23 08:57:10.389927: Pseudo dice [np.float32(0.9799)]\n",
            "2025-12-23 08:57:10.390048: Epoch time: 22.47 s\n",
            "2025-12-23 08:57:12.239077: \n",
            "2025-12-23 08:57:12.239393: Epoch 111\n",
            "2025-12-23 08:57:12.239542: Current learning rate: 0.009\n",
            "2025-12-23 08:57:34.765986: train_loss -0.9615\n",
            "2025-12-23 08:57:34.766257: val_loss -0.9772\n",
            "2025-12-23 08:57:34.766379: Pseudo dice [np.float32(0.9816)]\n",
            "2025-12-23 08:57:34.766481: Epoch time: 22.53 s\n",
            "2025-12-23 08:57:36.112554: \n",
            "2025-12-23 08:57:36.112965: Epoch 112\n",
            "2025-12-23 08:57:36.113133: Current learning rate: 0.00899\n",
            "2025-12-23 08:57:58.614814: train_loss -0.966\n",
            "2025-12-23 08:57:58.615072: val_loss -0.978\n",
            "2025-12-23 08:57:58.615177: Pseudo dice [np.float32(0.9833)]\n",
            "2025-12-23 08:57:58.615306: Epoch time: 22.5 s\n",
            "2025-12-23 08:57:59.953714: \n",
            "2025-12-23 08:57:59.954069: Epoch 113\n",
            "2025-12-23 08:57:59.954230: Current learning rate: 0.00898\n",
            "2025-12-23 08:58:22.411997: train_loss -0.9662\n",
            "2025-12-23 08:58:22.412302: val_loss -0.9768\n",
            "2025-12-23 08:58:22.412426: Pseudo dice [np.float32(0.9817)]\n",
            "2025-12-23 08:58:22.412594: Epoch time: 22.46 s\n",
            "2025-12-23 08:58:23.753565: \n",
            "2025-12-23 08:58:23.753904: Epoch 114\n",
            "2025-12-23 08:58:23.754042: Current learning rate: 0.00897\n",
            "2025-12-23 08:58:46.335159: train_loss -0.9655\n",
            "2025-12-23 08:58:46.335453: val_loss -0.9761\n",
            "2025-12-23 08:58:46.335562: Pseudo dice [np.float32(0.9827)]\n",
            "2025-12-23 08:58:46.335656: Epoch time: 22.58 s\n",
            "2025-12-23 08:58:47.674085: \n",
            "2025-12-23 08:58:47.674290: Epoch 115\n",
            "2025-12-23 08:58:47.674420: Current learning rate: 0.00896\n",
            "2025-12-23 08:59:10.183048: train_loss -0.9659\n",
            "2025-12-23 08:59:10.183281: val_loss -0.9769\n",
            "2025-12-23 08:59:10.183392: Pseudo dice [np.float32(0.9824)]\n",
            "2025-12-23 08:59:10.183487: Epoch time: 22.51 s\n",
            "2025-12-23 08:59:11.509445: \n",
            "2025-12-23 08:59:11.509643: Epoch 116\n",
            "2025-12-23 08:59:11.509778: Current learning rate: 0.00895\n",
            "2025-12-23 08:59:33.952349: train_loss -0.9655\n",
            "2025-12-23 08:59:33.952652: val_loss -0.9759\n",
            "2025-12-23 08:59:33.952773: Pseudo dice [np.float32(0.9813)]\n",
            "2025-12-23 08:59:33.952902: Epoch time: 22.44 s\n",
            "2025-12-23 08:59:35.300380: \n",
            "2025-12-23 08:59:35.300770: Epoch 117\n",
            "2025-12-23 08:59:35.300941: Current learning rate: 0.00894\n",
            "2025-12-23 08:59:57.786300: train_loss -0.9658\n",
            "2025-12-23 08:59:57.786569: val_loss -0.9802\n",
            "2025-12-23 08:59:57.786664: Pseudo dice [np.float32(0.9854)]\n",
            "2025-12-23 08:59:57.786758: Epoch time: 22.49 s\n",
            "2025-12-23 08:59:59.161126: \n",
            "2025-12-23 08:59:59.161445: Epoch 118\n",
            "2025-12-23 08:59:59.161593: Current learning rate: 0.00893\n",
            "2025-12-23 09:00:21.634498: train_loss -0.9665\n",
            "2025-12-23 09:00:21.634750: val_loss -0.9775\n",
            "2025-12-23 09:00:21.634860: Pseudo dice [np.float32(0.9832)]\n",
            "2025-12-23 09:00:21.634961: Epoch time: 22.47 s\n",
            "2025-12-23 09:00:22.991284: \n",
            "2025-12-23 09:00:22.991688: Epoch 119\n",
            "2025-12-23 09:00:22.991849: Current learning rate: 0.00892\n",
            "2025-12-23 09:00:45.422532: train_loss -0.9677\n",
            "2025-12-23 09:00:45.422748: val_loss -0.9791\n",
            "2025-12-23 09:00:45.422838: Pseudo dice [np.float32(0.9847)]\n",
            "2025-12-23 09:00:45.422930: Epoch time: 22.43 s\n",
            "2025-12-23 09:00:46.792332: \n",
            "2025-12-23 09:00:46.792578: Epoch 120\n",
            "2025-12-23 09:00:46.792757: Current learning rate: 0.00891\n",
            "2025-12-23 09:01:09.267284: train_loss -0.9673\n",
            "2025-12-23 09:01:09.267631: val_loss -0.9808\n",
            "2025-12-23 09:01:09.267735: Pseudo dice [np.float32(0.9845)]\n",
            "2025-12-23 09:01:09.267844: Epoch time: 22.48 s\n",
            "2025-12-23 09:01:10.611147: \n",
            "2025-12-23 09:01:10.611608: Epoch 121\n",
            "2025-12-23 09:01:10.611755: Current learning rate: 0.0089\n",
            "2025-12-23 09:01:33.092525: train_loss -0.9674\n",
            "2025-12-23 09:01:33.092745: val_loss -0.9806\n",
            "2025-12-23 09:01:33.092863: Pseudo dice [np.float32(0.9849)]\n",
            "2025-12-23 09:01:33.092982: Epoch time: 22.48 s\n",
            "2025-12-23 09:01:34.474764: \n",
            "2025-12-23 09:01:34.475124: Epoch 122\n",
            "2025-12-23 09:01:34.475282: Current learning rate: 0.00889\n",
            "2025-12-23 09:01:56.966973: train_loss -0.9681\n",
            "2025-12-23 09:01:56.967262: val_loss -0.9795\n",
            "2025-12-23 09:01:56.967477: Pseudo dice [np.float32(0.9839)]\n",
            "2025-12-23 09:01:56.967603: Epoch time: 22.49 s\n",
            "2025-12-23 09:01:58.326083: \n",
            "2025-12-23 09:01:58.326401: Epoch 123\n",
            "2025-12-23 09:01:58.326601: Current learning rate: 0.00889\n",
            "2025-12-23 09:02:20.775915: train_loss -0.9688\n",
            "2025-12-23 09:02:20.776180: val_loss -0.9789\n",
            "2025-12-23 09:02:20.776312: Pseudo dice [np.float32(0.9845)]\n",
            "2025-12-23 09:02:20.776528: Epoch time: 22.45 s\n",
            "2025-12-23 09:02:22.119500: \n",
            "2025-12-23 09:02:22.119735: Epoch 124\n",
            "2025-12-23 09:02:22.119933: Current learning rate: 0.00888\n",
            "2025-12-23 09:02:44.623620: train_loss -0.9679\n",
            "2025-12-23 09:02:44.623838: val_loss -0.9794\n",
            "2025-12-23 09:02:44.623927: Pseudo dice [np.float32(0.9835)]\n",
            "2025-12-23 09:02:44.624026: Epoch time: 22.51 s\n",
            "2025-12-23 09:02:46.435900: \n",
            "2025-12-23 09:02:46.436159: Epoch 125\n",
            "2025-12-23 09:02:46.436373: Current learning rate: 0.00887\n",
            "2025-12-23 09:03:08.906162: train_loss -0.9689\n",
            "2025-12-23 09:03:08.906401: val_loss -0.9784\n",
            "2025-12-23 09:03:08.906506: Pseudo dice [np.float32(0.984)]\n",
            "2025-12-23 09:03:08.906600: Epoch time: 22.47 s\n",
            "2025-12-23 09:03:10.275517: \n",
            "2025-12-23 09:03:10.275814: Epoch 126\n",
            "2025-12-23 09:03:10.275950: Current learning rate: 0.00886\n",
            "2025-12-23 09:03:32.793619: train_loss -0.9689\n",
            "2025-12-23 09:03:32.793854: val_loss -0.9798\n",
            "2025-12-23 09:03:32.793962: Pseudo dice [np.float32(0.9851)]\n",
            "2025-12-23 09:03:32.794055: Epoch time: 22.52 s\n",
            "2025-12-23 09:03:32.794130: Yayy! New best EMA pseudo Dice: 0.983299970626831\n",
            "2025-12-23 09:03:34.651065: \n",
            "2025-12-23 09:03:34.651334: Epoch 127\n",
            "2025-12-23 09:03:34.651479: Current learning rate: 0.00885\n",
            "2025-12-23 09:03:57.138763: train_loss -0.9682\n",
            "2025-12-23 09:03:57.139276: val_loss -0.9777\n",
            "2025-12-23 09:03:57.139511: Pseudo dice [np.float32(0.9825)]\n",
            "2025-12-23 09:03:57.139610: Epoch time: 22.49 s\n",
            "2025-12-23 09:03:58.472342: \n",
            "2025-12-23 09:03:58.472635: Epoch 128\n",
            "2025-12-23 09:03:58.472773: Current learning rate: 0.00884\n",
            "2025-12-23 09:04:20.924091: train_loss -0.967\n",
            "2025-12-23 09:04:20.924314: val_loss -0.9807\n",
            "2025-12-23 09:04:20.924417: Pseudo dice [np.float32(0.9853)]\n",
            "2025-12-23 09:04:20.924520: Epoch time: 22.45 s\n",
            "2025-12-23 09:04:20.924597: Yayy! New best EMA pseudo Dice: 0.9833999872207642\n",
            "2025-12-23 09:04:22.801444: \n",
            "2025-12-23 09:04:22.801728: Epoch 129\n",
            "2025-12-23 09:04:22.801868: Current learning rate: 0.00883\n",
            "2025-12-23 09:04:45.336990: train_loss -0.9675\n",
            "2025-12-23 09:04:45.337404: val_loss -0.9807\n",
            "2025-12-23 09:04:45.337500: Pseudo dice [np.float32(0.9857)]\n",
            "2025-12-23 09:04:45.337608: Epoch time: 22.54 s\n",
            "2025-12-23 09:04:45.337713: Yayy! New best EMA pseudo Dice: 0.9836000204086304\n",
            "2025-12-23 09:04:47.210045: \n",
            "2025-12-23 09:04:47.210436: Epoch 130\n",
            "2025-12-23 09:04:47.210582: Current learning rate: 0.00882\n",
            "2025-12-23 09:05:09.664543: train_loss -0.9661\n",
            "2025-12-23 09:05:09.664780: val_loss -0.9772\n",
            "2025-12-23 09:05:09.664879: Pseudo dice [np.float32(0.9829)]\n",
            "2025-12-23 09:05:09.664969: Epoch time: 22.46 s\n",
            "2025-12-23 09:05:11.009974: \n",
            "2025-12-23 09:05:11.010334: Epoch 131\n",
            "2025-12-23 09:05:11.010499: Current learning rate: 0.00881\n",
            "2025-12-23 09:05:33.499780: train_loss -0.9643\n",
            "2025-12-23 09:05:33.500149: val_loss -0.974\n",
            "2025-12-23 09:05:33.500309: Pseudo dice [np.float32(0.9798)]\n",
            "2025-12-23 09:05:33.500420: Epoch time: 22.49 s\n",
            "2025-12-23 09:05:34.838903: \n",
            "2025-12-23 09:05:34.839098: Epoch 132\n",
            "2025-12-23 09:05:34.839246: Current learning rate: 0.0088\n",
            "2025-12-23 09:05:57.271855: train_loss -0.9657\n",
            "2025-12-23 09:05:57.272069: val_loss -0.978\n",
            "2025-12-23 09:05:57.272157: Pseudo dice [np.float32(0.984)]\n",
            "2025-12-23 09:05:57.272274: Epoch time: 22.43 s\n",
            "2025-12-23 09:05:58.609663: \n",
            "2025-12-23 09:05:58.609927: Epoch 133\n",
            "2025-12-23 09:05:58.610060: Current learning rate: 0.00879\n",
            "2025-12-23 09:06:21.122653: train_loss -0.966\n",
            "2025-12-23 09:06:21.122872: val_loss -0.98\n",
            "2025-12-23 09:06:21.122988: Pseudo dice [np.float32(0.9853)]\n",
            "2025-12-23 09:06:21.123083: Epoch time: 22.51 s\n",
            "2025-12-23 09:06:22.464186: \n",
            "2025-12-23 09:06:22.464498: Epoch 134\n",
            "2025-12-23 09:06:22.464640: Current learning rate: 0.00879\n",
            "2025-12-23 09:06:44.970860: train_loss -0.9677\n",
            "2025-12-23 09:06:44.971134: val_loss -0.9797\n",
            "2025-12-23 09:06:44.971266: Pseudo dice [np.float32(0.9842)]\n",
            "2025-12-23 09:06:44.971404: Epoch time: 22.51 s\n",
            "2025-12-23 09:06:46.338587: \n",
            "2025-12-23 09:06:46.338746: Epoch 135\n",
            "2025-12-23 09:06:46.338928: Current learning rate: 0.00878\n",
            "2025-12-23 09:07:08.873472: train_loss -0.9673\n",
            "2025-12-23 09:07:08.873665: val_loss -0.9808\n",
            "2025-12-23 09:07:08.873833: Pseudo dice [np.float32(0.9856)]\n",
            "2025-12-23 09:07:08.873928: Epoch time: 22.54 s\n",
            "2025-12-23 09:07:08.874003: Yayy! New best EMA pseudo Dice: 0.9837999939918518\n",
            "2025-12-23 09:07:10.781970: \n",
            "2025-12-23 09:07:10.782290: Epoch 136\n",
            "2025-12-23 09:07:10.782470: Current learning rate: 0.00877\n",
            "2025-12-23 09:07:33.286532: train_loss -0.9688\n",
            "2025-12-23 09:07:33.286914: val_loss -0.9798\n",
            "2025-12-23 09:07:33.287115: Pseudo dice [np.float32(0.9848)]\n",
            "2025-12-23 09:07:33.287322: Epoch time: 22.51 s\n",
            "2025-12-23 09:07:33.287474: Yayy! New best EMA pseudo Dice: 0.9839000105857849\n",
            "2025-12-23 09:07:35.184905: \n",
            "2025-12-23 09:07:35.185174: Epoch 137\n",
            "2025-12-23 09:07:35.185349: Current learning rate: 0.00876\n",
            "2025-12-23 09:07:57.698780: train_loss -0.9685\n",
            "2025-12-23 09:07:57.699044: val_loss -0.9778\n",
            "2025-12-23 09:07:57.699145: Pseudo dice [np.float32(0.9844)]\n",
            "2025-12-23 09:07:57.699267: Epoch time: 22.52 s\n",
            "2025-12-23 09:07:57.699390: Yayy! New best EMA pseudo Dice: 0.9839000105857849\n",
            "2025-12-23 09:07:59.604488: \n",
            "2025-12-23 09:07:59.604719: Epoch 138\n",
            "2025-12-23 09:07:59.604854: Current learning rate: 0.00875\n",
            "2025-12-23 09:08:22.129403: train_loss -0.9694\n",
            "2025-12-23 09:08:22.129628: val_loss -0.9815\n",
            "2025-12-23 09:08:22.129721: Pseudo dice [np.float32(0.9856)]\n",
            "2025-12-23 09:08:22.129814: Epoch time: 22.53 s\n",
            "2025-12-23 09:08:22.129890: Yayy! New best EMA pseudo Dice: 0.9840999841690063\n",
            "2025-12-23 09:08:24.476105: \n",
            "2025-12-23 09:08:24.476377: Epoch 139\n",
            "2025-12-23 09:08:24.476510: Current learning rate: 0.00874\n",
            "2025-12-23 09:08:47.061644: train_loss -0.9699\n",
            "2025-12-23 09:08:47.061845: val_loss -0.9792\n",
            "2025-12-23 09:08:47.061934: Pseudo dice [np.float32(0.9833)]\n",
            "2025-12-23 09:08:47.062023: Epoch time: 22.59 s\n",
            "2025-12-23 09:08:48.406085: \n",
            "2025-12-23 09:08:48.406411: Epoch 140\n",
            "2025-12-23 09:08:48.406545: Current learning rate: 0.00873\n",
            "2025-12-23 09:09:10.926080: train_loss -0.9691\n",
            "2025-12-23 09:09:10.926317: val_loss -0.9804\n",
            "2025-12-23 09:09:10.926553: Pseudo dice [np.float32(0.9854)]\n",
            "2025-12-23 09:09:10.926690: Epoch time: 22.52 s\n",
            "2025-12-23 09:09:10.926781: Yayy! New best EMA pseudo Dice: 0.9840999841690063\n",
            "2025-12-23 09:09:12.779493: \n",
            "2025-12-23 09:09:12.779798: Epoch 141\n",
            "2025-12-23 09:09:12.779939: Current learning rate: 0.00872\n",
            "2025-12-23 09:09:35.353382: train_loss -0.9695\n",
            "2025-12-23 09:09:35.353786: val_loss -0.9816\n",
            "2025-12-23 09:09:35.353918: Pseudo dice [np.float32(0.9866)]\n",
            "2025-12-23 09:09:35.354027: Epoch time: 22.58 s\n",
            "2025-12-23 09:09:35.354097: Yayy! New best EMA pseudo Dice: 0.9843999743461609\n",
            "2025-12-23 09:09:37.253451: \n",
            "2025-12-23 09:09:37.253715: Epoch 142\n",
            "2025-12-23 09:09:37.253849: Current learning rate: 0.00871\n",
            "2025-12-23 09:09:59.739893: train_loss -0.9694\n",
            "2025-12-23 09:09:59.740175: val_loss -0.9793\n",
            "2025-12-23 09:09:59.740319: Pseudo dice [np.float32(0.9844)]\n",
            "2025-12-23 09:09:59.740417: Epoch time: 22.49 s\n",
            "2025-12-23 09:09:59.740506: Yayy! New best EMA pseudo Dice: 0.9843999743461609\n",
            "2025-12-23 09:10:01.631444: \n",
            "2025-12-23 09:10:01.631747: Epoch 143\n",
            "2025-12-23 09:10:01.631891: Current learning rate: 0.0087\n",
            "2025-12-23 09:10:24.195266: train_loss -0.9706\n",
            "2025-12-23 09:10:24.195473: val_loss -0.9799\n",
            "2025-12-23 09:10:24.195564: Pseudo dice [np.float32(0.9851)]\n",
            "2025-12-23 09:10:24.195655: Epoch time: 22.57 s\n",
            "2025-12-23 09:10:24.195781: Yayy! New best EMA pseudo Dice: 0.984499990940094\n",
            "2025-12-23 09:10:26.102714: \n",
            "2025-12-23 09:10:26.103026: Epoch 144\n",
            "2025-12-23 09:10:26.103168: Current learning rate: 0.00869\n",
            "2025-12-23 09:10:48.569496: train_loss -0.9694\n",
            "2025-12-23 09:10:48.569714: val_loss -0.9796\n",
            "2025-12-23 09:10:48.569806: Pseudo dice [np.float32(0.9848)]\n",
            "2025-12-23 09:10:48.569899: Epoch time: 22.47 s\n",
            "2025-12-23 09:10:48.569973: Yayy! New best EMA pseudo Dice: 0.984499990940094\n",
            "2025-12-23 09:10:50.476206: \n",
            "2025-12-23 09:10:50.476564: Epoch 145\n",
            "2025-12-23 09:10:50.476723: Current learning rate: 0.00868\n",
            "2025-12-23 09:11:12.970712: train_loss -0.9705\n",
            "2025-12-23 09:11:12.970954: val_loss -0.9805\n",
            "2025-12-23 09:11:12.971043: Pseudo dice [np.float32(0.9849)]\n",
            "2025-12-23 09:11:12.971133: Epoch time: 22.5 s\n",
            "2025-12-23 09:11:12.971208: Yayy! New best EMA pseudo Dice: 0.984499990940094\n",
            "2025-12-23 09:11:14.875876: \n",
            "2025-12-23 09:11:14.876256: Epoch 146\n",
            "2025-12-23 09:11:14.876429: Current learning rate: 0.00868\n",
            "2025-12-23 09:11:37.379156: train_loss -0.9696\n",
            "2025-12-23 09:11:37.379424: val_loss -0.9797\n",
            "2025-12-23 09:11:37.379610: Pseudo dice [np.float32(0.984)]\n",
            "2025-12-23 09:11:37.379803: Epoch time: 22.5 s\n",
            "2025-12-23 09:11:38.737182: \n",
            "2025-12-23 09:11:38.737369: Epoch 147\n",
            "2025-12-23 09:11:38.737568: Current learning rate: 0.00867\n",
            "2025-12-23 09:12:01.166806: train_loss -0.9687\n",
            "2025-12-23 09:12:01.167167: val_loss -0.9783\n",
            "2025-12-23 09:12:01.167308: Pseudo dice [np.float32(0.9833)]\n",
            "2025-12-23 09:12:01.167419: Epoch time: 22.43 s\n",
            "2025-12-23 09:12:02.561322: \n",
            "2025-12-23 09:12:02.561636: Epoch 148\n",
            "2025-12-23 09:12:02.561819: Current learning rate: 0.00866\n",
            "2025-12-23 09:12:25.063099: train_loss -0.9678\n",
            "2025-12-23 09:12:25.063330: val_loss -0.9787\n",
            "2025-12-23 09:12:25.063423: Pseudo dice [np.float32(0.9829)]\n",
            "2025-12-23 09:12:25.063513: Epoch time: 22.5 s\n",
            "2025-12-23 09:12:26.404420: \n",
            "2025-12-23 09:12:26.404754: Epoch 149\n",
            "2025-12-23 09:12:26.404886: Current learning rate: 0.00865\n",
            "2025-12-23 09:12:48.933639: train_loss -0.9685\n",
            "2025-12-23 09:12:48.933969: val_loss -0.9777\n",
            "2025-12-23 09:12:48.934183: Pseudo dice [np.float32(0.9833)]\n",
            "2025-12-23 09:12:48.934375: Epoch time: 22.53 s\n",
            "2025-12-23 09:12:50.817632: \n",
            "2025-12-23 09:12:50.817922: Epoch 150\n",
            "2025-12-23 09:12:50.818066: Current learning rate: 0.00864\n",
            "2025-12-23 09:13:13.327074: train_loss -0.9694\n",
            "2025-12-23 09:13:13.327494: val_loss -0.9814\n",
            "2025-12-23 09:13:13.327609: Pseudo dice [np.float32(0.9866)]\n",
            "2025-12-23 09:13:13.327709: Epoch time: 22.51 s\n",
            "2025-12-23 09:13:15.149009: \n",
            "2025-12-23 09:13:15.149230: Epoch 151\n",
            "2025-12-23 09:13:15.149399: Current learning rate: 0.00863\n",
            "2025-12-23 09:13:37.689361: train_loss -0.9684\n",
            "2025-12-23 09:13:37.689654: val_loss -0.9806\n",
            "2025-12-23 09:13:37.689763: Pseudo dice [np.float32(0.9854)]\n",
            "2025-12-23 09:13:37.689858: Epoch time: 22.54 s\n",
            "2025-12-23 09:13:39.026363: \n",
            "2025-12-23 09:13:39.026688: Epoch 152\n",
            "2025-12-23 09:13:39.026819: Current learning rate: 0.00862\n",
            "2025-12-23 09:14:01.594439: train_loss -0.9698\n",
            "2025-12-23 09:14:01.594650: val_loss -0.9806\n",
            "2025-12-23 09:14:01.594743: Pseudo dice [np.float32(0.9856)]\n",
            "2025-12-23 09:14:01.594838: Epoch time: 22.57 s\n",
            "2025-12-23 09:14:01.594913: Yayy! New best EMA pseudo Dice: 0.9846000075340271\n",
            "2025-12-23 09:14:03.501666: \n",
            "2025-12-23 09:14:03.501950: Epoch 153\n",
            "2025-12-23 09:14:03.502084: Current learning rate: 0.00861\n",
            "2025-12-23 09:14:26.025079: train_loss -0.9694\n",
            "2025-12-23 09:14:26.025346: val_loss -0.9816\n",
            "2025-12-23 09:14:26.025530: Pseudo dice [np.float32(0.986)]\n",
            "2025-12-23 09:14:26.025634: Epoch time: 22.52 s\n",
            "2025-12-23 09:14:26.025723: Yayy! New best EMA pseudo Dice: 0.9847000241279602\n",
            "2025-12-23 09:14:27.888160: \n",
            "2025-12-23 09:14:27.888511: Epoch 154\n",
            "2025-12-23 09:14:27.888646: Current learning rate: 0.0086\n",
            "2025-12-23 09:14:50.411527: train_loss -0.9696\n",
            "2025-12-23 09:14:50.411736: val_loss -0.9806\n",
            "2025-12-23 09:14:50.411826: Pseudo dice [np.float32(0.9848)]\n",
            "2025-12-23 09:14:50.411917: Epoch time: 22.52 s\n",
            "2025-12-23 09:14:50.411994: Yayy! New best EMA pseudo Dice: 0.9847000241279602\n",
            "2025-12-23 09:14:52.303544: \n",
            "2025-12-23 09:14:52.303875: Epoch 155\n",
            "2025-12-23 09:14:52.304016: Current learning rate: 0.00859\n",
            "2025-12-23 09:15:14.795516: train_loss -0.9691\n",
            "2025-12-23 09:15:14.795788: val_loss -0.9803\n",
            "2025-12-23 09:15:14.795931: Pseudo dice [np.float32(0.9853)]\n",
            "2025-12-23 09:15:14.796052: Epoch time: 22.49 s\n",
            "2025-12-23 09:15:14.796159: Yayy! New best EMA pseudo Dice: 0.9847999811172485\n",
            "2025-12-23 09:15:16.692614: \n",
            "2025-12-23 09:15:16.692914: Epoch 156\n",
            "2025-12-23 09:15:16.693058: Current learning rate: 0.00858\n",
            "2025-12-23 09:15:39.201570: train_loss -0.9683\n",
            "2025-12-23 09:15:39.201800: val_loss -0.9762\n",
            "2025-12-23 09:15:39.201919: Pseudo dice [np.float32(0.9825)]\n",
            "2025-12-23 09:15:39.202036: Epoch time: 22.51 s\n",
            "2025-12-23 09:15:40.559832: \n",
            "2025-12-23 09:15:40.560170: Epoch 157\n",
            "2025-12-23 09:15:40.560327: Current learning rate: 0.00858\n",
            "2025-12-23 09:16:03.096315: train_loss -0.9685\n",
            "2025-12-23 09:16:03.096540: val_loss -0.9805\n",
            "2025-12-23 09:16:03.096631: Pseudo dice [np.float32(0.9852)]\n",
            "2025-12-23 09:16:03.096723: Epoch time: 22.54 s\n",
            "2025-12-23 09:16:04.492405: \n",
            "2025-12-23 09:16:04.492641: Epoch 158\n",
            "2025-12-23 09:16:04.492809: Current learning rate: 0.00857\n",
            "2025-12-23 09:16:27.024491: train_loss -0.9664\n",
            "2025-12-23 09:16:27.024701: val_loss -0.9796\n",
            "2025-12-23 09:16:27.024793: Pseudo dice [np.float32(0.9848)]\n",
            "2025-12-23 09:16:27.024886: Epoch time: 22.53 s\n",
            "2025-12-23 09:16:28.380060: \n",
            "2025-12-23 09:16:28.380293: Epoch 159\n",
            "2025-12-23 09:16:28.380430: Current learning rate: 0.00856\n",
            "2025-12-23 09:16:50.865743: train_loss -0.9667\n",
            "2025-12-23 09:16:50.866043: val_loss -0.9781\n",
            "2025-12-23 09:16:50.866205: Pseudo dice [np.float32(0.9839)]\n",
            "2025-12-23 09:16:50.866516: Epoch time: 22.49 s\n",
            "2025-12-23 09:16:52.243654: \n",
            "2025-12-23 09:16:52.243969: Epoch 160\n",
            "2025-12-23 09:16:52.244102: Current learning rate: 0.00855\n",
            "2025-12-23 09:17:14.747747: train_loss -0.9684\n",
            "2025-12-23 09:17:14.747950: val_loss -0.9783\n",
            "2025-12-23 09:17:14.748038: Pseudo dice [np.float32(0.9845)]\n",
            "2025-12-23 09:17:14.748129: Epoch time: 22.51 s\n",
            "2025-12-23 09:17:16.105079: \n",
            "2025-12-23 09:17:16.105294: Epoch 161\n",
            "2025-12-23 09:17:16.105431: Current learning rate: 0.00854\n",
            "2025-12-23 09:17:38.610264: train_loss -0.9671\n",
            "2025-12-23 09:17:38.610506: val_loss -0.9767\n",
            "2025-12-23 09:17:38.610596: Pseudo dice [np.float32(0.9812)]\n",
            "2025-12-23 09:17:38.610687: Epoch time: 22.51 s\n",
            "2025-12-23 09:17:39.990500: \n",
            "2025-12-23 09:17:39.990885: Epoch 162\n",
            "2025-12-23 09:17:39.991033: Current learning rate: 0.00853\n",
            "2025-12-23 09:18:02.515269: train_loss -0.9662\n",
            "2025-12-23 09:18:02.515604: val_loss -0.978\n",
            "2025-12-23 09:18:02.515754: Pseudo dice [np.float32(0.9842)]\n",
            "2025-12-23 09:18:02.515908: Epoch time: 22.53 s\n",
            "2025-12-23 09:18:03.885797: \n",
            "2025-12-23 09:18:03.886103: Epoch 163\n",
            "2025-12-23 09:18:03.886262: Current learning rate: 0.00852\n",
            "2025-12-23 09:18:26.338193: train_loss -0.968\n",
            "2025-12-23 09:18:26.338520: val_loss -0.9793\n",
            "2025-12-23 09:18:26.338717: Pseudo dice [np.float32(0.9849)]\n",
            "2025-12-23 09:18:26.338933: Epoch time: 22.45 s\n",
            "2025-12-23 09:18:27.701354: \n",
            "2025-12-23 09:18:27.701590: Epoch 164\n",
            "2025-12-23 09:18:27.701722: Current learning rate: 0.00851\n",
            "2025-12-23 09:18:50.202053: train_loss -0.9693\n",
            "2025-12-23 09:18:50.202336: val_loss -0.9799\n",
            "2025-12-23 09:18:50.202494: Pseudo dice [np.float32(0.9846)]\n",
            "2025-12-23 09:18:50.202597: Epoch time: 22.5 s\n",
            "2025-12-23 09:18:52.065532: \n",
            "2025-12-23 09:18:52.065859: Epoch 165\n",
            "2025-12-23 09:18:52.065997: Current learning rate: 0.0085\n",
            "2025-12-23 09:19:14.626838: train_loss -0.9664\n",
            "2025-12-23 09:19:14.627180: val_loss -0.9779\n",
            "2025-12-23 09:19:14.627313: Pseudo dice [np.float32(0.9824)]\n",
            "2025-12-23 09:19:14.627423: Epoch time: 22.56 s\n",
            "2025-12-23 09:19:16.015892: \n",
            "2025-12-23 09:19:16.016167: Epoch 166\n",
            "2025-12-23 09:19:16.016351: Current learning rate: 0.00849\n",
            "2025-12-23 09:19:38.528507: train_loss -0.969\n",
            "2025-12-23 09:19:38.528918: val_loss -0.9783\n",
            "2025-12-23 09:19:38.529013: Pseudo dice [np.float32(0.9826)]\n",
            "2025-12-23 09:19:38.529104: Epoch time: 22.51 s\n",
            "2025-12-23 09:19:39.912227: \n",
            "2025-12-23 09:19:39.912570: Epoch 167\n",
            "2025-12-23 09:19:39.912728: Current learning rate: 0.00848\n",
            "2025-12-23 09:20:02.461763: train_loss -0.9687\n",
            "2025-12-23 09:20:02.462006: val_loss -0.9794\n",
            "2025-12-23 09:20:02.462143: Pseudo dice [np.float32(0.984)]\n",
            "2025-12-23 09:20:02.462281: Epoch time: 22.55 s\n",
            "2025-12-23 09:20:03.864673: \n",
            "2025-12-23 09:20:03.865002: Epoch 168\n",
            "2025-12-23 09:20:03.865148: Current learning rate: 0.00847\n",
            "2025-12-23 09:20:26.394937: train_loss -0.9675\n",
            "2025-12-23 09:20:26.395235: val_loss -0.9786\n",
            "2025-12-23 09:20:26.395361: Pseudo dice [np.float32(0.9843)]\n",
            "2025-12-23 09:20:26.395461: Epoch time: 22.53 s\n",
            "2025-12-23 09:20:27.786452: \n",
            "2025-12-23 09:20:27.786739: Epoch 169\n",
            "2025-12-23 09:20:27.786881: Current learning rate: 0.00847\n",
            "2025-12-23 09:20:50.301069: train_loss -0.9672\n",
            "2025-12-23 09:20:50.301584: val_loss -0.9801\n",
            "2025-12-23 09:20:50.301773: Pseudo dice [np.float32(0.9855)]\n",
            "2025-12-23 09:20:50.301936: Epoch time: 22.52 s\n",
            "2025-12-23 09:20:51.709461: \n",
            "2025-12-23 09:20:51.709769: Epoch 170\n",
            "2025-12-23 09:20:51.709943: Current learning rate: 0.00846\n",
            "2025-12-23 09:21:14.264250: train_loss -0.9684\n",
            "2025-12-23 09:21:14.264614: val_loss -0.9783\n",
            "2025-12-23 09:21:14.264712: Pseudo dice [np.float32(0.9842)]\n",
            "2025-12-23 09:21:14.264821: Epoch time: 22.56 s\n",
            "2025-12-23 09:21:15.657316: \n",
            "2025-12-23 09:21:15.657662: Epoch 171\n",
            "2025-12-23 09:21:15.657799: Current learning rate: 0.00845\n",
            "2025-12-23 09:21:38.137013: train_loss -0.9687\n",
            "2025-12-23 09:21:38.137319: val_loss -0.9795\n",
            "2025-12-23 09:21:38.137436: Pseudo dice [np.float32(0.9848)]\n",
            "2025-12-23 09:21:38.137532: Epoch time: 22.48 s\n",
            "2025-12-23 09:21:39.504421: \n",
            "2025-12-23 09:21:39.504708: Epoch 172\n",
            "2025-12-23 09:21:39.504892: Current learning rate: 0.00844\n",
            "2025-12-23 09:22:02.023292: train_loss -0.9695\n",
            "2025-12-23 09:22:02.023479: val_loss -0.9799\n",
            "2025-12-23 09:22:02.023573: Pseudo dice [np.float32(0.9847)]\n",
            "2025-12-23 09:22:02.023666: Epoch time: 22.52 s\n",
            "2025-12-23 09:22:03.404882: \n",
            "2025-12-23 09:22:03.405198: Epoch 173\n",
            "2025-12-23 09:22:03.405362: Current learning rate: 0.00843\n",
            "2025-12-23 09:22:25.936653: train_loss -0.97\n",
            "2025-12-23 09:22:25.936868: val_loss -0.9806\n",
            "2025-12-23 09:22:25.936957: Pseudo dice [np.float32(0.9846)]\n",
            "2025-12-23 09:22:25.937081: Epoch time: 22.53 s\n",
            "2025-12-23 09:22:27.322687: \n",
            "2025-12-23 09:22:27.322930: Epoch 174\n",
            "2025-12-23 09:22:27.323081: Current learning rate: 0.00842\n",
            "2025-12-23 09:22:49.840744: train_loss -0.9712\n",
            "2025-12-23 09:22:49.840998: val_loss -0.9794\n",
            "2025-12-23 09:22:49.841175: Pseudo dice [np.float32(0.985)]\n",
            "2025-12-23 09:22:49.841317: Epoch time: 22.52 s\n",
            "2025-12-23 09:22:51.232290: \n",
            "2025-12-23 09:22:51.232648: Epoch 175\n",
            "2025-12-23 09:22:51.232807: Current learning rate: 0.00841\n",
            "2025-12-23 09:23:13.686627: train_loss -0.9677\n",
            "2025-12-23 09:23:13.686927: val_loss -0.9792\n",
            "2025-12-23 09:23:13.687026: Pseudo dice [np.float32(0.9849)]\n",
            "2025-12-23 09:23:13.687124: Epoch time: 22.46 s\n",
            "2025-12-23 09:23:15.051399: \n",
            "2025-12-23 09:23:15.051666: Epoch 176\n",
            "2025-12-23 09:23:15.051800: Current learning rate: 0.0084\n",
            "2025-12-23 09:23:37.586379: train_loss -0.9677\n",
            "2025-12-23 09:23:37.586596: val_loss -0.9781\n",
            "2025-12-23 09:23:37.586755: Pseudo dice [np.float32(0.983)]\n",
            "2025-12-23 09:23:37.586851: Epoch time: 22.54 s\n",
            "2025-12-23 09:23:38.971927: \n",
            "2025-12-23 09:23:38.972191: Epoch 177\n",
            "2025-12-23 09:23:38.972375: Current learning rate: 0.00839\n",
            "2025-12-23 09:24:01.467879: train_loss -0.9676\n",
            "2025-12-23 09:24:01.468365: val_loss -0.9795\n",
            "2025-12-23 09:24:01.468486: Pseudo dice [np.float32(0.9842)]\n",
            "2025-12-23 09:24:01.468576: Epoch time: 22.5 s\n",
            "2025-12-23 09:24:03.312461: \n",
            "2025-12-23 09:24:03.312809: Epoch 178\n",
            "2025-12-23 09:24:03.313004: Current learning rate: 0.00838\n",
            "2025-12-23 09:24:25.853782: train_loss -0.9657\n",
            "2025-12-23 09:24:25.854002: val_loss -0.9753\n",
            "2025-12-23 09:24:25.854089: Pseudo dice [np.float32(0.9809)]\n",
            "2025-12-23 09:24:25.854179: Epoch time: 22.54 s\n",
            "2025-12-23 09:24:27.215391: \n",
            "2025-12-23 09:24:27.215750: Epoch 179\n",
            "2025-12-23 09:24:27.215889: Current learning rate: 0.00837\n",
            "2025-12-23 09:24:49.841572: train_loss -0.9588\n",
            "2025-12-23 09:24:49.841939: val_loss -0.9731\n",
            "2025-12-23 09:24:49.842041: Pseudo dice [np.float32(0.9799)]\n",
            "2025-12-23 09:24:49.842143: Epoch time: 22.63 s\n",
            "2025-12-23 09:24:51.201204: \n",
            "2025-12-23 09:24:51.201575: Epoch 180\n",
            "2025-12-23 09:24:51.201720: Current learning rate: 0.00836\n",
            "2025-12-23 09:25:13.713877: train_loss -0.9618\n",
            "2025-12-23 09:25:13.714300: val_loss -0.9752\n",
            "2025-12-23 09:25:13.714498: Pseudo dice [np.float32(0.9818)]\n",
            "2025-12-23 09:25:13.714708: Epoch time: 22.51 s\n",
            "2025-12-23 09:25:15.082314: \n",
            "2025-12-23 09:25:15.082690: Epoch 181\n",
            "2025-12-23 09:25:15.082848: Current learning rate: 0.00836\n",
            "2025-12-23 09:25:37.599658: train_loss -0.9551\n",
            "2025-12-23 09:25:37.599874: val_loss -0.9706\n",
            "2025-12-23 09:25:37.599965: Pseudo dice [np.float32(0.9778)]\n",
            "2025-12-23 09:25:37.600057: Epoch time: 22.52 s\n",
            "2025-12-23 09:25:38.938274: \n",
            "2025-12-23 09:25:38.938557: Epoch 182\n",
            "2025-12-23 09:25:38.938692: Current learning rate: 0.00835\n",
            "2025-12-23 09:26:01.485331: train_loss -0.9575\n",
            "2025-12-23 09:26:01.485551: val_loss -0.9745\n",
            "2025-12-23 09:26:01.485706: Pseudo dice [np.float32(0.9817)]\n",
            "2025-12-23 09:26:01.485807: Epoch time: 22.55 s\n",
            "2025-12-23 09:26:02.858841: \n",
            "2025-12-23 09:26:02.859060: Epoch 183\n",
            "2025-12-23 09:26:02.859191: Current learning rate: 0.00834\n",
            "2025-12-23 09:26:25.378609: train_loss -0.962\n",
            "2025-12-23 09:26:25.378955: val_loss -0.9759\n",
            "2025-12-23 09:26:25.379050: Pseudo dice [np.float32(0.9822)]\n",
            "2025-12-23 09:26:25.379141: Epoch time: 22.52 s\n",
            "2025-12-23 09:26:26.742571: \n",
            "2025-12-23 09:26:26.742918: Epoch 184\n",
            "2025-12-23 09:26:26.743056: Current learning rate: 0.00833\n",
            "2025-12-23 09:26:49.274142: train_loss -0.9625\n",
            "2025-12-23 09:26:49.274393: val_loss -0.978\n",
            "2025-12-23 09:26:49.274499: Pseudo dice [np.float32(0.9827)]\n",
            "2025-12-23 09:26:49.274594: Epoch time: 22.53 s\n",
            "2025-12-23 09:26:50.629923: \n",
            "2025-12-23 09:26:50.630192: Epoch 185\n",
            "2025-12-23 09:26:50.630396: Current learning rate: 0.00832\n",
            "2025-12-23 09:27:13.144844: train_loss -0.9656\n",
            "2025-12-23 09:27:13.145062: val_loss -0.979\n",
            "2025-12-23 09:27:13.145151: Pseudo dice [np.float32(0.9853)]\n",
            "2025-12-23 09:27:13.145257: Epoch time: 22.52 s\n",
            "2025-12-23 09:27:14.523328: \n",
            "2025-12-23 09:27:14.523549: Epoch 186\n",
            "2025-12-23 09:27:14.523683: Current learning rate: 0.00831\n",
            "2025-12-23 09:27:37.024977: train_loss -0.9655\n",
            "2025-12-23 09:27:37.025331: val_loss -0.9779\n",
            "2025-12-23 09:27:37.025439: Pseudo dice [np.float32(0.9847)]\n",
            "2025-12-23 09:27:37.025533: Epoch time: 22.5 s\n",
            "2025-12-23 09:27:38.419202: \n",
            "2025-12-23 09:27:38.419489: Epoch 187\n",
            "2025-12-23 09:27:38.419746: Current learning rate: 0.0083\n",
            "2025-12-23 09:28:00.947625: train_loss -0.9618\n",
            "2025-12-23 09:28:00.947864: val_loss -0.9765\n",
            "2025-12-23 09:28:00.948044: Pseudo dice [np.float32(0.982)]\n",
            "2025-12-23 09:28:00.948163: Epoch time: 22.53 s\n",
            "2025-12-23 09:28:02.330529: \n",
            "2025-12-23 09:28:02.330736: Epoch 188\n",
            "2025-12-23 09:28:02.330880: Current learning rate: 0.00829\n",
            "2025-12-23 09:28:24.877188: train_loss -0.9661\n",
            "2025-12-23 09:28:24.877405: val_loss -0.9812\n",
            "2025-12-23 09:28:24.877489: Pseudo dice [np.float32(0.9861)]\n",
            "2025-12-23 09:28:24.877585: Epoch time: 22.55 s\n",
            "2025-12-23 09:28:26.214021: \n",
            "2025-12-23 09:28:26.214371: Epoch 189\n",
            "2025-12-23 09:28:26.214553: Current learning rate: 0.00828\n",
            "2025-12-23 09:28:48.718823: train_loss -0.9666\n",
            "2025-12-23 09:28:48.719022: val_loss -0.9803\n",
            "2025-12-23 09:28:48.719109: Pseudo dice [np.float32(0.9851)]\n",
            "2025-12-23 09:28:48.719278: Epoch time: 22.51 s\n",
            "2025-12-23 09:28:50.107296: \n",
            "2025-12-23 09:28:50.107633: Epoch 190\n",
            "2025-12-23 09:28:50.107791: Current learning rate: 0.00827\n",
            "2025-12-23 09:29:12.577601: train_loss -0.9674\n",
            "2025-12-23 09:29:12.577933: val_loss -0.9809\n",
            "2025-12-23 09:29:12.578042: Pseudo dice [np.float32(0.9868)]\n",
            "2025-12-23 09:29:12.578139: Epoch time: 22.47 s\n",
            "2025-12-23 09:29:14.453789: \n",
            "2025-12-23 09:29:14.454155: Epoch 191\n",
            "2025-12-23 09:29:14.454336: Current learning rate: 0.00826\n",
            "2025-12-23 09:29:37.056698: train_loss -0.9651\n",
            "2025-12-23 09:29:37.056914: val_loss -0.9785\n",
            "2025-12-23 09:29:37.057003: Pseudo dice [np.float32(0.9834)]\n",
            "2025-12-23 09:29:37.057109: Epoch time: 22.6 s\n",
            "2025-12-23 09:29:38.450449: \n",
            "2025-12-23 09:29:38.450826: Epoch 192\n",
            "2025-12-23 09:29:38.450979: Current learning rate: 0.00825\n",
            "2025-12-23 09:30:01.028082: train_loss -0.965\n",
            "2025-12-23 09:30:01.028452: val_loss -0.9743\n",
            "2025-12-23 09:30:01.028582: Pseudo dice [np.float32(0.9808)]\n",
            "2025-12-23 09:30:01.028713: Epoch time: 22.58 s\n",
            "2025-12-23 09:30:02.447697: \n",
            "2025-12-23 09:30:02.448067: Epoch 193\n",
            "2025-12-23 09:30:02.448235: Current learning rate: 0.00824\n",
            "2025-12-23 09:30:24.969349: train_loss -0.965\n",
            "2025-12-23 09:30:24.969556: val_loss -0.9778\n",
            "2025-12-23 09:30:24.969642: Pseudo dice [np.float32(0.983)]\n",
            "2025-12-23 09:30:24.969744: Epoch time: 22.52 s\n",
            "2025-12-23 09:30:26.331814: \n",
            "2025-12-23 09:30:26.332199: Epoch 194\n",
            "2025-12-23 09:30:26.332352: Current learning rate: 0.00824\n",
            "2025-12-23 09:30:48.932792: train_loss -0.9671\n",
            "2025-12-23 09:30:48.933180: val_loss -0.9778\n",
            "2025-12-23 09:30:48.933401: Pseudo dice [np.float32(0.9847)]\n",
            "2025-12-23 09:30:48.933520: Epoch time: 22.6 s\n",
            "2025-12-23 09:30:50.306718: \n",
            "2025-12-23 09:30:50.306932: Epoch 195\n",
            "2025-12-23 09:30:50.307060: Current learning rate: 0.00823\n",
            "2025-12-23 09:31:12.768588: train_loss -0.9686\n",
            "2025-12-23 09:31:12.768857: val_loss -0.9795\n",
            "2025-12-23 09:31:12.769004: Pseudo dice [np.float32(0.9837)]\n",
            "2025-12-23 09:31:12.769099: Epoch time: 22.46 s\n",
            "2025-12-23 09:31:14.150163: \n",
            "2025-12-23 09:31:14.150554: Epoch 196\n",
            "2025-12-23 09:31:14.150730: Current learning rate: 0.00822\n",
            "2025-12-23 09:31:36.664303: train_loss -0.9689\n",
            "2025-12-23 09:31:36.664643: val_loss -0.9776\n",
            "2025-12-23 09:31:36.664800: Pseudo dice [np.float32(0.9842)]\n",
            "2025-12-23 09:31:36.664906: Epoch time: 22.52 s\n",
            "2025-12-23 09:31:38.043940: \n",
            "2025-12-23 09:31:38.044228: Epoch 197\n",
            "2025-12-23 09:31:38.044366: Current learning rate: 0.00821\n",
            "2025-12-23 09:32:00.596848: train_loss -0.9679\n",
            "2025-12-23 09:32:00.597138: val_loss -0.9774\n",
            "2025-12-23 09:32:00.597361: Pseudo dice [np.float32(0.9827)]\n",
            "2025-12-23 09:32:00.597653: Epoch time: 22.55 s\n",
            "2025-12-23 09:32:02.007617: \n",
            "2025-12-23 09:32:02.007927: Epoch 198\n",
            "2025-12-23 09:32:02.008065: Current learning rate: 0.0082\n",
            "2025-12-23 09:32:24.551472: train_loss -0.968\n",
            "2025-12-23 09:32:24.551754: val_loss -0.9788\n",
            "2025-12-23 09:32:24.552033: Pseudo dice [np.float32(0.9828)]\n",
            "2025-12-23 09:32:24.552361: Epoch time: 22.55 s\n",
            "2025-12-23 09:32:25.950613: \n",
            "2025-12-23 09:32:25.950784: Epoch 199\n",
            "2025-12-23 09:32:25.950919: Current learning rate: 0.00819\n",
            "2025-12-23 09:32:48.438909: train_loss -0.9679\n",
            "2025-12-23 09:32:48.439274: val_loss -0.978\n",
            "2025-12-23 09:32:48.439387: Pseudo dice [np.float32(0.9828)]\n",
            "2025-12-23 09:32:48.439480: Epoch time: 22.49 s\n",
            "2025-12-23 09:32:50.342723: \n",
            "2025-12-23 09:32:50.342967: Epoch 200\n",
            "2025-12-23 09:32:50.343168: Current learning rate: 0.00818\n",
            "2025-12-23 09:33:12.896641: train_loss -0.9653\n",
            "2025-12-23 09:33:12.896877: val_loss -0.9738\n",
            "2025-12-23 09:33:12.896965: Pseudo dice [np.float32(0.981)]\n",
            "2025-12-23 09:33:12.897053: Epoch time: 22.56 s\n",
            "2025-12-23 09:33:14.304299: \n",
            "2025-12-23 09:33:14.304610: Epoch 201\n",
            "2025-12-23 09:33:14.304742: Current learning rate: 0.00817\n",
            "2025-12-23 09:33:36.795967: train_loss -0.9452\n",
            "2025-12-23 09:33:36.796180: val_loss -0.9715\n",
            "2025-12-23 09:33:36.796309: Pseudo dice [np.float32(0.9782)]\n",
            "2025-12-23 09:33:36.796416: Epoch time: 22.49 s\n",
            "2025-12-23 09:33:38.199241: \n",
            "2025-12-23 09:33:38.199568: Epoch 202\n",
            "2025-12-23 09:33:38.199710: Current learning rate: 0.00816\n",
            "2025-12-23 09:34:00.702095: train_loss -0.9533\n",
            "2025-12-23 09:34:00.702526: val_loss -0.9744\n",
            "2025-12-23 09:34:00.702775: Pseudo dice [np.float32(0.9781)]\n",
            "2025-12-23 09:34:00.702946: Epoch time: 22.5 s\n",
            "2025-12-23 09:34:02.112047: \n",
            "2025-12-23 09:34:02.112253: Epoch 203\n",
            "2025-12-23 09:34:02.112386: Current learning rate: 0.00815\n",
            "2025-12-23 09:34:24.556904: train_loss -0.9592\n",
            "2025-12-23 09:34:24.557267: val_loss -0.9766\n",
            "2025-12-23 09:34:24.557390: Pseudo dice [np.float32(0.9823)]\n",
            "2025-12-23 09:34:24.557544: Epoch time: 22.45 s\n",
            "2025-12-23 09:34:26.487042: \n",
            "2025-12-23 09:34:26.487439: Epoch 204\n",
            "2025-12-23 09:34:26.487613: Current learning rate: 0.00814\n",
            "2025-12-23 09:34:49.035924: train_loss -0.9626\n",
            "2025-12-23 09:34:49.036275: val_loss -0.9737\n",
            "2025-12-23 09:34:49.036401: Pseudo dice [np.float32(0.9818)]\n",
            "2025-12-23 09:34:49.036539: Epoch time: 22.55 s\n",
            "2025-12-23 09:34:50.457017: \n",
            "2025-12-23 09:34:50.457367: Epoch 205\n",
            "2025-12-23 09:34:50.457523: Current learning rate: 0.00813\n",
            "2025-12-23 09:35:12.942652: train_loss -0.9607\n",
            "2025-12-23 09:35:12.942887: val_loss -0.9768\n",
            "2025-12-23 09:35:12.942989: Pseudo dice [np.float32(0.9832)]\n",
            "2025-12-23 09:35:12.943080: Epoch time: 22.49 s\n",
            "2025-12-23 09:35:14.292463: \n",
            "2025-12-23 09:35:14.292629: Epoch 206\n",
            "2025-12-23 09:35:14.292758: Current learning rate: 0.00813\n",
            "2025-12-23 09:35:36.756894: train_loss -0.9619\n",
            "2025-12-23 09:35:36.757154: val_loss -0.9769\n",
            "2025-12-23 09:35:36.757282: Pseudo dice [np.float32(0.9825)]\n",
            "2025-12-23 09:35:36.757399: Epoch time: 22.47 s\n",
            "2025-12-23 09:35:38.114379: \n",
            "2025-12-23 09:35:38.114740: Epoch 207\n",
            "2025-12-23 09:35:38.114947: Current learning rate: 0.00812\n",
            "2025-12-23 09:36:00.589805: train_loss -0.9563\n",
            "2025-12-23 09:36:00.590098: val_loss -0.9747\n",
            "2025-12-23 09:36:00.590303: Pseudo dice [np.float32(0.9809)]\n",
            "2025-12-23 09:36:00.590420: Epoch time: 22.48 s\n",
            "2025-12-23 09:36:01.932453: \n",
            "2025-12-23 09:36:01.932791: Epoch 208\n",
            "2025-12-23 09:36:01.932953: Current learning rate: 0.00811\n",
            "2025-12-23 09:36:24.351446: train_loss -0.9582\n",
            "2025-12-23 09:36:24.351725: val_loss -0.9772\n",
            "2025-12-23 09:36:24.351954: Pseudo dice [np.float32(0.9827)]\n",
            "2025-12-23 09:36:24.352060: Epoch time: 22.42 s\n",
            "2025-12-23 09:36:25.677163: \n",
            "2025-12-23 09:36:25.677435: Epoch 209\n",
            "2025-12-23 09:36:25.677606: Current learning rate: 0.0081\n",
            "2025-12-23 09:36:48.144355: train_loss -0.9627\n",
            "2025-12-23 09:36:48.144617: val_loss -0.9769\n",
            "2025-12-23 09:36:48.144782: Pseudo dice [np.float32(0.9821)]\n",
            "2025-12-23 09:36:48.144897: Epoch time: 22.47 s\n",
            "2025-12-23 09:36:49.477784: \n",
            "2025-12-23 09:36:49.478048: Epoch 210\n",
            "2025-12-23 09:36:49.478185: Current learning rate: 0.00809\n",
            "2025-12-23 09:37:11.926905: train_loss -0.9628\n",
            "2025-12-23 09:37:11.927377: val_loss -0.976\n",
            "2025-12-23 09:37:11.927605: Pseudo dice [np.float32(0.9826)]\n",
            "2025-12-23 09:37:11.927759: Epoch time: 22.45 s\n",
            "2025-12-23 09:37:13.275597: \n",
            "2025-12-23 09:37:13.275830: Epoch 211\n",
            "2025-12-23 09:37:13.275966: Current learning rate: 0.00808\n",
            "2025-12-23 09:37:35.815541: train_loss -0.9635\n",
            "2025-12-23 09:37:35.815779: val_loss -0.9765\n",
            "2025-12-23 09:37:35.815873: Pseudo dice [np.float32(0.9816)]\n",
            "2025-12-23 09:37:35.815975: Epoch time: 22.54 s\n",
            "2025-12-23 09:37:37.168675: \n",
            "2025-12-23 09:37:37.169004: Epoch 212\n",
            "2025-12-23 09:37:37.169171: Current learning rate: 0.00807\n",
            "2025-12-23 09:37:59.672791: train_loss -0.9662\n",
            "2025-12-23 09:37:59.673001: val_loss -0.9803\n",
            "2025-12-23 09:37:59.673089: Pseudo dice [np.float32(0.9854)]\n",
            "2025-12-23 09:37:59.673193: Epoch time: 22.51 s\n",
            "2025-12-23 09:38:00.995018: \n",
            "2025-12-23 09:38:00.995306: Epoch 213\n",
            "2025-12-23 09:38:00.995461: Current learning rate: 0.00806\n",
            "2025-12-23 09:38:23.440007: train_loss -0.9677\n",
            "2025-12-23 09:38:23.440252: val_loss -0.9781\n",
            "2025-12-23 09:38:23.440369: Pseudo dice [np.float32(0.9837)]\n",
            "2025-12-23 09:38:23.440472: Epoch time: 22.45 s\n",
            "2025-12-23 09:38:24.790118: \n",
            "2025-12-23 09:38:24.790333: Epoch 214\n",
            "2025-12-23 09:38:24.790462: Current learning rate: 0.00805\n",
            "2025-12-23 09:38:47.244159: train_loss -0.9647\n",
            "2025-12-23 09:38:47.244398: val_loss -0.9779\n",
            "2025-12-23 09:38:47.244499: Pseudo dice [np.float32(0.9832)]\n",
            "2025-12-23 09:38:47.244592: Epoch time: 22.46 s\n",
            "2025-12-23 09:38:48.559057: \n",
            "2025-12-23 09:38:48.559398: Epoch 215\n",
            "2025-12-23 09:38:48.559583: Current learning rate: 0.00804\n",
            "2025-12-23 09:39:11.011147: train_loss -0.9634\n",
            "2025-12-23 09:39:11.011381: val_loss -0.9773\n",
            "2025-12-23 09:39:11.011483: Pseudo dice [np.float32(0.9817)]\n",
            "2025-12-23 09:39:11.011576: Epoch time: 22.45 s\n",
            "2025-12-23 09:39:12.359210: \n",
            "2025-12-23 09:39:12.359510: Epoch 216\n",
            "2025-12-23 09:39:12.359642: Current learning rate: 0.00803\n",
            "2025-12-23 09:39:34.833374: train_loss -0.9654\n",
            "2025-12-23 09:39:34.833590: val_loss -0.9784\n",
            "2025-12-23 09:39:34.833679: Pseudo dice [np.float32(0.9836)]\n",
            "2025-12-23 09:39:34.833783: Epoch time: 22.48 s\n",
            "2025-12-23 09:39:36.178276: \n",
            "2025-12-23 09:39:36.178564: Epoch 217\n",
            "2025-12-23 09:39:36.178706: Current learning rate: 0.00802\n",
            "2025-12-23 09:39:58.632699: train_loss -0.9654\n",
            "2025-12-23 09:39:58.632917: val_loss -0.9771\n",
            "2025-12-23 09:39:58.633030: Pseudo dice [np.float32(0.9827)]\n",
            "2025-12-23 09:39:58.633151: Epoch time: 22.46 s\n",
            "2025-12-23 09:40:00.457249: \n",
            "2025-12-23 09:40:00.457556: Epoch 218\n",
            "2025-12-23 09:40:00.457703: Current learning rate: 0.00801\n",
            "2025-12-23 09:40:22.975880: train_loss -0.9615\n",
            "2025-12-23 09:40:22.976153: val_loss -0.9715\n",
            "2025-12-23 09:40:22.976279: Pseudo dice [np.float32(0.977)]\n",
            "2025-12-23 09:40:22.976400: Epoch time: 22.52 s\n",
            "2025-12-23 09:40:24.319559: \n",
            "2025-12-23 09:40:24.320004: Epoch 219\n",
            "2025-12-23 09:40:24.320187: Current learning rate: 0.00801\n",
            "2025-12-23 09:40:46.867878: train_loss -0.9581\n",
            "2025-12-23 09:40:46.868124: val_loss -0.9754\n",
            "2025-12-23 09:40:46.868231: Pseudo dice [np.float32(0.9815)]\n",
            "2025-12-23 09:40:46.868328: Epoch time: 22.55 s\n",
            "2025-12-23 09:40:48.215336: \n",
            "2025-12-23 09:40:48.215586: Epoch 220\n",
            "2025-12-23 09:40:48.215715: Current learning rate: 0.008\n",
            "2025-12-23 09:41:10.753124: train_loss -0.962\n",
            "2025-12-23 09:41:10.753374: val_loss -0.9734\n",
            "2025-12-23 09:41:10.753525: Pseudo dice [np.float32(0.9791)]\n",
            "2025-12-23 09:41:10.753650: Epoch time: 22.54 s\n",
            "2025-12-23 09:41:12.087633: \n",
            "2025-12-23 09:41:12.087871: Epoch 221\n",
            "2025-12-23 09:41:12.088025: Current learning rate: 0.00799\n",
            "2025-12-23 09:41:34.609529: train_loss -0.9616\n",
            "2025-12-23 09:41:34.609733: val_loss -0.9741\n",
            "2025-12-23 09:41:34.609823: Pseudo dice [np.float32(0.9813)]\n",
            "2025-12-23 09:41:34.609913: Epoch time: 22.52 s\n",
            "2025-12-23 09:41:35.925735: \n",
            "2025-12-23 09:41:35.925941: Epoch 222\n",
            "2025-12-23 09:41:35.926068: Current learning rate: 0.00798\n",
            "2025-12-23 09:41:58.388165: train_loss -0.9597\n",
            "2025-12-23 09:41:58.388461: val_loss -0.9743\n",
            "2025-12-23 09:41:58.388561: Pseudo dice [np.float32(0.9791)]\n",
            "2025-12-23 09:41:58.388652: Epoch time: 22.46 s\n",
            "2025-12-23 09:41:59.698192: \n",
            "2025-12-23 09:41:59.698632: Epoch 223\n",
            "2025-12-23 09:41:59.698780: Current learning rate: 0.00797\n",
            "2025-12-23 09:42:22.284515: train_loss -0.9614\n",
            "2025-12-23 09:42:22.284863: val_loss -0.9726\n",
            "2025-12-23 09:42:22.284973: Pseudo dice [np.float32(0.979)]\n",
            "2025-12-23 09:42:22.285066: Epoch time: 22.59 s\n",
            "2025-12-23 09:42:23.611643: \n",
            "2025-12-23 09:42:23.612016: Epoch 224\n",
            "2025-12-23 09:42:23.612152: Current learning rate: 0.00796\n",
            "2025-12-23 09:42:46.106112: train_loss -0.956\n",
            "2025-12-23 09:42:46.106481: val_loss -0.9758\n",
            "2025-12-23 09:42:46.106712: Pseudo dice [np.float32(0.9827)]\n",
            "2025-12-23 09:42:46.106900: Epoch time: 22.5 s\n",
            "2025-12-23 09:42:47.458883: \n",
            "2025-12-23 09:42:47.459237: Epoch 225\n",
            "2025-12-23 09:42:47.459415: Current learning rate: 0.00795\n",
            "2025-12-23 09:43:09.983888: train_loss -0.9641\n",
            "2025-12-23 09:43:09.984157: val_loss -0.974\n",
            "2025-12-23 09:43:09.984292: Pseudo dice [np.float32(0.9779)]\n",
            "2025-12-23 09:43:09.984434: Epoch time: 22.53 s\n",
            "2025-12-23 09:43:11.329535: \n",
            "2025-12-23 09:43:11.329798: Epoch 226\n",
            "2025-12-23 09:43:11.329933: Current learning rate: 0.00794\n",
            "2025-12-23 09:43:33.825376: train_loss -0.9644\n",
            "2025-12-23 09:43:33.825612: val_loss -0.9769\n",
            "2025-12-23 09:43:33.825703: Pseudo dice [np.float32(0.984)]\n",
            "2025-12-23 09:43:33.825792: Epoch time: 22.5 s\n",
            "2025-12-23 09:43:35.131153: \n",
            "2025-12-23 09:43:35.131491: Epoch 227\n",
            "2025-12-23 09:43:35.131630: Current learning rate: 0.00793\n",
            "2025-12-23 09:43:57.647147: train_loss -0.9636\n",
            "2025-12-23 09:43:57.647461: val_loss -0.9783\n",
            "2025-12-23 09:43:57.647579: Pseudo dice [np.float32(0.9825)]\n",
            "2025-12-23 09:43:57.647702: Epoch time: 22.52 s\n",
            "2025-12-23 09:43:58.997996: \n",
            "2025-12-23 09:43:58.998309: Epoch 228\n",
            "2025-12-23 09:43:58.998487: Current learning rate: 0.00792\n",
            "2025-12-23 09:44:21.509034: train_loss -0.9671\n",
            "2025-12-23 09:44:21.509297: val_loss -0.9791\n",
            "2025-12-23 09:44:21.509411: Pseudo dice [np.float32(0.9835)]\n",
            "2025-12-23 09:44:21.509531: Epoch time: 22.51 s\n",
            "2025-12-23 09:44:22.854083: \n",
            "2025-12-23 09:44:22.854430: Epoch 229\n",
            "2025-12-23 09:44:22.854569: Current learning rate: 0.00791\n",
            "2025-12-23 09:44:45.375901: train_loss -0.9662\n",
            "2025-12-23 09:44:45.376163: val_loss -0.9786\n",
            "2025-12-23 09:44:45.376281: Pseudo dice [np.float32(0.9833)]\n",
            "2025-12-23 09:44:45.376388: Epoch time: 22.52 s\n",
            "2025-12-23 09:44:46.710846: \n",
            "2025-12-23 09:44:46.711109: Epoch 230\n",
            "2025-12-23 09:44:46.711300: Current learning rate: 0.0079\n",
            "2025-12-23 09:45:09.227508: train_loss -0.9684\n",
            "2025-12-23 09:45:09.227826: val_loss -0.9814\n",
            "2025-12-23 09:45:09.227981: Pseudo dice [np.float32(0.9868)]\n",
            "2025-12-23 09:45:09.228205: Epoch time: 22.52 s\n",
            "2025-12-23 09:45:10.556753: \n",
            "2025-12-23 09:45:10.557060: Epoch 231\n",
            "2025-12-23 09:45:10.557204: Current learning rate: 0.00789\n",
            "2025-12-23 09:45:33.077802: train_loss -0.9693\n",
            "2025-12-23 09:45:33.078139: val_loss -0.9798\n",
            "2025-12-23 09:45:33.078266: Pseudo dice [np.float32(0.9855)]\n",
            "2025-12-23 09:45:33.078406: Epoch time: 22.52 s\n",
            "2025-12-23 09:45:34.845760: \n",
            "2025-12-23 09:45:34.845988: Epoch 232\n",
            "2025-12-23 09:45:34.846117: Current learning rate: 0.00789\n",
            "2025-12-23 09:45:57.391069: train_loss -0.9691\n",
            "2025-12-23 09:45:57.391339: val_loss -0.9812\n",
            "2025-12-23 09:45:57.391447: Pseudo dice [np.float32(0.9856)]\n",
            "2025-12-23 09:45:57.391543: Epoch time: 22.55 s\n",
            "2025-12-23 09:45:58.678200: \n",
            "2025-12-23 09:45:58.678543: Epoch 233\n",
            "2025-12-23 09:45:58.678682: Current learning rate: 0.00788\n",
            "2025-12-23 09:46:21.246093: train_loss -0.9683\n",
            "2025-12-23 09:46:21.246371: val_loss -0.9801\n",
            "2025-12-23 09:46:21.246592: Pseudo dice [np.float32(0.9852)]\n",
            "2025-12-23 09:46:21.246736: Epoch time: 22.57 s\n",
            "2025-12-23 09:46:22.553844: \n",
            "2025-12-23 09:46:22.554173: Epoch 234\n",
            "2025-12-23 09:46:22.554424: Current learning rate: 0.00787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "65ioojzsQGHu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the most of your colab subscription",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}